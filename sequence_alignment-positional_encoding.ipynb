{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf912ca6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f85dd40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import numpy as np\n",
    "import linecache #fast access to a specific file line\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from einops import rearrange, repeat\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import torchinfo\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9bab698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.11.0\n",
      "11.1\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1eac7b6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "453df495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': 0, 'R': 1, 'N': 2, 'D': 3, 'C': 4, 'Q': 5, 'E': 6, 'G': 7, 'H': 8, 'I': 9, 'L': 10, 'K': 11, 'M': 12, 'F': 13, 'P': 14, 'S': 15, 'T': 16, 'W': 17, 'Y': 18, 'V': 19, '-': 20, 'Z': 21}\n"
     ]
    }
   ],
   "source": [
    "ALPHABET = [\"A\", \"R\", \"N\", \"D\", \"C\", \"Q\", \"E\", \"G\", \"H\", \"I\",\n",
    "            \"L\", \"K\", \"M\", \"F\", \"P\", \"S\", \"T\", \"W\", \"Y\", \"V\"]\n",
    "\n",
    "ALPHABET = {ALPHABET[i]:i for i in range(len(ALPHABET))}\n",
    "\n",
    "ALPHABET['-']= 20\n",
    "ALPHABET['Z']= 21\n",
    "\n",
    "print(ALPHABET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "475e513f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data_dir, cont_size=6,div=1400000,verbose=False):\n",
    "        \n",
    "        self.col_size = 60 #number of column per file (Fasta standard)\n",
    "        self.data_dir = data_dir #directory of the dataset\n",
    "        self.cont_size = cont_size\n",
    "        self.div = div\n",
    "        self.len = 0  #number of families of sequences (1 per file)\n",
    "        self.paths = {} #path of each families in the folder\n",
    "        self.seq_lens = {} #length of each member of the family\n",
    "        self.seq_nums = {} #number of member of the family\n",
    "        self.aa_freqs = {} #frequencies of each symbol in the sequence family\n",
    "        self.p_aa_freqs = {} #frequencies of each symbol in each sequence of a family\n",
    "        \n",
    "        \n",
    "        dir_path = data_dir\n",
    "        count = 0\n",
    "        \n",
    "        # Iterate directory\n",
    "        for path in os.listdir(dir_path):\n",
    "            # check if current path is a file\n",
    "            temp_path = os.path.join(dir_path, path)\n",
    "            if os.path.isfile(temp_path):\n",
    "                n = 0 #number of sequences\n",
    "                p = 0 # used to calculate the length of the sequences\n",
    "                r = 0 # also used this way\n",
    "\n",
    "                l = 0 # length of the seq l = p * self.col_size + r \n",
    "\n",
    "                cpt = 0 # to detect inconsistencies\n",
    "                \n",
    "                with open(temp_path, newline='') as f:\n",
    "                    first_prot = True\n",
    "                    newf = True\n",
    "                    \n",
    "                    aa_freq = torch.zeros(20)\n",
    "                    p_aa_freq = torch.zeros(0)\n",
    "                    \n",
    "                    #parsing the file\n",
    "                    line = f.readline()[:-1]\n",
    "                    while line:\n",
    "                        cpt += 1\n",
    "                        if line[0] == '>': #header line\n",
    "                            if not first_prot:\n",
    "                                p_aa_freq = torch.cat([p_aa_freq,prot_aa_freq])\n",
    "                            prot_aa_freq = torch.zeros(1,20)\n",
    "                            n += 1\n",
    "                            if newf and not first_prot:\n",
    "                                newf = False\n",
    "                            first_prot = False\n",
    "                                \n",
    "                        else:# sequence line\n",
    "                            if newf and len(line) == self.col_size:\n",
    "                                p += 1\n",
    "\n",
    "                            if newf and len(line) != self.col_size:\n",
    "                                r = len(line)\n",
    "                            for aa in line:\n",
    "                                aa_id = ALPHABET.get(aa,21)\n",
    "                                if aa_id < 20:\n",
    "                                    aa_freq[aa_id] += 1\n",
    "                                    prot_aa_freq[0][aa_id] += 1\n",
    "\n",
    "                            assert len(line) == self.col_size or len(line) == r\n",
    "                        line = f.readline()[:-1]\n",
    "                    \n",
    "                    p_aa_freq = torch.cat([p_aa_freq,prot_aa_freq])\n",
    "                    aa_freq = F.normalize(aa_freq,dim=0,p=1)\n",
    "                    p_aa_freq = F.normalize(p_aa_freq,dim=1,p=1)\n",
    "\n",
    "                l = p*self.col_size + r\n",
    "                \n",
    "                #sanity check\n",
    "                #if the file line count is coherent with the number of sequences and their line count\n",
    "                try: #if r != 0\n",
    "                    assert (p+2) * n == cpt\n",
    "                except: #if r == 0\n",
    "                    assert (p+1) * n == cpt\n",
    "                    assert r == 0\n",
    "                    \n",
    "                \n",
    "                if n>1: #if this is false, we can't find pairs\n",
    "                    self.paths[count] = path\n",
    "                    self.seq_lens[count] = l\n",
    "                    self.seq_nums[count] = n\n",
    "                    self.aa_freqs[count] = aa_freq\n",
    "                    self.p_aa_freqs[count] = p_aa_freq\n",
    "                    count += 1\n",
    "                    \n",
    "                    if verbose and (count % 100 ==0) : print(f\"seen = {count}\")\n",
    "            \n",
    "        self.len = count\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "     \n",
    "    def sample(self, high, low=0, s=1):\n",
    "        sample = np.random.choice(high-low, s, replace=False)\n",
    "        return sample + low\n",
    "    \n",
    "    def __getitem__(self, idx, sample_size='auto'): \n",
    "        #for each sample:\n",
    "        #sample i, j st i != j the two sequences to compare\n",
    "        #sample k the sequence position of the prediction\n",
    "        #compute the file positions of the 25 + 1 AA\n",
    "        \n",
    "        X = []\n",
    "        y = []\n",
    "        \n",
    "        PIDs = []\n",
    "        local_PIDs = []\n",
    "        \n",
    "        pfreqs = []\n",
    "        local_pfreqs = []\n",
    "        \n",
    "        lengths = []\n",
    "        \n",
    "        pos = []\n",
    "        \n",
    "        \n",
    "        precomputed_pos = []\n",
    "        for i in range(-self.cont_size,self.cont_size+1):\n",
    "            precomputed_pos.append(i)\n",
    "        for i in range(-self.cont_size,0):\n",
    "            precomputed_pos.append(i)\n",
    "        for i in range(1,self.cont_size+1):\n",
    "            precomputed_pos.append(i)\n",
    "        \n",
    "        precomputed_pos = torch.tensor(precomputed_pos).float()\n",
    "        \n",
    "        data_path = os.path.join(self.data_dir, self.paths[idx])\n",
    "        try:\n",
    "            n = self.seq_nums[idx]\n",
    "            l = self.seq_lens[idx]\n",
    "        except:\n",
    "            print(idx)\n",
    "            pass\n",
    "        \n",
    "        if type(sample_size) != int:\n",
    "            coef = round((n**2 * l)/self.div) \n",
    "            sample_size = max(1,coef)\n",
    "        \n",
    "        p = l // self.col_size\n",
    "        r = l % self.col_size # l = p * q + r\n",
    "        sequence_line_count = p+2 if r else p+1\n",
    "\n",
    "\n",
    "        for _ in range(sample_size):\n",
    "            i,j = self.sample(n,s=2)\n",
    "\n",
    "            start_i = 2 + (sequence_line_count)*i #start line of protein i\n",
    "            start_j = 2 + (sequence_line_count)*j #start line of protein j\n",
    "            \n",
    "            seq_i = ''\n",
    "            seq_j = ''\n",
    "            \n",
    "            PID_ij = 0\n",
    "            \n",
    "            l_ij = 0\n",
    "            for offset in range(sequence_line_count-1):\n",
    "                line_i = linecache.getline(data_path, (start_i + offset))[:-1]\n",
    "                line_j = linecache.getline(data_path, (start_j + offset))[:-1]\n",
    "                for aa_i, aa_j in zip(line_i,line_j):\n",
    "                    if aa_i == aa_j:\n",
    "                        if aa_i != '-':\n",
    "                            PID_ij += 1\n",
    "                            seq_i += aa_i\n",
    "                            seq_j += aa_j        \n",
    "                    else:\n",
    "                        seq_i += aa_i\n",
    "                        seq_j += aa_j\n",
    "                    \n",
    "                    if aa_i != '-' and aa_j != '-':\n",
    "                        l_ij += 1\n",
    "            \n",
    "            try:\n",
    "                PID_ij = PID_ij/l_ij\n",
    "            except:\n",
    "                PID_ij = 0\n",
    "            \n",
    "            align_l = len(seq_i)\n",
    "            possible_k = []\n",
    "            for k,(a_i,a_j) in enumerate(zip(seq_i,seq_j)):   \n",
    "                if ALPHABET.get(a_i,21) < 20 and ALPHABET.get(a_j,21) < 20:\n",
    "                    possible_k.append(k)\n",
    "                    \n",
    "            try:   \n",
    "                k = np.random.choice(possible_k)\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "            lengths.append(align_l)\n",
    "            pos_ij = (k + precomputed_pos)\n",
    "            pos.append(pos_ij)\n",
    "            \n",
    "            window_i = ''\n",
    "            window_j = ''\n",
    "            \n",
    "            for w in range(k-self.cont_size,k+self.cont_size+1):\n",
    "                if w < 0 or w >= align_l: #case of the edges\n",
    "                    window_i += 'Z'\n",
    "                    window_j += 'Z'\n",
    "                else:\n",
    "                    window_i += seq_i[w]\n",
    "                    window_j += seq_j[w]\n",
    "        \n",
    "            y_j = ALPHABET.get(window_j[self.cont_size], 21) # 'Z' is the default value for rare AA\n",
    "            X_i = [ALPHABET.get(i, 21) for i in (window_i+window_j[:self.cont_size]+window_j[self.cont_size+1:])]       \n",
    "            \n",
    "            X.append(X_i)\n",
    "            y.append(y_j)\n",
    "            PIDs.append(PID_ij)\n",
    "            local_PID_ij = sum(1 for AA1,AA2 in zip(window_i, window_j[:self.cont_size]) if AA1 == AA2 and ALPHABET.get(AA1,21) < 20) \\\n",
    "                         + sum(1 for AA1,AA2 in zip(reversed(window_i), reversed(window_j[self.cont_size+1:])) if AA1 == AA2 and ALPHABET.get(AA1,21) < 20)\n",
    "            \n",
    "            loc_comp = sum(1 for AA1,AA2 in zip(window_i, window_j[:self.cont_size]) if ALPHABET.get(AA1,21) < 20 and ALPHABET.get(AA2,21) < 20) \\\n",
    "                         + sum(1 for AA1,AA2 in zip(reversed(window_i), reversed(window_j[self.cont_size+1:])) if ALPHABET.get(AA1,21) < 20 and ALPHABET.get(AA2,21) < 20)\n",
    "            try:\n",
    "                tmp = local_PID_ij/loc_comp\n",
    "            except:\n",
    "                tmp = 0\n",
    "                \n",
    "            local_PIDs.append(tmp)\n",
    "            pfreqs.append(self.aa_freqs[idx])\n",
    "            p_i_freqs = self.p_aa_freqs[idx][i]\n",
    "            p_j_freqs = self.p_aa_freqs[idx][j]\n",
    "            \n",
    "            local_pfreqs.append(torch.stack((p_i_freqs,p_j_freqs)))\n",
    "            \n",
    "            assert y_j < 20\n",
    "            assert X_i[self.cont_size] < 20\n",
    "            \n",
    "        linecache.clearcache()   \n",
    "        X = torch.tensor(X)\n",
    "        try:\n",
    "            X = F.one_hot(X,22)[:,:,0:-1]\n",
    "        except RuntimeError:\n",
    "            pass\n",
    "        if len(pos) == 0:\n",
    "            pos = torch.tensor(pos)\n",
    "        else:\n",
    "            pos = torch.stack(pos)\n",
    "        pfreqs = torch.stack(pfreqs)\n",
    "        local_pfreqs = torch.stack(local_pfreqs)\n",
    "        X = X.float()\n",
    "        y = torch.tensor(y)\n",
    "        PIDs = torch.tensor(PIDs)\n",
    "        local_PIDs = torch.tensor(local_PIDs)\n",
    "        lengths = torch.tensor(lengths)\n",
    "        out = X,y.long(),PIDs,local_PIDs,pfreqs,local_pfreqs,pos,lengths\n",
    "        return out\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1d9b12fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntrain_dataset = MyDataset(r\"data/train_data\",cont_size = 6)\\ntest_dataset = MyDataset(r\"data/test_data\",cont_size = 6,div=700000)\\nval_dataset = MyDataset(r\"data/val_data\",cont_size = 6,div=700000)\\n\\nfname = \\'data/train_dataset1.pth\\'\\nsavepath = Path(fname)\\nwith savepath.open(\"wb\") as fp:\\n    torch.save(train_dataset,fp)\\n    \\nfname = \\'data/test_dataset1.pth\\'\\nsavepath = Path(fname)\\nwith savepath.open(\"wb\") as fp:\\n    torch.save(test_dataset,fp)\\n    \\nfname = \\'data/val_dataset1.pth\\'\\nsavepath = Path(fname)\\nwith savepath.open(\"wb\") as fp:\\n    torch.save(val_dataset,fp)\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "train_dataset = MyDataset(r\"data/train_data\",cont_size = 6)\n",
    "test_dataset = MyDataset(r\"data/test_data\",cont_size = 6,div=700000)\n",
    "val_dataset = MyDataset(r\"data/val_data\",cont_size = 6,div=700000)\n",
    "\n",
    "fname = 'data/train_dataset1.pth'\n",
    "savepath = Path(fname)\n",
    "with savepath.open(\"wb\") as fp:\n",
    "    torch.save(train_dataset,fp)\n",
    "    \n",
    "fname = 'data/test_dataset1.pth'\n",
    "savepath = Path(fname)\n",
    "with savepath.open(\"wb\") as fp:\n",
    "    torch.save(test_dataset,fp)\n",
    "    \n",
    "fname = 'data/val_dataset1.pth'\n",
    "savepath = Path(fname)\n",
    "with savepath.open(\"wb\") as fp:\n",
    "    torch.save(val_dataset,fp)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0b79b8da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13219\n",
      "2838\n",
      "2826\n"
     ]
    }
   ],
   "source": [
    "fname = 'data/train_dataset1.pth'\n",
    "savepath = Path(fname)\n",
    "with savepath.open(\"rb\") as fp:\n",
    "    train_dataset = torch.load(fp)\n",
    "    \n",
    "fname = 'data/test_dataset1.pth'\n",
    "savepath = Path(fname)\n",
    "with savepath.open(\"rb\") as fp:\n",
    "    test_dataset = torch.load(fp)\n",
    "    \n",
    "fname = 'data/val_dataset1.pth'\n",
    "savepath = Path(fname)\n",
    "with savepath.open(\"rb\") as fp:\n",
    "    val_dataset = torch.load(fp)\n",
    "    \n",
    "print(len(train_dataset))\n",
    "print(len(test_dataset))\n",
    "print(len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "378c93c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_collate(batch):\n",
    "    data = torch.cat([item[0] for item in batch],dim=0)\n",
    "    target = torch.cat([item[1] for item in batch],dim=0)\n",
    "    PID = torch.cat([item[2] for item in batch],dim=0)\n",
    "    lPID = torch.cat([item[3] for item in batch],dim=0)\n",
    "    pfreqs = torch.cat([item[4] for item in batch],dim=0)\n",
    "    lpfreqs = torch.cat([item[5] for item in batch],dim=0)\n",
    "    pos = torch.cat([item[6] for item in batch],dim=0)\n",
    "    length = torch.cat([item[7] for item in batch],dim=0)\n",
    "    return data, target, PID, lPID,pfreqs,lpfreqs, pos, length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "66f5e639",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True,collate_fn=my_collate,num_workers=4)\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=True,collate_fn=my_collate,num_workers=4)\n",
    "\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=64, shuffle=True,collate_fn=my_collate,num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7c0f4e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttBlock(nn.Module):\n",
    "    def __init__(self,in_features,out_features=None,num_heads=8,head_dims=24):\n",
    "        super().__init__()\n",
    "        out_features = out_features or in_features\n",
    "        \n",
    "        self.Q_w = nn.Linear(in_features,num_heads*head_dims,bias=False)\n",
    "        self.K_w = nn.Linear(in_features,num_heads*head_dims,bias=False)\n",
    "        self.V_w = nn.Linear(in_features,num_heads*head_dims,bias=False)\n",
    "        \n",
    "        self.att = nn.MultiheadAttention(num_heads*head_dims,num_heads=num_heads,batch_first=True)\n",
    "        self.lin = nn.Linear(num_heads*head_dims,out_features)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        Q = self.Q_w(x)\n",
    "        K = self.K_w(x)\n",
    "        V = self.V_w(x)\n",
    "        out,_ = self.att(Q,K,V,need_weights=False)\n",
    "        out = self.lin(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d97a7106",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedFoward(nn.Module):\n",
    "    def __init__(self,in_features,out_features=None,wide_factor=4):\n",
    "        super().__init__()\n",
    "        out_features = out_features or in_features\n",
    "        hidden_dim = wide_factor * in_features\n",
    "        \n",
    "        self.lin1 = nn.Linear(in_features,hidden_dim)\n",
    "        self.act1 = nn.GELU()\n",
    "        self.lin2 = nn.Linear(hidden_dim,out_features)\n",
    "        self.act2 = nn.GELU()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = self.lin1(x)\n",
    "        out = self.act1(out)\n",
    "        out = self.lin2(out)\n",
    "        out = self.act2(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3e2f0e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_path(x, drop_prob: float = 0.1, training: bool = False, scale_by_keep: bool = True):\n",
    "    \"\"\"Drop paths (Stochastic Depth) per sample (when applied in main path of residual blocks).\n",
    "\n",
    "    This is the same as the DropConnect impl I created for EfficientNet, etc networks, however,\n",
    "    the original name is misleading as 'Drop Connect' is a different form of dropout in a separate paper...\n",
    "    See discussion: https://github.com/tensorflow/tpu/issues/494#issuecomment-532968956 ... I've opted for\n",
    "    changing the layer and argument names to 'drop path' rather than mix DropConnect as a layer name and use\n",
    "    'survival rate' as the argument.\n",
    "\n",
    "    \"\"\"\n",
    "    if drop_prob == 0. or not training:\n",
    "        return x\n",
    "    keep_prob = 1 - drop_prob\n",
    "    shape = (x.shape[0],) + (1,) * (x.ndim - 1)  # work with diff dim tensors, not just 2D ConvNets\n",
    "    random_tensor = x.new_empty(shape).bernoulli_(keep_prob)\n",
    "    if keep_prob > 0.0 and scale_by_keep:\n",
    "        random_tensor.div_(keep_prob)\n",
    "    return x * random_tensor\n",
    "\n",
    "\n",
    "class DropPath(nn.Module):\n",
    "    \"\"\"Drop paths (Stochastic Depth) per sample  (when applied in main path of residual blocks).\n",
    "    \"\"\"\n",
    "    def __init__(self, drop_prob=None, scale_by_keep=True):\n",
    "        super(DropPath, self).__init__()\n",
    "        self.drop_prob = drop_prob\n",
    "        self.scale_by_keep = scale_by_keep\n",
    "\n",
    "    def forward(self, x):\n",
    "        return drop_path(x, self.drop_prob, self.training, self.scale_by_keep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fb41b0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self,in_features,num_heads=8,head_dims=24,wide_factor=4,drop=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.att_block = AttBlock(in_features,num_heads=num_heads,head_dims=head_dims)\n",
    "        self.ff = FeedFoward(in_features,wide_factor=wide_factor)\n",
    "        self.drop_path = DropPath(drop)\n",
    "        \n",
    "        self.norm1 = nn.LayerNorm(in_features)\n",
    "        self.norm2 = nn.LayerNorm(in_features)\n",
    "    def forward(self,x):\n",
    "        out = x + self.drop_path(self.att_block(x))\n",
    "        out = self.norm1(out)\n",
    "        out = out + self.drop_path(self.ff(out))\n",
    "        out = self.norm2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c55b8e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier_Head(nn.Module):\n",
    "    def __init__(self,in_features,clf_dims,out_size,seq_len):\n",
    "        super().__init__()\n",
    "        in_dim = seq_len*in_features\n",
    "        self.in_dim = in_dim\n",
    "        \n",
    "        layers = []\n",
    "        for out_dim in clf_dims:\n",
    "            layers.append(nn.Linear(in_dim,out_dim))\n",
    "            layers.append(nn.GELU())\n",
    "            layers.append(nn.Dropout(p=0.2))\n",
    "            in_dim = out_dim\n",
    "\n",
    "        layers.append(nn.Linear(in_dim,out_size))\n",
    "        \n",
    "        self.clf = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = x.reshape((-1,self.in_dim))\n",
    "        \n",
    "        out = self.clf(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7a397a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttNet(nn.Module):\n",
    "    def __init__(self,in_features,num_heads,head_dims,wide_factors,drops,input_dim=21,out_size=20,seq_len=30,clf_dims=[256,64],cont_size=6):\n",
    "        super().__init__()\n",
    "        \n",
    "        blocks = []\n",
    "        for n_h, h_d,w,d in zip(num_heads,head_dims,wide_factors,drops):\n",
    "            blocks.append(Block(in_features,num_heads=n_h,head_dims=h_d,wide_factor=w,drop=d))\n",
    "        self.feature_extractor = nn.Sequential(*blocks)\n",
    "        self.in_features = in_features\n",
    "        self.input_dim = input_dim\n",
    "        self.clf = Classifier_Head(in_features,clf_dims,out_size=out_size,seq_len=seq_len)\n",
    "        \n",
    "        self.cont_size=cont_size\n",
    "        \n",
    "        sp = Path(\"data/freq.pth\")\n",
    "        with sp.open(\"rb\") as fp:\n",
    "            self.F = nn.Parameter(torch.log(torch.load(fp)))\n",
    "            \n",
    "        pid_layers = [nn.Linear(1,in_features),nn.Sigmoid()]\n",
    "        self.pid_l = nn.Sequential(*pid_layers)\n",
    "    \n",
    "    def to_input(self,x,PID,pfreqs,lpfreqs,pos,length):\n",
    "        X_idx = torch.argmax(x[:,self.cont_size],dim=1)\n",
    "        seq1 = x[:,:2*self.cont_size+1]\n",
    "        y_freq = F.pad(F.softmax(self.F[X_idx],dim=1).unsqueeze(1), pad=(0, 1), mode='constant', value=0) \n",
    "        seq2 = torch.cat((x[:,2*self.cont_size+1:3*self.cont_size+1],y_freq,x[:,3*self.cont_size+1:]),dim=1)\n",
    "        aa_pos = pos[:,:2*self.cont_size+1]/length.unsqueeze(1)\n",
    "        aa_pos = aa_pos.unsqueeze(2)\n",
    "        pos_dim = (self.in_features-self.input_dim-1)//2\n",
    "        \n",
    "        for i in range(pos_dim): #positionnal_encoding\n",
    "            p = torch.cos(pos[:,:2*self.cont_size+1]/(4**(2*i/pos_dim))).unsqueeze(2)\n",
    "            ip = torch.sin(pos[:,:2*self.cont_size+1]/(4**(2*i/pos_dim))).unsqueeze(2)\n",
    "            aa_pos = torch.cat([aa_pos,p,ip],dim=2)\n",
    "\n",
    "        seq1 = torch.cat([seq1,aa_pos],dim=2)\n",
    "        seq2 = torch.cat([seq2,aa_pos],dim=2)\n",
    "        X = torch.cat([seq1,seq2],dim=1)\n",
    "        \n",
    "        pad = (0,self.in_features-self.input_dim+1)\n",
    "        pf = F.pad(pfreqs.unsqueeze(1),pad =pad, mode='constant', value=0)\n",
    "        pid = self.pid_l(PID.unsqueeze(1)).unsqueeze(1)\n",
    "        lpf = F.pad(lpfreqs,pad=pad, mode='constant', value=0)\n",
    "\n",
    "        X_input = torch.cat([X,pf,lpf,pid],dim=1)\n",
    "        \n",
    "        return X_input\n",
    "    \n",
    "    def forward(self,x,PID,pfreqs,lpfreqs,pos,length):\n",
    "        X_input = self.to_input(x,PID,pfreqs,lpfreqs,pos,length)\n",
    "        features = self.feature_extractor(X_input)\n",
    "        out = self.clf(features)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "313c7bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State:\n",
    "    def __init__(self,model,optim,scheduler):\n",
    "        self.model = model\n",
    "        self.optim = optim\n",
    "        self.scheduler = scheduler\n",
    "        self.epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8dab16ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(fname,train,test,val,N=10):\n",
    "    savepath = Path(fname)\n",
    "    with savepath.open(\"rb\") as fp:\n",
    "        state = torch.load(fp)\n",
    "        \n",
    "    state.model.eval()\n",
    "    with torch.no_grad():\n",
    "        print('EVALUATING ON TRAIN DATA : ')\n",
    "        eval_losses = []\n",
    "        for _ in range(N):\n",
    "            for X,y, PID, lPID,pfreqs,lpfreqs,pos,length in train:\n",
    "                X = X.to(device)\n",
    "                y = y.to(device)\n",
    "                PID = PID.to(device)\n",
    "                pos = pos.to(device)\n",
    "                pfreqs = pfreqs.to(device)\n",
    "                lpfreqs = lpfreqs.to(device)\n",
    "                length = length.to(device)\n",
    "\n",
    "                y_hat = state.model(X,PID,pfreqs,lpfreqs,pos,length)\n",
    "                y_hat = F.softmax(y_hat,dim=1)\n",
    "\n",
    "                y = F.one_hot(y, 20)\n",
    "                eval_l = (y_hat-y)**2\n",
    "                eval_losses.append(torch.sum(eval_l,dim=1).detach().cpu())\n",
    "\n",
    "        score_train = torch.mean(torch.cat(eval_losses)).detach().cpu().item()\n",
    "        print(f\"{score_train = }\\n\")\n",
    "\n",
    "        print('EVALUATING ON TEST DATA : ')\n",
    "        eval_losses = []\n",
    "        for _ in range(N):\n",
    "            for X,y, PID, lPID,pfreqs,lpfreqs, pos,length in test:\n",
    "                X = X.to(device)\n",
    "                y = y.to(device)\n",
    "                PID = PID.to(device)\n",
    "                pos = pos.to(device)\n",
    "                pfreqs = pfreqs.to(device)\n",
    "                lpfreqs = lpfreqs.to(device)\n",
    "                length = length.to(device)\n",
    "\n",
    "                y_hat = state.model(X,PID,pfreqs,lpfreqs,pos,length)\n",
    "                y_hat = F.softmax(y_hat,dim=1)\n",
    "\n",
    "                y = F.one_hot(y, 20)\n",
    "                eval_l = (y_hat-y)**2\n",
    "                eval_losses.append(torch.sum(eval_l,dim=1).detach().cpu())\n",
    "    \n",
    "        score_test = torch.mean(torch.cat(eval_losses)).detach().cpu().item()\n",
    "        print(f\"{score_test = }\\n\")\n",
    "\n",
    "        print('EVALUATING ON VAL DATA : ')\n",
    "        eval_losses = []\n",
    "        for _ in range(N):\n",
    "            for X,y, PID, lPID,pfreqs,lpfreqs, pos, length in val:\n",
    "                X = X.to(device)\n",
    "                y = y.to(device)\n",
    "                PID = PID.to(device)\n",
    "                lPID = lPID.to(device)\n",
    "                pos = pos.to(device)\n",
    "                pfreqs = pfreqs.to(device)\n",
    "                lpfreqs = lpfreqs.to(device)\n",
    "                length = length.to(device)\n",
    "\n",
    "                y_hat = state.model(X,PID,pfreqs,lpfreqs,pos,length)\n",
    "                y_hat = F.softmax(y_hat,dim=1)\n",
    "\n",
    "                y = F.one_hot(y, 20)\n",
    "                eval_l = (y_hat-y)**2\n",
    "                eval_losses.append(torch.sum(eval_l,dim=1).detach().cpu())\n",
    "    \n",
    "        score_val = torch.mean(torch.cat(eval_losses)).detach().cpu().item()\n",
    "        print(f\"{score_val = }\\n\")\n",
    "    \n",
    "    return score_train, score_test, score_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "00349869",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(train_loader,val_loader,epochs=101,fname=\"models/state.pth\",fnameb=None,state=None,last_epoch_sched=float('inf'),use_mut=True):\n",
    "    \n",
    "    #to get the best model\n",
    "    best = float('inf')\n",
    "    \n",
    "    #getting the acceleration device\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    #loading from previous checkpoint\n",
    "    if fnameb is None:\n",
    "        fnameb = fname[:-4] + '_best' +fname[-4:]\n",
    "        \n",
    "    savepath = Path(fname)\n",
    "    if savepath.is_file():\n",
    "        with savepath.open(\"rb\") as fp:\n",
    "            state = torch.load(fp)\n",
    "    else:\n",
    "        if state is None:\n",
    "            model = AttNet(22,[8,8,8],[24,24,24],[4,4,4],[0.1,0.1,0.1])\n",
    "            model = model.to(device)\n",
    "            optim = torch.optim.AdamW(model.parameters(),lr = 0.0001)\n",
    "            scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optim,16,2)\n",
    "            state = State(model,optim,scheduler)\n",
    "    \n",
    "    \n",
    "    Loss = nn.CrossEntropyLoss(reduction='sum')\n",
    "    LossMut = nn.BCELoss(reduction='sum')\n",
    "    EvalLoss = nn.MSELoss(reduction='mean')\n",
    "    \n",
    "    #for logs\n",
    "    List_Loss = []\n",
    "    Eval_Loss = []\n",
    "    for epoch in range(state.epoch, epochs):\n",
    "        batch_losses = []\n",
    "        state.model.train()\n",
    "        for X,y, PID, lPID,pfreqs,lpfreqs,pos,length in train_loader:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            PID = PID.to(device)\n",
    "            pos = pos.to(device)\n",
    "            pfreqs = pfreqs.to(device)\n",
    "            lpfreqs = lpfreqs.to(device)\n",
    "            length = length.to(device)\n",
    "            \n",
    "            state.optim.zero_grad()\n",
    "            y_hat = state.model(X,PID,pfreqs,lpfreqs,pos,length)\n",
    "            \n",
    "\n",
    "            if use_mut:\n",
    "                X_idx = torch.argmax(X[:,6],dim=1)\n",
    "                y_true = (X_idx == y).float().unsqueeze(1)  #0 if a mutation happens else 1 \n",
    "                y_pred = F.softmax(y_hat,dim=1)\n",
    "                y_pred = y_pred.gather(1,X_idx.view(-1,1)) #the Xth component of y_hat should be predicting ^\n",
    "                l = (Loss(y_hat,y) + LossMut(y_pred,y_true))/311\n",
    "            else:\n",
    "                l = Loss(y_hat,y)/311\n",
    "            l.backward()\n",
    "            state.optim.step()\n",
    "            \n",
    "            \n",
    "            \n",
    "            batch_losses.append(l.detach().cpu())\n",
    "        List_Loss.append(torch.mean(torch.stack(batch_losses)).detach().cpu())\n",
    "        state.epoch = epoch + 1\n",
    "        if epoch < last_epoch_sched:\n",
    "            state.scheduler.step()\n",
    "        \n",
    "        savepath = Path(fname)\n",
    "        with savepath.open(\"wb\") as fp:\n",
    "            torch.save(state,fp)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            eval_losses = [] \n",
    "            state.model.eval()\n",
    "            for X,y, PID, lPID,pfreqs,lpfreqs, pos,length in val_loader:\n",
    "\n",
    "                X = X.to(device)\n",
    "                y = y.to(device)\n",
    "                PID = PID.to(device)\n",
    "                pos = pos.to(device)\n",
    "                pfreqs = pfreqs.to(device)\n",
    "                lpfreqs = lpfreqs.to(device)\n",
    "                length = length.to(device)\n",
    "\n",
    "                y_hat = state.model(X,PID,pfreqs,lpfreqs,pos,length)\n",
    "                y_hat = F.softmax(y_hat,dim=1)\n",
    "\n",
    "                y = F.one_hot(y, 20)\n",
    "                eval_l = (y_hat-y)**2\n",
    "                eval_losses.append(torch.sum(eval_l,dim=1).detach().cpu())\n",
    "    \n",
    "            score = torch.mean(torch.cat(eval_losses)).detach().cpu().item()\n",
    "            Eval_Loss.append(score)\n",
    "        \n",
    "        if score < best :\n",
    "            best = score\n",
    "            savepath = Path(fnameb)\n",
    "            with savepath.open(\"wb\") as fp:\n",
    "                torch.save(state,fp)\n",
    "        \n",
    "        print(f\"epoch n°{epoch} : train_loss = {List_Loss[-1]}, val_loss = {Eval_Loss[-1]}\") \n",
    "\n",
    "\n",
    "        \n",
    "    return List_Loss,Eval_Loss,state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a48c6f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_params(input_size,N,head,head_dim,wide_factor,drop_prob):\n",
    "    return input_size, [head for _ in range(N)], [head_dim for _ in range(N)], [wide_factor for _ in range(N)], [drop_prob for _ in range(N)], "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3b97a85f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "AttNet                                        [1, 20]                   400\n",
       "├─Sequential: 1-1                             [1, 32]                   --\n",
       "│    └─Linear: 2-1                            [1, 32]                   64\n",
       "│    └─Sigmoid: 2-2                           [1, 32]                   --\n",
       "├─Sequential: 1-2                             [1, 30, 32]               --\n",
       "│    └─Block: 2-3                             [1, 30, 32]               --\n",
       "│    │    └─AttBlock: 3-1                     [1, 30, 32]               295,968\n",
       "│    │    └─DropPath: 3-2                     [1, 30, 32]               --\n",
       "│    │    └─LayerNorm: 3-3                    [1, 30, 32]               64\n",
       "│    │    └─FeedFoward: 3-4                   [1, 30, 32]               8,352\n",
       "│    │    └─DropPath: 3-5                     [1, 30, 32]               --\n",
       "│    │    └─LayerNorm: 3-6                    [1, 30, 32]               64\n",
       "│    └─Block: 2-4                             [1, 30, 32]               --\n",
       "│    │    └─AttBlock: 3-7                     [1, 30, 32]               295,968\n",
       "│    │    └─DropPath: 3-8                     [1, 30, 32]               --\n",
       "│    │    └─LayerNorm: 3-9                    [1, 30, 32]               64\n",
       "│    │    └─FeedFoward: 3-10                  [1, 30, 32]               8,352\n",
       "│    │    └─DropPath: 3-11                    [1, 30, 32]               --\n",
       "│    │    └─LayerNorm: 3-12                   [1, 30, 32]               64\n",
       "│    └─Block: 2-5                             [1, 30, 32]               --\n",
       "│    │    └─AttBlock: 3-13                    [1, 30, 32]               295,968\n",
       "│    │    └─DropPath: 3-14                    [1, 30, 32]               --\n",
       "│    │    └─LayerNorm: 3-15                   [1, 30, 32]               64\n",
       "│    │    └─FeedFoward: 3-16                  [1, 30, 32]               8,352\n",
       "│    │    └─DropPath: 3-17                    [1, 30, 32]               --\n",
       "│    │    └─LayerNorm: 3-18                   [1, 30, 32]               64\n",
       "│    └─Block: 2-6                             [1, 30, 32]               --\n",
       "│    │    └─AttBlock: 3-19                    [1, 30, 32]               295,968\n",
       "│    │    └─DropPath: 3-20                    [1, 30, 32]               --\n",
       "│    │    └─LayerNorm: 3-21                   [1, 30, 32]               64\n",
       "│    │    └─FeedFoward: 3-22                  [1, 30, 32]               8,352\n",
       "│    │    └─DropPath: 3-23                    [1, 30, 32]               --\n",
       "│    │    └─LayerNorm: 3-24                   [1, 30, 32]               64\n",
       "├─Classifier_Head: 1-3                        [1, 20]                   --\n",
       "│    └─Sequential: 2-7                        [1, 20]                   --\n",
       "│    │    └─Linear: 3-25                      [1, 1024]                 984,064\n",
       "│    │    └─GELU: 3-26                        [1, 1024]                 --\n",
       "│    │    └─Dropout: 3-27                     [1, 1024]                 --\n",
       "│    │    └─Linear: 3-28                      [1, 256]                  262,400\n",
       "│    │    └─GELU: 3-29                        [1, 256]                  --\n",
       "│    │    └─Dropout: 3-30                     [1, 256]                  --\n",
       "│    │    └─Linear: 3-31                      [1, 64]                   16,448\n",
       "│    │    └─GELU: 3-32                        [1, 64]                   --\n",
       "│    │    └─Dropout: 3-33                     [1, 64]                   --\n",
       "│    │    └─Linear: 3-34                      [1, 20]                   1,300\n",
       "===============================================================================================\n",
       "Total params: 2,482,468\n",
       "Trainable params: 2,482,468\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 1.43\n",
       "===============================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.99\n",
       "Params size (MB): 5.72\n",
       "Estimated Total Size (MB): 6.71\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = get_params(32,4,8,32,4,0.1)\n",
    "model = AttNet(*params,clf_dims=[1024,256,64])\n",
    "model = model.to(device)\n",
    "torchinfo.summary(model,[(1,25,21),(1,),(1,20),(1,2,20),(1,25),(1,)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bd883578",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°0 : train_loss = 2.7820186614990234, val_loss = 0.8786128163337708\n",
      "epoch n°1 : train_loss = 2.496732711791992, val_loss = 0.8379143476486206\n",
      "epoch n°2 : train_loss = 2.396580696105957, val_loss = 0.8233270645141602\n",
      "epoch n°3 : train_loss = 2.3632419109344482, val_loss = 0.8242983222007751\n",
      "epoch n°4 : train_loss = 2.341736316680908, val_loss = 0.8151569366455078\n",
      "epoch n°5 : train_loss = 2.330084800720215, val_loss = 0.8113887906074524\n",
      "epoch n°6 : train_loss = 2.3223018646240234, val_loss = 0.8084423542022705\n",
      "epoch n°7 : train_loss = 2.3109476566314697, val_loss = 0.8103057146072388\n",
      "epoch n°8 : train_loss = 2.3055741786956787, val_loss = 0.8092596530914307\n",
      "epoch n°9 : train_loss = 2.294175386428833, val_loss = 0.8076428771018982\n",
      "epoch n°10 : train_loss = 2.294893264770508, val_loss = 0.8058606386184692\n",
      "epoch n°11 : train_loss = 2.2987349033355713, val_loss = 0.8114710450172424\n",
      "epoch n°12 : train_loss = 2.287438154220581, val_loss = 0.8090648651123047\n",
      "epoch n°13 : train_loss = 2.2890067100524902, val_loss = 0.8057113885879517\n",
      "epoch n°14 : train_loss = 2.2865777015686035, val_loss = 0.8054680228233337\n",
      "epoch n°15 : train_loss = 2.2886369228363037, val_loss = 0.807421863079071\n",
      "epoch n°16 : train_loss = 2.304713487625122, val_loss = 0.8083859086036682\n",
      "epoch n°17 : train_loss = 2.2970950603485107, val_loss = 0.8084814548492432\n",
      "epoch n°18 : train_loss = 2.3019015789031982, val_loss = 0.8106260895729065\n",
      "epoch n°19 : train_loss = 2.2916510105133057, val_loss = 0.8082827925682068\n",
      "epoch n°20 : train_loss = 2.2929859161376953, val_loss = 0.8109200596809387\n",
      "epoch n°21 : train_loss = 2.29376482963562, val_loss = 0.8068051338195801\n",
      "epoch n°22 : train_loss = 2.293822765350342, val_loss = 0.8103627562522888\n",
      "epoch n°23 : train_loss = 2.2831318378448486, val_loss = 0.8072342872619629\n",
      "epoch n°24 : train_loss = 2.2773091793060303, val_loss = 0.8060383200645447\n",
      "epoch n°25 : train_loss = 2.2620723247528076, val_loss = 0.8086826205253601\n",
      "epoch n°26 : train_loss = 2.265523910522461, val_loss = 0.8060013651847839\n",
      "epoch n°27 : train_loss = 2.2711832523345947, val_loss = 0.8087517023086548\n",
      "epoch n°28 : train_loss = 2.267697334289551, val_loss = 0.8027096390724182\n",
      "epoch n°29 : train_loss = 2.2636404037475586, val_loss = 0.8052103519439697\n",
      "epoch n°30 : train_loss = 2.264707326889038, val_loss = 0.8061383366584778\n",
      "epoch n°31 : train_loss = 2.2554879188537598, val_loss = 0.8041936755180359\n",
      "epoch n°32 : train_loss = 2.2564704418182373, val_loss = 0.8026474118232727\n",
      "epoch n°33 : train_loss = 2.2598936557769775, val_loss = 0.7999715209007263\n",
      "epoch n°34 : train_loss = 2.246602773666382, val_loss = 0.8046768307685852\n",
      "epoch n°35 : train_loss = 2.246410608291626, val_loss = 0.8042854070663452\n",
      "epoch n°36 : train_loss = 2.250720500946045, val_loss = 0.8025525212287903\n",
      "epoch n°37 : train_loss = 2.2509729862213135, val_loss = 0.8055615425109863\n",
      "epoch n°38 : train_loss = 2.2427690029144287, val_loss = 0.8016205430030823\n",
      "epoch n°39 : train_loss = 2.2415859699249268, val_loss = 0.8005189895629883\n",
      "epoch n°40 : train_loss = 2.2349724769592285, val_loss = 0.7997212409973145\n",
      "epoch n°41 : train_loss = 2.233208179473877, val_loss = 0.798565685749054\n",
      "epoch n°42 : train_loss = 2.2413558959960938, val_loss = 0.799863874912262\n",
      "epoch n°43 : train_loss = 2.236600399017334, val_loss = 0.7992711067199707\n",
      "epoch n°44 : train_loss = 2.2444963455200195, val_loss = 0.8021773099899292\n",
      "epoch n°45 : train_loss = 2.241486072540283, val_loss = 0.8004319667816162\n",
      "epoch n°46 : train_loss = 2.231337785720825, val_loss = 0.8047751188278198\n",
      "epoch n°47 : train_loss = 2.236182689666748, val_loss = 0.796010434627533\n",
      "epoch n°48 : train_loss = 2.2554314136505127, val_loss = 0.8031015396118164\n",
      "epoch n°49 : train_loss = 2.260010004043579, val_loss = 0.8071349263191223\n",
      "epoch n°50 : train_loss = 2.2553727626800537, val_loss = 0.8091174364089966\n",
      "epoch n°51 : train_loss = 2.252185821533203, val_loss = 0.8043889403343201\n",
      "epoch n°52 : train_loss = 2.252424955368042, val_loss = 0.8030458688735962\n",
      "epoch n°53 : train_loss = 2.25331711769104, val_loss = 0.8066935539245605\n",
      "epoch n°54 : train_loss = 2.2457432746887207, val_loss = 0.802832305431366\n",
      "epoch n°55 : train_loss = 2.247020721435547, val_loss = 0.8029540777206421\n",
      "epoch n°56 : train_loss = 2.25189471244812, val_loss = 0.8042129278182983\n",
      "epoch n°57 : train_loss = 2.24959659576416, val_loss = 0.8062143921852112\n",
      "epoch n°58 : train_loss = 2.248887062072754, val_loss = 0.8038829565048218\n",
      "epoch n°59 : train_loss = 2.2469263076782227, val_loss = 0.8022701144218445\n",
      "epoch n°60 : train_loss = 2.248150110244751, val_loss = 0.8005268573760986\n",
      "epoch n°61 : train_loss = 2.2415902614593506, val_loss = 0.8050522804260254\n",
      "epoch n°62 : train_loss = 2.243565320968628, val_loss = 0.808303952217102\n",
      "epoch n°63 : train_loss = 2.2459301948547363, val_loss = 0.8021039366722107\n",
      "epoch n°64 : train_loss = 2.235872507095337, val_loss = 0.8050668835639954\n",
      "epoch n°65 : train_loss = 2.250631332397461, val_loss = 0.805242657661438\n",
      "epoch n°66 : train_loss = 2.2388803958892822, val_loss = 0.8043875098228455\n",
      "epoch n°67 : train_loss = 2.2361223697662354, val_loss = 0.7993740439414978\n",
      "epoch n°68 : train_loss = 2.242297887802124, val_loss = 0.8048586845397949\n",
      "epoch n°69 : train_loss = 2.2455968856811523, val_loss = 0.8016293048858643\n",
      "epoch n°70 : train_loss = 2.235499143600464, val_loss = 0.8023629784584045\n",
      "epoch n°71 : train_loss = 2.234875440597534, val_loss = 0.8054166436195374\n",
      "epoch n°72 : train_loss = 2.2366843223571777, val_loss = 0.7999786734580994\n",
      "epoch n°73 : train_loss = 2.2316391468048096, val_loss = 0.8045075535774231\n",
      "epoch n°74 : train_loss = 2.2303919792175293, val_loss = 0.803093433380127\n",
      "epoch n°75 : train_loss = 2.2243809700012207, val_loss = 0.7998178005218506\n",
      "epoch n°76 : train_loss = 2.226383924484253, val_loss = 0.8004491329193115\n",
      "epoch n°77 : train_loss = 2.228398323059082, val_loss = 0.8020570278167725\n",
      "epoch n°78 : train_loss = 2.2290070056915283, val_loss = 0.7979871034622192\n",
      "epoch n°79 : train_loss = 2.2109646797180176, val_loss = 0.7983834743499756\n",
      "epoch n°80 : train_loss = 2.224893093109131, val_loss = 0.8008556365966797\n",
      "epoch n°81 : train_loss = 2.2217020988464355, val_loss = 0.7986378073692322\n",
      "epoch n°82 : train_loss = 2.2113287448883057, val_loss = 0.7990488409996033\n",
      "epoch n°83 : train_loss = 2.2132887840270996, val_loss = 0.8003219962120056\n",
      "epoch n°84 : train_loss = 2.2202911376953125, val_loss = 0.8026090264320374\n",
      "epoch n°85 : train_loss = 2.211232900619507, val_loss = 0.7990873456001282\n",
      "epoch n°86 : train_loss = 2.2118515968322754, val_loss = 0.7948499917984009\n",
      "epoch n°87 : train_loss = 2.2214198112487793, val_loss = 0.798619270324707\n",
      "epoch n°88 : train_loss = 2.204127073287964, val_loss = 0.7949109077453613\n",
      "epoch n°89 : train_loss = 2.2112951278686523, val_loss = 0.7992398142814636\n",
      "epoch n°90 : train_loss = 2.2116174697875977, val_loss = 0.7988238334655762\n",
      "epoch n°91 : train_loss = 2.212040424346924, val_loss = 0.8025785088539124\n",
      "epoch n°92 : train_loss = 2.2096211910247803, val_loss = 0.7983917593955994\n",
      "epoch n°93 : train_loss = 2.210787534713745, val_loss = 0.7956095933914185\n",
      "epoch n°94 : train_loss = 2.205068588256836, val_loss = 0.7987642288208008\n",
      "epoch n°95 : train_loss = 2.2152514457702637, val_loss = 0.8031745553016663\n",
      "epoch n°96 : train_loss = 2.2095277309417725, val_loss = 0.7970138788223267\n",
      "epoch n°97 : train_loss = 2.2037594318389893, val_loss = 0.7989039421081543\n",
      "epoch n°98 : train_loss = 2.2030110359191895, val_loss = 0.7987307906150818\n",
      "epoch n°99 : train_loss = 2.198439598083496, val_loss = 0.799551248550415\n",
      "epoch n°100 : train_loss = 2.2062392234802246, val_loss = 0.7954710125923157\n",
      "epoch n°101 : train_loss = 2.205656051635742, val_loss = 0.7998608350753784\n",
      "epoch n°102 : train_loss = 2.20867919921875, val_loss = 0.7980374693870544\n",
      "epoch n°103 : train_loss = 2.1986050605773926, val_loss = 0.7945769429206848\n",
      "epoch n°104 : train_loss = 2.2034049034118652, val_loss = 0.7925390601158142\n",
      "epoch n°105 : train_loss = 2.2038114070892334, val_loss = 0.7992403507232666\n",
      "epoch n°106 : train_loss = 2.1963627338409424, val_loss = 0.794529139995575\n",
      "epoch n°107 : train_loss = 2.1978583335876465, val_loss = 0.7980973124504089\n",
      "epoch n°108 : train_loss = 2.19978928565979, val_loss = 0.8024671077728271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°109 : train_loss = 2.194643020629883, val_loss = 0.7960415482521057\n",
      "epoch n°110 : train_loss = 2.2085750102996826, val_loss = 0.7987204790115356\n",
      "epoch n°111 : train_loss = 2.1956968307495117, val_loss = 0.795861005783081\n",
      "epoch n°112 : train_loss = 2.2203705310821533, val_loss = 0.7983351945877075\n",
      "epoch n°113 : train_loss = 2.2149548530578613, val_loss = 0.8011788129806519\n",
      "epoch n°114 : train_loss = 2.2284748554229736, val_loss = 0.8026575446128845\n",
      "epoch n°115 : train_loss = 2.2205591201782227, val_loss = 0.8040472269058228\n",
      "epoch n°116 : train_loss = 2.224886178970337, val_loss = 0.799980103969574\n",
      "epoch n°117 : train_loss = 2.2168514728546143, val_loss = 0.8045084476470947\n",
      "epoch n°118 : train_loss = 2.215970039367676, val_loss = 0.800125002861023\n",
      "epoch n°119 : train_loss = 2.2299087047576904, val_loss = 0.7986940741539001\n",
      "epoch n°120 : train_loss = 2.2166528701782227, val_loss = 0.7978545427322388\n",
      "epoch n°121 : train_loss = 2.2222299575805664, val_loss = 0.8009495735168457\n",
      "epoch n°122 : train_loss = 2.2261953353881836, val_loss = 0.8001868724822998\n",
      "epoch n°123 : train_loss = 2.2259390354156494, val_loss = 0.8040609955787659\n",
      "epoch n°124 : train_loss = 2.21658992767334, val_loss = 0.8010129928588867\n",
      "epoch n°125 : train_loss = 2.2199933528900146, val_loss = 0.8001072406768799\n",
      "epoch n°126 : train_loss = 2.217308759689331, val_loss = 0.7962778806686401\n",
      "epoch n°127 : train_loss = 2.222115993499756, val_loss = 0.8010148406028748\n",
      "epoch n°128 : train_loss = 2.2242279052734375, val_loss = 0.8022750616073608\n",
      "epoch n°129 : train_loss = 2.2281384468078613, val_loss = 0.8009287714958191\n",
      "epoch n°130 : train_loss = 2.2196314334869385, val_loss = 0.8004595041275024\n",
      "epoch n°131 : train_loss = 2.2106382846832275, val_loss = 0.7967298030853271\n",
      "epoch n°132 : train_loss = 2.2187747955322266, val_loss = 0.8017026782035828\n",
      "epoch n°133 : train_loss = 2.2183241844177246, val_loss = 0.8021702766418457\n",
      "epoch n°134 : train_loss = 2.217848777770996, val_loss = 0.7994517683982849\n",
      "epoch n°135 : train_loss = 2.2077178955078125, val_loss = 0.7992181181907654\n",
      "epoch n°136 : train_loss = 2.2142317295074463, val_loss = 0.7974523901939392\n",
      "epoch n°137 : train_loss = 2.215043544769287, val_loss = 0.7971364855766296\n",
      "epoch n°138 : train_loss = 2.201972246170044, val_loss = 0.7995455265045166\n",
      "epoch n°139 : train_loss = 2.209148406982422, val_loss = 0.8001552820205688\n",
      "epoch n°140 : train_loss = 2.208500623703003, val_loss = 0.7968130707740784\n",
      "epoch n°141 : train_loss = 2.204355478286743, val_loss = 0.799710214138031\n",
      "epoch n°142 : train_loss = 2.207681655883789, val_loss = 0.8038397431373596\n",
      "epoch n°143 : train_loss = 2.2159974575042725, val_loss = 0.7999386787414551\n",
      "epoch n°144 : train_loss = 2.2028045654296875, val_loss = 0.7976064085960388\n",
      "epoch n°145 : train_loss = 2.214820384979248, val_loss = 0.8012231588363647\n",
      "epoch n°146 : train_loss = 2.206725835800171, val_loss = 0.7963830828666687\n",
      "epoch n°147 : train_loss = 2.209954023361206, val_loss = 0.7967730164527893\n",
      "epoch n°148 : train_loss = 2.2028563022613525, val_loss = 0.8027286529541016\n",
      "epoch n°149 : train_loss = 2.210707902908325, val_loss = 0.7970153093338013\n",
      "epoch n°150 : train_loss = 2.206362724304199, val_loss = 0.8026981353759766\n",
      "epoch n°151 : train_loss = 2.2006142139434814, val_loss = 0.7982950806617737\n",
      "epoch n°152 : train_loss = 2.1947848796844482, val_loss = 0.8044912219047546\n",
      "epoch n°153 : train_loss = 2.2022042274475098, val_loss = 0.8001561164855957\n",
      "epoch n°154 : train_loss = 2.1979708671569824, val_loss = 0.8017065525054932\n",
      "epoch n°155 : train_loss = 2.208386182785034, val_loss = 0.7991758584976196\n",
      "epoch n°156 : train_loss = 2.1972203254699707, val_loss = 0.8013902902603149\n",
      "epoch n°157 : train_loss = 2.2012674808502197, val_loss = 0.7975757718086243\n",
      "epoch n°158 : train_loss = 2.204620838165283, val_loss = 0.7951323986053467\n",
      "epoch n°159 : train_loss = 2.1985201835632324, val_loss = 0.797404944896698\n",
      "epoch n°160 : train_loss = 2.1922359466552734, val_loss = 0.7963797450065613\n",
      "epoch n°161 : train_loss = 2.197801113128662, val_loss = 0.7991794347763062\n",
      "epoch n°162 : train_loss = 2.1889867782592773, val_loss = 0.7991619110107422\n",
      "epoch n°163 : train_loss = 2.1910758018493652, val_loss = 0.7979001402854919\n",
      "epoch n°164 : train_loss = 2.1906423568725586, val_loss = 0.7974624633789062\n",
      "epoch n°165 : train_loss = 2.202679395675659, val_loss = 0.7996089458465576\n",
      "epoch n°166 : train_loss = 2.190554618835449, val_loss = 0.7973535060882568\n",
      "epoch n°167 : train_loss = 2.1880502700805664, val_loss = 0.7983593940734863\n",
      "epoch n°168 : train_loss = 2.1861746311187744, val_loss = 0.8008278012275696\n",
      "epoch n°169 : train_loss = 2.2019851207733154, val_loss = 0.7966735363006592\n",
      "epoch n°170 : train_loss = 2.1908767223358154, val_loss = 0.7983477115631104\n",
      "epoch n°171 : train_loss = 2.1942999362945557, val_loss = 0.8010423183441162\n",
      "epoch n°172 : train_loss = 2.190308094024658, val_loss = 0.7976933717727661\n",
      "epoch n°173 : train_loss = 2.189570665359497, val_loss = 0.7956530451774597\n",
      "epoch n°174 : train_loss = 2.191068410873413, val_loss = 0.7965525388717651\n",
      "epoch n°175 : train_loss = 2.1899001598358154, val_loss = 0.7944663763046265\n",
      "epoch n°176 : train_loss = 2.186251163482666, val_loss = 0.7952037453651428\n",
      "epoch n°177 : train_loss = 2.195688486099243, val_loss = 0.7973583936691284\n",
      "epoch n°178 : train_loss = 2.1919384002685547, val_loss = 0.7976928353309631\n",
      "epoch n°179 : train_loss = 2.183238983154297, val_loss = 0.7960276007652283\n",
      "epoch n°180 : train_loss = 2.1813831329345703, val_loss = 0.7974488735198975\n",
      "epoch n°181 : train_loss = 2.1853933334350586, val_loss = 0.7964222431182861\n",
      "epoch n°182 : train_loss = 2.178558826446533, val_loss = 0.7969908714294434\n",
      "epoch n°183 : train_loss = 2.1794509887695312, val_loss = 0.8027172088623047\n",
      "epoch n°184 : train_loss = 2.1912472248077393, val_loss = 0.7970194220542908\n",
      "epoch n°185 : train_loss = 2.1721184253692627, val_loss = 0.7992632985115051\n",
      "epoch n°186 : train_loss = 2.1890921592712402, val_loss = 0.796417236328125\n",
      "epoch n°187 : train_loss = 2.185647487640381, val_loss = 0.7971518635749817\n",
      "epoch n°188 : train_loss = 2.182147979736328, val_loss = 0.8004534244537354\n",
      "epoch n°189 : train_loss = 2.1811399459838867, val_loss = 0.7963579893112183\n",
      "epoch n°190 : train_loss = 2.171948194503784, val_loss = 0.7982909679412842\n",
      "epoch n°191 : train_loss = 2.1749625205993652, val_loss = 0.7942078113555908\n",
      "epoch n°192 : train_loss = 2.180299758911133, val_loss = 0.7930662035942078\n",
      "epoch n°193 : train_loss = 2.1791892051696777, val_loss = 0.7962667346000671\n",
      "epoch n°194 : train_loss = 2.1722874641418457, val_loss = 0.7961652874946594\n",
      "epoch n°195 : train_loss = 2.1833877563476562, val_loss = 0.7969894409179688\n",
      "epoch n°196 : train_loss = 2.180492639541626, val_loss = 0.794666588306427\n",
      "epoch n°197 : train_loss = 2.1726419925689697, val_loss = 0.7971888184547424\n",
      "epoch n°198 : train_loss = 2.181316375732422, val_loss = 0.794447660446167\n",
      "epoch n°199 : train_loss = 2.181457281112671, val_loss = 0.7970656752586365\n",
      "epoch n°200 : train_loss = 2.174679756164551, val_loss = 0.7998536229133606\n",
      "epoch n°201 : train_loss = 2.173893928527832, val_loss = 0.7942938208580017\n",
      "epoch n°202 : train_loss = 2.172530174255371, val_loss = 0.7968101501464844\n",
      "epoch n°203 : train_loss = 2.1847760677337646, val_loss = 0.8020145297050476\n",
      "epoch n°204 : train_loss = 2.1686651706695557, val_loss = 0.800853967666626\n",
      "epoch n°205 : train_loss = 2.1706700325012207, val_loss = 0.7966259717941284\n",
      "epoch n°206 : train_loss = 2.1694483757019043, val_loss = 0.7945753931999207\n",
      "epoch n°207 : train_loss = 2.177309036254883, val_loss = 0.7985960841178894\n",
      "epoch n°208 : train_loss = 2.163949489593506, val_loss = 0.7956603169441223\n",
      "epoch n°209 : train_loss = 2.1687569618225098, val_loss = 0.7996333837509155\n",
      "epoch n°210 : train_loss = 2.1721351146698, val_loss = 0.7967490553855896\n",
      "epoch n°211 : train_loss = 2.174590826034546, val_loss = 0.7927212119102478\n",
      "epoch n°212 : train_loss = 2.176140785217285, val_loss = 0.7967591285705566\n",
      "epoch n°213 : train_loss = 2.166060447692871, val_loss = 0.7990232110023499\n",
      "epoch n°214 : train_loss = 2.1685125827789307, val_loss = 0.7968626618385315\n",
      "epoch n°215 : train_loss = 2.171182632446289, val_loss = 0.8016676306724548\n",
      "epoch n°216 : train_loss = 2.1763243675231934, val_loss = 0.7943713068962097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°217 : train_loss = 2.164964437484741, val_loss = 0.7964461445808411\n",
      "epoch n°218 : train_loss = 2.1685073375701904, val_loss = 0.7924831509590149\n",
      "epoch n°219 : train_loss = 2.177841901779175, val_loss = 0.7966830134391785\n",
      "epoch n°220 : train_loss = 2.1617815494537354, val_loss = 0.7964267730712891\n",
      "epoch n°221 : train_loss = 2.167971611022949, val_loss = 0.795137882232666\n",
      "epoch n°222 : train_loss = 2.1667776107788086, val_loss = 0.7941673398017883\n",
      "epoch n°223 : train_loss = 2.1639537811279297, val_loss = 0.7903527021408081\n",
      "epoch n°224 : train_loss = 2.167325019836426, val_loss = 0.7972897887229919\n",
      "epoch n°225 : train_loss = 2.1676554679870605, val_loss = 0.795190155506134\n",
      "epoch n°226 : train_loss = 2.1697821617126465, val_loss = 0.7974259257316589\n",
      "epoch n°227 : train_loss = 2.1700024604797363, val_loss = 0.7925180196762085\n",
      "epoch n°228 : train_loss = 2.1640031337738037, val_loss = 0.7999800443649292\n",
      "epoch n°229 : train_loss = 2.1716418266296387, val_loss = 0.7943512201309204\n",
      "epoch n°230 : train_loss = 2.1749701499938965, val_loss = 0.7972005605697632\n",
      "epoch n°231 : train_loss = 2.169433832168579, val_loss = 0.7979638576507568\n",
      "epoch n°232 : train_loss = 2.1594858169555664, val_loss = 0.7968540787696838\n",
      "epoch n°233 : train_loss = 2.169856071472168, val_loss = 0.7960490584373474\n",
      "epoch n°234 : train_loss = 2.172177314758301, val_loss = 0.7929260730743408\n",
      "epoch n°235 : train_loss = 2.153759241104126, val_loss = 0.7940447926521301\n",
      "epoch n°236 : train_loss = 2.1715166568756104, val_loss = 0.7957606315612793\n",
      "epoch n°237 : train_loss = 2.165437698364258, val_loss = 0.7926335334777832\n",
      "epoch n°238 : train_loss = 2.16671085357666, val_loss = 0.7982717752456665\n",
      "epoch n°239 : train_loss = 2.1565403938293457, val_loss = 0.7946000695228577\n",
      "epoch n°240 : train_loss = 2.1777141094207764, val_loss = 0.7996821999549866\n",
      "epoch n°241 : train_loss = 2.185045003890991, val_loss = 0.796650230884552\n",
      "epoch n°242 : train_loss = 2.189378499984741, val_loss = 0.8018561005592346\n",
      "epoch n°243 : train_loss = 2.185272693634033, val_loss = 0.7993085384368896\n",
      "epoch n°244 : train_loss = 2.1867666244506836, val_loss = 0.7965116500854492\n",
      "epoch n°245 : train_loss = 2.18376088142395, val_loss = 0.7993413805961609\n",
      "epoch n°246 : train_loss = 2.1941723823547363, val_loss = 0.7960850596427917\n",
      "epoch n°247 : train_loss = 2.1924750804901123, val_loss = 0.7985740303993225\n",
      "epoch n°248 : train_loss = 2.1965153217315674, val_loss = 0.7934496402740479\n",
      "epoch n°249 : train_loss = 2.1838228702545166, val_loss = 0.8031741976737976\n",
      "epoch n°250 : train_loss = 2.1807823181152344, val_loss = 0.7960430383682251\n",
      "epoch n°251 : train_loss = 2.1930227279663086, val_loss = 0.8010168671607971\n",
      "epoch n°252 : train_loss = 2.1908538341522217, val_loss = 0.8017077445983887\n",
      "epoch n°253 : train_loss = 2.19132137298584, val_loss = 0.7973610758781433\n",
      "epoch n°254 : train_loss = 2.185134172439575, val_loss = 0.800913393497467\n",
      "epoch n°255 : train_loss = 2.1801490783691406, val_loss = 0.795861542224884\n",
      "epoch n°256 : train_loss = 2.1840126514434814, val_loss = 0.8004300594329834\n",
      "epoch n°257 : train_loss = 2.189075469970703, val_loss = 0.7987551093101501\n",
      "epoch n°258 : train_loss = 2.189122200012207, val_loss = 0.7975260615348816\n",
      "epoch n°259 : train_loss = 2.1852927207946777, val_loss = 0.8020315766334534\n",
      "epoch n°260 : train_loss = 2.187527894973755, val_loss = 0.7956420183181763\n",
      "epoch n°261 : train_loss = 2.187554359436035, val_loss = 0.8002312183380127\n",
      "epoch n°262 : train_loss = 2.1935205459594727, val_loss = 0.7977263331413269\n",
      "epoch n°263 : train_loss = 2.187631607055664, val_loss = 0.7984095811843872\n",
      "epoch n°264 : train_loss = 2.1848809719085693, val_loss = 0.8026195168495178\n",
      "epoch n°265 : train_loss = 2.188173532485962, val_loss = 0.8018269538879395\n",
      "epoch n°266 : train_loss = 2.184480905532837, val_loss = 0.8000780344009399\n",
      "epoch n°267 : train_loss = 2.1852123737335205, val_loss = 0.8001319169998169\n",
      "epoch n°268 : train_loss = 2.180736541748047, val_loss = 0.802276611328125\n",
      "epoch n°269 : train_loss = 2.179403781890869, val_loss = 0.7974686622619629\n",
      "epoch n°270 : train_loss = 2.1825337409973145, val_loss = 0.8012979030609131\n",
      "epoch n°271 : train_loss = 2.1917831897735596, val_loss = 0.797028124332428\n",
      "epoch n°272 : train_loss = 2.18514347076416, val_loss = 0.7979342937469482\n",
      "epoch n°273 : train_loss = 2.1868646144866943, val_loss = 0.8004015684127808\n",
      "epoch n°274 : train_loss = 2.189824342727661, val_loss = 0.79646897315979\n",
      "epoch n°275 : train_loss = 2.179936170578003, val_loss = 0.8009330630302429\n",
      "epoch n°276 : train_loss = 2.1771111488342285, val_loss = 0.7987368702888489\n",
      "epoch n°277 : train_loss = 2.19234299659729, val_loss = 0.8029480576515198\n",
      "epoch n°278 : train_loss = 2.1778724193573, val_loss = 0.795656681060791\n",
      "epoch n°279 : train_loss = 2.192917585372925, val_loss = 0.7973743081092834\n",
      "epoch n°280 : train_loss = 2.182577133178711, val_loss = 0.8011173009872437\n",
      "epoch n°281 : train_loss = 2.185227870941162, val_loss = 0.8007978796958923\n",
      "epoch n°282 : train_loss = 2.177018642425537, val_loss = 0.7978031635284424\n",
      "epoch n°283 : train_loss = 2.1901803016662598, val_loss = 0.7987203001976013\n",
      "epoch n°284 : train_loss = 2.1818864345550537, val_loss = 0.7983611226081848\n",
      "epoch n°285 : train_loss = 2.1832261085510254, val_loss = 0.7965933084487915\n",
      "epoch n°286 : train_loss = 2.1815576553344727, val_loss = 0.7962665557861328\n",
      "epoch n°287 : train_loss = 2.1835362911224365, val_loss = 0.7986146807670593\n",
      "epoch n°288 : train_loss = 2.182964563369751, val_loss = 0.79727703332901\n",
      "epoch n°289 : train_loss = 2.181666851043701, val_loss = 0.7987900972366333\n",
      "epoch n°290 : train_loss = 2.174703359603882, val_loss = 0.8012173175811768\n",
      "epoch n°291 : train_loss = 2.187382459640503, val_loss = 0.8010942339897156\n",
      "epoch n°292 : train_loss = 2.185224771499634, val_loss = 0.7980291843414307\n",
      "epoch n°293 : train_loss = 2.1936862468719482, val_loss = 0.7982969880104065\n",
      "epoch n°294 : train_loss = 2.1787378787994385, val_loss = 0.7990361452102661\n",
      "epoch n°295 : train_loss = 2.1746861934661865, val_loss = 0.8009804487228394\n",
      "epoch n°296 : train_loss = 2.1787984371185303, val_loss = 0.7959942817687988\n",
      "epoch n°297 : train_loss = 2.178866147994995, val_loss = 0.8001465201377869\n",
      "epoch n°298 : train_loss = 2.1683363914489746, val_loss = 0.795780599117279\n",
      "epoch n°299 : train_loss = 2.172262191772461, val_loss = 0.7965470552444458\n",
      "epoch n°300 : train_loss = 2.1725194454193115, val_loss = 0.799305260181427\n",
      "epoch n°301 : train_loss = 2.1753082275390625, val_loss = 0.8010593056678772\n",
      "epoch n°302 : train_loss = 2.173646926879883, val_loss = 0.8035040497779846\n",
      "epoch n°303 : train_loss = 2.172550678253174, val_loss = 0.8001394867897034\n",
      "epoch n°304 : train_loss = 2.174535036087036, val_loss = 0.8014407157897949\n",
      "epoch n°305 : train_loss = 2.1794071197509766, val_loss = 0.798947811126709\n",
      "epoch n°306 : train_loss = 2.170450210571289, val_loss = 0.7941363453865051\n",
      "epoch n°307 : train_loss = 2.172513246536255, val_loss = 0.8004890084266663\n",
      "epoch n°308 : train_loss = 2.1774275302886963, val_loss = 0.8045749664306641\n",
      "epoch n°309 : train_loss = 2.170773506164551, val_loss = 0.7929180860519409\n",
      "epoch n°310 : train_loss = 2.1719861030578613, val_loss = 0.7974191904067993\n",
      "epoch n°311 : train_loss = 2.172023296356201, val_loss = 0.7986940741539001\n",
      "epoch n°312 : train_loss = 2.1742172241210938, val_loss = 0.7986240983009338\n",
      "epoch n°313 : train_loss = 2.1742465496063232, val_loss = 0.7967699766159058\n",
      "epoch n°314 : train_loss = 2.172638416290283, val_loss = 0.7976409196853638\n",
      "epoch n°315 : train_loss = 2.160771131515503, val_loss = 0.792978048324585\n",
      "epoch n°316 : train_loss = 2.172330856323242, val_loss = 0.7972856163978577\n",
      "epoch n°317 : train_loss = 2.1632180213928223, val_loss = 0.7927570343017578\n",
      "epoch n°318 : train_loss = 2.1675703525543213, val_loss = 0.7974399924278259\n",
      "epoch n°319 : train_loss = 2.1698546409606934, val_loss = 0.7985303997993469\n",
      "epoch n°320 : train_loss = 2.174311399459839, val_loss = 0.7973041534423828\n",
      "epoch n°321 : train_loss = 2.1625776290893555, val_loss = 0.7965539693832397\n",
      "epoch n°322 : train_loss = 2.1610753536224365, val_loss = 0.7960281372070312\n",
      "epoch n°323 : train_loss = 2.1601221561431885, val_loss = 0.7964399456977844\n",
      "epoch n°324 : train_loss = 2.1688051223754883, val_loss = 0.7991511225700378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°325 : train_loss = 2.170844078063965, val_loss = 0.7925413250923157\n",
      "epoch n°326 : train_loss = 2.1630187034606934, val_loss = 0.7963082790374756\n",
      "epoch n°327 : train_loss = 2.1650102138519287, val_loss = 0.7952379584312439\n",
      "epoch n°328 : train_loss = 2.1694140434265137, val_loss = 0.7999599575996399\n",
      "epoch n°329 : train_loss = 2.162374496459961, val_loss = 0.7957209348678589\n",
      "epoch n°330 : train_loss = 2.170335292816162, val_loss = 0.7991862893104553\n",
      "epoch n°331 : train_loss = 2.1643879413604736, val_loss = 0.7967243790626526\n",
      "epoch n°332 : train_loss = 2.163628578186035, val_loss = 0.8007946610450745\n",
      "epoch n°333 : train_loss = 2.1668198108673096, val_loss = 0.7971087694168091\n",
      "epoch n°334 : train_loss = 2.1703054904937744, val_loss = 0.7969145178794861\n",
      "epoch n°335 : train_loss = 2.1613430976867676, val_loss = 0.801114559173584\n",
      "epoch n°336 : train_loss = 2.155878782272339, val_loss = 0.7956725358963013\n",
      "epoch n°337 : train_loss = 2.1701431274414062, val_loss = 0.7965765595436096\n",
      "epoch n°338 : train_loss = 2.168517827987671, val_loss = 0.7979324460029602\n",
      "epoch n°339 : train_loss = 2.1652722358703613, val_loss = 0.7967080473899841\n",
      "epoch n°340 : train_loss = 2.1663546562194824, val_loss = 0.7959201335906982\n",
      "epoch n°341 : train_loss = 2.162313461303711, val_loss = 0.7971398234367371\n",
      "epoch n°342 : train_loss = 2.167137384414673, val_loss = 0.7989771366119385\n",
      "epoch n°343 : train_loss = 2.151017665863037, val_loss = 0.7942874431610107\n",
      "epoch n°344 : train_loss = 2.1565232276916504, val_loss = 0.7988272905349731\n",
      "epoch n°345 : train_loss = 2.1528074741363525, val_loss = 0.7934526205062866\n",
      "epoch n°346 : train_loss = 2.1588144302368164, val_loss = 0.802802562713623\n",
      "epoch n°347 : train_loss = 2.1585304737091064, val_loss = 0.8005730509757996\n",
      "epoch n°348 : train_loss = 2.1554768085479736, val_loss = 0.7974990606307983\n",
      "epoch n°349 : train_loss = 2.158461332321167, val_loss = 0.7949617505073547\n",
      "epoch n°350 : train_loss = 2.1481847763061523, val_loss = 0.8001050353050232\n",
      "epoch n°351 : train_loss = 2.1424098014831543, val_loss = 0.7961117029190063\n",
      "epoch n°352 : train_loss = 2.153639554977417, val_loss = 0.7964695692062378\n",
      "epoch n°353 : train_loss = 2.154752492904663, val_loss = 0.7955898642539978\n",
      "epoch n°354 : train_loss = 2.1527059078216553, val_loss = 0.7920950055122375\n",
      "epoch n°355 : train_loss = 2.1576988697052, val_loss = 0.7942752838134766\n",
      "epoch n°356 : train_loss = 2.1618874073028564, val_loss = 0.794276773929596\n",
      "epoch n°357 : train_loss = 2.1573615074157715, val_loss = 0.8005785942077637\n",
      "epoch n°358 : train_loss = 2.149038076400757, val_loss = 0.7967099547386169\n",
      "epoch n°359 : train_loss = 2.1504688262939453, val_loss = 0.7942774295806885\n",
      "epoch n°360 : train_loss = 2.150385618209839, val_loss = 0.7970454692840576\n",
      "epoch n°361 : train_loss = 2.147017002105713, val_loss = 0.7985342144966125\n",
      "epoch n°362 : train_loss = 2.1578664779663086, val_loss = 0.7942324280738831\n",
      "epoch n°363 : train_loss = 2.1550724506378174, val_loss = 0.7968732714653015\n",
      "epoch n°364 : train_loss = 2.15511417388916, val_loss = 0.7956855297088623\n",
      "epoch n°365 : train_loss = 2.148897171020508, val_loss = 0.796613872051239\n",
      "epoch n°366 : train_loss = 2.1506526470184326, val_loss = 0.7968147993087769\n",
      "epoch n°367 : train_loss = 2.1522252559661865, val_loss = 0.7958351373672485\n",
      "epoch n°368 : train_loss = 2.1527159214019775, val_loss = 0.7953420877456665\n",
      "epoch n°369 : train_loss = 2.1463522911071777, val_loss = 0.7992516756057739\n",
      "epoch n°370 : train_loss = 2.1398210525512695, val_loss = 0.796707808971405\n",
      "epoch n°371 : train_loss = 2.156572103500366, val_loss = 0.795168399810791\n",
      "epoch n°372 : train_loss = 2.146676540374756, val_loss = 0.7942062020301819\n",
      "epoch n°373 : train_loss = 2.1488595008850098, val_loss = 0.7990548014640808\n",
      "epoch n°374 : train_loss = 2.1566014289855957, val_loss = 0.7925707101821899\n",
      "epoch n°375 : train_loss = 2.14436674118042, val_loss = 0.7942373752593994\n",
      "epoch n°376 : train_loss = 2.153977870941162, val_loss = 0.7934978008270264\n",
      "epoch n°377 : train_loss = 2.1520705223083496, val_loss = 0.7930232286453247\n",
      "epoch n°378 : train_loss = 2.1421542167663574, val_loss = 0.7967232465744019\n",
      "epoch n°379 : train_loss = 2.1507408618927, val_loss = 0.7975993156433105\n",
      "epoch n°380 : train_loss = 2.1427266597747803, val_loss = 0.7951186895370483\n",
      "epoch n°381 : train_loss = 2.146200180053711, val_loss = 0.7957190275192261\n",
      "epoch n°382 : train_loss = 2.1456613540649414, val_loss = 0.794218897819519\n",
      "epoch n°383 : train_loss = 2.139503002166748, val_loss = 0.7910080552101135\n",
      "epoch n°384 : train_loss = 2.153696298599243, val_loss = 0.7985477447509766\n",
      "epoch n°385 : train_loss = 2.1522953510284424, val_loss = 0.7986816763877869\n",
      "epoch n°386 : train_loss = 2.151378631591797, val_loss = 0.7905802130699158\n",
      "epoch n°387 : train_loss = 2.1374101638793945, val_loss = 0.7910104393959045\n",
      "epoch n°388 : train_loss = 2.140880823135376, val_loss = 0.7937437891960144\n",
      "epoch n°389 : train_loss = 2.134796619415283, val_loss = 0.7993786334991455\n",
      "epoch n°390 : train_loss = 2.1432571411132812, val_loss = 0.7967485189437866\n",
      "epoch n°391 : train_loss = 2.140505313873291, val_loss = 0.7973147034645081\n",
      "epoch n°392 : train_loss = 2.1344528198242188, val_loss = 0.7977104783058167\n",
      "epoch n°393 : train_loss = 2.1458804607391357, val_loss = 0.7946975231170654\n",
      "epoch n°394 : train_loss = 2.144465208053589, val_loss = 0.796839714050293\n",
      "epoch n°395 : train_loss = 2.1388516426086426, val_loss = 0.7968286275863647\n",
      "epoch n°396 : train_loss = 2.1394894123077393, val_loss = 0.7947936058044434\n",
      "epoch n°397 : train_loss = 2.1374704837799072, val_loss = 0.7922170758247375\n",
      "epoch n°398 : train_loss = 2.144070863723755, val_loss = 0.7943273186683655\n",
      "epoch n°399 : train_loss = 2.1509621143341064, val_loss = 0.7956129908561707\n",
      "epoch n°400 : train_loss = 2.1448044776916504, val_loss = 0.7928274869918823\n",
      "epoch n°401 : train_loss = 2.143267869949341, val_loss = 0.7938671708106995\n",
      "epoch n°402 : train_loss = 2.145515203475952, val_loss = 0.7984614968299866\n",
      "epoch n°403 : train_loss = 2.1338510513305664, val_loss = 0.797798216342926\n",
      "epoch n°404 : train_loss = 2.128664255142212, val_loss = 0.7947544455528259\n",
      "epoch n°405 : train_loss = 2.139518976211548, val_loss = 0.7965074777603149\n",
      "epoch n°406 : train_loss = 2.139465570449829, val_loss = 0.7955493927001953\n",
      "epoch n°407 : train_loss = 2.139657735824585, val_loss = 0.8016623854637146\n",
      "epoch n°408 : train_loss = 2.130640983581543, val_loss = 0.8011532425880432\n",
      "epoch n°409 : train_loss = 2.1322011947631836, val_loss = 0.7919915318489075\n",
      "epoch n°410 : train_loss = 2.131638765335083, val_loss = 0.796209990978241\n",
      "epoch n°411 : train_loss = 2.1388583183288574, val_loss = 0.7977682948112488\n",
      "epoch n°412 : train_loss = 2.140432596206665, val_loss = 0.7911330461502075\n",
      "epoch n°413 : train_loss = 2.1370797157287598, val_loss = 0.7896990180015564\n",
      "epoch n°414 : train_loss = 2.147421360015869, val_loss = 0.796295702457428\n",
      "epoch n°415 : train_loss = 2.1308770179748535, val_loss = 0.7947902083396912\n",
      "epoch n°416 : train_loss = 2.1379787921905518, val_loss = 0.7981390357017517\n",
      "epoch n°417 : train_loss = 2.1341757774353027, val_loss = 0.7940617799758911\n",
      "epoch n°418 : train_loss = 2.1317312717437744, val_loss = 0.7945042252540588\n",
      "epoch n°419 : train_loss = 2.136380910873413, val_loss = 0.7971290946006775\n",
      "epoch n°420 : train_loss = 2.135206699371338, val_loss = 0.7934327125549316\n",
      "epoch n°421 : train_loss = 2.133894205093384, val_loss = 0.7987228035926819\n",
      "epoch n°422 : train_loss = 2.137709140777588, val_loss = 0.7946198582649231\n",
      "epoch n°423 : train_loss = 2.131495952606201, val_loss = 0.7924159169197083\n",
      "epoch n°424 : train_loss = 2.1402995586395264, val_loss = 0.7923341989517212\n",
      "epoch n°425 : train_loss = 2.1367969512939453, val_loss = 0.793657124042511\n",
      "epoch n°426 : train_loss = 2.1287970542907715, val_loss = 0.7946571707725525\n",
      "epoch n°427 : train_loss = 2.1286511421203613, val_loss = 0.7934263348579407\n",
      "epoch n°428 : train_loss = 2.140933036804199, val_loss = 0.7922442555427551\n",
      "epoch n°429 : train_loss = 2.1349945068359375, val_loss = 0.7961428165435791\n",
      "epoch n°430 : train_loss = 2.136979818344116, val_loss = 0.7914307713508606\n",
      "epoch n°431 : train_loss = 2.136676788330078, val_loss = 0.7932454943656921\n",
      "epoch n°432 : train_loss = 2.1287341117858887, val_loss = 0.7954889535903931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°433 : train_loss = 2.134564161300659, val_loss = 0.795060396194458\n",
      "epoch n°434 : train_loss = 2.1393375396728516, val_loss = 0.794508695602417\n",
      "epoch n°435 : train_loss = 2.1227221488952637, val_loss = 0.7936189770698547\n",
      "epoch n°436 : train_loss = 2.125113010406494, val_loss = 0.798017680644989\n",
      "epoch n°437 : train_loss = 2.1252057552337646, val_loss = 0.7974850535392761\n",
      "epoch n°438 : train_loss = 2.129065990447998, val_loss = 0.7927441000938416\n",
      "epoch n°439 : train_loss = 2.131645441055298, val_loss = 0.7943243980407715\n",
      "epoch n°440 : train_loss = 2.1307482719421387, val_loss = 0.7909774780273438\n",
      "epoch n°441 : train_loss = 2.1272504329681396, val_loss = 0.7913808822631836\n",
      "epoch n°442 : train_loss = 2.1291346549987793, val_loss = 0.794945478439331\n",
      "epoch n°443 : train_loss = 2.1245803833007812, val_loss = 0.7950128316879272\n",
      "epoch n°444 : train_loss = 2.134723424911499, val_loss = 0.795994222164154\n",
      "epoch n°445 : train_loss = 2.1215362548828125, val_loss = 0.7931074500083923\n",
      "epoch n°446 : train_loss = 2.14261531829834, val_loss = 0.7954655289649963\n",
      "epoch n°447 : train_loss = 2.1384005546569824, val_loss = 0.7935077548027039\n",
      "epoch n°448 : train_loss = 2.127819061279297, val_loss = 0.7940914630889893\n",
      "epoch n°449 : train_loss = 2.13055682182312, val_loss = 0.796505331993103\n",
      "epoch n°450 : train_loss = 2.1359291076660156, val_loss = 0.7923737168312073\n",
      "epoch n°451 : train_loss = 2.124354839324951, val_loss = 0.7932870388031006\n",
      "epoch n°452 : train_loss = 2.1205878257751465, val_loss = 0.7986665964126587\n",
      "epoch n°453 : train_loss = 2.134044885635376, val_loss = 0.7977493405342102\n",
      "epoch n°454 : train_loss = 2.128479480743408, val_loss = 0.7923157215118408\n",
      "epoch n°455 : train_loss = 2.133086681365967, val_loss = 0.7923352122306824\n",
      "epoch n°456 : train_loss = 2.1222941875457764, val_loss = 0.7942180633544922\n",
      "epoch n°457 : train_loss = 2.1285295486450195, val_loss = 0.7944126129150391\n",
      "epoch n°458 : train_loss = 2.132093667984009, val_loss = 0.7958232164382935\n",
      "epoch n°459 : train_loss = 2.1225292682647705, val_loss = 0.7961074113845825\n",
      "epoch n°460 : train_loss = 2.123969078063965, val_loss = 0.793157160282135\n",
      "epoch n°461 : train_loss = 2.1323320865631104, val_loss = 0.7924078702926636\n",
      "epoch n°462 : train_loss = 2.1345651149749756, val_loss = 0.7928217649459839\n",
      "epoch n°463 : train_loss = 2.133884906768799, val_loss = 0.7888948917388916\n",
      "epoch n°464 : train_loss = 2.1293516159057617, val_loss = 0.796793520450592\n",
      "epoch n°465 : train_loss = 2.1333792209625244, val_loss = 0.7983884215354919\n",
      "epoch n°466 : train_loss = 2.1262569427490234, val_loss = 0.7914377450942993\n",
      "epoch n°467 : train_loss = 2.1312153339385986, val_loss = 0.7937257289886475\n",
      "epoch n°468 : train_loss = 2.121835947036743, val_loss = 0.7916158437728882\n",
      "epoch n°469 : train_loss = 2.1407253742218018, val_loss = 0.7960646152496338\n",
      "epoch n°470 : train_loss = 2.125354766845703, val_loss = 0.7934694290161133\n",
      "epoch n°471 : train_loss = 2.1249639987945557, val_loss = 0.7932012677192688\n",
      "epoch n°472 : train_loss = 2.1274056434631348, val_loss = 0.7910178899765015\n",
      "epoch n°473 : train_loss = 2.1304681301116943, val_loss = 0.7930156588554382\n",
      "epoch n°474 : train_loss = 2.126770496368408, val_loss = 0.792279839515686\n",
      "epoch n°475 : train_loss = 2.1264140605926514, val_loss = 0.7910029292106628\n",
      "epoch n°476 : train_loss = 2.1277008056640625, val_loss = 0.7961652874946594\n",
      "epoch n°477 : train_loss = 2.120898485183716, val_loss = 0.793176531791687\n",
      "epoch n°478 : train_loss = 2.1310956478118896, val_loss = 0.7950989603996277\n",
      "epoch n°479 : train_loss = 2.1211845874786377, val_loss = 0.7957802414894104\n",
      "epoch n°480 : train_loss = 2.1314663887023926, val_loss = 0.7983695864677429\n",
      "epoch n°481 : train_loss = 2.131937265396118, val_loss = 0.7929656505584717\n",
      "epoch n°482 : train_loss = 2.1312272548675537, val_loss = 0.7990459203720093\n",
      "epoch n°483 : train_loss = 2.134124755859375, val_loss = 0.7976215481758118\n",
      "epoch n°484 : train_loss = 2.124788999557495, val_loss = 0.7943134307861328\n",
      "epoch n°485 : train_loss = 2.1279168128967285, val_loss = 0.7983205914497375\n",
      "epoch n°486 : train_loss = 2.134298324584961, val_loss = 0.7904239892959595\n",
      "epoch n°487 : train_loss = 2.1244678497314453, val_loss = 0.7918207049369812\n",
      "epoch n°488 : train_loss = 2.130016326904297, val_loss = 0.7965918779373169\n",
      "epoch n°489 : train_loss = 2.1291768550872803, val_loss = 0.7951614856719971\n",
      "epoch n°490 : train_loss = 2.1336212158203125, val_loss = 0.7967647910118103\n",
      "epoch n°491 : train_loss = 2.125586986541748, val_loss = 0.7953115701675415\n",
      "epoch n°492 : train_loss = 2.1275742053985596, val_loss = 0.7957134246826172\n",
      "epoch n°493 : train_loss = 2.129244089126587, val_loss = 0.7946166396141052\n",
      "epoch n°494 : train_loss = 2.1216111183166504, val_loss = 0.7974948287010193\n",
      "epoch n°495 : train_loss = 2.129673957824707, val_loss = 0.7901867628097534\n",
      "epoch n°496 : train_loss = 2.136763095855713, val_loss = 0.7949144840240479\n",
      "epoch n°497 : train_loss = 2.1527981758117676, val_loss = 0.7934157848358154\n",
      "epoch n°498 : train_loss = 2.157559871673584, val_loss = 0.7991319894790649\n",
      "epoch n°499 : train_loss = 2.1454086303710938, val_loss = 0.8024454712867737\n",
      "epoch n°500 : train_loss = 2.1556856632232666, val_loss = 0.800701379776001\n",
      "epoch n°501 : train_loss = 2.1526103019714355, val_loss = 0.799656093120575\n",
      "epoch n°502 : train_loss = 2.159301996231079, val_loss = 0.7989317774772644\n",
      "epoch n°503 : train_loss = 2.1450912952423096, val_loss = 0.7968996167182922\n",
      "epoch n°504 : train_loss = 2.142592668533325, val_loss = 0.8001846671104431\n",
      "epoch n°505 : train_loss = 2.148439645767212, val_loss = 0.8013988733291626\n",
      "epoch n°506 : train_loss = 2.144641876220703, val_loss = 0.793846607208252\n",
      "epoch n°507 : train_loss = 2.158761739730835, val_loss = 0.7974317073822021\n",
      "epoch n°508 : train_loss = 2.1534523963928223, val_loss = 0.8006638288497925\n",
      "epoch n°509 : train_loss = 2.1487464904785156, val_loss = 0.7958171963691711\n",
      "epoch n°510 : train_loss = 2.1519992351531982, val_loss = 0.7953144311904907\n",
      "epoch n°511 : train_loss = 2.1502442359924316, val_loss = 0.7947421073913574\n",
      "epoch n°512 : train_loss = 2.149322748184204, val_loss = 0.8017635345458984\n",
      "epoch n°513 : train_loss = 2.1535747051239014, val_loss = 0.8020401000976562\n",
      "epoch n°514 : train_loss = 2.1604228019714355, val_loss = 0.7991300821304321\n",
      "epoch n°515 : train_loss = 2.162904977798462, val_loss = 0.7972868084907532\n",
      "epoch n°516 : train_loss = 2.1550490856170654, val_loss = 0.7960205674171448\n",
      "epoch n°517 : train_loss = 2.142843246459961, val_loss = 0.8002124428749084\n",
      "epoch n°518 : train_loss = 2.144744634628296, val_loss = 0.8014854192733765\n",
      "epoch n°519 : train_loss = 2.153611898422241, val_loss = 0.8036405444145203\n",
      "epoch n°520 : train_loss = 2.149573802947998, val_loss = 0.7981285452842712\n",
      "epoch n°521 : train_loss = 2.153085708618164, val_loss = 0.8009565472602844\n",
      "epoch n°522 : train_loss = 2.1542088985443115, val_loss = 0.7962521314620972\n",
      "epoch n°523 : train_loss = 2.1544106006622314, val_loss = 0.7981463074684143\n",
      "epoch n°524 : train_loss = 2.1555888652801514, val_loss = 0.7936269044876099\n",
      "epoch n°525 : train_loss = 2.1599316596984863, val_loss = 0.7950688004493713\n",
      "epoch n°526 : train_loss = 2.1532504558563232, val_loss = 0.794118344783783\n",
      "epoch n°527 : train_loss = 2.159196138381958, val_loss = 0.7975202798843384\n",
      "epoch n°528 : train_loss = 2.1587533950805664, val_loss = 0.7997404932975769\n",
      "epoch n°529 : train_loss = 2.1533634662628174, val_loss = 0.7982887625694275\n",
      "epoch n°530 : train_loss = 2.143432855606079, val_loss = 0.7998462319374084\n",
      "epoch n°531 : train_loss = 2.14609432220459, val_loss = 0.7997997999191284\n",
      "epoch n°532 : train_loss = 2.1497268676757812, val_loss = 0.7975666522979736\n",
      "epoch n°533 : train_loss = 2.146193027496338, val_loss = 0.7967575788497925\n",
      "epoch n°534 : train_loss = 2.1535418033599854, val_loss = 0.7970943450927734\n",
      "epoch n°535 : train_loss = 2.1559436321258545, val_loss = 0.7998400330543518\n",
      "epoch n°536 : train_loss = 2.149630069732666, val_loss = 0.7987739443778992\n",
      "epoch n°537 : train_loss = 2.1518709659576416, val_loss = 0.8008771538734436\n",
      "epoch n°538 : train_loss = 2.15012526512146, val_loss = 0.7957670092582703\n",
      "epoch n°539 : train_loss = 2.152369737625122, val_loss = 0.8003906011581421\n",
      "epoch n°540 : train_loss = 2.1459429264068604, val_loss = 0.8015810251235962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°541 : train_loss = 2.1503310203552246, val_loss = 0.7957137823104858\n",
      "epoch n°542 : train_loss = 2.1441502571105957, val_loss = 0.7969171404838562\n",
      "epoch n°543 : train_loss = 2.1451189517974854, val_loss = 0.7967893481254578\n",
      "epoch n°544 : train_loss = 2.1446499824523926, val_loss = 0.8011394739151001\n",
      "epoch n°545 : train_loss = 2.145958423614502, val_loss = 0.7959136962890625\n",
      "epoch n°546 : train_loss = 2.1519837379455566, val_loss = 0.7980996966362\n",
      "epoch n°547 : train_loss = 2.148897409439087, val_loss = 0.794563889503479\n",
      "epoch n°548 : train_loss = 2.16215443611145, val_loss = 0.8000584244728088\n",
      "epoch n°549 : train_loss = 2.1601579189300537, val_loss = 0.7988405227661133\n",
      "epoch n°550 : train_loss = 2.151627779006958, val_loss = 0.8016908168792725\n",
      "epoch n°551 : train_loss = 2.1486260890960693, val_loss = 0.7973856329917908\n",
      "epoch n°552 : train_loss = 2.145580768585205, val_loss = 0.7984769940376282\n",
      "epoch n°553 : train_loss = 2.150256395339966, val_loss = 0.7993171215057373\n",
      "epoch n°554 : train_loss = 2.1485867500305176, val_loss = 0.7963346242904663\n",
      "epoch n°555 : train_loss = 2.1440789699554443, val_loss = 0.7942923903465271\n",
      "epoch n°556 : train_loss = 2.144197702407837, val_loss = 0.7976511120796204\n",
      "epoch n°557 : train_loss = 2.1392362117767334, val_loss = 0.7971353530883789\n",
      "epoch n°558 : train_loss = 2.1465940475463867, val_loss = 0.7944086790084839\n",
      "epoch n°559 : train_loss = 2.1566665172576904, val_loss = 0.8016700744628906\n",
      "epoch n°560 : train_loss = 2.149792194366455, val_loss = 0.8000051379203796\n",
      "epoch n°561 : train_loss = 2.152475595474243, val_loss = 0.7994475960731506\n",
      "epoch n°562 : train_loss = 2.1462252140045166, val_loss = 0.7988576889038086\n",
      "epoch n°563 : train_loss = 2.14958119392395, val_loss = 0.8000347018241882\n",
      "epoch n°564 : train_loss = 2.15702486038208, val_loss = 0.8020679354667664\n",
      "epoch n°565 : train_loss = 2.156625509262085, val_loss = 0.7940937280654907\n",
      "epoch n°566 : train_loss = 2.141951322555542, val_loss = 0.8014241456985474\n",
      "epoch n°567 : train_loss = 2.1423044204711914, val_loss = 0.7969905138015747\n",
      "epoch n°568 : train_loss = 2.1491293907165527, val_loss = 0.7948448657989502\n",
      "epoch n°569 : train_loss = 2.1403303146362305, val_loss = 0.7944449186325073\n",
      "epoch n°570 : train_loss = 2.146000623703003, val_loss = 0.7979260683059692\n",
      "epoch n°571 : train_loss = 2.1449055671691895, val_loss = 0.7978003025054932\n",
      "epoch n°572 : train_loss = 2.137655258178711, val_loss = 0.7989494204521179\n",
      "epoch n°573 : train_loss = 2.1417105197906494, val_loss = 0.7970592975616455\n",
      "epoch n°574 : train_loss = 2.1451058387756348, val_loss = 0.7997991442680359\n",
      "epoch n°575 : train_loss = 2.1502506732940674, val_loss = 0.7991368174552917\n",
      "epoch n°576 : train_loss = 2.141040325164795, val_loss = 0.7956140637397766\n",
      "epoch n°577 : train_loss = 2.1442723274230957, val_loss = 0.7964475750923157\n",
      "epoch n°578 : train_loss = 2.1514039039611816, val_loss = 0.7962529063224792\n",
      "epoch n°579 : train_loss = 2.146895170211792, val_loss = 0.7987476587295532\n",
      "epoch n°580 : train_loss = 2.1305973529815674, val_loss = 0.8038877248764038\n",
      "epoch n°581 : train_loss = 2.137237310409546, val_loss = 0.794068455696106\n",
      "epoch n°582 : train_loss = 2.1422276496887207, val_loss = 0.7976649403572083\n",
      "epoch n°583 : train_loss = 2.149571418762207, val_loss = 0.7946850657463074\n",
      "epoch n°584 : train_loss = 2.1297943592071533, val_loss = 0.7992351055145264\n",
      "epoch n°585 : train_loss = 2.138213872909546, val_loss = 0.7979329228401184\n",
      "epoch n°586 : train_loss = 2.143226146697998, val_loss = 0.7963640093803406\n",
      "epoch n°587 : train_loss = 2.137810230255127, val_loss = 0.7977142930030823\n",
      "epoch n°588 : train_loss = 2.1441280841827393, val_loss = 0.7991234660148621\n",
      "epoch n°589 : train_loss = 2.138427495956421, val_loss = 0.7960272431373596\n",
      "epoch n°590 : train_loss = 2.1427581310272217, val_loss = 0.7982223629951477\n",
      "epoch n°591 : train_loss = 2.1374902725219727, val_loss = 0.7982653379440308\n",
      "epoch n°592 : train_loss = 2.141011953353882, val_loss = 0.7957629561424255\n",
      "epoch n°593 : train_loss = 2.143174648284912, val_loss = 0.7948102951049805\n",
      "epoch n°594 : train_loss = 2.141495943069458, val_loss = 0.8006750345230103\n",
      "epoch n°595 : train_loss = 2.1459386348724365, val_loss = 0.7992292642593384\n",
      "epoch n°596 : train_loss = 2.131831169128418, val_loss = 0.796008825302124\n",
      "epoch n°597 : train_loss = 2.146355152130127, val_loss = 0.7963694930076599\n",
      "epoch n°598 : train_loss = 2.1439356803894043, val_loss = 0.7991330623626709\n",
      "epoch n°599 : train_loss = 2.138388156890869, val_loss = 0.7988045811653137\n",
      "epoch n°600 : train_loss = 2.140516757965088, val_loss = 0.7957697510719299\n",
      "epoch n°601 : train_loss = 2.1419663429260254, val_loss = 0.7992672920227051\n",
      "epoch n°602 : train_loss = 2.1394946575164795, val_loss = 0.7979728579521179\n",
      "epoch n°603 : train_loss = 2.138829231262207, val_loss = 0.7937905788421631\n",
      "epoch n°604 : train_loss = 2.1408591270446777, val_loss = 0.7962852120399475\n",
      "epoch n°605 : train_loss = 2.143178701400757, val_loss = 0.7944114208221436\n",
      "epoch n°606 : train_loss = 2.138873338699341, val_loss = 0.7965720891952515\n",
      "epoch n°607 : train_loss = 2.1328485012054443, val_loss = 0.7936837673187256\n",
      "epoch n°608 : train_loss = 2.1393916606903076, val_loss = 0.7958407402038574\n",
      "epoch n°609 : train_loss = 2.1480259895324707, val_loss = 0.7964927554130554\n",
      "epoch n°610 : train_loss = 2.1378536224365234, val_loss = 0.7959131002426147\n",
      "epoch n°611 : train_loss = 2.133777379989624, val_loss = 0.799589216709137\n",
      "epoch n°612 : train_loss = 2.1378533840179443, val_loss = 0.796599805355072\n",
      "epoch n°613 : train_loss = 2.1425273418426514, val_loss = 0.7957203984260559\n",
      "epoch n°614 : train_loss = 2.1414740085601807, val_loss = 0.796147882938385\n",
      "epoch n°615 : train_loss = 2.1275570392608643, val_loss = 0.7948918342590332\n",
      "epoch n°616 : train_loss = 2.1428654193878174, val_loss = 0.7970707416534424\n",
      "epoch n°617 : train_loss = 2.137648820877075, val_loss = 0.7956407070159912\n",
      "epoch n°618 : train_loss = 2.1311404705047607, val_loss = 0.7977624535560608\n",
      "epoch n°619 : train_loss = 2.1390695571899414, val_loss = 0.7891865968704224\n",
      "epoch n°620 : train_loss = 2.141643524169922, val_loss = 0.794317901134491\n",
      "epoch n°621 : train_loss = 2.1317083835601807, val_loss = 0.7994652986526489\n",
      "epoch n°622 : train_loss = 2.135146141052246, val_loss = 0.7967979907989502\n",
      "epoch n°623 : train_loss = 2.1297144889831543, val_loss = 0.7941645979881287\n",
      "epoch n°624 : train_loss = 2.136219024658203, val_loss = 0.7954123020172119\n",
      "epoch n°625 : train_loss = 2.1385786533355713, val_loss = 0.796307384967804\n",
      "epoch n°626 : train_loss = 2.1330313682556152, val_loss = 0.7936614155769348\n",
      "epoch n°627 : train_loss = 2.1347908973693848, val_loss = 0.7925359010696411\n",
      "epoch n°628 : train_loss = 2.134869337081909, val_loss = 0.8004636168479919\n",
      "epoch n°629 : train_loss = 2.133180618286133, val_loss = 0.7981182336807251\n",
      "epoch n°630 : train_loss = 2.1289827823638916, val_loss = 0.7958297729492188\n",
      "epoch n°631 : train_loss = 2.1334023475646973, val_loss = 0.7970591187477112\n",
      "epoch n°632 : train_loss = 2.135071277618408, val_loss = 0.797871470451355\n",
      "epoch n°633 : train_loss = 2.136561393737793, val_loss = 0.7966508865356445\n",
      "epoch n°634 : train_loss = 2.1347920894622803, val_loss = 0.7948064208030701\n",
      "epoch n°635 : train_loss = 2.135425567626953, val_loss = 0.7959339022636414\n",
      "epoch n°636 : train_loss = 2.138709545135498, val_loss = 0.7970836758613586\n",
      "epoch n°637 : train_loss = 2.1395602226257324, val_loss = 0.7986234426498413\n",
      "epoch n°638 : train_loss = 2.128666639328003, val_loss = 0.7962479591369629\n",
      "epoch n°639 : train_loss = 2.1381711959838867, val_loss = 0.7965793609619141\n",
      "epoch n°640 : train_loss = 2.1376564502716064, val_loss = 0.7915418148040771\n",
      "epoch n°641 : train_loss = 2.125647783279419, val_loss = 0.794585108757019\n",
      "epoch n°642 : train_loss = 2.1327834129333496, val_loss = 0.7937222719192505\n",
      "epoch n°643 : train_loss = 2.144742727279663, val_loss = 0.7970460057258606\n",
      "epoch n°644 : train_loss = 2.140532970428467, val_loss = 0.7957845330238342\n",
      "epoch n°645 : train_loss = 2.1284618377685547, val_loss = 0.7949729561805725\n",
      "epoch n°646 : train_loss = 2.128981113433838, val_loss = 0.7963038086891174\n",
      "epoch n°647 : train_loss = 2.126575231552124, val_loss = 0.7973256707191467\n",
      "epoch n°648 : train_loss = 2.13000226020813, val_loss = 0.79901123046875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°649 : train_loss = 2.1303791999816895, val_loss = 0.8002824187278748\n",
      "epoch n°650 : train_loss = 2.1319453716278076, val_loss = 0.7975820899009705\n",
      "epoch n°651 : train_loss = 2.132533550262451, val_loss = 0.7994584441184998\n",
      "epoch n°652 : train_loss = 2.130791664123535, val_loss = 0.7956908345222473\n",
      "epoch n°653 : train_loss = 2.1364810466766357, val_loss = 0.7974616289138794\n",
      "epoch n°654 : train_loss = 2.1301305294036865, val_loss = 0.7976738810539246\n",
      "epoch n°655 : train_loss = 2.126800537109375, val_loss = 0.7918621301651001\n",
      "epoch n°656 : train_loss = 2.1201705932617188, val_loss = 0.7955260276794434\n",
      "epoch n°657 : train_loss = 2.1267447471618652, val_loss = 0.7986381649971008\n",
      "epoch n°658 : train_loss = 2.1321308612823486, val_loss = 0.795946478843689\n",
      "epoch n°659 : train_loss = 2.1261467933654785, val_loss = 0.7923848032951355\n",
      "epoch n°660 : train_loss = 2.125624418258667, val_loss = 0.7985841035842896\n",
      "epoch n°661 : train_loss = 2.132521867752075, val_loss = 0.7926510572433472\n",
      "epoch n°662 : train_loss = 2.123837947845459, val_loss = 0.797580361366272\n",
      "epoch n°663 : train_loss = 2.1260430812835693, val_loss = 0.8001419901847839\n",
      "epoch n°664 : train_loss = 2.121674060821533, val_loss = 0.8002590537071228\n",
      "epoch n°665 : train_loss = 2.1277449131011963, val_loss = 0.7952449917793274\n",
      "epoch n°666 : train_loss = 2.127485990524292, val_loss = 0.8010417819023132\n",
      "epoch n°667 : train_loss = 2.123427391052246, val_loss = 0.7973974943161011\n",
      "epoch n°668 : train_loss = 2.135936737060547, val_loss = 0.7980992794036865\n",
      "epoch n°669 : train_loss = 2.128182888031006, val_loss = 0.7932642102241516\n",
      "epoch n°670 : train_loss = 2.128439426422119, val_loss = 0.7962653636932373\n",
      "epoch n°671 : train_loss = 2.1174066066741943, val_loss = 0.7942172884941101\n",
      "epoch n°672 : train_loss = 2.1261649131774902, val_loss = 0.7946100831031799\n",
      "epoch n°673 : train_loss = 2.127565860748291, val_loss = 0.7943434715270996\n",
      "epoch n°674 : train_loss = 2.131972312927246, val_loss = 0.798823356628418\n",
      "epoch n°675 : train_loss = 2.1265008449554443, val_loss = 0.7947085499763489\n",
      "epoch n°676 : train_loss = 2.1217005252838135, val_loss = 0.7998327612876892\n",
      "epoch n°677 : train_loss = 2.127943277359009, val_loss = 0.7967387437820435\n",
      "epoch n°678 : train_loss = 2.120840072631836, val_loss = 0.7993833422660828\n",
      "epoch n°679 : train_loss = 2.1253762245178223, val_loss = 0.7952954173088074\n",
      "epoch n°680 : train_loss = 2.1207759380340576, val_loss = 0.7949278950691223\n",
      "epoch n°681 : train_loss = 2.116877794265747, val_loss = 0.7960770726203918\n",
      "epoch n°682 : train_loss = 2.1204276084899902, val_loss = 0.7955406904220581\n",
      "epoch n°683 : train_loss = 2.1235806941986084, val_loss = 0.7986311316490173\n",
      "epoch n°684 : train_loss = 2.126467704772949, val_loss = 0.7952513694763184\n",
      "epoch n°685 : train_loss = 2.1189231872558594, val_loss = 0.7943658828735352\n",
      "epoch n°686 : train_loss = 2.114781379699707, val_loss = 0.7939943671226501\n",
      "epoch n°687 : train_loss = 2.1166372299194336, val_loss = 0.7984606027603149\n",
      "epoch n°688 : train_loss = 2.1200554370880127, val_loss = 0.7918781638145447\n",
      "epoch n°689 : train_loss = 2.11993408203125, val_loss = 0.7959268689155579\n",
      "epoch n°690 : train_loss = 2.1274023056030273, val_loss = 0.7959665656089783\n",
      "epoch n°691 : train_loss = 2.122976779937744, val_loss = 0.793078601360321\n",
      "epoch n°692 : train_loss = 2.1222567558288574, val_loss = 0.7981263399124146\n",
      "epoch n°693 : train_loss = 2.1219353675842285, val_loss = 0.7983086705207825\n",
      "epoch n°694 : train_loss = 2.1192307472229004, val_loss = 0.7938193678855896\n",
      "epoch n°695 : train_loss = 2.1240596771240234, val_loss = 0.7949686646461487\n",
      "epoch n°696 : train_loss = 2.1252787113189697, val_loss = 0.7950146794319153\n",
      "epoch n°697 : train_loss = 2.115133285522461, val_loss = 0.7988499999046326\n",
      "epoch n°698 : train_loss = 2.113887071609497, val_loss = 0.7988214492797852\n",
      "epoch n°699 : train_loss = 2.1118977069854736, val_loss = 0.7937332391738892\n",
      "epoch n°700 : train_loss = 2.112276554107666, val_loss = 0.8013424873352051\n",
      "epoch n°701 : train_loss = 2.1113085746765137, val_loss = 0.7947776317596436\n",
      "epoch n°702 : train_loss = 2.1251299381256104, val_loss = 0.8007993102073669\n",
      "epoch n°703 : train_loss = 2.116382360458374, val_loss = 0.7982457876205444\n",
      "epoch n°704 : train_loss = 2.1161365509033203, val_loss = 0.7954552173614502\n",
      "epoch n°705 : train_loss = 2.1169004440307617, val_loss = 0.7930048704147339\n",
      "epoch n°706 : train_loss = 2.12227725982666, val_loss = 0.7986984848976135\n",
      "epoch n°707 : train_loss = 2.1266729831695557, val_loss = 0.7928241491317749\n",
      "epoch n°708 : train_loss = 2.1254467964172363, val_loss = 0.796694815158844\n",
      "epoch n°709 : train_loss = 2.1224021911621094, val_loss = 0.7920130491256714\n",
      "epoch n°710 : train_loss = 2.126141309738159, val_loss = 0.7964344620704651\n",
      "epoch n°711 : train_loss = 2.110001802444458, val_loss = 0.7901474833488464\n",
      "epoch n°712 : train_loss = 2.123645544052124, val_loss = 0.7950242757797241\n",
      "epoch n°713 : train_loss = 2.1195220947265625, val_loss = 0.7976710200309753\n",
      "epoch n°714 : train_loss = 2.106879949569702, val_loss = 0.7970434427261353\n",
      "epoch n°715 : train_loss = 2.115051746368408, val_loss = 0.7961510419845581\n",
      "epoch n°716 : train_loss = 2.1231689453125, val_loss = 0.7963936924934387\n",
      "epoch n°717 : train_loss = 2.117819309234619, val_loss = 0.7948586344718933\n",
      "epoch n°718 : train_loss = 2.118131160736084, val_loss = 0.7958110570907593\n",
      "epoch n°719 : train_loss = 2.1126503944396973, val_loss = 0.8016313910484314\n",
      "epoch n°720 : train_loss = 2.10959529876709, val_loss = 0.7995284199714661\n",
      "epoch n°721 : train_loss = 2.109250068664551, val_loss = 0.7948166728019714\n",
      "epoch n°722 : train_loss = 2.1138455867767334, val_loss = 0.7974696755409241\n",
      "epoch n°723 : train_loss = 2.113734483718872, val_loss = 0.7975339889526367\n",
      "epoch n°724 : train_loss = 2.113069534301758, val_loss = 0.8000566363334656\n",
      "epoch n°725 : train_loss = 2.1133084297180176, val_loss = 0.7975829839706421\n",
      "epoch n°726 : train_loss = 2.1172657012939453, val_loss = 0.7975339889526367\n",
      "epoch n°727 : train_loss = 2.1161441802978516, val_loss = 0.7987679839134216\n",
      "epoch n°728 : train_loss = 2.116649627685547, val_loss = 0.7979580163955688\n",
      "epoch n°729 : train_loss = 2.1015217304229736, val_loss = 0.7959333658218384\n",
      "epoch n°730 : train_loss = 2.1094412803649902, val_loss = 0.7968035340309143\n",
      "epoch n°731 : train_loss = 2.1080541610717773, val_loss = 0.7982908487319946\n",
      "epoch n°732 : train_loss = 2.1106817722320557, val_loss = 0.7972115278244019\n",
      "epoch n°733 : train_loss = 2.114527940750122, val_loss = 0.7979217767715454\n",
      "epoch n°734 : train_loss = 2.10904598236084, val_loss = 0.7964423298835754\n",
      "epoch n°735 : train_loss = 2.1117544174194336, val_loss = 0.7990732192993164\n",
      "epoch n°736 : train_loss = 2.111567974090576, val_loss = 0.7978636622428894\n",
      "epoch n°737 : train_loss = 2.1121740341186523, val_loss = 0.7968868613243103\n",
      "epoch n°738 : train_loss = 2.104973316192627, val_loss = 0.7971530556678772\n",
      "epoch n°739 : train_loss = 2.109579086303711, val_loss = 0.7966499924659729\n",
      "epoch n°740 : train_loss = 2.113560676574707, val_loss = 0.7975931167602539\n",
      "epoch n°741 : train_loss = 2.113513946533203, val_loss = 0.7911915183067322\n",
      "epoch n°742 : train_loss = 2.1101255416870117, val_loss = 0.7969797253608704\n",
      "epoch n°743 : train_loss = 2.110962152481079, val_loss = 0.7956283688545227\n",
      "epoch n°744 : train_loss = 2.1158034801483154, val_loss = 0.7944504022598267\n",
      "epoch n°745 : train_loss = 2.104243516921997, val_loss = 0.7976638078689575\n",
      "epoch n°746 : train_loss = 2.1054511070251465, val_loss = 0.797208845615387\n",
      "epoch n°747 : train_loss = 2.1058382987976074, val_loss = 0.7988183498382568\n",
      "epoch n°748 : train_loss = 2.111280918121338, val_loss = 0.7942036986351013\n",
      "epoch n°749 : train_loss = 2.1123204231262207, val_loss = 0.7867001295089722\n",
      "epoch n°750 : train_loss = 2.108947992324829, val_loss = 0.7968925833702087\n",
      "epoch n°751 : train_loss = 2.1162803173065186, val_loss = 0.7926825284957886\n",
      "epoch n°752 : train_loss = 2.107023239135742, val_loss = 0.7942563891410828\n",
      "epoch n°753 : train_loss = 2.104733467102051, val_loss = 0.7930377125740051\n",
      "epoch n°754 : train_loss = 2.1089866161346436, val_loss = 0.79901123046875\n",
      "epoch n°755 : train_loss = 2.1039035320281982, val_loss = 0.7959646582603455\n",
      "epoch n°756 : train_loss = 2.107046127319336, val_loss = 0.7889865040779114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°757 : train_loss = 2.112431526184082, val_loss = 0.7959250211715698\n",
      "epoch n°758 : train_loss = 2.1150624752044678, val_loss = 0.7949783802032471\n",
      "epoch n°759 : train_loss = 2.106018304824829, val_loss = 0.7940213680267334\n",
      "epoch n°760 : train_loss = 2.1020054817199707, val_loss = 0.7913523316383362\n",
      "epoch n°761 : train_loss = 2.1078286170959473, val_loss = 0.7940971851348877\n",
      "epoch n°762 : train_loss = 2.1164636611938477, val_loss = 0.795708954334259\n",
      "epoch n°763 : train_loss = 2.0963404178619385, val_loss = 0.7925156950950623\n",
      "epoch n°764 : train_loss = 2.0967540740966797, val_loss = 0.7976400852203369\n",
      "epoch n°765 : train_loss = 2.1064279079437256, val_loss = 0.7906830310821533\n",
      "epoch n°766 : train_loss = 2.1014325618743896, val_loss = 0.7972185611724854\n",
      "epoch n°767 : train_loss = 2.108130931854248, val_loss = 0.790743887424469\n",
      "epoch n°768 : train_loss = 2.1039376258850098, val_loss = 0.7979441285133362\n",
      "epoch n°769 : train_loss = 2.1048591136932373, val_loss = 0.7950937747955322\n",
      "epoch n°770 : train_loss = 2.1112046241760254, val_loss = 0.7958165407180786\n",
      "epoch n°771 : train_loss = 2.106696605682373, val_loss = 0.7917612195014954\n",
      "epoch n°772 : train_loss = 2.100501775741577, val_loss = 0.7971445322036743\n",
      "epoch n°773 : train_loss = 2.1038074493408203, val_loss = 0.7978522181510925\n",
      "epoch n°774 : train_loss = 2.1031460762023926, val_loss = 0.794241726398468\n",
      "epoch n°775 : train_loss = 2.1049981117248535, val_loss = 0.7947574257850647\n",
      "epoch n°776 : train_loss = 2.107837438583374, val_loss = 0.7941147089004517\n",
      "epoch n°777 : train_loss = 2.104433536529541, val_loss = 0.7980959415435791\n",
      "epoch n°778 : train_loss = 2.112301826477051, val_loss = 0.7922248244285583\n",
      "epoch n°779 : train_loss = 2.0964114665985107, val_loss = 0.7979714870452881\n",
      "epoch n°780 : train_loss = 2.1145553588867188, val_loss = 0.7991327047348022\n",
      "epoch n°781 : train_loss = 2.106597423553467, val_loss = 0.7987212538719177\n",
      "epoch n°782 : train_loss = 2.1011645793914795, val_loss = 0.7965760827064514\n",
      "epoch n°783 : train_loss = 2.103672742843628, val_loss = 0.7945607900619507\n",
      "epoch n°784 : train_loss = 2.102945566177368, val_loss = 0.7944760322570801\n",
      "epoch n°785 : train_loss = 2.094099283218384, val_loss = 0.7946052551269531\n",
      "epoch n°786 : train_loss = 2.1011579036712646, val_loss = 0.7914893627166748\n",
      "epoch n°787 : train_loss = 2.1000754833221436, val_loss = 0.7935686111450195\n",
      "epoch n°788 : train_loss = 2.1022748947143555, val_loss = 0.7949252724647522\n",
      "epoch n°789 : train_loss = 2.1021251678466797, val_loss = 0.7937439680099487\n",
      "epoch n°790 : train_loss = 2.0985472202301025, val_loss = 0.7939996719360352\n",
      "epoch n°791 : train_loss = 2.0966544151306152, val_loss = 0.7996901273727417\n",
      "epoch n°792 : train_loss = 2.101698398590088, val_loss = 0.7935593128204346\n",
      "epoch n°793 : train_loss = 2.106003522872925, val_loss = 0.7927824258804321\n",
      "epoch n°794 : train_loss = 2.1017911434173584, val_loss = 0.7947496175765991\n",
      "epoch n°795 : train_loss = 2.103123426437378, val_loss = 0.7967749834060669\n",
      "epoch n°796 : train_loss = 2.1029484272003174, val_loss = 0.7976489663124084\n",
      "epoch n°797 : train_loss = 2.1061055660247803, val_loss = 0.7959975600242615\n",
      "epoch n°798 : train_loss = 2.102764368057251, val_loss = 0.7958996891975403\n",
      "epoch n°799 : train_loss = 2.098273754119873, val_loss = 0.7922535538673401\n",
      "epoch n°800 : train_loss = 2.1015777587890625, val_loss = 0.7951602339744568\n",
      "epoch n°801 : train_loss = 2.098965644836426, val_loss = 0.7965166568756104\n",
      "epoch n°802 : train_loss = 2.1026225090026855, val_loss = 0.7955210208892822\n",
      "epoch n°803 : train_loss = 2.109760284423828, val_loss = 0.7960284948348999\n",
      "epoch n°804 : train_loss = 2.1063809394836426, val_loss = 0.792046070098877\n",
      "epoch n°805 : train_loss = 2.1014792919158936, val_loss = 0.7931903600692749\n",
      "epoch n°806 : train_loss = 2.1001369953155518, val_loss = 0.793006181716919\n",
      "epoch n°807 : train_loss = 2.0905771255493164, val_loss = 0.7943140864372253\n",
      "epoch n°808 : train_loss = 2.1044387817382812, val_loss = 0.7952316403388977\n",
      "epoch n°809 : train_loss = 2.099547863006592, val_loss = 0.7935408353805542\n",
      "epoch n°810 : train_loss = 2.0979156494140625, val_loss = 0.794693648815155\n",
      "epoch n°811 : train_loss = 2.1044843196868896, val_loss = 0.7936521768569946\n",
      "epoch n°812 : train_loss = 2.0892820358276367, val_loss = 0.8003886938095093\n",
      "epoch n°813 : train_loss = 2.1002213954925537, val_loss = 0.7951831817626953\n",
      "epoch n°814 : train_loss = 2.0980794429779053, val_loss = 0.7946774363517761\n",
      "epoch n°815 : train_loss = 2.094531297683716, val_loss = 0.7931901216506958\n",
      "epoch n°816 : train_loss = 2.0973010063171387, val_loss = 0.7955185174942017\n",
      "epoch n°817 : train_loss = 2.094956159591675, val_loss = 0.7950448989868164\n",
      "epoch n°818 : train_loss = 2.100318670272827, val_loss = 0.7918172478675842\n",
      "epoch n°819 : train_loss = 2.0971357822418213, val_loss = 0.7978827357292175\n",
      "epoch n°820 : train_loss = 2.093993663787842, val_loss = 0.7953367829322815\n",
      "epoch n°821 : train_loss = 2.1042532920837402, val_loss = 0.7936018109321594\n",
      "epoch n°822 : train_loss = 2.1021671295166016, val_loss = 0.7947607636451721\n",
      "epoch n°823 : train_loss = 2.1011195182800293, val_loss = 0.7966082096099854\n",
      "epoch n°824 : train_loss = 2.097158908843994, val_loss = 0.7954287528991699\n",
      "epoch n°825 : train_loss = 2.097987651824951, val_loss = 0.798591136932373\n",
      "epoch n°826 : train_loss = 2.089815378189087, val_loss = 0.7961986660957336\n",
      "epoch n°827 : train_loss = 2.102268934249878, val_loss = 0.7957711815834045\n",
      "epoch n°828 : train_loss = 2.094869613647461, val_loss = 0.790396511554718\n",
      "epoch n°829 : train_loss = 2.0901358127593994, val_loss = 0.7947947978973389\n",
      "epoch n°830 : train_loss = 2.0922343730926514, val_loss = 0.7944377064704895\n",
      "epoch n°831 : train_loss = 2.0990920066833496, val_loss = 0.7966706156730652\n",
      "epoch n°832 : train_loss = 2.094980478286743, val_loss = 0.796924889087677\n",
      "epoch n°833 : train_loss = 2.0978124141693115, val_loss = 0.7943742871284485\n",
      "epoch n°834 : train_loss = 2.101774215698242, val_loss = 0.7913413047790527\n",
      "epoch n°835 : train_loss = 2.088775157928467, val_loss = 0.7972249984741211\n",
      "epoch n°836 : train_loss = 2.091804027557373, val_loss = 0.7938419580459595\n",
      "epoch n°837 : train_loss = 2.096916675567627, val_loss = 0.7922890782356262\n",
      "epoch n°838 : train_loss = 2.098956823348999, val_loss = 0.7945837378501892\n",
      "epoch n°839 : train_loss = 2.087407112121582, val_loss = 0.7916958928108215\n",
      "epoch n°840 : train_loss = 2.0928828716278076, val_loss = 0.7956216335296631\n",
      "epoch n°841 : train_loss = 2.0988898277282715, val_loss = 0.7959007024765015\n",
      "epoch n°842 : train_loss = 2.08492112159729, val_loss = 0.7942230105400085\n",
      "epoch n°843 : train_loss = 2.0944366455078125, val_loss = 0.7955305576324463\n",
      "epoch n°844 : train_loss = 2.1027328968048096, val_loss = 0.7941914200782776\n",
      "epoch n°845 : train_loss = 2.090055227279663, val_loss = 0.7918466329574585\n",
      "epoch n°846 : train_loss = 2.095072031021118, val_loss = 0.7949161529541016\n",
      "epoch n°847 : train_loss = 2.093553304672241, val_loss = 0.7972359657287598\n",
      "epoch n°848 : train_loss = 2.087658643722534, val_loss = 0.7932189702987671\n",
      "epoch n°849 : train_loss = 2.0839121341705322, val_loss = 0.7921512722969055\n",
      "epoch n°850 : train_loss = 2.0895419120788574, val_loss = 0.7964385747909546\n",
      "epoch n°851 : train_loss = 2.0854251384735107, val_loss = 0.7931323647499084\n",
      "epoch n°852 : train_loss = 2.097658395767212, val_loss = 0.7971866726875305\n",
      "epoch n°853 : train_loss = 2.085357427597046, val_loss = 0.7944107055664062\n",
      "epoch n°854 : train_loss = 2.0951240062713623, val_loss = 0.7950262427330017\n",
      "epoch n°855 : train_loss = 2.093932628631592, val_loss = 0.7969217896461487\n",
      "epoch n°856 : train_loss = 2.0947704315185547, val_loss = 0.7966649532318115\n",
      "epoch n°857 : train_loss = 2.0917861461639404, val_loss = 0.7940107583999634\n",
      "epoch n°858 : train_loss = 2.09503173828125, val_loss = 0.7958874702453613\n",
      "epoch n°859 : train_loss = 2.093273401260376, val_loss = 0.7954007387161255\n",
      "epoch n°860 : train_loss = 2.0868563652038574, val_loss = 0.7956048250198364\n",
      "epoch n°861 : train_loss = 2.0897791385650635, val_loss = 0.7947511672973633\n",
      "epoch n°862 : train_loss = 2.0877552032470703, val_loss = 0.7926232814788818\n",
      "epoch n°863 : train_loss = 2.094534397125244, val_loss = 0.7963839173316956\n",
      "epoch n°864 : train_loss = 2.088047742843628, val_loss = 0.792262613773346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°865 : train_loss = 2.0960114002227783, val_loss = 0.7944086790084839\n",
      "epoch n°866 : train_loss = 2.0905959606170654, val_loss = 0.7946683168411255\n",
      "epoch n°867 : train_loss = 2.0986156463623047, val_loss = 0.7952635884284973\n",
      "epoch n°868 : train_loss = 2.084088087081909, val_loss = 0.7928475737571716\n",
      "epoch n°869 : train_loss = 2.0925939083099365, val_loss = 0.7963499426841736\n",
      "epoch n°870 : train_loss = 2.0830323696136475, val_loss = 0.7947874069213867\n",
      "epoch n°871 : train_loss = 2.0836739540100098, val_loss = 0.7935760021209717\n",
      "epoch n°872 : train_loss = 2.086003303527832, val_loss = 0.7910417914390564\n",
      "epoch n°873 : train_loss = 2.0875046253204346, val_loss = 0.7965996861457825\n",
      "epoch n°874 : train_loss = 2.0975074768066406, val_loss = 0.7991911768913269\n",
      "epoch n°875 : train_loss = 2.0875401496887207, val_loss = 0.7932277321815491\n",
      "epoch n°876 : train_loss = 2.0925750732421875, val_loss = 0.7939833402633667\n",
      "epoch n°877 : train_loss = 2.0969855785369873, val_loss = 0.7958443760871887\n",
      "epoch n°878 : train_loss = 2.085397243499756, val_loss = 0.7933923006057739\n",
      "epoch n°879 : train_loss = 2.095855474472046, val_loss = 0.793681263923645\n",
      "epoch n°880 : train_loss = 2.085050344467163, val_loss = 0.7909863591194153\n",
      "epoch n°881 : train_loss = 2.0911004543304443, val_loss = 0.7985430955886841\n",
      "epoch n°882 : train_loss = 2.09544038772583, val_loss = 0.7918522357940674\n",
      "epoch n°883 : train_loss = 2.0915629863739014, val_loss = 0.7961421012878418\n",
      "epoch n°884 : train_loss = 2.0842087268829346, val_loss = 0.7955076098442078\n",
      "epoch n°885 : train_loss = 2.0854291915893555, val_loss = 0.7956006526947021\n",
      "epoch n°886 : train_loss = 2.0845837593078613, val_loss = 0.7956905364990234\n",
      "epoch n°887 : train_loss = 2.0827901363372803, val_loss = 0.7934486865997314\n",
      "epoch n°888 : train_loss = 2.089374303817749, val_loss = 0.7921091914176941\n",
      "epoch n°889 : train_loss = 2.0870437622070312, val_loss = 0.7951575517654419\n",
      "epoch n°890 : train_loss = 2.0936405658721924, val_loss = 0.7954045534133911\n",
      "epoch n°891 : train_loss = 2.084604024887085, val_loss = 0.794191837310791\n",
      "epoch n°892 : train_loss = 2.081141710281372, val_loss = 0.7947732210159302\n",
      "epoch n°893 : train_loss = 2.090956449508667, val_loss = 0.7925036549568176\n",
      "epoch n°894 : train_loss = 2.091582775115967, val_loss = 0.7948316335678101\n",
      "epoch n°895 : train_loss = 2.0879225730895996, val_loss = 0.7904150485992432\n",
      "epoch n°896 : train_loss = 2.084747552871704, val_loss = 0.7967358231544495\n",
      "epoch n°897 : train_loss = 2.089733123779297, val_loss = 0.7950373888015747\n",
      "epoch n°898 : train_loss = 2.08772611618042, val_loss = 0.7951759099960327\n",
      "epoch n°899 : train_loss = 2.086315393447876, val_loss = 0.795654833316803\n",
      "epoch n°900 : train_loss = 2.0849924087524414, val_loss = 0.7931681275367737\n",
      "epoch n°901 : train_loss = 2.091905355453491, val_loss = 0.7933613061904907\n",
      "epoch n°902 : train_loss = 2.0898730754852295, val_loss = 0.7916768789291382\n",
      "epoch n°903 : train_loss = 2.095247507095337, val_loss = 0.7966334819793701\n",
      "epoch n°904 : train_loss = 2.088585615158081, val_loss = 0.7933221459388733\n",
      "epoch n°905 : train_loss = 2.0822055339813232, val_loss = 0.7983903884887695\n",
      "epoch n°906 : train_loss = 2.085832118988037, val_loss = 0.7933668494224548\n",
      "epoch n°907 : train_loss = 2.0874528884887695, val_loss = 0.7951180338859558\n",
      "epoch n°908 : train_loss = 2.08829927444458, val_loss = 0.7973440885543823\n",
      "epoch n°909 : train_loss = 2.081909656524658, val_loss = 0.7923334836959839\n",
      "epoch n°910 : train_loss = 2.0762739181518555, val_loss = 0.7946152687072754\n",
      "epoch n°911 : train_loss = 2.0789241790771484, val_loss = 0.7973300218582153\n",
      "epoch n°912 : train_loss = 2.090085983276367, val_loss = 0.7895050644874573\n",
      "epoch n°913 : train_loss = 2.09073543548584, val_loss = 0.7997005581855774\n",
      "epoch n°914 : train_loss = 2.093100070953369, val_loss = 0.7901157736778259\n",
      "epoch n°915 : train_loss = 2.0811548233032227, val_loss = 0.7918796539306641\n",
      "epoch n°916 : train_loss = 2.0857162475585938, val_loss = 0.7988957166671753\n",
      "epoch n°917 : train_loss = 2.0934860706329346, val_loss = 0.796543300151825\n",
      "epoch n°918 : train_loss = 2.0892977714538574, val_loss = 0.7941042184829712\n",
      "epoch n°919 : train_loss = 2.0892045497894287, val_loss = 0.7937012910842896\n",
      "epoch n°920 : train_loss = 2.0889790058135986, val_loss = 0.7963684797286987\n",
      "epoch n°921 : train_loss = 2.084294557571411, val_loss = 0.7936064004898071\n",
      "epoch n°922 : train_loss = 2.0861732959747314, val_loss = 0.7943710088729858\n",
      "epoch n°923 : train_loss = 2.0858194828033447, val_loss = 0.7932773232460022\n",
      "epoch n°924 : train_loss = 2.0906057357788086, val_loss = 0.7990644574165344\n",
      "epoch n°925 : train_loss = 2.0838613510131836, val_loss = 0.7942779660224915\n",
      "epoch n°926 : train_loss = 2.0889909267425537, val_loss = 0.7926463484764099\n",
      "epoch n°927 : train_loss = 2.0888314247131348, val_loss = 0.7962377071380615\n",
      "epoch n°928 : train_loss = 2.0849506855010986, val_loss = 0.7976514101028442\n",
      "epoch n°929 : train_loss = 2.088395833969116, val_loss = 0.7922879457473755\n",
      "epoch n°930 : train_loss = 2.0890963077545166, val_loss = 0.7948203086853027\n",
      "epoch n°931 : train_loss = 2.084653854370117, val_loss = 0.797535240650177\n",
      "epoch n°932 : train_loss = 2.090315341949463, val_loss = 0.7957254648208618\n",
      "epoch n°933 : train_loss = 2.0805695056915283, val_loss = 0.7935375571250916\n",
      "epoch n°934 : train_loss = 2.0765273571014404, val_loss = 0.7957980036735535\n",
      "epoch n°935 : train_loss = 2.0867233276367188, val_loss = 0.7908473014831543\n",
      "epoch n°936 : train_loss = 2.085663318634033, val_loss = 0.7942293882369995\n",
      "epoch n°937 : train_loss = 2.079855442047119, val_loss = 0.794529139995575\n",
      "epoch n°938 : train_loss = 2.0841386318206787, val_loss = 0.7926926612854004\n",
      "epoch n°939 : train_loss = 2.0759620666503906, val_loss = 0.7960087060928345\n",
      "epoch n°940 : train_loss = 2.088545560836792, val_loss = 0.7917260527610779\n",
      "epoch n°941 : train_loss = 2.0873377323150635, val_loss = 0.7953652143478394\n",
      "epoch n°942 : train_loss = 2.087923765182495, val_loss = 0.7949538230895996\n",
      "epoch n°943 : train_loss = 2.0786514282226562, val_loss = 0.7972215414047241\n",
      "epoch n°944 : train_loss = 2.0856196880340576, val_loss = 0.7919799089431763\n",
      "epoch n°945 : train_loss = 2.0817453861236572, val_loss = 0.7912498712539673\n",
      "epoch n°946 : train_loss = 2.0924618244171143, val_loss = 0.7968382239341736\n",
      "epoch n°947 : train_loss = 2.085770845413208, val_loss = 0.7934218645095825\n",
      "epoch n°948 : train_loss = 2.0839991569519043, val_loss = 0.7940073013305664\n",
      "epoch n°949 : train_loss = 2.0805089473724365, val_loss = 0.7931066155433655\n",
      "epoch n°950 : train_loss = 2.0823726654052734, val_loss = 0.7926886081695557\n",
      "epoch n°951 : train_loss = 2.0885040760040283, val_loss = 0.7938134074211121\n",
      "epoch n°952 : train_loss = 2.083848237991333, val_loss = 0.7935382127761841\n",
      "epoch n°953 : train_loss = 2.085003137588501, val_loss = 0.7936969995498657\n",
      "epoch n°954 : train_loss = 2.0831265449523926, val_loss = 0.7973861694335938\n",
      "epoch n°955 : train_loss = 2.084003448486328, val_loss = 0.7932844758033752\n",
      "epoch n°956 : train_loss = 2.087986946105957, val_loss = 0.7969315052032471\n",
      "epoch n°957 : train_loss = 2.0826237201690674, val_loss = 0.7953789234161377\n",
      "epoch n°958 : train_loss = 2.085317373275757, val_loss = 0.7947560548782349\n",
      "epoch n°959 : train_loss = 2.0876450538635254, val_loss = 0.7958834171295166\n",
      "epoch n°960 : train_loss = 2.080570936203003, val_loss = 0.7956075072288513\n",
      "epoch n°961 : train_loss = 2.068617582321167, val_loss = 0.7956582307815552\n",
      "epoch n°962 : train_loss = 2.0812394618988037, val_loss = 0.7920553088188171\n",
      "epoch n°963 : train_loss = 2.0710837841033936, val_loss = 0.7954469323158264\n",
      "epoch n°964 : train_loss = 2.0846822261810303, val_loss = 0.791252851486206\n",
      "epoch n°965 : train_loss = 2.094264507293701, val_loss = 0.793507993221283\n",
      "epoch n°966 : train_loss = 2.081509828567505, val_loss = 0.7928028702735901\n",
      "epoch n°967 : train_loss = 2.0868358612060547, val_loss = 0.7945767641067505\n",
      "epoch n°968 : train_loss = 2.081129550933838, val_loss = 0.7976871132850647\n",
      "epoch n°969 : train_loss = 2.082165479660034, val_loss = 0.791045069694519\n",
      "epoch n°970 : train_loss = 2.092590093612671, val_loss = 0.7902100086212158\n",
      "epoch n°971 : train_loss = 2.0798425674438477, val_loss = 0.7925248146057129\n",
      "epoch n°972 : train_loss = 2.0765233039855957, val_loss = 0.7949007153511047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°973 : train_loss = 2.0821382999420166, val_loss = 0.7902575731277466\n",
      "epoch n°974 : train_loss = 2.087383985519409, val_loss = 0.7955136299133301\n",
      "epoch n°975 : train_loss = 2.094142198562622, val_loss = 0.7923141717910767\n",
      "epoch n°976 : train_loss = 2.0857443809509277, val_loss = 0.7947831153869629\n",
      "epoch n°977 : train_loss = 2.0837440490722656, val_loss = 0.7899805903434753\n",
      "epoch n°978 : train_loss = 2.0800020694732666, val_loss = 0.7905567288398743\n",
      "epoch n°979 : train_loss = 2.087979555130005, val_loss = 0.7964320778846741\n",
      "epoch n°980 : train_loss = 2.0866315364837646, val_loss = 0.7942238450050354\n",
      "epoch n°981 : train_loss = 2.0930447578430176, val_loss = 0.7934526205062866\n",
      "epoch n°982 : train_loss = 2.091853141784668, val_loss = 0.7860899567604065\n",
      "epoch n°983 : train_loss = 2.0944583415985107, val_loss = 0.7938951849937439\n",
      "epoch n°984 : train_loss = 2.0877339839935303, val_loss = 0.7906990647315979\n",
      "epoch n°985 : train_loss = 2.0858161449432373, val_loss = 0.7960745692253113\n",
      "epoch n°986 : train_loss = 2.08522367477417, val_loss = 0.7930906414985657\n",
      "epoch n°987 : train_loss = 2.0800416469573975, val_loss = 0.7941856980323792\n",
      "epoch n°988 : train_loss = 2.0844736099243164, val_loss = 0.7939639091491699\n",
      "epoch n°989 : train_loss = 2.0872609615325928, val_loss = 0.794313371181488\n",
      "epoch n°990 : train_loss = 2.0814082622528076, val_loss = 0.7939017415046692\n",
      "epoch n°991 : train_loss = 2.091939926147461, val_loss = 0.7944194674491882\n",
      "epoch n°992 : train_loss = 2.07843279838562, val_loss = 0.7942160964012146\n",
      "epoch n°993 : train_loss = 2.082705497741699, val_loss = 0.7967868447303772\n",
      "epoch n°994 : train_loss = 2.0863006114959717, val_loss = 0.7927916646003723\n",
      "epoch n°995 : train_loss = 2.0764598846435547, val_loss = 0.7895879149436951\n",
      "epoch n°996 : train_loss = 2.0888442993164062, val_loss = 0.7970216274261475\n",
      "epoch n°997 : train_loss = 2.093893527984619, val_loss = 0.7900638580322266\n",
      "epoch n°998 : train_loss = 2.084332227706909, val_loss = 0.7941243052482605\n",
      "epoch n°999 : train_loss = 2.084019660949707, val_loss = 0.795188844203949\n",
      "epoch n°1000 : train_loss = 2.0881311893463135, val_loss = 0.7968488335609436\n",
      "epoch n°1001 : train_loss = 2.0799803733825684, val_loss = 0.7930624485015869\n",
      "epoch n°1002 : train_loss = 2.072956085205078, val_loss = 0.7948890924453735\n",
      "epoch n°1003 : train_loss = 2.0861895084381104, val_loss = 0.7880426645278931\n",
      "epoch n°1004 : train_loss = 2.085192918777466, val_loss = 0.7952752709388733\n",
      "epoch n°1005 : train_loss = 2.0807769298553467, val_loss = 0.794256329536438\n",
      "epoch n°1006 : train_loss = 2.0898046493530273, val_loss = 0.7943519353866577\n",
      "epoch n°1007 : train_loss = 2.074814558029175, val_loss = 0.7950940728187561\n",
      "epoch n°1008 : train_loss = 2.112391471862793, val_loss = 0.7981046438217163\n",
      "epoch n°1009 : train_loss = 2.1115593910217285, val_loss = 0.7946924567222595\n",
      "epoch n°1010 : train_loss = 2.116708755493164, val_loss = 0.7974317073822021\n",
      "epoch n°1011 : train_loss = 2.1165053844451904, val_loss = 0.7963746190071106\n",
      "epoch n°1012 : train_loss = 2.1076998710632324, val_loss = 0.79845130443573\n",
      "epoch n°1013 : train_loss = 2.103980541229248, val_loss = 0.7975699305534363\n",
      "epoch n°1014 : train_loss = 2.109138250350952, val_loss = 0.7946133613586426\n",
      "epoch n°1015 : train_loss = 2.111955404281616, val_loss = 0.8014249205589294\n",
      "epoch n°1016 : train_loss = 2.1168086528778076, val_loss = 0.8007022142410278\n",
      "epoch n°1017 : train_loss = 2.1189067363739014, val_loss = 0.7968631386756897\n",
      "epoch n°1018 : train_loss = 2.1087958812713623, val_loss = 0.7974671721458435\n",
      "epoch n°1019 : train_loss = 2.1131770610809326, val_loss = 0.7976498603820801\n",
      "epoch n°1020 : train_loss = 2.1158361434936523, val_loss = 0.7985697388648987\n",
      "epoch n°1021 : train_loss = 2.107714891433716, val_loss = 0.7976278066635132\n",
      "epoch n°1022 : train_loss = 2.1223416328430176, val_loss = 0.8004000186920166\n",
      "epoch n°1023 : train_loss = 2.1117818355560303, val_loss = 0.7975094318389893\n",
      "epoch n°1024 : train_loss = 2.1220812797546387, val_loss = 0.792204737663269\n",
      "epoch n°1025 : train_loss = 2.12111759185791, val_loss = 0.7994611263275146\n",
      "epoch n°1026 : train_loss = 2.1160244941711426, val_loss = 0.7963423132896423\n",
      "epoch n°1027 : train_loss = 2.117122173309326, val_loss = 0.8033010363578796\n",
      "epoch n°1028 : train_loss = 2.114028215408325, val_loss = 0.7995408773422241\n",
      "epoch n°1029 : train_loss = 2.1110737323760986, val_loss = 0.7988539338111877\n",
      "epoch n°1030 : train_loss = 2.1082375049591064, val_loss = 0.7976416349411011\n",
      "epoch n°1031 : train_loss = 2.1160593032836914, val_loss = 0.7987767457962036\n",
      "epoch n°1032 : train_loss = 2.1112406253814697, val_loss = 0.7985213398933411\n",
      "epoch n°1033 : train_loss = 2.1177849769592285, val_loss = 0.8030633330345154\n",
      "epoch n°1034 : train_loss = 2.110513687133789, val_loss = 0.7962315082550049\n",
      "epoch n°1035 : train_loss = 2.113009214401245, val_loss = 0.80233234167099\n",
      "epoch n°1036 : train_loss = 2.1271731853485107, val_loss = 0.7943768501281738\n",
      "epoch n°1037 : train_loss = 2.1131718158721924, val_loss = 0.7963657379150391\n",
      "epoch n°1038 : train_loss = 2.1199748516082764, val_loss = 0.8005890846252441\n",
      "epoch n°1039 : train_loss = 2.114696979522705, val_loss = 0.7926292419433594\n",
      "epoch n°1040 : train_loss = 2.112513780593872, val_loss = 0.7971323132514954\n",
      "epoch n°1041 : train_loss = 2.107419013977051, val_loss = 0.7916634678840637\n",
      "epoch n°1042 : train_loss = 2.1167750358581543, val_loss = 0.7994318008422852\n",
      "epoch n°1043 : train_loss = 2.1091415882110596, val_loss = 0.7958902716636658\n",
      "epoch n°1044 : train_loss = 2.1226096153259277, val_loss = 0.8022673726081848\n",
      "epoch n°1045 : train_loss = 2.1291134357452393, val_loss = 0.8013333678245544\n",
      "epoch n°1046 : train_loss = 2.1121997833251953, val_loss = 0.8000459671020508\n",
      "epoch n°1047 : train_loss = 2.1201281547546387, val_loss = 0.7967832684516907\n",
      "epoch n°1048 : train_loss = 2.1204497814178467, val_loss = 0.7967832088470459\n",
      "epoch n°1049 : train_loss = 2.1168320178985596, val_loss = 0.7946056127548218\n",
      "epoch n°1050 : train_loss = 2.12091326713562, val_loss = 0.8003010153770447\n",
      "epoch n°1051 : train_loss = 2.107100248336792, val_loss = 0.7971964478492737\n",
      "epoch n°1052 : train_loss = 2.1223948001861572, val_loss = 0.7994025349617004\n",
      "epoch n°1053 : train_loss = 2.1152796745300293, val_loss = 0.7964507341384888\n",
      "epoch n°1054 : train_loss = 2.1151070594787598, val_loss = 0.7954385280609131\n",
      "epoch n°1055 : train_loss = 2.121293306350708, val_loss = 0.7978838086128235\n",
      "epoch n°1056 : train_loss = 2.1132185459136963, val_loss = 0.7954289317131042\n",
      "epoch n°1057 : train_loss = 2.114032030105591, val_loss = 0.800911009311676\n",
      "epoch n°1058 : train_loss = 2.108365774154663, val_loss = 0.8001980185508728\n",
      "epoch n°1059 : train_loss = 2.113215208053589, val_loss = 0.8003109693527222\n",
      "epoch n°1060 : train_loss = 2.1118624210357666, val_loss = 0.8014934062957764\n",
      "epoch n°1061 : train_loss = 2.1104578971862793, val_loss = 0.7889067530632019\n",
      "epoch n°1062 : train_loss = 2.115630626678467, val_loss = 0.8007056713104248\n",
      "epoch n°1063 : train_loss = 2.1135923862457275, val_loss = 0.8012779951095581\n",
      "epoch n°1064 : train_loss = 2.114161729812622, val_loss = 0.7956684231758118\n",
      "epoch n°1065 : train_loss = 2.1195290088653564, val_loss = 0.7954249382019043\n",
      "epoch n°1066 : train_loss = 2.1137940883636475, val_loss = 0.7989353537559509\n",
      "epoch n°1067 : train_loss = 2.1111886501312256, val_loss = 0.7981083989143372\n",
      "epoch n°1068 : train_loss = 2.1132261753082275, val_loss = 0.7994639277458191\n",
      "epoch n°1069 : train_loss = 2.1109659671783447, val_loss = 0.7982867360115051\n",
      "epoch n°1070 : train_loss = 2.1181535720825195, val_loss = 0.7985110282897949\n",
      "epoch n°1071 : train_loss = 2.114804983139038, val_loss = 0.7975704669952393\n",
      "epoch n°1072 : train_loss = 2.1105310916900635, val_loss = 0.7963070869445801\n",
      "epoch n°1073 : train_loss = 2.10235595703125, val_loss = 0.7953377962112427\n",
      "epoch n°1074 : train_loss = 2.114755868911743, val_loss = 0.7994523644447327\n",
      "epoch n°1075 : train_loss = 2.106910467147827, val_loss = 0.8013442158699036\n",
      "epoch n°1076 : train_loss = 2.1138906478881836, val_loss = 0.7922440767288208\n",
      "epoch n°1077 : train_loss = 2.10921573638916, val_loss = 0.7968102097511292\n",
      "epoch n°1078 : train_loss = 2.1161680221557617, val_loss = 0.8008630275726318\n",
      "epoch n°1079 : train_loss = 2.1186861991882324, val_loss = 0.7976427674293518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°1080 : train_loss = 2.1144027709960938, val_loss = 0.8009821772575378\n",
      "epoch n°1081 : train_loss = 2.110629081726074, val_loss = 0.7927142381668091\n",
      "epoch n°1082 : train_loss = 2.1196067333221436, val_loss = 0.7985926270484924\n",
      "epoch n°1083 : train_loss = 2.1137633323669434, val_loss = 0.8001385927200317\n",
      "epoch n°1084 : train_loss = 2.1142218112945557, val_loss = 0.7914597988128662\n",
      "epoch n°1085 : train_loss = 2.1245017051696777, val_loss = 0.8023023009300232\n",
      "epoch n°1086 : train_loss = 2.1126339435577393, val_loss = 0.7931470274925232\n",
      "epoch n°1087 : train_loss = 2.115662097930908, val_loss = 0.7948542833328247\n",
      "epoch n°1088 : train_loss = 2.1105875968933105, val_loss = 0.7951690554618835\n",
      "epoch n°1089 : train_loss = 2.110071897506714, val_loss = 0.7976348996162415\n",
      "epoch n°1090 : train_loss = 2.112971305847168, val_loss = 0.7917351126670837\n",
      "epoch n°1091 : train_loss = 2.107487678527832, val_loss = 0.7961307764053345\n",
      "epoch n°1092 : train_loss = 2.11391282081604, val_loss = 0.7950688600540161\n",
      "epoch n°1093 : train_loss = 2.1154134273529053, val_loss = 0.7976621985435486\n",
      "epoch n°1094 : train_loss = 2.1168458461761475, val_loss = 0.7983253598213196\n",
      "epoch n°1095 : train_loss = 2.1096668243408203, val_loss = 0.7996137738227844\n",
      "epoch n°1096 : train_loss = 2.1101551055908203, val_loss = 0.7986720204353333\n",
      "epoch n°1097 : train_loss = 2.120136260986328, val_loss = 0.8021583557128906\n",
      "epoch n°1098 : train_loss = 2.1140332221984863, val_loss = 0.7975075840950012\n",
      "epoch n°1099 : train_loss = 2.112539768218994, val_loss = 0.7972421050071716\n",
      "epoch n°1100 : train_loss = 2.1076719760894775, val_loss = 0.7969064712524414\n",
      "epoch n°1101 : train_loss = 2.1091949939727783, val_loss = 0.7999129295349121\n",
      "epoch n°1102 : train_loss = 2.1142919063568115, val_loss = 0.7997005581855774\n",
      "epoch n°1103 : train_loss = 2.110466718673706, val_loss = 0.7963727116584778\n",
      "epoch n°1104 : train_loss = 2.1199793815612793, val_loss = 0.7995529770851135\n",
      "epoch n°1105 : train_loss = 2.1101536750793457, val_loss = 0.7933111786842346\n",
      "epoch n°1106 : train_loss = 2.1170196533203125, val_loss = 0.7988986372947693\n",
      "epoch n°1107 : train_loss = 2.105652332305908, val_loss = 0.796204149723053\n",
      "epoch n°1108 : train_loss = 2.1130383014678955, val_loss = 0.7954233884811401\n",
      "epoch n°1109 : train_loss = 2.108405590057373, val_loss = 0.7993449568748474\n",
      "epoch n°1110 : train_loss = 2.1083145141601562, val_loss = 0.7967510223388672\n",
      "epoch n°1111 : train_loss = 2.1166796684265137, val_loss = 0.8001658916473389\n",
      "epoch n°1112 : train_loss = 2.1112282276153564, val_loss = 0.7973156571388245\n",
      "epoch n°1113 : train_loss = 2.1090152263641357, val_loss = 0.7972990274429321\n",
      "epoch n°1114 : train_loss = 2.1058664321899414, val_loss = 0.7966058254241943\n",
      "epoch n°1115 : train_loss = 2.1186907291412354, val_loss = 0.7943230271339417\n",
      "epoch n°1116 : train_loss = 2.1101489067077637, val_loss = 0.7937201857566833\n",
      "epoch n°1117 : train_loss = 2.1108739376068115, val_loss = 0.7951070070266724\n",
      "epoch n°1118 : train_loss = 2.1111178398132324, val_loss = 0.7999982833862305\n",
      "epoch n°1119 : train_loss = 2.109046220779419, val_loss = 0.7943806052207947\n",
      "epoch n°1120 : train_loss = 2.116095542907715, val_loss = 0.7979570031166077\n",
      "epoch n°1121 : train_loss = 2.1024341583251953, val_loss = 0.7986703515052795\n",
      "epoch n°1122 : train_loss = 2.1074023246765137, val_loss = 0.79984050989151\n",
      "epoch n°1123 : train_loss = 2.1056807041168213, val_loss = 0.7979135513305664\n",
      "epoch n°1124 : train_loss = 2.1142866611480713, val_loss = 0.7998339533805847\n",
      "epoch n°1125 : train_loss = 2.1093387603759766, val_loss = 0.7945160269737244\n",
      "epoch n°1126 : train_loss = 2.113095998764038, val_loss = 0.7973216772079468\n",
      "epoch n°1127 : train_loss = 2.112478733062744, val_loss = 0.8020493984222412\n",
      "epoch n°1128 : train_loss = 2.106588363647461, val_loss = 0.8026902079582214\n",
      "epoch n°1129 : train_loss = 2.1125810146331787, val_loss = 0.7989044785499573\n",
      "epoch n°1130 : train_loss = 2.1119298934936523, val_loss = 0.7974640727043152\n",
      "epoch n°1131 : train_loss = 2.1073811054229736, val_loss = 0.7988571524620056\n",
      "epoch n°1132 : train_loss = 2.1021392345428467, val_loss = 0.8007819652557373\n",
      "epoch n°1133 : train_loss = 2.108760118484497, val_loss = 0.7980572581291199\n",
      "epoch n°1134 : train_loss = 2.106757879257202, val_loss = 0.7957814335823059\n",
      "epoch n°1135 : train_loss = 2.1005747318267822, val_loss = 0.7952611446380615\n",
      "epoch n°1136 : train_loss = 2.1269447803497314, val_loss = 0.7974452972412109\n",
      "epoch n°1137 : train_loss = 2.118145704269409, val_loss = 0.7965744137763977\n",
      "epoch n°1138 : train_loss = 2.108194351196289, val_loss = 0.7961335182189941\n",
      "epoch n°1139 : train_loss = 2.1034457683563232, val_loss = 0.80191570520401\n",
      "epoch n°1140 : train_loss = 2.1185646057128906, val_loss = 0.7981166839599609\n",
      "epoch n°1141 : train_loss = 2.113659143447876, val_loss = 0.7966359257698059\n",
      "epoch n°1142 : train_loss = 2.112758159637451, val_loss = 0.7960304021835327\n",
      "epoch n°1143 : train_loss = 2.107196807861328, val_loss = 0.8005763292312622\n",
      "epoch n°1144 : train_loss = 2.1018548011779785, val_loss = 0.7965086698532104\n",
      "epoch n°1145 : train_loss = 2.112902879714966, val_loss = 0.7989659309387207\n",
      "epoch n°1146 : train_loss = 2.1221206188201904, val_loss = 0.7940090298652649\n",
      "epoch n°1147 : train_loss = 2.1062374114990234, val_loss = 0.7990611791610718\n",
      "epoch n°1148 : train_loss = 2.105710029602051, val_loss = 0.7986884117126465\n",
      "epoch n°1149 : train_loss = 2.108004331588745, val_loss = 0.7974121570587158\n",
      "epoch n°1150 : train_loss = 2.111647367477417, val_loss = 0.797653079032898\n",
      "epoch n°1151 : train_loss = 2.1078884601593018, val_loss = 0.7936779856681824\n",
      "epoch n°1152 : train_loss = 2.1076858043670654, val_loss = 0.7950199842453003\n",
      "epoch n°1153 : train_loss = 2.1090595722198486, val_loss = 0.7952761650085449\n",
      "epoch n°1154 : train_loss = 2.1133153438568115, val_loss = 0.7952117919921875\n",
      "epoch n°1155 : train_loss = 2.1118783950805664, val_loss = 0.7948713898658752\n",
      "epoch n°1156 : train_loss = 2.1100521087646484, val_loss = 0.8003776669502258\n",
      "epoch n°1157 : train_loss = 2.102478504180908, val_loss = 0.7986683249473572\n",
      "epoch n°1158 : train_loss = 2.1165974140167236, val_loss = 0.8006975650787354\n",
      "epoch n°1159 : train_loss = 2.105323553085327, val_loss = 0.7992117404937744\n",
      "epoch n°1160 : train_loss = 2.105330228805542, val_loss = 0.7942577600479126\n",
      "epoch n°1161 : train_loss = 2.1115987300872803, val_loss = 0.7953616976737976\n",
      "epoch n°1162 : train_loss = 2.10516095161438, val_loss = 0.7974527478218079\n",
      "epoch n°1163 : train_loss = 2.1217665672302246, val_loss = 0.798275351524353\n",
      "epoch n°1164 : train_loss = 2.111847400665283, val_loss = 0.8017869591712952\n",
      "epoch n°1165 : train_loss = 2.1081273555755615, val_loss = 0.7933477759361267\n",
      "epoch n°1166 : train_loss = 2.107945680618286, val_loss = 0.7989155650138855\n",
      "epoch n°1167 : train_loss = 2.107243537902832, val_loss = 0.7983664274215698\n",
      "epoch n°1168 : train_loss = 2.1082205772399902, val_loss = 0.7972062230110168\n",
      "epoch n°1169 : train_loss = 2.1237740516662598, val_loss = 0.7950468063354492\n",
      "epoch n°1170 : train_loss = 2.1089868545532227, val_loss = 0.7971169948577881\n",
      "epoch n°1171 : train_loss = 2.114323377609253, val_loss = 0.79720538854599\n",
      "epoch n°1172 : train_loss = 2.105611801147461, val_loss = 0.8032218217849731\n",
      "epoch n°1173 : train_loss = 2.1138315200805664, val_loss = 0.79493647813797\n",
      "epoch n°1174 : train_loss = 2.113870143890381, val_loss = 0.7972580790519714\n",
      "epoch n°1175 : train_loss = 2.107708215713501, val_loss = 0.7999594807624817\n",
      "epoch n°1176 : train_loss = 2.1082828044891357, val_loss = 0.8016154170036316\n",
      "epoch n°1177 : train_loss = 2.105665683746338, val_loss = 0.7938719987869263\n",
      "epoch n°1178 : train_loss = 2.1070556640625, val_loss = 0.7976187467575073\n",
      "epoch n°1179 : train_loss = 2.108025074005127, val_loss = 0.7979126572608948\n",
      "epoch n°1180 : train_loss = 2.110801935195923, val_loss = 0.8002382516860962\n",
      "epoch n°1181 : train_loss = 2.1001698970794678, val_loss = 0.7952405214309692\n",
      "epoch n°1182 : train_loss = 2.112776517868042, val_loss = 0.8003531098365784\n",
      "epoch n°1183 : train_loss = 2.1128668785095215, val_loss = 0.7957574129104614\n",
      "epoch n°1184 : train_loss = 2.1100196838378906, val_loss = 0.795991837978363\n",
      "epoch n°1185 : train_loss = 2.1080846786499023, val_loss = 0.7990354299545288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°1186 : train_loss = 2.1054821014404297, val_loss = 0.7936445474624634\n",
      "epoch n°1187 : train_loss = 2.1046438217163086, val_loss = 0.7995098233222961\n",
      "epoch n°1188 : train_loss = 2.0967061519622803, val_loss = 0.798674464225769\n",
      "epoch n°1189 : train_loss = 2.108660936355591, val_loss = 0.7972611784934998\n",
      "epoch n°1190 : train_loss = 2.0948026180267334, val_loss = 0.7939765453338623\n",
      "epoch n°1191 : train_loss = 2.1101465225219727, val_loss = 0.7945985794067383\n",
      "epoch n°1192 : train_loss = 2.1112356185913086, val_loss = 0.7931476831436157\n",
      "epoch n°1193 : train_loss = 2.0975844860076904, val_loss = 0.7955998182296753\n",
      "epoch n°1194 : train_loss = 2.114030361175537, val_loss = 0.7984564900398254\n",
      "epoch n°1195 : train_loss = 2.1130754947662354, val_loss = 0.7965525984764099\n",
      "epoch n°1196 : train_loss = 2.109983205795288, val_loss = 0.7979747653007507\n",
      "epoch n°1197 : train_loss = 2.106410503387451, val_loss = 0.8009868264198303\n",
      "epoch n°1198 : train_loss = 2.104114532470703, val_loss = 0.7977232336997986\n",
      "epoch n°1199 : train_loss = 2.112712860107422, val_loss = 0.7977875471115112\n",
      "epoch n°1200 : train_loss = 2.0979199409484863, val_loss = 0.7938733696937561\n",
      "epoch n°1201 : train_loss = 2.1055381298065186, val_loss = 0.7929935455322266\n",
      "epoch n°1202 : train_loss = 2.111490488052368, val_loss = 0.7958756685256958\n",
      "epoch n°1203 : train_loss = 2.0959925651550293, val_loss = 0.7948904037475586\n",
      "epoch n°1204 : train_loss = 2.0994372367858887, val_loss = 0.7966499924659729\n",
      "epoch n°1205 : train_loss = 2.102423667907715, val_loss = 0.7979000806808472\n",
      "epoch n°1206 : train_loss = 2.1154403686523438, val_loss = 0.7955189943313599\n",
      "epoch n°1207 : train_loss = 2.1139814853668213, val_loss = 0.7980943918228149\n",
      "epoch n°1208 : train_loss = 2.0943667888641357, val_loss = 0.7922578454017639\n",
      "epoch n°1209 : train_loss = 2.107334613800049, val_loss = 0.7986911535263062\n",
      "epoch n°1210 : train_loss = 2.1005477905273438, val_loss = 0.7979142069816589\n",
      "epoch n°1211 : train_loss = 2.0914344787597656, val_loss = 0.8021640181541443\n",
      "epoch n°1212 : train_loss = 2.1001195907592773, val_loss = 0.7942099571228027\n",
      "epoch n°1213 : train_loss = 2.1115963459014893, val_loss = 0.8027830123901367\n",
      "epoch n°1214 : train_loss = 2.104365348815918, val_loss = 0.7961415648460388\n",
      "epoch n°1215 : train_loss = 2.1048049926757812, val_loss = 0.7966070175170898\n",
      "epoch n°1216 : train_loss = 2.1033148765563965, val_loss = 0.8005746603012085\n",
      "epoch n°1217 : train_loss = 2.098968029022217, val_loss = 0.7970432639122009\n",
      "epoch n°1218 : train_loss = 2.102924346923828, val_loss = 0.797555685043335\n",
      "epoch n°1219 : train_loss = 2.105753183364868, val_loss = 0.8001773953437805\n",
      "epoch n°1220 : train_loss = 2.102874279022217, val_loss = 0.7947152256965637\n",
      "epoch n°1221 : train_loss = 2.097022533416748, val_loss = 0.7970721125602722\n",
      "epoch n°1222 : train_loss = 2.0878429412841797, val_loss = 0.794154942035675\n",
      "epoch n°1223 : train_loss = 2.105708599090576, val_loss = 0.7925612330436707\n",
      "epoch n°1224 : train_loss = 2.0991220474243164, val_loss = 0.7957163453102112\n",
      "epoch n°1225 : train_loss = 2.095449924468994, val_loss = 0.7977730631828308\n",
      "epoch n°1226 : train_loss = 2.0990686416625977, val_loss = 0.8004910945892334\n",
      "epoch n°1227 : train_loss = 2.0962235927581787, val_loss = 0.7962484359741211\n",
      "epoch n°1228 : train_loss = 2.1094677448272705, val_loss = 0.7955822944641113\n",
      "epoch n°1229 : train_loss = 2.1042470932006836, val_loss = 0.800122082233429\n",
      "epoch n°1230 : train_loss = 2.1085495948791504, val_loss = 0.7955752611160278\n",
      "epoch n°1231 : train_loss = 2.1050033569335938, val_loss = 0.796423077583313\n",
      "epoch n°1232 : train_loss = 2.099015951156616, val_loss = 0.7995079755783081\n",
      "epoch n°1233 : train_loss = 2.102855682373047, val_loss = 0.7987033724784851\n",
      "epoch n°1234 : train_loss = 2.099087953567505, val_loss = 0.794854998588562\n",
      "epoch n°1235 : train_loss = 2.0906753540039062, val_loss = 0.7974128723144531\n",
      "epoch n°1236 : train_loss = 2.104212999343872, val_loss = 0.7960862517356873\n",
      "epoch n°1237 : train_loss = 2.1004092693328857, val_loss = 0.796909511089325\n",
      "epoch n°1238 : train_loss = 2.10233211517334, val_loss = 0.7960410714149475\n",
      "epoch n°1239 : train_loss = 2.100714921951294, val_loss = 0.7981890439987183\n",
      "epoch n°1240 : train_loss = 2.099055051803589, val_loss = 0.7963166832923889\n",
      "epoch n°1241 : train_loss = 2.0952343940734863, val_loss = 0.7970633506774902\n",
      "epoch n°1242 : train_loss = 2.114290952682495, val_loss = 0.7962733507156372\n",
      "epoch n°1243 : train_loss = 2.097177505493164, val_loss = 0.7966468930244446\n",
      "epoch n°1244 : train_loss = 2.098426103591919, val_loss = 0.7985073328018188\n",
      "epoch n°1245 : train_loss = 2.1034438610076904, val_loss = 0.7972407341003418\n",
      "epoch n°1246 : train_loss = 2.090566396713257, val_loss = 0.7947134971618652\n",
      "epoch n°1247 : train_loss = 2.0982518196105957, val_loss = 0.7969738841056824\n",
      "epoch n°1248 : train_loss = 2.1041860580444336, val_loss = 0.7988138198852539\n",
      "epoch n°1249 : train_loss = 2.098520278930664, val_loss = 0.7981235980987549\n",
      "epoch n°1250 : train_loss = 2.0978777408599854, val_loss = 0.795471727848053\n",
      "epoch n°1251 : train_loss = 2.099295139312744, val_loss = 0.7978025078773499\n",
      "epoch n°1252 : train_loss = 2.100353956222534, val_loss = 0.7949875593185425\n",
      "epoch n°1253 : train_loss = 2.1115822792053223, val_loss = 0.7982825636863708\n",
      "epoch n°1254 : train_loss = 2.101499557495117, val_loss = 0.80003422498703\n",
      "epoch n°1255 : train_loss = 2.0999252796173096, val_loss = 0.7951002717018127\n",
      "epoch n°1256 : train_loss = 2.0921623706817627, val_loss = 0.7971082329750061\n",
      "epoch n°1257 : train_loss = 2.1115097999572754, val_loss = 0.7979470491409302\n",
      "epoch n°1258 : train_loss = 2.0908284187316895, val_loss = 0.792603611946106\n",
      "epoch n°1259 : train_loss = 2.103618621826172, val_loss = 0.801662802696228\n",
      "epoch n°1260 : train_loss = 2.0932633876800537, val_loss = 0.7957769632339478\n",
      "epoch n°1261 : train_loss = 2.1014013290405273, val_loss = 0.797211766242981\n",
      "epoch n°1262 : train_loss = 2.1030898094177246, val_loss = 0.7964220643043518\n",
      "epoch n°1263 : train_loss = 2.1050686836242676, val_loss = 0.7963280081748962\n",
      "epoch n°1264 : train_loss = 2.1060314178466797, val_loss = 0.7963103652000427\n",
      "epoch n°1265 : train_loss = 2.0960073471069336, val_loss = 0.7964169383049011\n",
      "epoch n°1266 : train_loss = 2.105440855026245, val_loss = 0.8000189661979675\n",
      "epoch n°1267 : train_loss = 2.0953919887542725, val_loss = 0.7943393588066101\n",
      "epoch n°1268 : train_loss = 2.088452100753784, val_loss = 0.7977951169013977\n",
      "epoch n°1269 : train_loss = 2.101975917816162, val_loss = 0.794200599193573\n",
      "epoch n°1270 : train_loss = 2.0984134674072266, val_loss = 0.795183002948761\n",
      "epoch n°1271 : train_loss = 2.095065116882324, val_loss = 0.7994072437286377\n",
      "epoch n°1272 : train_loss = 2.1086156368255615, val_loss = 0.7950085401535034\n",
      "epoch n°1273 : train_loss = 2.096205949783325, val_loss = 0.7998522520065308\n",
      "epoch n°1274 : train_loss = 2.100332736968994, val_loss = 0.8001838326454163\n",
      "epoch n°1275 : train_loss = 2.0990209579467773, val_loss = 0.7962654829025269\n",
      "epoch n°1276 : train_loss = 2.094980478286743, val_loss = 0.8000751733779907\n",
      "epoch n°1277 : train_loss = 2.0981521606445312, val_loss = 0.7968101501464844\n",
      "epoch n°1278 : train_loss = 2.0950093269348145, val_loss = 0.7987743616104126\n",
      "epoch n°1279 : train_loss = 2.1017534732818604, val_loss = 0.7961233258247375\n",
      "epoch n°1280 : train_loss = 2.0992839336395264, val_loss = 0.7991580963134766\n",
      "epoch n°1281 : train_loss = 2.100951671600342, val_loss = 0.7970659136772156\n",
      "epoch n°1282 : train_loss = 2.1016757488250732, val_loss = 0.7930513024330139\n",
      "epoch n°1283 : train_loss = 2.104264974594116, val_loss = 0.7952629327774048\n",
      "epoch n°1284 : train_loss = 2.0984575748443604, val_loss = 0.7946121692657471\n",
      "epoch n°1285 : train_loss = 2.090716600418091, val_loss = 0.7972071170806885\n",
      "epoch n°1286 : train_loss = 2.0952367782592773, val_loss = 0.7963282465934753\n",
      "epoch n°1287 : train_loss = 2.0985043048858643, val_loss = 0.7980572581291199\n",
      "epoch n°1288 : train_loss = 2.0992836952209473, val_loss = 0.7940346598625183\n",
      "epoch n°1289 : train_loss = 2.105875253677368, val_loss = 0.7975383400917053\n",
      "epoch n°1290 : train_loss = 2.1009700298309326, val_loss = 0.7995325326919556\n",
      "epoch n°1291 : train_loss = 2.1045141220092773, val_loss = 0.7969298362731934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°1292 : train_loss = 2.0941238403320312, val_loss = 0.79915851354599\n",
      "epoch n°1293 : train_loss = 2.0899980068206787, val_loss = 0.7945043444633484\n",
      "epoch n°1294 : train_loss = 2.1012470722198486, val_loss = 0.7954715490341187\n",
      "epoch n°1295 : train_loss = 2.1030209064483643, val_loss = 0.7989568710327148\n",
      "epoch n°1296 : train_loss = 2.1029679775238037, val_loss = 0.7999507188796997\n",
      "epoch n°1297 : train_loss = 2.101386547088623, val_loss = 0.7985039353370667\n",
      "epoch n°1298 : train_loss = 2.1010513305664062, val_loss = 0.7934228777885437\n",
      "epoch n°1299 : train_loss = 2.095639705657959, val_loss = 0.7999349236488342\n",
      "epoch n°1300 : train_loss = 2.094599723815918, val_loss = 0.8010786175727844\n",
      "epoch n°1301 : train_loss = 2.1030120849609375, val_loss = 0.7986981272697449\n",
      "epoch n°1302 : train_loss = 2.0941920280456543, val_loss = 0.7945689558982849\n",
      "epoch n°1303 : train_loss = 2.09795880317688, val_loss = 0.7929841876029968\n",
      "epoch n°1304 : train_loss = 2.096822738647461, val_loss = 0.7986739277839661\n",
      "epoch n°1305 : train_loss = 2.094820976257324, val_loss = 0.7958182692527771\n",
      "epoch n°1306 : train_loss = 2.094674587249756, val_loss = 0.7986202836036682\n",
      "epoch n°1307 : train_loss = 2.100529670715332, val_loss = 0.7989177107810974\n",
      "epoch n°1308 : train_loss = 2.0932600498199463, val_loss = 0.7911767363548279\n",
      "epoch n°1309 : train_loss = 2.0984325408935547, val_loss = 0.7957938313484192\n",
      "epoch n°1310 : train_loss = 2.0957515239715576, val_loss = 0.7992503046989441\n",
      "epoch n°1311 : train_loss = 2.0991432666778564, val_loss = 0.7991913557052612\n",
      "epoch n°1312 : train_loss = 2.0930352210998535, val_loss = 0.7960653901100159\n",
      "epoch n°1313 : train_loss = 2.094554901123047, val_loss = 0.7979851961135864\n",
      "epoch n°1314 : train_loss = 2.0988519191741943, val_loss = 0.7969762682914734\n",
      "epoch n°1315 : train_loss = 2.095573902130127, val_loss = 0.7955878973007202\n",
      "epoch n°1316 : train_loss = 2.1035919189453125, val_loss = 0.7954282760620117\n",
      "epoch n°1317 : train_loss = 2.0939443111419678, val_loss = 0.792765736579895\n",
      "epoch n°1318 : train_loss = 2.1009387969970703, val_loss = 0.7957931160926819\n",
      "epoch n°1319 : train_loss = 2.096278429031372, val_loss = 0.8013811111450195\n",
      "epoch n°1320 : train_loss = 2.0919864177703857, val_loss = 0.7948379516601562\n",
      "epoch n°1321 : train_loss = 2.08721661567688, val_loss = 0.7997760772705078\n",
      "epoch n°1322 : train_loss = 2.1057236194610596, val_loss = 0.7990637421607971\n",
      "epoch n°1323 : train_loss = 2.094060182571411, val_loss = 0.7947587370872498\n",
      "epoch n°1324 : train_loss = 2.099581003189087, val_loss = 0.79883873462677\n",
      "epoch n°1325 : train_loss = 2.090217113494873, val_loss = 0.798163652420044\n",
      "epoch n°1326 : train_loss = 2.096181869506836, val_loss = 0.7979324460029602\n",
      "epoch n°1327 : train_loss = 2.102417230606079, val_loss = 0.7974910736083984\n",
      "epoch n°1328 : train_loss = 2.0896410942077637, val_loss = 0.7971675992012024\n",
      "epoch n°1329 : train_loss = 2.0914957523345947, val_loss = 0.7976730465888977\n",
      "epoch n°1330 : train_loss = 2.095001220703125, val_loss = 0.799838662147522\n",
      "epoch n°1331 : train_loss = 2.0947718620300293, val_loss = 0.8017549514770508\n",
      "epoch n°1332 : train_loss = 2.0935404300689697, val_loss = 0.7970604300498962\n",
      "epoch n°1333 : train_loss = 2.0973494052886963, val_loss = 0.7970056533813477\n",
      "epoch n°1334 : train_loss = 2.0924148559570312, val_loss = 0.7923880815505981\n",
      "epoch n°1335 : train_loss = 2.096705675125122, val_loss = 0.7963835597038269\n",
      "epoch n°1336 : train_loss = 2.085294008255005, val_loss = 0.7951216101646423\n",
      "epoch n°1337 : train_loss = 2.088103771209717, val_loss = 0.7983466386795044\n",
      "epoch n°1338 : train_loss = 2.08851957321167, val_loss = 0.7976548671722412\n",
      "epoch n°1339 : train_loss = 2.0886054039001465, val_loss = 0.7910000085830688\n",
      "epoch n°1340 : train_loss = 2.088761329650879, val_loss = 0.7957111597061157\n",
      "epoch n°1341 : train_loss = 2.0843493938446045, val_loss = 0.7942716479301453\n",
      "epoch n°1342 : train_loss = 2.0939738750457764, val_loss = 0.7975355386734009\n",
      "epoch n°1343 : train_loss = 2.0922908782958984, val_loss = 0.800830066204071\n",
      "epoch n°1344 : train_loss = 2.087994337081909, val_loss = 0.7939952611923218\n",
      "epoch n°1345 : train_loss = 2.0951435565948486, val_loss = 0.7953887581825256\n",
      "epoch n°1346 : train_loss = 2.092193603515625, val_loss = 0.793711245059967\n",
      "epoch n°1347 : train_loss = 2.0867743492126465, val_loss = 0.7942664623260498\n",
      "epoch n°1348 : train_loss = 2.0836825370788574, val_loss = 0.7959124445915222\n",
      "epoch n°1349 : train_loss = 2.0839498043060303, val_loss = 0.7977400422096252\n",
      "epoch n°1350 : train_loss = 2.0899486541748047, val_loss = 0.7947283387184143\n",
      "epoch n°1351 : train_loss = 2.0931501388549805, val_loss = 0.7974558472633362\n",
      "epoch n°1352 : train_loss = 2.0915310382843018, val_loss = 0.7993475794792175\n",
      "epoch n°1353 : train_loss = 2.086554527282715, val_loss = 0.7989524006843567\n",
      "epoch n°1354 : train_loss = 2.0860860347747803, val_loss = 0.7982557415962219\n",
      "epoch n°1355 : train_loss = 2.0943543910980225, val_loss = 0.7955127954483032\n",
      "epoch n°1356 : train_loss = 2.0940566062927246, val_loss = 0.7989557981491089\n",
      "epoch n°1357 : train_loss = 2.0936803817749023, val_loss = 0.7994952201843262\n",
      "epoch n°1358 : train_loss = 2.0977108478546143, val_loss = 0.7972631454467773\n",
      "epoch n°1359 : train_loss = 2.104448080062866, val_loss = 0.7971495389938354\n",
      "epoch n°1360 : train_loss = 2.098080635070801, val_loss = 0.8001684546470642\n",
      "epoch n°1361 : train_loss = 2.097440719604492, val_loss = 0.7996182441711426\n",
      "epoch n°1362 : train_loss = 2.0908291339874268, val_loss = 0.799361526966095\n",
      "epoch n°1363 : train_loss = 2.0902979373931885, val_loss = 0.8022501468658447\n",
      "epoch n°1364 : train_loss = 2.0890161991119385, val_loss = 0.7969231605529785\n",
      "epoch n°1365 : train_loss = 2.0884201526641846, val_loss = 0.7982631921768188\n",
      "epoch n°1366 : train_loss = 2.0858139991760254, val_loss = 0.7979301810264587\n",
      "epoch n°1367 : train_loss = 2.093149423599243, val_loss = 0.7965745329856873\n",
      "epoch n°1368 : train_loss = 2.086008071899414, val_loss = 0.7995242476463318\n",
      "epoch n°1369 : train_loss = 2.088116407394409, val_loss = 0.7974258661270142\n",
      "epoch n°1370 : train_loss = 2.081646203994751, val_loss = 0.7972423434257507\n",
      "epoch n°1371 : train_loss = 2.089641571044922, val_loss = 0.7988490462303162\n",
      "epoch n°1372 : train_loss = 2.082409620285034, val_loss = 0.7983108758926392\n",
      "epoch n°1373 : train_loss = 2.086934804916382, val_loss = 0.7972953915596008\n",
      "epoch n°1374 : train_loss = 2.0974745750427246, val_loss = 0.7981008291244507\n",
      "epoch n°1375 : train_loss = 2.0923807621002197, val_loss = 0.7956565618515015\n",
      "epoch n°1376 : train_loss = 2.0854763984680176, val_loss = 0.7961441278457642\n",
      "epoch n°1377 : train_loss = 2.091780662536621, val_loss = 0.7980307936668396\n",
      "epoch n°1378 : train_loss = 2.0825178623199463, val_loss = 0.8022641539573669\n",
      "epoch n°1379 : train_loss = 2.0907211303710938, val_loss = 0.7932451367378235\n",
      "epoch n°1380 : train_loss = 2.0772788524627686, val_loss = 0.7949753403663635\n",
      "epoch n°1381 : train_loss = 2.098344326019287, val_loss = 0.7987455725669861\n",
      "epoch n°1382 : train_loss = 2.0807998180389404, val_loss = 0.7954208850860596\n",
      "epoch n°1383 : train_loss = 2.0916783809661865, val_loss = 0.7985413670539856\n",
      "epoch n°1384 : train_loss = 2.091135025024414, val_loss = 0.7983269095420837\n",
      "epoch n°1385 : train_loss = 2.0850908756256104, val_loss = 0.7952677607536316\n",
      "epoch n°1386 : train_loss = 2.080251455307007, val_loss = 0.7957744002342224\n",
      "epoch n°1387 : train_loss = 2.0919909477233887, val_loss = 0.7927076816558838\n",
      "epoch n°1388 : train_loss = 2.0868825912475586, val_loss = 0.795784592628479\n",
      "epoch n°1389 : train_loss = 2.086315155029297, val_loss = 0.7951374053955078\n",
      "epoch n°1390 : train_loss = 2.0841426849365234, val_loss = 0.7976109981536865\n",
      "epoch n°1391 : train_loss = 2.090885877609253, val_loss = 0.7969797253608704\n",
      "epoch n°1392 : train_loss = 2.0910539627075195, val_loss = 0.8025256991386414\n",
      "epoch n°1393 : train_loss = 2.085336685180664, val_loss = 0.7955235242843628\n",
      "epoch n°1394 : train_loss = 2.0791499614715576, val_loss = 0.7973514199256897\n",
      "epoch n°1395 : train_loss = 2.084834337234497, val_loss = 0.7979439496994019\n",
      "epoch n°1396 : train_loss = 2.0984764099121094, val_loss = 0.798966109752655\n",
      "epoch n°1397 : train_loss = 2.0888848304748535, val_loss = 0.7972739338874817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°1398 : train_loss = 2.0858755111694336, val_loss = 0.7950429320335388\n",
      "epoch n°1399 : train_loss = 2.0781009197235107, val_loss = 0.7961634397506714\n",
      "epoch n°1400 : train_loss = 2.079864501953125, val_loss = 0.7962453961372375\n",
      "epoch n°1401 : train_loss = 2.082064628601074, val_loss = 0.7993195056915283\n",
      "epoch n°1402 : train_loss = 2.0821774005889893, val_loss = 0.7977215647697449\n",
      "epoch n°1403 : train_loss = 2.086373805999756, val_loss = 0.7965757250785828\n",
      "epoch n°1404 : train_loss = 2.0756876468658447, val_loss = 0.7975977659225464\n",
      "epoch n°1405 : train_loss = 2.0853934288024902, val_loss = 0.7937021851539612\n",
      "epoch n°1406 : train_loss = 2.0841803550720215, val_loss = 0.8018986582756042\n",
      "epoch n°1407 : train_loss = 2.083834648132324, val_loss = 0.7994644641876221\n",
      "epoch n°1408 : train_loss = 2.0864477157592773, val_loss = 0.7978305220603943\n",
      "epoch n°1409 : train_loss = 2.082054853439331, val_loss = 0.7961593270301819\n",
      "epoch n°1410 : train_loss = 2.078791618347168, val_loss = 0.796290397644043\n",
      "epoch n°1411 : train_loss = 2.078213930130005, val_loss = 0.797583818435669\n",
      "epoch n°1412 : train_loss = 2.070128917694092, val_loss = 0.7980804443359375\n",
      "epoch n°1413 : train_loss = 2.088395357131958, val_loss = 0.794812023639679\n",
      "epoch n°1414 : train_loss = 2.0807504653930664, val_loss = 0.7924707531929016\n",
      "epoch n°1415 : train_loss = 2.0725979804992676, val_loss = 0.7972113490104675\n",
      "epoch n°1416 : train_loss = 2.0788519382476807, val_loss = 0.7923197150230408\n",
      "epoch n°1417 : train_loss = 2.083634614944458, val_loss = 0.7979405522346497\n",
      "epoch n°1418 : train_loss = 2.090111255645752, val_loss = 0.7945083379745483\n",
      "epoch n°1419 : train_loss = 2.083937406539917, val_loss = 0.7964231371879578\n",
      "epoch n°1420 : train_loss = 2.085286855697632, val_loss = 0.798213005065918\n",
      "epoch n°1421 : train_loss = 2.081329584121704, val_loss = 0.7960658073425293\n",
      "epoch n°1422 : train_loss = 2.082887649536133, val_loss = 0.7910916209220886\n",
      "epoch n°1423 : train_loss = 2.0857062339782715, val_loss = 0.7967720031738281\n",
      "epoch n°1424 : train_loss = 2.086993932723999, val_loss = 0.796062171459198\n",
      "epoch n°1425 : train_loss = 2.0816102027893066, val_loss = 0.7958590388298035\n",
      "epoch n°1426 : train_loss = 2.0805001258850098, val_loss = 0.7964458465576172\n",
      "epoch n°1427 : train_loss = 2.0854859352111816, val_loss = 0.7956047654151917\n",
      "epoch n°1428 : train_loss = 2.0809247493743896, val_loss = 0.798177182674408\n",
      "epoch n°1429 : train_loss = 2.0937960147857666, val_loss = 0.7946109771728516\n",
      "epoch n°1430 : train_loss = 2.0815670490264893, val_loss = 0.797345757484436\n",
      "epoch n°1431 : train_loss = 2.076569080352783, val_loss = 0.7965400218963623\n",
      "epoch n°1432 : train_loss = 2.0792272090911865, val_loss = 0.7916539907455444\n",
      "epoch n°1433 : train_loss = 2.0896286964416504, val_loss = 0.7945605516433716\n",
      "epoch n°1434 : train_loss = 2.0745701789855957, val_loss = 0.7992696762084961\n",
      "epoch n°1435 : train_loss = 2.071483850479126, val_loss = 0.7957462668418884\n",
      "epoch n°1436 : train_loss = 2.0828604698181152, val_loss = 0.7949342131614685\n",
      "epoch n°1437 : train_loss = 2.087851047515869, val_loss = 0.7973856925964355\n",
      "epoch n°1438 : train_loss = 2.086345911026001, val_loss = 0.7927312254905701\n",
      "epoch n°1439 : train_loss = 2.0760419368743896, val_loss = 0.7971026301383972\n",
      "epoch n°1440 : train_loss = 2.0896053314208984, val_loss = 0.7983774542808533\n",
      "epoch n°1441 : train_loss = 2.0803990364074707, val_loss = 0.7989976406097412\n",
      "epoch n°1442 : train_loss = 2.0805599689483643, val_loss = 0.7933104634284973\n",
      "epoch n°1443 : train_loss = 2.094773292541504, val_loss = 0.8010033369064331\n",
      "epoch n°1444 : train_loss = 2.079547882080078, val_loss = 0.7980666756629944\n",
      "epoch n°1445 : train_loss = 2.0822980403900146, val_loss = 0.7916105389595032\n",
      "epoch n°1446 : train_loss = 2.078962564468384, val_loss = 0.7944105267524719\n",
      "epoch n°1447 : train_loss = 2.080003261566162, val_loss = 0.7982590198516846\n",
      "epoch n°1448 : train_loss = 2.079982280731201, val_loss = 0.7936242818832397\n",
      "epoch n°1449 : train_loss = 2.081953763961792, val_loss = 0.7933563590049744\n",
      "epoch n°1450 : train_loss = 2.079446315765381, val_loss = 0.79824298620224\n",
      "epoch n°1451 : train_loss = 2.0803380012512207, val_loss = 0.793310821056366\n",
      "epoch n°1452 : train_loss = 2.0898826122283936, val_loss = 0.7971598505973816\n",
      "epoch n°1453 : train_loss = 2.079345226287842, val_loss = 0.79217928647995\n",
      "epoch n°1454 : train_loss = 2.08184814453125, val_loss = 0.7931339740753174\n",
      "epoch n°1455 : train_loss = 2.087547779083252, val_loss = 0.7977868914604187\n",
      "epoch n°1456 : train_loss = 2.0788075923919678, val_loss = 0.7922071218490601\n",
      "epoch n°1457 : train_loss = 2.0854949951171875, val_loss = 0.7898125648498535\n",
      "epoch n°1458 : train_loss = 2.0741567611694336, val_loss = 0.7983487248420715\n",
      "epoch n°1459 : train_loss = 2.0796988010406494, val_loss = 0.7904831171035767\n",
      "epoch n°1460 : train_loss = 2.081354856491089, val_loss = 0.7965703010559082\n",
      "epoch n°1461 : train_loss = 2.075737237930298, val_loss = 0.795714259147644\n",
      "epoch n°1462 : train_loss = 2.082871675491333, val_loss = 0.794786810874939\n",
      "epoch n°1463 : train_loss = 2.0785791873931885, val_loss = 0.7921321988105774\n",
      "epoch n°1464 : train_loss = 2.076336145401001, val_loss = 0.7965178489685059\n",
      "epoch n°1465 : train_loss = 2.085963726043701, val_loss = 0.7991916537284851\n",
      "epoch n°1466 : train_loss = 2.083259105682373, val_loss = 0.7939576506614685\n",
      "epoch n°1467 : train_loss = 2.0843470096588135, val_loss = 0.7989095449447632\n",
      "epoch n°1468 : train_loss = 2.083880662918091, val_loss = 0.7942508459091187\n",
      "epoch n°1469 : train_loss = 2.0825090408325195, val_loss = 0.8006013035774231\n",
      "epoch n°1470 : train_loss = 2.068775177001953, val_loss = 0.7961458563804626\n",
      "epoch n°1471 : train_loss = 2.082019567489624, val_loss = 0.7919975519180298\n",
      "epoch n°1472 : train_loss = 2.0804662704467773, val_loss = 0.7910321354866028\n",
      "epoch n°1473 : train_loss = 2.071305751800537, val_loss = 0.7964487075805664\n",
      "epoch n°1474 : train_loss = 2.0808632373809814, val_loss = 0.7929218411445618\n",
      "epoch n°1475 : train_loss = 2.0791854858398438, val_loss = 0.7972450852394104\n",
      "epoch n°1476 : train_loss = 2.0893495082855225, val_loss = 0.7980220317840576\n",
      "epoch n°1477 : train_loss = 2.071744203567505, val_loss = 0.7955716252326965\n",
      "epoch n°1478 : train_loss = 2.0732805728912354, val_loss = 0.794809103012085\n",
      "epoch n°1479 : train_loss = 2.082253932952881, val_loss = 0.7978630065917969\n",
      "epoch n°1480 : train_loss = 2.0787227153778076, val_loss = 0.7963687777519226\n",
      "epoch n°1481 : train_loss = 2.080396890640259, val_loss = 0.7973586320877075\n",
      "epoch n°1482 : train_loss = 2.0833730697631836, val_loss = 0.7959751486778259\n",
      "epoch n°1483 : train_loss = 2.0883259773254395, val_loss = 0.7962966561317444\n",
      "epoch n°1484 : train_loss = 2.075469732284546, val_loss = 0.796550989151001\n",
      "epoch n°1485 : train_loss = 2.0694940090179443, val_loss = 0.7971278429031372\n",
      "epoch n°1486 : train_loss = 2.0771350860595703, val_loss = 0.7928625345230103\n",
      "epoch n°1487 : train_loss = 2.0755209922790527, val_loss = 0.7974904775619507\n",
      "epoch n°1488 : train_loss = 2.0826163291931152, val_loss = 0.7958465814590454\n",
      "epoch n°1489 : train_loss = 2.0716452598571777, val_loss = 0.7993550896644592\n",
      "epoch n°1490 : train_loss = 2.0730950832366943, val_loss = 0.7990490198135376\n",
      "epoch n°1491 : train_loss = 2.0795695781707764, val_loss = 0.7938830256462097\n",
      "epoch n°1492 : train_loss = 2.0828349590301514, val_loss = 0.7929452061653137\n",
      "epoch n°1493 : train_loss = 2.0820469856262207, val_loss = 0.7932238578796387\n",
      "epoch n°1494 : train_loss = 2.0761053562164307, val_loss = 0.8023089170455933\n",
      "epoch n°1495 : train_loss = 2.076209306716919, val_loss = 0.7985722422599792\n",
      "epoch n°1496 : train_loss = 2.073056936264038, val_loss = 0.7957724928855896\n",
      "epoch n°1497 : train_loss = 2.0729355812072754, val_loss = 0.7942186594009399\n",
      "epoch n°1498 : train_loss = 2.0711441040039062, val_loss = 0.7947739362716675\n",
      "epoch n°1499 : train_loss = 2.0818750858306885, val_loss = 0.7911419868469238\n",
      "epoch n°1500 : train_loss = 2.0811727046966553, val_loss = 0.794792652130127\n",
      "epoch n°1501 : train_loss = 2.073652505874634, val_loss = 0.802516758441925\n",
      "epoch n°1502 : train_loss = 2.067786931991577, val_loss = 0.7961429953575134\n",
      "epoch n°1503 : train_loss = 2.0771050453186035, val_loss = 0.7965822815895081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°1504 : train_loss = 2.0792768001556396, val_loss = 0.7947285175323486\n",
      "epoch n°1505 : train_loss = 2.067997932434082, val_loss = 0.7958195805549622\n",
      "epoch n°1506 : train_loss = 2.0802130699157715, val_loss = 0.7955266833305359\n",
      "epoch n°1507 : train_loss = 2.0666282176971436, val_loss = 0.7910339832305908\n",
      "epoch n°1508 : train_loss = 2.084613800048828, val_loss = 0.7950709462165833\n",
      "epoch n°1509 : train_loss = 2.073394298553467, val_loss = 0.793666422367096\n",
      "epoch n°1510 : train_loss = 2.0776944160461426, val_loss = 0.7979140877723694\n",
      "epoch n°1511 : train_loss = 2.067915678024292, val_loss = 0.7946256995201111\n",
      "epoch n°1512 : train_loss = 2.0817127227783203, val_loss = 0.7986162304878235\n",
      "epoch n°1513 : train_loss = 2.078017234802246, val_loss = 0.7962249517440796\n",
      "epoch n°1514 : train_loss = 2.0805952548980713, val_loss = 0.7931827306747437\n",
      "epoch n°1515 : train_loss = 2.085113525390625, val_loss = 0.798115611076355\n",
      "epoch n°1516 : train_loss = 2.072319746017456, val_loss = 0.7946310639381409\n",
      "epoch n°1517 : train_loss = 2.0795600414276123, val_loss = 0.792740523815155\n",
      "epoch n°1518 : train_loss = 2.0664734840393066, val_loss = 0.7971985340118408\n",
      "epoch n°1519 : train_loss = 2.0781912803649902, val_loss = 0.7935531735420227\n",
      "epoch n°1520 : train_loss = 2.084990978240967, val_loss = 0.7948402166366577\n",
      "epoch n°1521 : train_loss = 2.0699141025543213, val_loss = 0.7918422222137451\n",
      "epoch n°1522 : train_loss = 2.074462413787842, val_loss = 0.7938661575317383\n",
      "epoch n°1523 : train_loss = 2.079519033432007, val_loss = 0.7946441173553467\n",
      "epoch n°1524 : train_loss = 2.084636926651001, val_loss = 0.7924666404724121\n",
      "epoch n°1525 : train_loss = 2.0813472270965576, val_loss = 0.7982730865478516\n",
      "epoch n°1526 : train_loss = 2.073199987411499, val_loss = 0.793512761592865\n",
      "epoch n°1527 : train_loss = 2.0785562992095947, val_loss = 0.79669588804245\n",
      "epoch n°1528 : train_loss = 2.073403835296631, val_loss = 0.7959305047988892\n",
      "epoch n°1529 : train_loss = 2.0766665935516357, val_loss = 0.7929654717445374\n",
      "epoch n°1530 : train_loss = 2.0720155239105225, val_loss = 0.7971246242523193\n",
      "epoch n°1531 : train_loss = 2.076569080352783, val_loss = 0.7911876440048218\n",
      "epoch n°1532 : train_loss = 2.0705432891845703, val_loss = 0.7957795858383179\n",
      "epoch n°1533 : train_loss = 2.081815719604492, val_loss = 0.7960295081138611\n",
      "epoch n°1534 : train_loss = 2.0721163749694824, val_loss = 0.7950478196144104\n",
      "epoch n°1535 : train_loss = 2.08439564704895, val_loss = 0.793391227722168\n",
      "epoch n°1536 : train_loss = 2.07209849357605, val_loss = 0.7955665588378906\n",
      "epoch n°1537 : train_loss = 2.065594434738159, val_loss = 0.7953615784645081\n",
      "epoch n°1538 : train_loss = 2.0728299617767334, val_loss = 0.7927331328392029\n",
      "epoch n°1539 : train_loss = 2.067554473876953, val_loss = 0.7932299971580505\n",
      "epoch n°1540 : train_loss = 2.0742690563201904, val_loss = 0.7975149750709534\n",
      "epoch n°1541 : train_loss = 2.076385021209717, val_loss = 0.798486590385437\n",
      "epoch n°1542 : train_loss = 2.084693431854248, val_loss = 0.7928484082221985\n",
      "epoch n°1543 : train_loss = 2.0822949409484863, val_loss = 0.7973973751068115\n",
      "epoch n°1544 : train_loss = 2.071340322494507, val_loss = 0.7967524528503418\n",
      "epoch n°1545 : train_loss = 2.079158067703247, val_loss = 0.8025360107421875\n",
      "epoch n°1546 : train_loss = 2.072448253631592, val_loss = 0.7957825064659119\n",
      "epoch n°1547 : train_loss = 2.061349391937256, val_loss = 0.7977297306060791\n",
      "epoch n°1548 : train_loss = 2.073866605758667, val_loss = 0.7956959009170532\n",
      "epoch n°1549 : train_loss = 2.0640017986297607, val_loss = 0.7959792613983154\n",
      "epoch n°1550 : train_loss = 2.071542263031006, val_loss = 0.7904817461967468\n",
      "epoch n°1551 : train_loss = 2.0678763389587402, val_loss = 0.7945213317871094\n",
      "epoch n°1552 : train_loss = 2.071810007095337, val_loss = 0.7963452339172363\n",
      "epoch n°1553 : train_loss = 2.073711633682251, val_loss = 0.7980467081069946\n",
      "epoch n°1554 : train_loss = 2.072493076324463, val_loss = 0.7944608926773071\n",
      "epoch n°1555 : train_loss = 2.0721471309661865, val_loss = 0.789146363735199\n",
      "epoch n°1556 : train_loss = 2.070298194885254, val_loss = 0.7945897579193115\n",
      "epoch n°1557 : train_loss = 2.0633859634399414, val_loss = 0.7945050001144409\n",
      "epoch n°1558 : train_loss = 2.0674383640289307, val_loss = 0.7956230044364929\n",
      "epoch n°1559 : train_loss = 2.0710933208465576, val_loss = 0.7975298762321472\n",
      "epoch n°1560 : train_loss = 2.068002939224243, val_loss = 0.7939401865005493\n",
      "epoch n°1561 : train_loss = 2.0719246864318848, val_loss = 0.7955880761146545\n",
      "epoch n°1562 : train_loss = 2.074089527130127, val_loss = 0.797222375869751\n",
      "epoch n°1563 : train_loss = 2.072549343109131, val_loss = 0.796956479549408\n",
      "epoch n°1564 : train_loss = 2.066711902618408, val_loss = 0.7941086888313293\n",
      "epoch n°1565 : train_loss = 2.081428289413452, val_loss = 0.7951985597610474\n",
      "epoch n°1566 : train_loss = 2.0655202865600586, val_loss = 0.7970149517059326\n",
      "epoch n°1567 : train_loss = 2.0666451454162598, val_loss = 0.7964370250701904\n",
      "epoch n°1568 : train_loss = 2.0698695182800293, val_loss = 0.800196647644043\n",
      "epoch n°1569 : train_loss = 2.0687789916992188, val_loss = 0.7968546748161316\n",
      "epoch n°1570 : train_loss = 2.0823330879211426, val_loss = 0.7966917753219604\n",
      "epoch n°1571 : train_loss = 2.0779879093170166, val_loss = 0.7937793731689453\n",
      "epoch n°1572 : train_loss = 2.0779738426208496, val_loss = 0.793937623500824\n",
      "epoch n°1573 : train_loss = 2.0718672275543213, val_loss = 0.7965412139892578\n",
      "epoch n°1574 : train_loss = 2.068861246109009, val_loss = 0.793853223323822\n",
      "epoch n°1575 : train_loss = 2.0761516094207764, val_loss = 0.7955406308174133\n",
      "epoch n°1576 : train_loss = 2.0703253746032715, val_loss = 0.7951593995094299\n",
      "epoch n°1577 : train_loss = 2.069699287414551, val_loss = 0.7947388291358948\n",
      "epoch n°1578 : train_loss = 2.0727317333221436, val_loss = 0.7916404604911804\n",
      "epoch n°1579 : train_loss = 2.0720267295837402, val_loss = 0.7956414222717285\n",
      "epoch n°1580 : train_loss = 2.0726983547210693, val_loss = 0.7995968461036682\n",
      "epoch n°1581 : train_loss = 2.0574755668640137, val_loss = 0.7951233386993408\n",
      "epoch n°1582 : train_loss = 2.068258285522461, val_loss = 0.7979082465171814\n",
      "epoch n°1583 : train_loss = 2.0704660415649414, val_loss = 0.7987371683120728\n",
      "epoch n°1584 : train_loss = 2.0694637298583984, val_loss = 0.7957692742347717\n",
      "epoch n°1585 : train_loss = 2.067136526107788, val_loss = 0.7940056920051575\n",
      "epoch n°1586 : train_loss = 2.0666916370391846, val_loss = 0.7946323752403259\n",
      "epoch n°1587 : train_loss = 2.0701260566711426, val_loss = 0.7920511960983276\n",
      "epoch n°1588 : train_loss = 2.075084686279297, val_loss = 0.7958448529243469\n",
      "epoch n°1589 : train_loss = 2.067182779312134, val_loss = 0.79651939868927\n",
      "epoch n°1590 : train_loss = 2.0642173290252686, val_loss = 0.7962647676467896\n",
      "epoch n°1591 : train_loss = 2.0719048976898193, val_loss = 0.7962407469749451\n",
      "epoch n°1592 : train_loss = 2.0674777030944824, val_loss = 0.7924873232841492\n",
      "epoch n°1593 : train_loss = 2.071331262588501, val_loss = 0.7942869067192078\n",
      "epoch n°1594 : train_loss = 2.0690395832061768, val_loss = 0.7913993000984192\n",
      "epoch n°1595 : train_loss = 2.0677523612976074, val_loss = 0.7992463707923889\n",
      "epoch n°1596 : train_loss = 2.073331594467163, val_loss = 0.7931789755821228\n",
      "epoch n°1597 : train_loss = 2.0664637088775635, val_loss = 0.7953673601150513\n",
      "epoch n°1598 : train_loss = 2.0670461654663086, val_loss = 0.7909367680549622\n",
      "epoch n°1599 : train_loss = 2.059122085571289, val_loss = 0.7966179847717285\n",
      "epoch n°1600 : train_loss = 2.0615344047546387, val_loss = 0.7982661128044128\n",
      "epoch n°1601 : train_loss = 2.0636723041534424, val_loss = 0.7989103198051453\n",
      "epoch n°1602 : train_loss = 2.073115110397339, val_loss = 0.7942975759506226\n",
      "epoch n°1603 : train_loss = 2.063631772994995, val_loss = 0.7929525375366211\n",
      "epoch n°1604 : train_loss = 2.0733766555786133, val_loss = 0.7973384261131287\n",
      "epoch n°1605 : train_loss = 2.067244291305542, val_loss = 0.7955458164215088\n",
      "epoch n°1606 : train_loss = 2.0649313926696777, val_loss = 0.7953009009361267\n",
      "epoch n°1607 : train_loss = 2.063936471939087, val_loss = 0.796722412109375\n",
      "epoch n°1608 : train_loss = 2.066011667251587, val_loss = 0.7913421988487244\n",
      "epoch n°1609 : train_loss = 2.0656628608703613, val_loss = 0.7964420318603516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°1610 : train_loss = 2.07092547416687, val_loss = 0.7936727404594421\n",
      "epoch n°1611 : train_loss = 2.0715253353118896, val_loss = 0.7996019124984741\n",
      "epoch n°1612 : train_loss = 2.0569565296173096, val_loss = 0.795872688293457\n",
      "epoch n°1613 : train_loss = 2.0660579204559326, val_loss = 0.795289933681488\n",
      "epoch n°1614 : train_loss = 2.0653536319732666, val_loss = 0.7957164645195007\n",
      "epoch n°1615 : train_loss = 2.0614593029022217, val_loss = 0.799431324005127\n",
      "epoch n°1616 : train_loss = 2.073929786682129, val_loss = 0.7939778566360474\n",
      "epoch n°1617 : train_loss = 2.068357229232788, val_loss = 0.79669588804245\n",
      "epoch n°1618 : train_loss = 2.069711685180664, val_loss = 0.7962653636932373\n",
      "epoch n°1619 : train_loss = 2.065246820449829, val_loss = 0.7969264388084412\n",
      "epoch n°1620 : train_loss = 2.067380666732788, val_loss = 0.7949914336204529\n",
      "epoch n°1621 : train_loss = 2.0652406215667725, val_loss = 0.799624502658844\n",
      "epoch n°1622 : train_loss = 2.0611672401428223, val_loss = 0.7967348694801331\n",
      "epoch n°1623 : train_loss = 2.0649330615997314, val_loss = 0.7951374053955078\n",
      "epoch n°1624 : train_loss = 2.0644373893737793, val_loss = 0.7927729487419128\n",
      "epoch n°1625 : train_loss = 2.062729597091675, val_loss = 0.7953333258628845\n",
      "epoch n°1626 : train_loss = 2.0625483989715576, val_loss = 0.7996419668197632\n",
      "epoch n°1627 : train_loss = 2.058959484100342, val_loss = 0.798251748085022\n",
      "epoch n°1628 : train_loss = 2.068328380584717, val_loss = 0.794887125492096\n",
      "epoch n°1629 : train_loss = 2.069092273712158, val_loss = 0.7971165180206299\n",
      "epoch n°1630 : train_loss = 2.0773138999938965, val_loss = 0.79654860496521\n",
      "epoch n°1631 : train_loss = 2.065377712249756, val_loss = 0.7941365242004395\n",
      "epoch n°1632 : train_loss = 2.057147741317749, val_loss = 0.7974117994308472\n",
      "epoch n°1633 : train_loss = 2.0656254291534424, val_loss = 0.7991423010826111\n",
      "epoch n°1634 : train_loss = 2.068082094192505, val_loss = 0.7984257340431213\n",
      "epoch n°1635 : train_loss = 2.0691072940826416, val_loss = 0.7928861975669861\n",
      "epoch n°1636 : train_loss = 2.0628983974456787, val_loss = 0.7973124384880066\n",
      "epoch n°1637 : train_loss = 2.0624005794525146, val_loss = 0.796184241771698\n",
      "epoch n°1638 : train_loss = 2.06367564201355, val_loss = 0.7970576882362366\n",
      "epoch n°1639 : train_loss = 2.057156562805176, val_loss = 0.7982109189033508\n",
      "epoch n°1640 : train_loss = 2.058389663696289, val_loss = 0.7903113961219788\n",
      "epoch n°1641 : train_loss = 2.0709116458892822, val_loss = 0.7948012351989746\n",
      "epoch n°1642 : train_loss = 2.063663959503174, val_loss = 0.7959492802619934\n",
      "epoch n°1643 : train_loss = 2.063322067260742, val_loss = 0.7967716455459595\n",
      "epoch n°1644 : train_loss = 2.0615880489349365, val_loss = 0.79526686668396\n",
      "epoch n°1645 : train_loss = 2.0607588291168213, val_loss = 0.7961958646774292\n",
      "epoch n°1646 : train_loss = 2.06623911857605, val_loss = 0.7961658239364624\n",
      "epoch n°1647 : train_loss = 2.0651447772979736, val_loss = 0.7939426898956299\n",
      "epoch n°1648 : train_loss = 2.06624698638916, val_loss = 0.7989599108695984\n",
      "epoch n°1649 : train_loss = 2.0600533485412598, val_loss = 0.7955085635185242\n",
      "epoch n°1650 : train_loss = 2.062615156173706, val_loss = 0.7948898673057556\n",
      "epoch n°1651 : train_loss = 2.0512964725494385, val_loss = 0.7963349223136902\n",
      "epoch n°1652 : train_loss = 2.0633535385131836, val_loss = 0.7970221638679504\n",
      "epoch n°1653 : train_loss = 2.0647878646850586, val_loss = 0.794373095035553\n",
      "epoch n°1654 : train_loss = 2.061729907989502, val_loss = 0.7933211326599121\n",
      "epoch n°1655 : train_loss = 2.050213098526001, val_loss = 0.7942781448364258\n",
      "epoch n°1656 : train_loss = 2.0670905113220215, val_loss = 0.7936205863952637\n",
      "epoch n°1657 : train_loss = 2.067920446395874, val_loss = 0.7951291799545288\n",
      "epoch n°1658 : train_loss = 2.0567188262939453, val_loss = 0.7946538925170898\n",
      "epoch n°1659 : train_loss = 2.0593793392181396, val_loss = 0.7946217656135559\n",
      "epoch n°1660 : train_loss = 2.0644617080688477, val_loss = 0.7967357635498047\n",
      "epoch n°1661 : train_loss = 2.0595126152038574, val_loss = 0.7967504262924194\n",
      "epoch n°1662 : train_loss = 2.0590319633483887, val_loss = 0.7950519919395447\n",
      "epoch n°1663 : train_loss = 2.0681841373443604, val_loss = 0.794355571269989\n",
      "epoch n°1664 : train_loss = 2.0729570388793945, val_loss = 0.7965829968452454\n",
      "epoch n°1665 : train_loss = 2.059661388397217, val_loss = 0.794785737991333\n",
      "epoch n°1666 : train_loss = 2.063300132751465, val_loss = 0.7967075705528259\n",
      "epoch n°1667 : train_loss = 2.053438425064087, val_loss = 0.7949705123901367\n",
      "epoch n°1668 : train_loss = 2.0615224838256836, val_loss = 0.7961210608482361\n",
      "epoch n°1669 : train_loss = 2.0568063259124756, val_loss = 0.7916038036346436\n",
      "epoch n°1670 : train_loss = 2.0603504180908203, val_loss = 0.7950100898742676\n",
      "epoch n°1671 : train_loss = 2.053229331970215, val_loss = 0.7925000190734863\n",
      "epoch n°1672 : train_loss = 2.059424638748169, val_loss = 0.7984446287155151\n",
      "epoch n°1673 : train_loss = 2.0531370639801025, val_loss = 0.7962169051170349\n",
      "epoch n°1674 : train_loss = 2.05890154838562, val_loss = 0.7937485575675964\n",
      "epoch n°1675 : train_loss = 2.0582563877105713, val_loss = 0.7945229411125183\n",
      "epoch n°1676 : train_loss = 2.061551570892334, val_loss = 0.7943309545516968\n",
      "epoch n°1677 : train_loss = 2.0540645122528076, val_loss = 0.7945175766944885\n",
      "epoch n°1678 : train_loss = 2.0556039810180664, val_loss = 0.7942965030670166\n",
      "epoch n°1679 : train_loss = 2.06231427192688, val_loss = 0.7955538630485535\n",
      "epoch n°1680 : train_loss = 2.065093517303467, val_loss = 0.7954447865486145\n",
      "epoch n°1681 : train_loss = 2.0609395503997803, val_loss = 0.7918229699134827\n",
      "epoch n°1682 : train_loss = 2.053529977798462, val_loss = 0.7972285151481628\n",
      "epoch n°1683 : train_loss = 2.0622220039367676, val_loss = 0.7944971919059753\n",
      "epoch n°1684 : train_loss = 2.055246353149414, val_loss = 0.7933347225189209\n",
      "epoch n°1685 : train_loss = 2.06318736076355, val_loss = 0.7926356196403503\n",
      "epoch n°1686 : train_loss = 2.0498766899108887, val_loss = 0.7899552583694458\n",
      "epoch n°1687 : train_loss = 2.071810245513916, val_loss = 0.7965969443321228\n",
      "epoch n°1688 : train_loss = 2.060633897781372, val_loss = 0.7979298233985901\n",
      "epoch n°1689 : train_loss = 2.056122303009033, val_loss = 0.7979527711868286\n",
      "epoch n°1690 : train_loss = 2.059441089630127, val_loss = 0.7984631657600403\n",
      "epoch n°1691 : train_loss = 2.0577499866485596, val_loss = 0.7934596538543701\n",
      "epoch n°1692 : train_loss = 2.0636725425720215, val_loss = 0.7937011122703552\n",
      "epoch n°1693 : train_loss = 2.0599429607391357, val_loss = 0.7951329946517944\n",
      "epoch n°1694 : train_loss = 2.0691912174224854, val_loss = 0.7930605411529541\n",
      "epoch n°1695 : train_loss = 2.056771755218506, val_loss = 0.7913208603858948\n",
      "epoch n°1696 : train_loss = 2.050769329071045, val_loss = 0.7991710901260376\n",
      "epoch n°1697 : train_loss = 2.0561165809631348, val_loss = 0.7959757447242737\n",
      "epoch n°1698 : train_loss = 2.0574724674224854, val_loss = 0.7953278422355652\n",
      "epoch n°1699 : train_loss = 2.0562288761138916, val_loss = 0.7950741648674011\n",
      "epoch n°1700 : train_loss = 2.065563201904297, val_loss = 0.7942308783531189\n",
      "epoch n°1701 : train_loss = 2.0599920749664307, val_loss = 0.798149824142456\n",
      "epoch n°1702 : train_loss = 2.061929702758789, val_loss = 0.7949825525283813\n",
      "epoch n°1703 : train_loss = 2.0597116947174072, val_loss = 0.7943482398986816\n",
      "epoch n°1704 : train_loss = 2.058917284011841, val_loss = 0.7956903576850891\n",
      "epoch n°1705 : train_loss = 2.0614917278289795, val_loss = 0.7943151593208313\n",
      "epoch n°1706 : train_loss = 2.06500506401062, val_loss = 0.7946903109550476\n",
      "epoch n°1707 : train_loss = 2.057109832763672, val_loss = 0.7961186766624451\n",
      "epoch n°1708 : train_loss = 2.0610716342926025, val_loss = 0.7963427901268005\n",
      "epoch n°1709 : train_loss = 2.061383008956909, val_loss = 0.7983585000038147\n",
      "epoch n°1710 : train_loss = 2.049906015396118, val_loss = 0.794306218624115\n",
      "epoch n°1711 : train_loss = 2.0629146099090576, val_loss = 0.7949391007423401\n",
      "epoch n°1712 : train_loss = 2.061959981918335, val_loss = 0.7960996627807617\n",
      "epoch n°1713 : train_loss = 2.050697088241577, val_loss = 0.7928752303123474\n",
      "epoch n°1714 : train_loss = 2.056760787963867, val_loss = 0.7927621603012085\n",
      "epoch n°1715 : train_loss = 2.053466558456421, val_loss = 0.7969633340835571\n",
      "epoch n°1716 : train_loss = 2.0620033740997314, val_loss = 0.7944542169570923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°1717 : train_loss = 2.054715156555176, val_loss = 0.7974804043769836\n",
      "epoch n°1718 : train_loss = 2.0562291145324707, val_loss = 0.7934851050376892\n",
      "epoch n°1719 : train_loss = 2.052889108657837, val_loss = 0.7954766750335693\n",
      "epoch n°1720 : train_loss = 2.0535099506378174, val_loss = 0.7957900762557983\n",
      "epoch n°1721 : train_loss = 2.061640977859497, val_loss = 0.7962527275085449\n",
      "epoch n°1722 : train_loss = 2.0664310455322266, val_loss = 0.7942321300506592\n",
      "epoch n°1723 : train_loss = 2.061999559402466, val_loss = 0.7984193563461304\n",
      "epoch n°1724 : train_loss = 2.048781156539917, val_loss = 0.7950863838195801\n",
      "epoch n°1725 : train_loss = 2.063997745513916, val_loss = 0.7948804497718811\n",
      "epoch n°1726 : train_loss = 2.0536882877349854, val_loss = 0.7948334813117981\n",
      "epoch n°1727 : train_loss = 2.052067756652832, val_loss = 0.7897990345954895\n",
      "epoch n°1728 : train_loss = 2.0536108016967773, val_loss = 0.792493462562561\n",
      "epoch n°1729 : train_loss = 2.061002016067505, val_loss = 0.7952792644500732\n",
      "epoch n°1730 : train_loss = 2.0698869228363037, val_loss = 0.7905477285385132\n",
      "epoch n°1731 : train_loss = 2.0533554553985596, val_loss = 0.7943772077560425\n",
      "epoch n°1732 : train_loss = 2.053013801574707, val_loss = 0.7921047210693359\n",
      "epoch n°1733 : train_loss = 2.061330795288086, val_loss = 0.7965669631958008\n",
      "epoch n°1734 : train_loss = 2.0522501468658447, val_loss = 0.7981362342834473\n",
      "epoch n°1735 : train_loss = 2.055232048034668, val_loss = 0.7967780828475952\n",
      "epoch n°1736 : train_loss = 2.061616897583008, val_loss = 0.7940832376480103\n",
      "epoch n°1737 : train_loss = 2.0594191551208496, val_loss = 0.7987228035926819\n",
      "epoch n°1738 : train_loss = 2.0584588050842285, val_loss = 0.7912775874137878\n",
      "epoch n°1739 : train_loss = 2.06286883354187, val_loss = 0.7939189076423645\n",
      "epoch n°1740 : train_loss = 2.0514938831329346, val_loss = 0.796233057975769\n",
      "epoch n°1741 : train_loss = 2.0541276931762695, val_loss = 0.7942939400672913\n",
      "epoch n°1742 : train_loss = 2.0513296127319336, val_loss = 0.7939971089363098\n",
      "epoch n°1743 : train_loss = 2.0660409927368164, val_loss = 0.793199896812439\n",
      "epoch n°1744 : train_loss = 2.0518858432769775, val_loss = 0.7976537942886353\n",
      "epoch n°1745 : train_loss = 2.0525190830230713, val_loss = 0.7936797142028809\n",
      "epoch n°1746 : train_loss = 2.056156635284424, val_loss = 0.7933304309844971\n",
      "epoch n°1747 : train_loss = 2.0594704151153564, val_loss = 0.7948510050773621\n",
      "epoch n°1748 : train_loss = 2.0545196533203125, val_loss = 0.7960041165351868\n",
      "epoch n°1749 : train_loss = 2.0616726875305176, val_loss = 0.7922688722610474\n",
      "epoch n°1750 : train_loss = 2.0546672344207764, val_loss = 0.7987184524536133\n",
      "epoch n°1751 : train_loss = 2.0582077503204346, val_loss = 0.7938236594200134\n",
      "epoch n°1752 : train_loss = 2.052712917327881, val_loss = 0.7949313521385193\n",
      "epoch n°1753 : train_loss = 2.0540382862091064, val_loss = 0.7946910858154297\n",
      "epoch n°1754 : train_loss = 2.05138897895813, val_loss = 0.7959372401237488\n",
      "epoch n°1755 : train_loss = 2.0582706928253174, val_loss = 0.7968282103538513\n",
      "epoch n°1756 : train_loss = 2.0526697635650635, val_loss = 0.7946979403495789\n",
      "epoch n°1757 : train_loss = 2.0566837787628174, val_loss = 0.799498438835144\n",
      "epoch n°1758 : train_loss = 2.0547938346862793, val_loss = 0.797916829586029\n",
      "epoch n°1759 : train_loss = 2.0518345832824707, val_loss = 0.7962877154350281\n",
      "epoch n°1760 : train_loss = 2.0517396926879883, val_loss = 0.7957062125205994\n",
      "epoch n°1761 : train_loss = 2.0567715167999268, val_loss = 0.7980076670646667\n",
      "epoch n°1762 : train_loss = 2.0521395206451416, val_loss = 0.7920359373092651\n",
      "epoch n°1763 : train_loss = 2.0602614879608154, val_loss = 0.7950384020805359\n",
      "epoch n°1764 : train_loss = 2.056804895401001, val_loss = 0.7924149632453918\n",
      "epoch n°1765 : train_loss = 2.0532596111297607, val_loss = 0.7952751517295837\n",
      "epoch n°1766 : train_loss = 2.065753221511841, val_loss = 0.7970331311225891\n",
      "epoch n°1767 : train_loss = 2.0494496822357178, val_loss = 0.7914774417877197\n",
      "epoch n°1768 : train_loss = 2.0562796592712402, val_loss = 0.7938637137413025\n",
      "epoch n°1769 : train_loss = 2.055206537246704, val_loss = 0.7970303297042847\n",
      "epoch n°1770 : train_loss = 2.0505430698394775, val_loss = 0.7916693091392517\n",
      "epoch n°1771 : train_loss = 2.0537333488464355, val_loss = 0.7881072163581848\n",
      "epoch n°1772 : train_loss = 2.0490338802337646, val_loss = 0.7944784164428711\n",
      "epoch n°1773 : train_loss = 2.051215648651123, val_loss = 0.7947006225585938\n",
      "epoch n°1774 : train_loss = 2.0472214221954346, val_loss = 0.7957829833030701\n",
      "epoch n°1775 : train_loss = 2.056551694869995, val_loss = 0.7948824763298035\n",
      "epoch n°1776 : train_loss = 2.056185245513916, val_loss = 0.7945401668548584\n",
      "epoch n°1777 : train_loss = 2.0571160316467285, val_loss = 0.7993286848068237\n",
      "epoch n°1778 : train_loss = 2.0453338623046875, val_loss = 0.796664297580719\n",
      "epoch n°1779 : train_loss = 2.0530097484588623, val_loss = 0.7947962284088135\n",
      "epoch n°1780 : train_loss = 2.0538010597229004, val_loss = 0.7963342666625977\n",
      "epoch n°1781 : train_loss = 2.052719831466675, val_loss = 0.7959585189819336\n",
      "epoch n°1782 : train_loss = 2.0510010719299316, val_loss = 0.7942719459533691\n",
      "epoch n°1783 : train_loss = 2.0539369583129883, val_loss = 0.7941398024559021\n",
      "epoch n°1784 : train_loss = 2.065919876098633, val_loss = 0.795072078704834\n",
      "epoch n°1785 : train_loss = 2.0532422065734863, val_loss = 0.7960996031761169\n",
      "epoch n°1786 : train_loss = 2.050863742828369, val_loss = 0.7893142700195312\n",
      "epoch n°1787 : train_loss = 2.051898956298828, val_loss = 0.7896945476531982\n",
      "epoch n°1788 : train_loss = 2.0537045001983643, val_loss = 0.794730544090271\n",
      "epoch n°1789 : train_loss = 2.056811809539795, val_loss = 0.7931839227676392\n",
      "epoch n°1790 : train_loss = 2.051654100418091, val_loss = 0.7981562614440918\n",
      "epoch n°1791 : train_loss = 2.050287961959839, val_loss = 0.7926796674728394\n",
      "epoch n°1792 : train_loss = 2.054245710372925, val_loss = 0.7930997610092163\n",
      "epoch n°1793 : train_loss = 2.0531632900238037, val_loss = 0.7944765686988831\n",
      "epoch n°1794 : train_loss = 2.044261932373047, val_loss = 0.7889330983161926\n",
      "epoch n°1795 : train_loss = 2.0529415607452393, val_loss = 0.791822075843811\n",
      "epoch n°1796 : train_loss = 2.046581268310547, val_loss = 0.7900742292404175\n",
      "epoch n°1797 : train_loss = 2.053370714187622, val_loss = 0.7939430475234985\n",
      "epoch n°1798 : train_loss = 2.060346841812134, val_loss = 0.7957746386528015\n",
      "epoch n°1799 : train_loss = 2.053274154663086, val_loss = 0.7908442616462708\n",
      "epoch n°1800 : train_loss = 2.0616488456726074, val_loss = 0.7955583930015564\n",
      "epoch n°1801 : train_loss = 2.050896167755127, val_loss = 0.7973015904426575\n",
      "epoch n°1802 : train_loss = 2.053101062774658, val_loss = 0.7962560057640076\n",
      "epoch n°1803 : train_loss = 2.0602331161499023, val_loss = 0.7881556749343872\n",
      "epoch n°1804 : train_loss = 2.0526890754699707, val_loss = 0.790286123752594\n",
      "epoch n°1805 : train_loss = 2.055248975753784, val_loss = 0.7965697050094604\n",
      "epoch n°1806 : train_loss = 2.043935775756836, val_loss = 0.7961655855178833\n",
      "epoch n°1807 : train_loss = 2.0479366779327393, val_loss = 0.7915261387825012\n",
      "epoch n°1808 : train_loss = 2.0624170303344727, val_loss = 0.7948001623153687\n",
      "epoch n°1809 : train_loss = 2.0587735176086426, val_loss = 0.7920399308204651\n",
      "epoch n°1810 : train_loss = 2.0534727573394775, val_loss = 0.7933320999145508\n",
      "epoch n°1811 : train_loss = 2.051807165145874, val_loss = 0.7968131303787231\n",
      "epoch n°1812 : train_loss = 2.043992519378662, val_loss = 0.7945593595504761\n",
      "epoch n°1813 : train_loss = 2.0524661540985107, val_loss = 0.7951973676681519\n",
      "epoch n°1814 : train_loss = 2.063720464706421, val_loss = 0.7952027320861816\n",
      "epoch n°1815 : train_loss = 2.0515315532684326, val_loss = 0.7952518463134766\n",
      "epoch n°1816 : train_loss = 2.053147792816162, val_loss = 0.7934036254882812\n",
      "epoch n°1817 : train_loss = 2.056727409362793, val_loss = 0.7928492426872253\n",
      "epoch n°1818 : train_loss = 2.048536539077759, val_loss = 0.7935593128204346\n",
      "epoch n°1819 : train_loss = 2.0519068241119385, val_loss = 0.7916316390037537\n",
      "epoch n°1820 : train_loss = 2.0450098514556885, val_loss = 0.7982459664344788\n",
      "epoch n°1821 : train_loss = 2.056813955307007, val_loss = 0.7925311326980591\n",
      "epoch n°1822 : train_loss = 2.043661117553711, val_loss = 0.7983106970787048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°1823 : train_loss = 2.041687488555908, val_loss = 0.7917378544807434\n",
      "epoch n°1824 : train_loss = 2.065434217453003, val_loss = 0.7919575572013855\n",
      "epoch n°1825 : train_loss = 2.063791513442993, val_loss = 0.7946022152900696\n",
      "epoch n°1826 : train_loss = 2.049182891845703, val_loss = 0.7931392192840576\n",
      "epoch n°1827 : train_loss = 2.0546083450317383, val_loss = 0.795271098613739\n",
      "epoch n°1828 : train_loss = 2.0530011653900146, val_loss = 0.7970831990242004\n",
      "epoch n°1829 : train_loss = 2.057102918624878, val_loss = 0.7926550507545471\n",
      "epoch n°1830 : train_loss = 2.057692766189575, val_loss = 0.7982276082038879\n",
      "epoch n°1831 : train_loss = 2.0557427406311035, val_loss = 0.7965456247329712\n",
      "epoch n°1832 : train_loss = 2.0523040294647217, val_loss = 0.7944374680519104\n",
      "epoch n°1833 : train_loss = 2.052788019180298, val_loss = 0.794458270072937\n",
      "epoch n°1834 : train_loss = 2.0547051429748535, val_loss = 0.7913875579833984\n",
      "epoch n°1835 : train_loss = 2.0547733306884766, val_loss = 0.7937393188476562\n",
      "epoch n°1836 : train_loss = 2.0482070446014404, val_loss = 0.7957573533058167\n",
      "epoch n°1837 : train_loss = 2.0482826232910156, val_loss = 0.7918513417243958\n",
      "epoch n°1838 : train_loss = 2.0566790103912354, val_loss = 0.7930120825767517\n",
      "epoch n°1839 : train_loss = 2.046862840652466, val_loss = 0.7920970916748047\n",
      "epoch n°1840 : train_loss = 2.059751510620117, val_loss = 0.7928397059440613\n",
      "epoch n°1841 : train_loss = 2.04883074760437, val_loss = 0.8004725575447083\n",
      "epoch n°1842 : train_loss = 2.0554637908935547, val_loss = 0.794050395488739\n",
      "epoch n°1843 : train_loss = 2.0613906383514404, val_loss = 0.7994089722633362\n",
      "epoch n°1844 : train_loss = 2.0474696159362793, val_loss = 0.7899391055107117\n",
      "epoch n°1845 : train_loss = 2.0572755336761475, val_loss = 0.7947714924812317\n",
      "epoch n°1846 : train_loss = 2.0500996112823486, val_loss = 0.7938357591629028\n",
      "epoch n°1847 : train_loss = 2.042330026626587, val_loss = 0.794854998588562\n",
      "epoch n°1848 : train_loss = 2.053283214569092, val_loss = 0.7988714575767517\n",
      "epoch n°1849 : train_loss = 2.054133892059326, val_loss = 0.7943938970565796\n",
      "epoch n°1850 : train_loss = 2.0492711067199707, val_loss = 0.7954409122467041\n",
      "epoch n°1851 : train_loss = 2.0548722743988037, val_loss = 0.7955846786499023\n",
      "epoch n°1852 : train_loss = 2.0455329418182373, val_loss = 0.7919063568115234\n",
      "epoch n°1853 : train_loss = 2.0517611503601074, val_loss = 0.7882997989654541\n",
      "epoch n°1854 : train_loss = 2.057258129119873, val_loss = 0.7866222262382507\n",
      "epoch n°1855 : train_loss = 2.044734477996826, val_loss = 0.7941972017288208\n",
      "epoch n°1856 : train_loss = 2.054131031036377, val_loss = 0.7943966388702393\n",
      "epoch n°1857 : train_loss = 2.062157154083252, val_loss = 0.7926648259162903\n",
      "epoch n°1858 : train_loss = 2.052964687347412, val_loss = 0.7902119159698486\n",
      "epoch n°1859 : train_loss = 2.060469388961792, val_loss = 0.7940906882286072\n",
      "epoch n°1860 : train_loss = 2.0558924674987793, val_loss = 0.7969194650650024\n",
      "epoch n°1861 : train_loss = 2.0545947551727295, val_loss = 0.7989522814750671\n",
      "epoch n°1862 : train_loss = 2.0453553199768066, val_loss = 0.7971226572990417\n",
      "epoch n°1863 : train_loss = 2.041926383972168, val_loss = 0.7945365309715271\n",
      "epoch n°1864 : train_loss = 2.049285650253296, val_loss = 0.7926892638206482\n",
      "epoch n°1865 : train_loss = 2.045459508895874, val_loss = 0.7921770811080933\n",
      "epoch n°1866 : train_loss = 2.047647476196289, val_loss = 0.7950007319450378\n",
      "epoch n°1867 : train_loss = 2.054961919784546, val_loss = 0.7928436398506165\n",
      "epoch n°1868 : train_loss = 2.0544748306274414, val_loss = 0.7900551557540894\n",
      "epoch n°1869 : train_loss = 2.051759958267212, val_loss = 0.7950356602668762\n",
      "epoch n°1870 : train_loss = 2.0509674549102783, val_loss = 0.7935284376144409\n",
      "epoch n°1871 : train_loss = 2.050797939300537, val_loss = 0.7935606837272644\n",
      "epoch n°1872 : train_loss = 2.040846586227417, val_loss = 0.7897859215736389\n",
      "epoch n°1873 : train_loss = 2.0507543087005615, val_loss = 0.7955844402313232\n",
      "epoch n°1874 : train_loss = 2.0502710342407227, val_loss = 0.7908017635345459\n",
      "epoch n°1875 : train_loss = 2.0565567016601562, val_loss = 0.7956275939941406\n",
      "epoch n°1876 : train_loss = 2.054457426071167, val_loss = 0.7920863032341003\n",
      "epoch n°1877 : train_loss = 2.050072431564331, val_loss = 0.7983847856521606\n",
      "epoch n°1878 : train_loss = 2.050652503967285, val_loss = 0.7959798574447632\n",
      "epoch n°1879 : train_loss = 2.0509696006774902, val_loss = 0.7937514781951904\n",
      "epoch n°1880 : train_loss = 2.0557827949523926, val_loss = 0.7946308255195618\n",
      "epoch n°1881 : train_loss = 2.0494003295898438, val_loss = 0.7969788312911987\n",
      "epoch n°1882 : train_loss = 2.0538337230682373, val_loss = 0.7927870750427246\n",
      "epoch n°1883 : train_loss = 2.0472545623779297, val_loss = 0.7904180288314819\n",
      "epoch n°1884 : train_loss = 2.055109739303589, val_loss = 0.7979644536972046\n",
      "epoch n°1885 : train_loss = 2.0546867847442627, val_loss = 0.7894144654273987\n",
      "epoch n°1886 : train_loss = 2.0568900108337402, val_loss = 0.7923702001571655\n",
      "epoch n°1887 : train_loss = 2.045114040374756, val_loss = 0.7962768077850342\n",
      "epoch n°1888 : train_loss = 2.049036741256714, val_loss = 0.7900750637054443\n",
      "epoch n°1889 : train_loss = 2.0616748332977295, val_loss = 0.7954102158546448\n",
      "epoch n°1890 : train_loss = 2.050365447998047, val_loss = 0.7924701571464539\n",
      "epoch n°1891 : train_loss = 2.049265146255493, val_loss = 0.7949340343475342\n",
      "epoch n°1892 : train_loss = 2.0407941341400146, val_loss = 0.7958454489707947\n",
      "epoch n°1893 : train_loss = 2.052279233932495, val_loss = 0.7904371023178101\n",
      "epoch n°1894 : train_loss = 2.0511233806610107, val_loss = 0.7899251580238342\n",
      "epoch n°1895 : train_loss = 2.0473031997680664, val_loss = 0.7909027338027954\n",
      "epoch n°1896 : train_loss = 2.050623893737793, val_loss = 0.7922987937927246\n",
      "epoch n°1897 : train_loss = 2.0443027019500732, val_loss = 0.7967624068260193\n",
      "epoch n°1898 : train_loss = 2.0382087230682373, val_loss = 0.7935083508491516\n",
      "epoch n°1899 : train_loss = 2.046966791152954, val_loss = 0.7896575927734375\n",
      "epoch n°1900 : train_loss = 2.0536017417907715, val_loss = 0.7932037115097046\n",
      "epoch n°1901 : train_loss = 2.0469868183135986, val_loss = 0.7943882942199707\n",
      "epoch n°1902 : train_loss = 2.040959358215332, val_loss = 0.7927121520042419\n",
      "epoch n°1903 : train_loss = 2.0578954219818115, val_loss = 0.7917888164520264\n",
      "epoch n°1904 : train_loss = 2.0579307079315186, val_loss = 0.792163610458374\n",
      "epoch n°1905 : train_loss = 2.051448106765747, val_loss = 0.7900265455245972\n",
      "epoch n°1906 : train_loss = 2.0552570819854736, val_loss = 0.7941860556602478\n",
      "epoch n°1907 : train_loss = 2.055384397506714, val_loss = 0.7975602746009827\n",
      "epoch n°1908 : train_loss = 2.0575850009918213, val_loss = 0.7943761348724365\n",
      "epoch n°1909 : train_loss = 2.054562568664551, val_loss = 0.7927813529968262\n",
      "epoch n°1910 : train_loss = 2.056591749191284, val_loss = 0.7946855425834656\n",
      "epoch n°1911 : train_loss = 2.0510573387145996, val_loss = 0.7955633997917175\n",
      "epoch n°1912 : train_loss = 2.043821096420288, val_loss = 0.7946485280990601\n",
      "epoch n°1913 : train_loss = 2.0364694595336914, val_loss = 0.7930651307106018\n",
      "epoch n°1914 : train_loss = 2.054560661315918, val_loss = 0.7950925827026367\n",
      "epoch n°1915 : train_loss = 2.058405876159668, val_loss = 0.7977261543273926\n",
      "epoch n°1916 : train_loss = 2.040195941925049, val_loss = 0.7982674837112427\n",
      "epoch n°1917 : train_loss = 2.0453145503997803, val_loss = 0.7916352152824402\n",
      "epoch n°1918 : train_loss = 2.0506234169006348, val_loss = 0.7975146174430847\n",
      "epoch n°1919 : train_loss = 2.0425713062286377, val_loss = 0.7927033305168152\n",
      "epoch n°1920 : train_loss = 2.0532546043395996, val_loss = 0.7924314737319946\n",
      "epoch n°1921 : train_loss = 2.0547034740448, val_loss = 0.7992720603942871\n",
      "epoch n°1922 : train_loss = 2.054410696029663, val_loss = 0.790865957736969\n",
      "epoch n°1923 : train_loss = 2.053865671157837, val_loss = 0.7944968342781067\n",
      "epoch n°1924 : train_loss = 2.0409343242645264, val_loss = 0.7923591136932373\n",
      "epoch n°1925 : train_loss = 2.0458593368530273, val_loss = 0.7973409295082092\n",
      "epoch n°1926 : train_loss = 2.042876720428467, val_loss = 0.7951853275299072\n",
      "epoch n°1927 : train_loss = 2.048842191696167, val_loss = 0.7903425693511963\n",
      "epoch n°1928 : train_loss = 2.051882743835449, val_loss = 0.7928863763809204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°1929 : train_loss = 2.0573384761810303, val_loss = 0.7938252687454224\n",
      "epoch n°1930 : train_loss = 2.0532548427581787, val_loss = 0.7956820726394653\n",
      "epoch n°1931 : train_loss = 2.048086166381836, val_loss = 0.7913590669631958\n",
      "epoch n°1932 : train_loss = 2.045391082763672, val_loss = 0.7973161935806274\n",
      "epoch n°1933 : train_loss = 2.0482537746429443, val_loss = 0.795298159122467\n",
      "epoch n°1934 : train_loss = 2.055270195007324, val_loss = 0.7946654558181763\n",
      "epoch n°1935 : train_loss = 2.046842336654663, val_loss = 0.7932131290435791\n",
      "epoch n°1936 : train_loss = 2.0462887287139893, val_loss = 0.795639157295227\n",
      "epoch n°1937 : train_loss = 2.048332691192627, val_loss = 0.794586718082428\n",
      "epoch n°1938 : train_loss = 2.0495097637176514, val_loss = 0.7965427041053772\n",
      "epoch n°1939 : train_loss = 2.047419786453247, val_loss = 0.7952966094017029\n",
      "epoch n°1940 : train_loss = 2.05322265625, val_loss = 0.8008441925048828\n",
      "epoch n°1941 : train_loss = 2.054086446762085, val_loss = 0.7922425866127014\n",
      "epoch n°1942 : train_loss = 2.0482513904571533, val_loss = 0.792627215385437\n",
      "epoch n°1943 : train_loss = 2.046292304992676, val_loss = 0.7947216629981995\n",
      "epoch n°1944 : train_loss = 2.046656847000122, val_loss = 0.7941060662269592\n",
      "epoch n°1945 : train_loss = 2.054396390914917, val_loss = 0.7962943911552429\n",
      "epoch n°1946 : train_loss = 2.0476973056793213, val_loss = 0.7953404188156128\n",
      "epoch n°1947 : train_loss = 2.0494725704193115, val_loss = 0.7938783764839172\n",
      "epoch n°1948 : train_loss = 2.052093744277954, val_loss = 0.7965537309646606\n",
      "epoch n°1949 : train_loss = 2.0491411685943604, val_loss = 0.799959123134613\n",
      "epoch n°1950 : train_loss = 2.039565324783325, val_loss = 0.7932312488555908\n",
      "epoch n°1951 : train_loss = 2.049684762954712, val_loss = 0.7926934361457825\n",
      "epoch n°1952 : train_loss = 2.0490834712982178, val_loss = 0.7919914126396179\n",
      "epoch n°1953 : train_loss = 2.045073986053467, val_loss = 0.7927774786949158\n",
      "epoch n°1954 : train_loss = 2.0446784496307373, val_loss = 0.7935463190078735\n",
      "epoch n°1955 : train_loss = 2.051690101623535, val_loss = 0.794379711151123\n",
      "epoch n°1956 : train_loss = 2.045830249786377, val_loss = 0.7938116192817688\n",
      "epoch n°1957 : train_loss = 2.048522472381592, val_loss = 0.7975472807884216\n",
      "epoch n°1958 : train_loss = 2.0505776405334473, val_loss = 0.7984484434127808\n",
      "epoch n°1959 : train_loss = 2.041294813156128, val_loss = 0.7934949398040771\n",
      "epoch n°1960 : train_loss = 2.0505359172821045, val_loss = 0.7884621620178223\n",
      "epoch n°1961 : train_loss = 2.045403242111206, val_loss = 0.7956544756889343\n",
      "epoch n°1962 : train_loss = 2.0472402572631836, val_loss = 0.790742814540863\n",
      "epoch n°1963 : train_loss = 2.063465118408203, val_loss = 0.795803964138031\n",
      "epoch n°1964 : train_loss = 2.0544912815093994, val_loss = 0.7905723452568054\n",
      "epoch n°1965 : train_loss = 2.043982982635498, val_loss = 0.7903218865394592\n",
      "epoch n°1966 : train_loss = 2.0472450256347656, val_loss = 0.7971863150596619\n",
      "epoch n°1967 : train_loss = 2.044546604156494, val_loss = 0.7928445935249329\n",
      "epoch n°1968 : train_loss = 2.055088996887207, val_loss = 0.7946537137031555\n",
      "epoch n°1969 : train_loss = 2.037039279937744, val_loss = 0.7945846319198608\n",
      "epoch n°1970 : train_loss = 2.0486485958099365, val_loss = 0.795642077922821\n",
      "epoch n°1971 : train_loss = 2.0455009937286377, val_loss = 0.7968694567680359\n",
      "epoch n°1972 : train_loss = 2.0544867515563965, val_loss = 0.7968829274177551\n",
      "epoch n°1973 : train_loss = 2.05670428276062, val_loss = 0.7951073050498962\n",
      "epoch n°1974 : train_loss = 2.049078941345215, val_loss = 0.7903580069541931\n",
      "epoch n°1975 : train_loss = 2.052098512649536, val_loss = 0.7968403100967407\n",
      "epoch n°1976 : train_loss = 2.046985387802124, val_loss = 0.7945374250411987\n",
      "epoch n°1977 : train_loss = 2.0474181175231934, val_loss = 0.7930631041526794\n",
      "epoch n°1978 : train_loss = 2.050166368484497, val_loss = 0.796938955783844\n",
      "epoch n°1979 : train_loss = 2.0503580570220947, val_loss = 0.7936694025993347\n",
      "epoch n°1980 : train_loss = 2.032925605773926, val_loss = 0.7972095012664795\n",
      "epoch n°1981 : train_loss = 2.0469672679901123, val_loss = 0.7955657243728638\n",
      "epoch n°1982 : train_loss = 2.0458662509918213, val_loss = 0.7919635772705078\n",
      "epoch n°1983 : train_loss = 2.045029640197754, val_loss = 0.7942386269569397\n",
      "epoch n°1984 : train_loss = 2.0448195934295654, val_loss = 0.7939728498458862\n",
      "epoch n°1985 : train_loss = 2.0533151626586914, val_loss = 0.7950597405433655\n",
      "epoch n°1986 : train_loss = 2.0506603717803955, val_loss = 0.794944167137146\n",
      "epoch n°1987 : train_loss = 2.0399129390716553, val_loss = 0.7971539497375488\n",
      "epoch n°1988 : train_loss = 2.054666042327881, val_loss = 0.7971956133842468\n",
      "epoch n°1989 : train_loss = 2.0440003871917725, val_loss = 0.7930013537406921\n",
      "epoch n°1990 : train_loss = 2.055387258529663, val_loss = 0.7928714752197266\n",
      "epoch n°1991 : train_loss = 2.049574375152588, val_loss = 0.7962546944618225\n",
      "epoch n°1992 : train_loss = 2.0515780448913574, val_loss = 0.7959799766540527\n",
      "epoch n°1993 : train_loss = 2.0499534606933594, val_loss = 0.7954782843589783\n",
      "epoch n°1994 : train_loss = 2.050051212310791, val_loss = 0.7900822758674622\n",
      "epoch n°1995 : train_loss = 2.0458171367645264, val_loss = 0.7920577526092529\n",
      "epoch n°1996 : train_loss = 2.0504493713378906, val_loss = 0.7957682609558105\n",
      "epoch n°1997 : train_loss = 2.0504443645477295, val_loss = 0.7985993027687073\n",
      "epoch n°1998 : train_loss = 2.048469066619873, val_loss = 0.7921974658966064\n",
      "epoch n°1999 : train_loss = 2.050530433654785, val_loss = 0.7961578965187073\n",
      "epoch n°2000 : train_loss = 2.0519516468048096, val_loss = 0.7914719581604004\n",
      "epoch n°2001 : train_loss = 2.055706024169922, val_loss = 0.7895061373710632\n",
      "epoch n°2002 : train_loss = 2.0488128662109375, val_loss = 0.7914648056030273\n",
      "epoch n°2003 : train_loss = 2.057976245880127, val_loss = 0.7918815612792969\n",
      "epoch n°2004 : train_loss = 2.052947521209717, val_loss = 0.7932164669036865\n",
      "epoch n°2005 : train_loss = 2.0528194904327393, val_loss = 0.7942463159561157\n",
      "epoch n°2006 : train_loss = 2.0498692989349365, val_loss = 0.789068341255188\n",
      "epoch n°2007 : train_loss = 2.0389857292175293, val_loss = 0.7976236939430237\n",
      "epoch n°2008 : train_loss = 2.059162139892578, val_loss = 0.7925848960876465\n",
      "epoch n°2009 : train_loss = 2.04841947555542, val_loss = 0.7931428551673889\n",
      "epoch n°2010 : train_loss = 2.0437450408935547, val_loss = 0.7969578504562378\n",
      "epoch n°2011 : train_loss = 2.046658515930176, val_loss = 0.7905864119529724\n",
      "epoch n°2012 : train_loss = 2.052694320678711, val_loss = 0.7915725708007812\n",
      "epoch n°2013 : train_loss = 2.0499210357666016, val_loss = 0.7893230319023132\n",
      "epoch n°2014 : train_loss = 2.0519657135009766, val_loss = 0.797386646270752\n",
      "epoch n°2015 : train_loss = 2.053546190261841, val_loss = 0.796105682849884\n",
      "epoch n°2016 : train_loss = 2.0387930870056152, val_loss = 0.79153972864151\n",
      "epoch n°2017 : train_loss = 2.040050506591797, val_loss = 0.796522319316864\n",
      "epoch n°2018 : train_loss = 2.049177646636963, val_loss = 0.7959508299827576\n",
      "epoch n°2019 : train_loss = 2.054826498031616, val_loss = 0.7917299270629883\n",
      "epoch n°2020 : train_loss = 2.0477161407470703, val_loss = 0.7934570908546448\n",
      "epoch n°2021 : train_loss = 2.0501904487609863, val_loss = 0.7955700159072876\n",
      "epoch n°2022 : train_loss = 2.0487985610961914, val_loss = 0.7958360910415649\n",
      "epoch n°2023 : train_loss = 2.0493505001068115, val_loss = 0.7925019264221191\n",
      "epoch n°2024 : train_loss = 2.0519468784332275, val_loss = 0.794731080532074\n",
      "epoch n°2025 : train_loss = 2.0508298873901367, val_loss = 0.7915593385696411\n",
      "epoch n°2026 : train_loss = 2.059185266494751, val_loss = 0.7962253093719482\n",
      "epoch n°2027 : train_loss = 2.0516672134399414, val_loss = 0.7885155081748962\n",
      "epoch n°2028 : train_loss = 2.045804977416992, val_loss = 0.793709397315979\n",
      "epoch n°2029 : train_loss = 2.0502429008483887, val_loss = 0.7941827178001404\n",
      "epoch n°2030 : train_loss = 2.046078681945801, val_loss = 0.7958312630653381\n",
      "epoch n°2031 : train_loss = 2.049329996109009, val_loss = 0.7948479652404785\n",
      "epoch n°2032 : train_loss = 2.0789170265197754, val_loss = 0.7952699661254883\n",
      "epoch n°2033 : train_loss = 2.0722217559814453, val_loss = 0.800253689289093\n",
      "epoch n°2034 : train_loss = 2.079540967941284, val_loss = 0.7981646060943604\n",
      "epoch n°2035 : train_loss = 2.0720245838165283, val_loss = 0.7994607090950012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°2036 : train_loss = 2.0869767665863037, val_loss = 0.7991718649864197\n",
      "epoch n°2037 : train_loss = 2.0815627574920654, val_loss = 0.8016192317008972\n",
      "epoch n°2038 : train_loss = 2.080280065536499, val_loss = 0.8001560568809509\n",
      "epoch n°2039 : train_loss = 2.0784783363342285, val_loss = 0.7942544221878052\n",
      "epoch n°2040 : train_loss = 2.0692138671875, val_loss = 0.800098180770874\n",
      "epoch n°2041 : train_loss = 2.0801985263824463, val_loss = 0.7999173998832703\n",
      "epoch n°2042 : train_loss = 2.084512710571289, val_loss = 0.8013613820075989\n",
      "epoch n°2043 : train_loss = 2.069826602935791, val_loss = 0.795193076133728\n",
      "epoch n°2044 : train_loss = 2.0764431953430176, val_loss = 0.7955039143562317\n",
      "epoch n°2045 : train_loss = 2.0829882621765137, val_loss = 0.7978289723396301\n",
      "epoch n°2046 : train_loss = 2.0794599056243896, val_loss = 0.7952543497085571\n",
      "epoch n°2047 : train_loss = 2.0804154872894287, val_loss = 0.7982009649276733\n",
      "epoch n°2048 : train_loss = 2.0779612064361572, val_loss = 0.7999672293663025\n",
      "epoch n°2049 : train_loss = 2.0821568965911865, val_loss = 0.7944864630699158\n",
      "epoch n°2050 : train_loss = 2.074700355529785, val_loss = 0.7983373403549194\n",
      "epoch n°2051 : train_loss = 2.089277982711792, val_loss = 0.7937875986099243\n",
      "epoch n°2052 : train_loss = 2.077575445175171, val_loss = 0.7980858087539673\n",
      "epoch n°2053 : train_loss = 2.0860064029693604, val_loss = 0.7971968054771423\n",
      "epoch n°2054 : train_loss = 2.0851755142211914, val_loss = 0.7948094606399536\n",
      "epoch n°2055 : train_loss = 2.081033229827881, val_loss = 0.7957261204719543\n",
      "epoch n°2056 : train_loss = 2.082305431365967, val_loss = 0.8019896149635315\n",
      "epoch n°2057 : train_loss = 2.0766634941101074, val_loss = 0.7926293015480042\n",
      "epoch n°2058 : train_loss = 2.0841176509857178, val_loss = 0.7982445955276489\n",
      "epoch n°2059 : train_loss = 2.080963373184204, val_loss = 0.793775200843811\n",
      "epoch n°2060 : train_loss = 2.0790016651153564, val_loss = 0.8003236651420593\n",
      "epoch n°2061 : train_loss = 2.0931355953216553, val_loss = 0.7977647185325623\n",
      "epoch n°2062 : train_loss = 2.079421281814575, val_loss = 0.7980307340621948\n",
      "epoch n°2063 : train_loss = 2.0953335762023926, val_loss = 0.7974197268486023\n",
      "epoch n°2064 : train_loss = 2.07729172706604, val_loss = 0.7930101752281189\n",
      "epoch n°2065 : train_loss = 2.083660125732422, val_loss = 0.7964882254600525\n",
      "epoch n°2066 : train_loss = 2.0841007232666016, val_loss = 0.7967270016670227\n",
      "epoch n°2067 : train_loss = 2.0842840671539307, val_loss = 0.7956570386886597\n",
      "epoch n°2068 : train_loss = 2.0894312858581543, val_loss = 0.7984357476234436\n",
      "epoch n°2069 : train_loss = 2.077660083770752, val_loss = 0.7996724247932434\n",
      "epoch n°2070 : train_loss = 2.0881261825561523, val_loss = 0.7995755076408386\n",
      "epoch n°2071 : train_loss = 2.0874903202056885, val_loss = 0.7965941429138184\n",
      "epoch n°2072 : train_loss = 2.0834434032440186, val_loss = 0.7988826632499695\n",
      "epoch n°2073 : train_loss = 2.084306001663208, val_loss = 0.79332435131073\n",
      "epoch n°2074 : train_loss = 2.0827078819274902, val_loss = 0.8001216053962708\n",
      "epoch n°2075 : train_loss = 2.0812976360321045, val_loss = 0.794853687286377\n",
      "epoch n°2076 : train_loss = 2.0857183933258057, val_loss = 0.7963000535964966\n",
      "epoch n°2077 : train_loss = 2.0843489170074463, val_loss = 0.7923392653465271\n",
      "epoch n°2078 : train_loss = 2.084369659423828, val_loss = 0.7906189560890198\n",
      "epoch n°2079 : train_loss = 2.0944454669952393, val_loss = 0.7962735891342163\n",
      "epoch n°2080 : train_loss = 2.084235429763794, val_loss = 0.7964415550231934\n",
      "epoch n°2081 : train_loss = 2.0803678035736084, val_loss = 0.7997249960899353\n",
      "epoch n°2082 : train_loss = 2.0893681049346924, val_loss = 0.7988418340682983\n",
      "epoch n°2083 : train_loss = 2.087897777557373, val_loss = 0.7997955083847046\n",
      "epoch n°2084 : train_loss = 2.088911533355713, val_loss = 0.7986782193183899\n",
      "epoch n°2085 : train_loss = 2.0799739360809326, val_loss = 0.7967659831047058\n",
      "epoch n°2086 : train_loss = 2.0753731727600098, val_loss = 0.8000037670135498\n",
      "epoch n°2087 : train_loss = 2.0808990001678467, val_loss = 0.8002104759216309\n",
      "epoch n°2088 : train_loss = 2.077747344970703, val_loss = 0.7973114252090454\n",
      "epoch n°2089 : train_loss = 2.0860390663146973, val_loss = 0.7957185506820679\n",
      "epoch n°2090 : train_loss = 2.085251569747925, val_loss = 0.7964831590652466\n",
      "epoch n°2091 : train_loss = 2.087050676345825, val_loss = 0.7948859930038452\n",
      "epoch n°2092 : train_loss = 2.082602024078369, val_loss = 0.7945965528488159\n",
      "epoch n°2093 : train_loss = 2.082810878753662, val_loss = 0.7947842478752136\n",
      "epoch n°2094 : train_loss = 2.082674026489258, val_loss = 0.7964702248573303\n",
      "epoch n°2095 : train_loss = 2.079983949661255, val_loss = 0.7979031801223755\n",
      "epoch n°2096 : train_loss = 2.087562084197998, val_loss = 0.7971476316452026\n",
      "epoch n°2097 : train_loss = 2.094452381134033, val_loss = 0.797088086605072\n",
      "epoch n°2098 : train_loss = 2.0856447219848633, val_loss = 0.8016308546066284\n",
      "epoch n°2099 : train_loss = 2.0862910747528076, val_loss = 0.7939343452453613\n",
      "epoch n°2100 : train_loss = 2.0907280445098877, val_loss = 0.7994013428688049\n",
      "epoch n°2101 : train_loss = 2.075432777404785, val_loss = 0.7967934012413025\n",
      "epoch n°2102 : train_loss = 2.076758623123169, val_loss = 0.8037511110305786\n",
      "epoch n°2103 : train_loss = 2.0902838706970215, val_loss = 0.797203004360199\n",
      "epoch n°2104 : train_loss = 2.0844762325286865, val_loss = 0.8000227212905884\n",
      "epoch n°2105 : train_loss = 2.0871474742889404, val_loss = 0.793799102306366\n",
      "epoch n°2106 : train_loss = 2.0975258350372314, val_loss = 0.7935394048690796\n",
      "epoch n°2107 : train_loss = 2.091458797454834, val_loss = 0.7982736229896545\n",
      "epoch n°2108 : train_loss = 2.0895462036132812, val_loss = 0.796265721321106\n",
      "epoch n°2109 : train_loss = 2.084948778152466, val_loss = 0.7994515895843506\n",
      "epoch n°2110 : train_loss = 2.08481502532959, val_loss = 0.797217071056366\n",
      "epoch n°2111 : train_loss = 2.0909745693206787, val_loss = 0.7978159189224243\n",
      "epoch n°2112 : train_loss = 2.088815927505493, val_loss = 0.7996366620063782\n",
      "epoch n°2113 : train_loss = 2.088437795639038, val_loss = 0.8027834892272949\n",
      "epoch n°2114 : train_loss = 2.0823841094970703, val_loss = 0.7939911484718323\n",
      "epoch n°2115 : train_loss = 2.083127021789551, val_loss = 0.7970795035362244\n",
      "epoch n°2116 : train_loss = 2.0848264694213867, val_loss = 0.7957634329795837\n",
      "epoch n°2117 : train_loss = 2.0785670280456543, val_loss = 0.7934424877166748\n",
      "epoch n°2118 : train_loss = 2.0775654315948486, val_loss = 0.7959969639778137\n",
      "epoch n°2119 : train_loss = 2.092702865600586, val_loss = 0.7931721210479736\n",
      "epoch n°2120 : train_loss = 2.081446886062622, val_loss = 0.7997134923934937\n",
      "epoch n°2121 : train_loss = 2.093527317047119, val_loss = 0.798147439956665\n",
      "epoch n°2122 : train_loss = 2.0934834480285645, val_loss = 0.7982590198516846\n",
      "epoch n°2123 : train_loss = 2.09311580657959, val_loss = 0.797554075717926\n",
      "epoch n°2124 : train_loss = 2.08878231048584, val_loss = 0.7953450679779053\n",
      "epoch n°2125 : train_loss = 2.0851473808288574, val_loss = 0.7996208667755127\n",
      "epoch n°2126 : train_loss = 2.091843366622925, val_loss = 0.7976445555686951\n",
      "epoch n°2127 : train_loss = 2.100600481033325, val_loss = 0.801864504814148\n",
      "epoch n°2128 : train_loss = 2.087085723876953, val_loss = 0.7969472408294678\n",
      "epoch n°2129 : train_loss = 2.082505941390991, val_loss = 0.795880138874054\n",
      "epoch n°2130 : train_loss = 2.0828428268432617, val_loss = 0.7952742576599121\n",
      "epoch n°2131 : train_loss = 2.0903632640838623, val_loss = 0.7971016764640808\n",
      "epoch n°2132 : train_loss = 2.0813605785369873, val_loss = 0.797653079032898\n",
      "epoch n°2133 : train_loss = 2.087246894836426, val_loss = 0.7941155433654785\n",
      "epoch n°2134 : train_loss = 2.091712474822998, val_loss = 0.7981789112091064\n",
      "epoch n°2135 : train_loss = 2.0691044330596924, val_loss = 0.799287736415863\n",
      "epoch n°2136 : train_loss = 2.084524631500244, val_loss = 0.796807050704956\n",
      "epoch n°2137 : train_loss = 2.0759778022766113, val_loss = 0.7978999614715576\n",
      "epoch n°2138 : train_loss = 2.08204984664917, val_loss = 0.7912055253982544\n",
      "epoch n°2139 : train_loss = 2.08029842376709, val_loss = 0.7965413331985474\n",
      "epoch n°2140 : train_loss = 2.0911850929260254, val_loss = 0.7978945970535278\n",
      "epoch n°2141 : train_loss = 2.0752241611480713, val_loss = 0.7943903803825378\n",
      "epoch n°2142 : train_loss = 2.083055019378662, val_loss = 0.7984603047370911\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°2143 : train_loss = 2.1000473499298096, val_loss = 0.7951269149780273\n",
      "epoch n°2144 : train_loss = 2.086395740509033, val_loss = 0.7947477698326111\n",
      "epoch n°2145 : train_loss = 2.0902864933013916, val_loss = 0.7990249395370483\n",
      "epoch n°2146 : train_loss = 2.0820980072021484, val_loss = 0.8007778525352478\n",
      "epoch n°2147 : train_loss = 2.087550640106201, val_loss = 0.7989120483398438\n",
      "epoch n°2148 : train_loss = 2.076240301132202, val_loss = 0.8003168106079102\n",
      "epoch n°2149 : train_loss = 2.094672203063965, val_loss = 0.7958433032035828\n",
      "epoch n°2150 : train_loss = 2.0845885276794434, val_loss = 0.7954462766647339\n",
      "epoch n°2151 : train_loss = 2.0846986770629883, val_loss = 0.7970520853996277\n",
      "epoch n°2152 : train_loss = 2.082131862640381, val_loss = 0.8000789284706116\n",
      "epoch n°2153 : train_loss = 2.087719202041626, val_loss = 0.7976233959197998\n",
      "epoch n°2154 : train_loss = 2.0811562538146973, val_loss = 0.7938465476036072\n",
      "epoch n°2155 : train_loss = 2.0887396335601807, val_loss = 0.8008362650871277\n",
      "epoch n°2156 : train_loss = 2.0910727977752686, val_loss = 0.7944462299346924\n",
      "epoch n°2157 : train_loss = 2.084657907485962, val_loss = 0.7944908142089844\n",
      "epoch n°2158 : train_loss = 2.0878429412841797, val_loss = 0.7983172535896301\n",
      "epoch n°2159 : train_loss = 2.089325428009033, val_loss = 0.7978163957595825\n",
      "epoch n°2160 : train_loss = 2.0902533531188965, val_loss = 0.7981560230255127\n",
      "epoch n°2161 : train_loss = 2.084749937057495, val_loss = 0.7955800294876099\n",
      "epoch n°2162 : train_loss = 2.091595411300659, val_loss = 0.8025246262550354\n",
      "epoch n°2163 : train_loss = 2.0799975395202637, val_loss = 0.794331431388855\n",
      "epoch n°2164 : train_loss = 2.0944299697875977, val_loss = 0.7951898574829102\n",
      "epoch n°2165 : train_loss = 2.0893936157226562, val_loss = 0.794109046459198\n",
      "epoch n°2166 : train_loss = 2.0882322788238525, val_loss = 0.796262264251709\n",
      "epoch n°2167 : train_loss = 2.075460433959961, val_loss = 0.7989608645439148\n",
      "epoch n°2168 : train_loss = 2.0793814659118652, val_loss = 0.7934989929199219\n",
      "epoch n°2169 : train_loss = 2.0910773277282715, val_loss = 0.7992232441902161\n",
      "epoch n°2170 : train_loss = 2.0845799446105957, val_loss = 0.7943439483642578\n",
      "epoch n°2171 : train_loss = 2.087090492248535, val_loss = 0.7980369329452515\n",
      "epoch n°2172 : train_loss = 2.098390817642212, val_loss = 0.7996452450752258\n",
      "epoch n°2173 : train_loss = 2.1104109287261963, val_loss = 0.7991786003112793\n",
      "epoch n°2174 : train_loss = 2.103902816772461, val_loss = 0.8002762794494629\n",
      "epoch n°2175 : train_loss = 2.092264175415039, val_loss = 0.7995206713676453\n",
      "epoch n°2176 : train_loss = 2.088589668273926, val_loss = 0.8021105527877808\n",
      "epoch n°2177 : train_loss = 2.091064214706421, val_loss = 0.7972683906555176\n",
      "epoch n°2178 : train_loss = 2.08404278755188, val_loss = 0.7998579144477844\n",
      "epoch n°2179 : train_loss = 2.085392713546753, val_loss = 0.7959042191505432\n",
      "epoch n°2180 : train_loss = 2.090893030166626, val_loss = 0.7970184683799744\n",
      "epoch n°2181 : train_loss = 2.078909397125244, val_loss = 0.7970943450927734\n",
      "epoch n°2182 : train_loss = 2.08307147026062, val_loss = 0.7925123572349548\n",
      "epoch n°2183 : train_loss = 2.08388614654541, val_loss = 0.7976242899894714\n",
      "epoch n°2184 : train_loss = 2.086294174194336, val_loss = 0.7990590929985046\n",
      "epoch n°2185 : train_loss = 2.0798394680023193, val_loss = 0.7996834516525269\n",
      "epoch n°2186 : train_loss = 2.089661121368408, val_loss = 0.7964650392532349\n",
      "epoch n°2187 : train_loss = 2.0918712615966797, val_loss = 0.7939941883087158\n",
      "epoch n°2188 : train_loss = 2.0862176418304443, val_loss = 0.7995980381965637\n",
      "epoch n°2189 : train_loss = 2.0784153938293457, val_loss = 0.7981296181678772\n",
      "epoch n°2190 : train_loss = 2.0805773735046387, val_loss = 0.7911614179611206\n",
      "epoch n°2191 : train_loss = 2.083315372467041, val_loss = 0.7948199510574341\n",
      "epoch n°2192 : train_loss = 2.0918188095092773, val_loss = 0.7970477342605591\n",
      "epoch n°2193 : train_loss = 2.0820724964141846, val_loss = 0.7960194945335388\n",
      "epoch n°2194 : train_loss = 2.091593027114868, val_loss = 0.7947587966918945\n",
      "epoch n°2195 : train_loss = 2.0800106525421143, val_loss = 0.801304280757904\n",
      "epoch n°2196 : train_loss = 2.0873494148254395, val_loss = 0.7970060110092163\n",
      "epoch n°2197 : train_loss = 2.08294677734375, val_loss = 0.796701192855835\n",
      "epoch n°2198 : train_loss = 2.0930683612823486, val_loss = 0.7956453561782837\n",
      "epoch n°2199 : train_loss = 2.077681303024292, val_loss = 0.7959219217300415\n",
      "epoch n°2200 : train_loss = 2.090855360031128, val_loss = 0.796511173248291\n",
      "epoch n°2201 : train_loss = 2.089106559753418, val_loss = 0.7976378798484802\n",
      "epoch n°2202 : train_loss = 2.086395263671875, val_loss = 0.7980411052703857\n",
      "epoch n°2203 : train_loss = 2.086193561553955, val_loss = 0.7986467480659485\n",
      "epoch n°2204 : train_loss = 2.0866665840148926, val_loss = 0.7912524938583374\n",
      "epoch n°2205 : train_loss = 2.085310935974121, val_loss = 0.7956147789955139\n",
      "epoch n°2206 : train_loss = 2.088772773742676, val_loss = 0.8005897402763367\n",
      "epoch n°2207 : train_loss = 2.0938522815704346, val_loss = 0.7973088622093201\n",
      "epoch n°2208 : train_loss = 2.0938336849212646, val_loss = 0.7952144742012024\n",
      "epoch n°2209 : train_loss = 2.0777461528778076, val_loss = 0.7997536063194275\n",
      "epoch n°2210 : train_loss = 2.082207202911377, val_loss = 0.7968288064002991\n",
      "epoch n°2211 : train_loss = 2.080461025238037, val_loss = 0.7957093119621277\n",
      "epoch n°2212 : train_loss = 2.0895180702209473, val_loss = 0.8004549741744995\n",
      "epoch n°2213 : train_loss = 2.082867383956909, val_loss = 0.7986608743667603\n",
      "epoch n°2214 : train_loss = 2.0865750312805176, val_loss = 0.7984573841094971\n",
      "epoch n°2215 : train_loss = 2.085505962371826, val_loss = 0.7931784391403198\n",
      "epoch n°2216 : train_loss = 2.083847761154175, val_loss = 0.7974926233291626\n",
      "epoch n°2217 : train_loss = 2.0827670097351074, val_loss = 0.7952261567115784\n",
      "epoch n°2218 : train_loss = 2.089933156967163, val_loss = 0.7976809144020081\n",
      "epoch n°2219 : train_loss = 2.079441785812378, val_loss = 0.7941320538520813\n",
      "epoch n°2220 : train_loss = 2.088778257369995, val_loss = 0.797552764415741\n",
      "epoch n°2221 : train_loss = 2.0827367305755615, val_loss = 0.7963954210281372\n",
      "epoch n°2222 : train_loss = 2.0850329399108887, val_loss = 0.7982701659202576\n",
      "epoch n°2223 : train_loss = 2.089160680770874, val_loss = 0.7968050241470337\n",
      "epoch n°2224 : train_loss = 2.082765817642212, val_loss = 0.794805645942688\n",
      "epoch n°2225 : train_loss = 2.0806264877319336, val_loss = 0.800788938999176\n",
      "epoch n°2226 : train_loss = 2.0891942977905273, val_loss = 0.793341875076294\n",
      "epoch n°2227 : train_loss = 2.076685905456543, val_loss = 0.7967584133148193\n",
      "epoch n°2228 : train_loss = 2.0879197120666504, val_loss = 0.7970635890960693\n",
      "epoch n°2229 : train_loss = 2.093153953552246, val_loss = 0.8006141781806946\n",
      "epoch n°2230 : train_loss = 2.079012155532837, val_loss = 0.7962982058525085\n",
      "epoch n°2231 : train_loss = 2.0837631225585938, val_loss = 0.7965539693832397\n",
      "epoch n°2232 : train_loss = 2.0794694423675537, val_loss = 0.7939996719360352\n",
      "epoch n°2233 : train_loss = 2.084711790084839, val_loss = 0.7958696484565735\n",
      "epoch n°2234 : train_loss = 2.073192834854126, val_loss = 0.80104660987854\n",
      "epoch n°2235 : train_loss = 2.0815300941467285, val_loss = 0.7941818833351135\n",
      "epoch n°2236 : train_loss = 2.0839967727661133, val_loss = 0.7922956943511963\n",
      "epoch n°2237 : train_loss = 2.0888473987579346, val_loss = 0.8002765774726868\n",
      "epoch n°2238 : train_loss = 2.0875067710876465, val_loss = 0.7985650897026062\n",
      "epoch n°2239 : train_loss = 2.085861921310425, val_loss = 0.7963715195655823\n",
      "epoch n°2240 : train_loss = 2.079366445541382, val_loss = 0.7999377846717834\n",
      "epoch n°2241 : train_loss = 2.085674524307251, val_loss = 0.8021387457847595\n",
      "epoch n°2242 : train_loss = 2.0822203159332275, val_loss = 0.7963483929634094\n",
      "epoch n°2243 : train_loss = 2.0801446437835693, val_loss = 0.7936010956764221\n",
      "epoch n°2244 : train_loss = 2.0804388523101807, val_loss = 0.7995771765708923\n",
      "epoch n°2245 : train_loss = 2.081505298614502, val_loss = 0.7905895709991455\n",
      "epoch n°2246 : train_loss = 2.0865697860717773, val_loss = 0.7985848784446716\n",
      "epoch n°2247 : train_loss = 2.0796656608581543, val_loss = 0.7981182336807251\n",
      "epoch n°2248 : train_loss = 2.0907657146453857, val_loss = 0.7958086729049683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°2249 : train_loss = 2.0828068256378174, val_loss = 0.7970081567764282\n",
      "epoch n°2250 : train_loss = 2.0930471420288086, val_loss = 0.7994988560676575\n",
      "epoch n°2251 : train_loss = 2.083028554916382, val_loss = 0.7955389618873596\n",
      "epoch n°2252 : train_loss = 2.0924923419952393, val_loss = 0.794829785823822\n",
      "epoch n°2253 : train_loss = 2.081854820251465, val_loss = 0.7952876091003418\n",
      "epoch n°2254 : train_loss = 2.0832183361053467, val_loss = 0.7956774830818176\n",
      "epoch n°2255 : train_loss = 2.0828278064727783, val_loss = 0.8001123070716858\n",
      "epoch n°2256 : train_loss = 2.0860178470611572, val_loss = 0.7988068461418152\n",
      "epoch n°2257 : train_loss = 2.08620548248291, val_loss = 0.7971639037132263\n",
      "epoch n°2258 : train_loss = 2.0959794521331787, val_loss = 0.7950190305709839\n",
      "epoch n°2259 : train_loss = 2.085265874862671, val_loss = 0.7981998324394226\n",
      "epoch n°2260 : train_loss = 2.0818028450012207, val_loss = 0.7968588471412659\n",
      "epoch n°2261 : train_loss = 2.0877110958099365, val_loss = 0.7955129742622375\n",
      "epoch n°2262 : train_loss = 2.085435628890991, val_loss = 0.792837381362915\n",
      "epoch n°2263 : train_loss = 2.087789535522461, val_loss = 0.7947589755058289\n",
      "epoch n°2264 : train_loss = 2.089750051498413, val_loss = 0.7960047721862793\n",
      "epoch n°2265 : train_loss = 2.080934762954712, val_loss = 0.8000239729881287\n",
      "epoch n°2266 : train_loss = 2.0881690979003906, val_loss = 0.797012209892273\n",
      "epoch n°2267 : train_loss = 2.083930730819702, val_loss = 0.7929359674453735\n",
      "epoch n°2268 : train_loss = 2.086801052093506, val_loss = 0.7982669472694397\n",
      "epoch n°2269 : train_loss = 2.086094379425049, val_loss = 0.7967062592506409\n",
      "epoch n°2270 : train_loss = 2.080976724624634, val_loss = 0.8010536432266235\n",
      "epoch n°2271 : train_loss = 2.0846080780029297, val_loss = 0.7936652302742004\n",
      "epoch n°2272 : train_loss = 2.075291395187378, val_loss = 0.7979336380958557\n",
      "epoch n°2273 : train_loss = 2.076669931411743, val_loss = 0.7943627238273621\n",
      "epoch n°2274 : train_loss = 2.0879437923431396, val_loss = 0.7959374189376831\n",
      "epoch n°2275 : train_loss = 2.0888521671295166, val_loss = 0.7982043027877808\n",
      "epoch n°2276 : train_loss = 2.08918833732605, val_loss = 0.7950485944747925\n",
      "epoch n°2277 : train_loss = 2.086662769317627, val_loss = 0.799048125743866\n",
      "epoch n°2278 : train_loss = 2.08479380607605, val_loss = 0.8000764846801758\n",
      "epoch n°2279 : train_loss = 2.0905776023864746, val_loss = 0.792658805847168\n",
      "epoch n°2280 : train_loss = 2.0878653526306152, val_loss = 0.7958569526672363\n",
      "epoch n°2281 : train_loss = 2.0852389335632324, val_loss = 0.7921971678733826\n",
      "epoch n°2282 : train_loss = 2.079633951187134, val_loss = 0.7980446815490723\n",
      "epoch n°2283 : train_loss = 2.082620143890381, val_loss = 0.7969961762428284\n",
      "epoch n°2284 : train_loss = 2.0882816314697266, val_loss = 0.7998932600021362\n",
      "epoch n°2285 : train_loss = 2.091872453689575, val_loss = 0.7966869473457336\n",
      "epoch n°2286 : train_loss = 2.08697772026062, val_loss = 0.7922533750534058\n",
      "epoch n°2287 : train_loss = 2.0807690620422363, val_loss = 0.7970408201217651\n",
      "epoch n°2288 : train_loss = 2.0821692943573, val_loss = 0.7970614433288574\n",
      "epoch n°2289 : train_loss = 2.0910661220550537, val_loss = 0.7969416379928589\n",
      "epoch n°2290 : train_loss = 2.088066816329956, val_loss = 0.7966158390045166\n",
      "epoch n°2291 : train_loss = 2.0770089626312256, val_loss = 0.79447340965271\n",
      "epoch n°2292 : train_loss = 2.082679510116577, val_loss = 0.8012580275535583\n",
      "epoch n°2293 : train_loss = 2.079920530319214, val_loss = 0.7920383214950562\n",
      "epoch n°2294 : train_loss = 2.078162670135498, val_loss = 0.7969790101051331\n",
      "epoch n°2295 : train_loss = 2.0841493606567383, val_loss = 0.798307478427887\n",
      "epoch n°2296 : train_loss = 2.081183910369873, val_loss = 0.7965162396430969\n",
      "epoch n°2297 : train_loss = 2.0726733207702637, val_loss = 0.7997682094573975\n",
      "epoch n°2298 : train_loss = 2.0879032611846924, val_loss = 0.798587441444397\n",
      "epoch n°2299 : train_loss = 2.077606439590454, val_loss = 0.7912125587463379\n",
      "epoch n°2300 : train_loss = 2.079622745513916, val_loss = 0.7963409423828125\n",
      "epoch n°2301 : train_loss = 2.0839991569519043, val_loss = 0.7938888072967529\n",
      "epoch n°2302 : train_loss = 2.08050274848938, val_loss = 0.7986770868301392\n",
      "epoch n°2303 : train_loss = 2.0816965103149414, val_loss = 0.7997650504112244\n",
      "epoch n°2304 : train_loss = 2.0864720344543457, val_loss = 0.7975834608078003\n",
      "epoch n°2305 : train_loss = 2.080080270767212, val_loss = 0.7971450686454773\n",
      "epoch n°2306 : train_loss = 2.0759356021881104, val_loss = 0.7973679304122925\n",
      "epoch n°2307 : train_loss = 2.077807903289795, val_loss = 0.7969750761985779\n",
      "epoch n°2308 : train_loss = 2.0725388526916504, val_loss = 0.798599123954773\n",
      "epoch n°2309 : train_loss = 2.0744009017944336, val_loss = 0.7941630482673645\n",
      "epoch n°2310 : train_loss = 2.0882465839385986, val_loss = 0.7963585257530212\n",
      "epoch n°2311 : train_loss = 2.083220958709717, val_loss = 0.7935857772827148\n",
      "epoch n°2312 : train_loss = 2.083918333053589, val_loss = 0.7975597977638245\n",
      "epoch n°2313 : train_loss = 2.08301043510437, val_loss = 0.7904831767082214\n",
      "epoch n°2314 : train_loss = 2.0797812938690186, val_loss = 0.7967737317085266\n",
      "epoch n°2315 : train_loss = 2.0815789699554443, val_loss = 0.7997081279754639\n",
      "epoch n°2316 : train_loss = 2.081594228744507, val_loss = 0.79510098695755\n",
      "epoch n°2317 : train_loss = 2.0837581157684326, val_loss = 0.7950523495674133\n",
      "epoch n°2318 : train_loss = 2.067161798477173, val_loss = 0.7982720732688904\n",
      "epoch n°2319 : train_loss = 2.082976818084717, val_loss = 0.8008826375007629\n",
      "epoch n°2320 : train_loss = 2.0771822929382324, val_loss = 0.7974236011505127\n",
      "epoch n°2321 : train_loss = 2.0728085041046143, val_loss = 0.7953724265098572\n",
      "epoch n°2322 : train_loss = 2.088306427001953, val_loss = 0.7965583801269531\n",
      "epoch n°2323 : train_loss = 2.0891411304473877, val_loss = 0.7961873412132263\n",
      "epoch n°2324 : train_loss = 2.085789918899536, val_loss = 0.7959815859794617\n",
      "epoch n°2325 : train_loss = 2.0737178325653076, val_loss = 0.7949139475822449\n",
      "epoch n°2326 : train_loss = 2.079326868057251, val_loss = 0.7932611107826233\n",
      "epoch n°2327 : train_loss = 2.081972360610962, val_loss = 0.7900545001029968\n",
      "epoch n°2328 : train_loss = 2.0775394439697266, val_loss = 0.7989929914474487\n",
      "epoch n°2329 : train_loss = 2.0859153270721436, val_loss = 0.7965621948242188\n",
      "epoch n°2330 : train_loss = 2.077467203140259, val_loss = 0.7980976700782776\n",
      "epoch n°2331 : train_loss = 2.0783400535583496, val_loss = 0.7907142639160156\n",
      "epoch n°2332 : train_loss = 2.0787389278411865, val_loss = 0.7941170930862427\n",
      "epoch n°2333 : train_loss = 2.079591989517212, val_loss = 0.79560387134552\n",
      "epoch n°2334 : train_loss = 2.076969623565674, val_loss = 0.7920881509780884\n",
      "epoch n°2335 : train_loss = 2.0780997276306152, val_loss = 0.7989069819450378\n",
      "epoch n°2336 : train_loss = 2.086638927459717, val_loss = 0.7957788705825806\n",
      "epoch n°2337 : train_loss = 2.078611373901367, val_loss = 0.798625648021698\n",
      "epoch n°2338 : train_loss = 2.071141481399536, val_loss = 0.7955661416053772\n",
      "epoch n°2339 : train_loss = 2.0782971382141113, val_loss = 0.7915128469467163\n",
      "epoch n°2340 : train_loss = 2.0742075443267822, val_loss = 0.7957252860069275\n",
      "epoch n°2341 : train_loss = 2.080942392349243, val_loss = 0.7989733219146729\n",
      "epoch n°2342 : train_loss = 2.073960781097412, val_loss = 0.7983030676841736\n",
      "epoch n°2343 : train_loss = 2.074110507965088, val_loss = 0.7988726496696472\n",
      "epoch n°2344 : train_loss = 2.075948476791382, val_loss = 0.7978105545043945\n",
      "epoch n°2345 : train_loss = 2.081345796585083, val_loss = 0.7977198362350464\n",
      "epoch n°2346 : train_loss = 2.077644109725952, val_loss = 0.7987588047981262\n",
      "epoch n°2347 : train_loss = 2.0751469135284424, val_loss = 0.7921643853187561\n",
      "epoch n°2348 : train_loss = 2.0880446434020996, val_loss = 0.7966212630271912\n",
      "epoch n°2349 : train_loss = 2.0834012031555176, val_loss = 0.7973364591598511\n",
      "epoch n°2350 : train_loss = 2.078284740447998, val_loss = 0.8010767102241516\n",
      "epoch n°2351 : train_loss = 2.092085361480713, val_loss = 0.7930893898010254\n",
      "epoch n°2352 : train_loss = 2.084646463394165, val_loss = 0.7989156246185303\n",
      "epoch n°2353 : train_loss = 2.0905561447143555, val_loss = 0.7941368818283081\n",
      "epoch n°2354 : train_loss = 2.0795676708221436, val_loss = 0.7960199117660522\n",
      "epoch n°2355 : train_loss = 2.0758159160614014, val_loss = 0.7958096265792847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°2356 : train_loss = 2.0792651176452637, val_loss = 0.8018456101417542\n",
      "epoch n°2357 : train_loss = 2.08305287361145, val_loss = 0.7970153093338013\n",
      "epoch n°2358 : train_loss = 2.0677878856658936, val_loss = 0.797870397567749\n",
      "epoch n°2359 : train_loss = 2.0787811279296875, val_loss = 0.7972357869148254\n",
      "epoch n°2360 : train_loss = 2.0857348442077637, val_loss = 0.7918193340301514\n",
      "epoch n°2361 : train_loss = 2.074453830718994, val_loss = 0.7953432202339172\n",
      "epoch n°2362 : train_loss = 2.0802013874053955, val_loss = 0.8003919720649719\n",
      "epoch n°2363 : train_loss = 2.083272695541382, val_loss = 0.7928943634033203\n",
      "epoch n°2364 : train_loss = 2.0780534744262695, val_loss = 0.7932597994804382\n",
      "epoch n°2365 : train_loss = 2.082683563232422, val_loss = 0.7892181873321533\n",
      "epoch n°2366 : train_loss = 2.077791213989258, val_loss = 0.7932784557342529\n",
      "epoch n°2367 : train_loss = 2.0777618885040283, val_loss = 0.7988696694374084\n",
      "epoch n°2368 : train_loss = 2.074524164199829, val_loss = 0.8000070452690125\n",
      "epoch n°2369 : train_loss = 2.0705037117004395, val_loss = 0.7952287197113037\n",
      "epoch n°2370 : train_loss = 2.0884315967559814, val_loss = 0.7973212003707886\n",
      "epoch n°2371 : train_loss = 2.076266050338745, val_loss = 0.7967705130577087\n",
      "epoch n°2372 : train_loss = 2.079153537750244, val_loss = 0.7964901328086853\n",
      "epoch n°2373 : train_loss = 2.0744214057922363, val_loss = 0.7943502068519592\n",
      "epoch n°2374 : train_loss = 2.0877459049224854, val_loss = 0.7956250309944153\n",
      "epoch n°2375 : train_loss = 2.0785751342773438, val_loss = 0.7945952415466309\n",
      "epoch n°2376 : train_loss = 2.0801827907562256, val_loss = 0.7955828905105591\n",
      "epoch n°2377 : train_loss = 2.077925205230713, val_loss = 0.7967158555984497\n",
      "epoch n°2378 : train_loss = 2.0768754482269287, val_loss = 0.7988539338111877\n",
      "epoch n°2379 : train_loss = 2.0846633911132812, val_loss = 0.7927214503288269\n",
      "epoch n°2380 : train_loss = 2.085935115814209, val_loss = 0.798996090888977\n",
      "epoch n°2381 : train_loss = 2.076282501220703, val_loss = 0.7971164584159851\n",
      "epoch n°2382 : train_loss = 2.0784647464752197, val_loss = 0.7976788878440857\n",
      "epoch n°2383 : train_loss = 2.080253839492798, val_loss = 0.7954767346382141\n",
      "epoch n°2384 : train_loss = 2.0776450634002686, val_loss = 0.7976502180099487\n",
      "epoch n°2385 : train_loss = 2.0740678310394287, val_loss = 0.7949088215827942\n",
      "epoch n°2386 : train_loss = 2.081834077835083, val_loss = 0.795170247554779\n",
      "epoch n°2387 : train_loss = 2.079622268676758, val_loss = 0.79387366771698\n",
      "epoch n°2388 : train_loss = 2.0841779708862305, val_loss = 0.8007312417030334\n",
      "epoch n°2389 : train_loss = 2.071819305419922, val_loss = 0.7981916666030884\n",
      "epoch n°2390 : train_loss = 2.0789432525634766, val_loss = 0.79393470287323\n",
      "epoch n°2391 : train_loss = 2.0742413997650146, val_loss = 0.7938336730003357\n",
      "epoch n°2392 : train_loss = 2.0784225463867188, val_loss = 0.7957367300987244\n",
      "epoch n°2393 : train_loss = 2.0799787044525146, val_loss = 0.7941445708274841\n",
      "epoch n°2394 : train_loss = 2.069445848464966, val_loss = 0.7958608865737915\n",
      "epoch n°2395 : train_loss = 2.0736687183380127, val_loss = 0.7957255840301514\n",
      "epoch n°2396 : train_loss = 2.0803306102752686, val_loss = 0.7942922711372375\n",
      "epoch n°2397 : train_loss = 2.0827558040618896, val_loss = 0.7942957282066345\n",
      "epoch n°2398 : train_loss = 2.0782716274261475, val_loss = 0.7951297163963318\n",
      "epoch n°2399 : train_loss = 2.076394557952881, val_loss = 0.7954227924346924\n",
      "epoch n°2400 : train_loss = 2.0812442302703857, val_loss = 0.8012843132019043\n",
      "epoch n°2401 : train_loss = 2.072537660598755, val_loss = 0.7985809445381165\n",
      "epoch n°2402 : train_loss = 2.0874149799346924, val_loss = 0.7963656783103943\n",
      "epoch n°2403 : train_loss = 2.0783565044403076, val_loss = 0.7980168461799622\n",
      "epoch n°2404 : train_loss = 2.080024003982544, val_loss = 0.79444420337677\n",
      "epoch n°2405 : train_loss = 2.078347682952881, val_loss = 0.792186975479126\n",
      "epoch n°2406 : train_loss = 2.083707094192505, val_loss = 0.7966421246528625\n",
      "epoch n°2407 : train_loss = 2.060581922531128, val_loss = 0.7987859845161438\n",
      "epoch n°2408 : train_loss = 2.0807266235351562, val_loss = 0.7981314659118652\n",
      "epoch n°2409 : train_loss = 2.081392526626587, val_loss = 0.7976678609848022\n",
      "epoch n°2410 : train_loss = 2.0748419761657715, val_loss = 0.8011365532875061\n",
      "epoch n°2411 : train_loss = 2.080681562423706, val_loss = 0.799401044845581\n",
      "epoch n°2412 : train_loss = 2.078155279159546, val_loss = 0.7940506339073181\n",
      "epoch n°2413 : train_loss = 2.074347972869873, val_loss = 0.7959669828414917\n",
      "epoch n°2414 : train_loss = 2.0790300369262695, val_loss = 0.7944873571395874\n",
      "epoch n°2415 : train_loss = 2.0774080753326416, val_loss = 0.7939950823783875\n",
      "epoch n°2416 : train_loss = 2.0805368423461914, val_loss = 0.7959282994270325\n",
      "epoch n°2417 : train_loss = 2.073565721511841, val_loss = 0.7959607243537903\n",
      "epoch n°2418 : train_loss = 2.0723090171813965, val_loss = 0.7965714335441589\n",
      "epoch n°2419 : train_loss = 2.084109306335449, val_loss = 0.796302318572998\n",
      "epoch n°2420 : train_loss = 2.076735734939575, val_loss = 0.8007943630218506\n",
      "epoch n°2421 : train_loss = 2.0747745037078857, val_loss = 0.7951090931892395\n",
      "epoch n°2422 : train_loss = 2.072970151901245, val_loss = 0.7922128438949585\n",
      "epoch n°2423 : train_loss = 2.0774757862091064, val_loss = 0.7962136268615723\n",
      "epoch n°2424 : train_loss = 2.0812556743621826, val_loss = 0.7949523329734802\n",
      "epoch n°2425 : train_loss = 2.0770273208618164, val_loss = 0.7974023818969727\n",
      "epoch n°2426 : train_loss = 2.078831672668457, val_loss = 0.7924308776855469\n",
      "epoch n°2427 : train_loss = 2.0681467056274414, val_loss = 0.7972158193588257\n",
      "epoch n°2428 : train_loss = 2.0737428665161133, val_loss = 0.7997803688049316\n",
      "epoch n°2429 : train_loss = 2.0715839862823486, val_loss = 0.7968253493309021\n",
      "epoch n°2430 : train_loss = 2.077054738998413, val_loss = 0.7891122102737427\n",
      "epoch n°2431 : train_loss = 2.084519624710083, val_loss = 0.7986598014831543\n",
      "epoch n°2432 : train_loss = 2.0733678340911865, val_loss = 0.7953823804855347\n",
      "epoch n°2433 : train_loss = 2.0712103843688965, val_loss = 0.7964414954185486\n",
      "epoch n°2434 : train_loss = 2.081104040145874, val_loss = 0.7977194786071777\n",
      "epoch n°2435 : train_loss = 2.0694005489349365, val_loss = 0.792819082736969\n",
      "epoch n°2436 : train_loss = 2.071204423904419, val_loss = 0.7993279099464417\n",
      "epoch n°2437 : train_loss = 2.0830986499786377, val_loss = 0.7998016476631165\n",
      "epoch n°2438 : train_loss = 2.0825438499450684, val_loss = 0.7975896596908569\n",
      "epoch n°2439 : train_loss = 2.0741796493530273, val_loss = 0.7973881959915161\n",
      "epoch n°2440 : train_loss = 2.0786468982696533, val_loss = 0.7946282625198364\n",
      "epoch n°2441 : train_loss = 2.086794853210449, val_loss = 0.7970271706581116\n",
      "epoch n°2442 : train_loss = 2.0723140239715576, val_loss = 0.7977688312530518\n",
      "epoch n°2443 : train_loss = 2.078575611114502, val_loss = 0.7940492630004883\n",
      "epoch n°2444 : train_loss = 2.083259105682373, val_loss = 0.7965087294578552\n",
      "epoch n°2445 : train_loss = 2.0730648040771484, val_loss = 0.7958696484565735\n",
      "epoch n°2446 : train_loss = 2.076212167739868, val_loss = 0.796747624874115\n",
      "epoch n°2447 : train_loss = 2.070695161819458, val_loss = 0.7917231321334839\n",
      "epoch n°2448 : train_loss = 2.069619655609131, val_loss = 0.7975690960884094\n",
      "epoch n°2449 : train_loss = 2.0777013301849365, val_loss = 0.7921844124794006\n",
      "epoch n°2450 : train_loss = 2.0782854557037354, val_loss = 0.7972557544708252\n",
      "epoch n°2451 : train_loss = 2.0758838653564453, val_loss = 0.7994710206985474\n",
      "epoch n°2452 : train_loss = 2.0800178050994873, val_loss = 0.792015790939331\n",
      "epoch n°2453 : train_loss = 2.0644097328186035, val_loss = 0.79520183801651\n",
      "epoch n°2454 : train_loss = 2.076368808746338, val_loss = 0.7960385680198669\n",
      "epoch n°2455 : train_loss = 2.0773603916168213, val_loss = 0.7985833883285522\n",
      "epoch n°2456 : train_loss = 2.0715909004211426, val_loss = 0.7941186428070068\n",
      "epoch n°2457 : train_loss = 2.0623855590820312, val_loss = 0.798565149307251\n",
      "epoch n°2458 : train_loss = 2.0793840885162354, val_loss = 0.799909234046936\n",
      "epoch n°2459 : train_loss = 2.0735397338867188, val_loss = 0.7964417338371277\n",
      "epoch n°2460 : train_loss = 2.075742244720459, val_loss = 0.7962144613265991\n",
      "epoch n°2461 : train_loss = 2.0721144676208496, val_loss = 0.7982203364372253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°2462 : train_loss = 2.075653314590454, val_loss = 0.7958348989486694\n",
      "epoch n°2463 : train_loss = 2.072819709777832, val_loss = 0.7935433983802795\n",
      "epoch n°2464 : train_loss = 2.0719661712646484, val_loss = 0.7972487211227417\n",
      "epoch n°2465 : train_loss = 2.0771045684814453, val_loss = 0.7980133891105652\n",
      "epoch n°2466 : train_loss = 2.072333812713623, val_loss = 0.7974958419799805\n",
      "epoch n°2467 : train_loss = 2.0789291858673096, val_loss = 0.8010901212692261\n",
      "epoch n°2468 : train_loss = 2.069622755050659, val_loss = 0.7977775931358337\n",
      "epoch n°2469 : train_loss = 2.0756590366363525, val_loss = 0.7981058955192566\n",
      "epoch n°2470 : train_loss = 2.0778419971466064, val_loss = 0.7981352210044861\n",
      "epoch n°2471 : train_loss = 2.08209228515625, val_loss = 0.7938374876976013\n",
      "epoch n°2472 : train_loss = 2.083462953567505, val_loss = 0.8000591993331909\n",
      "epoch n°2473 : train_loss = 2.080679416656494, val_loss = 0.797798752784729\n",
      "epoch n°2474 : train_loss = 2.0754668712615967, val_loss = 0.7970850467681885\n",
      "epoch n°2475 : train_loss = 2.0751354694366455, val_loss = 0.7919737100601196\n",
      "epoch n°2476 : train_loss = 2.0871529579162598, val_loss = 0.7942337989807129\n",
      "epoch n°2477 : train_loss = 2.0677096843719482, val_loss = 0.7956236600875854\n",
      "epoch n°2478 : train_loss = 2.072946548461914, val_loss = 0.7949519157409668\n",
      "epoch n°2479 : train_loss = 2.08497953414917, val_loss = 0.7974033355712891\n",
      "epoch n°2480 : train_loss = 2.0702741146087646, val_loss = 0.7917378544807434\n",
      "epoch n°2481 : train_loss = 2.078408718109131, val_loss = 0.7958868741989136\n",
      "epoch n°2482 : train_loss = 2.0769970417022705, val_loss = 0.8023005127906799\n",
      "epoch n°2483 : train_loss = 2.0738720893859863, val_loss = 0.7939174175262451\n",
      "epoch n°2484 : train_loss = 2.086707592010498, val_loss = 0.7923464775085449\n",
      "epoch n°2485 : train_loss = 2.0735433101654053, val_loss = 0.8002009391784668\n",
      "epoch n°2486 : train_loss = 2.0769128799438477, val_loss = 0.7958878874778748\n",
      "epoch n°2487 : train_loss = 2.0802016258239746, val_loss = 0.7934257388114929\n",
      "epoch n°2488 : train_loss = 2.0754666328430176, val_loss = 0.7977626323699951\n",
      "epoch n°2489 : train_loss = 2.080296277999878, val_loss = 0.796432614326477\n",
      "epoch n°2490 : train_loss = 2.080496311187744, val_loss = 0.796553373336792\n",
      "epoch n°2491 : train_loss = 2.0672030448913574, val_loss = 0.7946135401725769\n",
      "epoch n°2492 : train_loss = 2.077254056930542, val_loss = 0.7943055033683777\n",
      "epoch n°2493 : train_loss = 2.078902244567871, val_loss = 0.7991572618484497\n",
      "epoch n°2494 : train_loss = 2.0711779594421387, val_loss = 0.7945839762687683\n",
      "epoch n°2495 : train_loss = 2.0716867446899414, val_loss = 0.791817843914032\n",
      "epoch n°2496 : train_loss = 2.071988821029663, val_loss = 0.7968193292617798\n",
      "epoch n°2497 : train_loss = 2.0748395919799805, val_loss = 0.7955154180526733\n",
      "epoch n°2498 : train_loss = 2.0710558891296387, val_loss = 0.7958076000213623\n",
      "epoch n°2499 : train_loss = 2.0736165046691895, val_loss = 0.7940841317176819\n",
      "epoch n°2500 : train_loss = 2.0774002075195312, val_loss = 0.7961001396179199\n",
      "epoch n°2501 : train_loss = 2.081554412841797, val_loss = 0.7952479124069214\n",
      "epoch n°2502 : train_loss = 2.068922758102417, val_loss = 0.7945024371147156\n",
      "epoch n°2503 : train_loss = 2.0644707679748535, val_loss = 0.7986223697662354\n",
      "epoch n°2504 : train_loss = 2.070309638977051, val_loss = 0.7959216833114624\n",
      "epoch n°2505 : train_loss = 2.0667097568511963, val_loss = 0.7996672987937927\n",
      "epoch n°2506 : train_loss = 2.07012939453125, val_loss = 0.7942324876785278\n",
      "epoch n°2507 : train_loss = 2.068171739578247, val_loss = 0.7975402474403381\n",
      "epoch n°2508 : train_loss = 2.070843458175659, val_loss = 0.7909747362136841\n",
      "epoch n°2509 : train_loss = 2.064068078994751, val_loss = 0.7990740537643433\n",
      "epoch n°2510 : train_loss = 2.081829309463501, val_loss = 0.7967718243598938\n",
      "epoch n°2511 : train_loss = 2.067652940750122, val_loss = 0.7951821088790894\n",
      "epoch n°2512 : train_loss = 2.0747592449188232, val_loss = 0.7939878106117249\n",
      "epoch n°2513 : train_loss = 2.0814104080200195, val_loss = 0.801181435585022\n",
      "epoch n°2514 : train_loss = 2.0810160636901855, val_loss = 0.7952420711517334\n",
      "epoch n°2515 : train_loss = 2.0807759761810303, val_loss = 0.7940829396247864\n",
      "epoch n°2516 : train_loss = 2.064906358718872, val_loss = 0.7963323593139648\n",
      "epoch n°2517 : train_loss = 2.064483642578125, val_loss = 0.793807327747345\n",
      "epoch n°2518 : train_loss = 2.074761152267456, val_loss = 0.7969037294387817\n",
      "epoch n°2519 : train_loss = 2.06719708442688, val_loss = 0.79106205701828\n",
      "epoch n°2520 : train_loss = 2.077327013015747, val_loss = 0.7946715950965881\n",
      "epoch n°2521 : train_loss = 2.0722622871398926, val_loss = 0.7977495789527893\n",
      "epoch n°2522 : train_loss = 2.069396495819092, val_loss = 0.7974448204040527\n",
      "epoch n°2523 : train_loss = 2.0789921283721924, val_loss = 0.7960475087165833\n",
      "epoch n°2524 : train_loss = 2.0730669498443604, val_loss = 0.7941737771034241\n",
      "epoch n°2525 : train_loss = 2.0597829818725586, val_loss = 0.7989563345909119\n",
      "epoch n°2526 : train_loss = 2.069556713104248, val_loss = 0.7992321848869324\n",
      "epoch n°2527 : train_loss = 2.069875717163086, val_loss = 0.7977586984634399\n",
      "epoch n°2528 : train_loss = 2.0691325664520264, val_loss = 0.7972010374069214\n",
      "epoch n°2529 : train_loss = 2.083118200302124, val_loss = 0.8011647462844849\n",
      "epoch n°2530 : train_loss = 2.0690677165985107, val_loss = 0.7951090931892395\n",
      "epoch n°2531 : train_loss = 2.0870277881622314, val_loss = 0.7945970296859741\n",
      "epoch n°2532 : train_loss = 2.07528018951416, val_loss = 0.7938697934150696\n",
      "epoch n°2533 : train_loss = 2.0723490715026855, val_loss = 0.7948361039161682\n",
      "epoch n°2534 : train_loss = 2.0732288360595703, val_loss = 0.7947577238082886\n",
      "epoch n°2535 : train_loss = 2.07295823097229, val_loss = 0.7945321798324585\n",
      "epoch n°2536 : train_loss = 2.074631929397583, val_loss = 0.7952185869216919\n",
      "epoch n°2537 : train_loss = 2.0704996585845947, val_loss = 0.7948130369186401\n",
      "epoch n°2538 : train_loss = 2.0701687335968018, val_loss = 0.7976914644241333\n",
      "epoch n°2539 : train_loss = 2.0717551708221436, val_loss = 0.7994402050971985\n",
      "epoch n°2540 : train_loss = 2.0763189792633057, val_loss = 0.8012478947639465\n",
      "epoch n°2541 : train_loss = 2.0666041374206543, val_loss = 0.7965683341026306\n",
      "epoch n°2542 : train_loss = 2.080432891845703, val_loss = 0.7942013740539551\n",
      "epoch n°2543 : train_loss = 2.0736711025238037, val_loss = 0.7967830896377563\n",
      "epoch n°2544 : train_loss = 2.070904493331909, val_loss = 0.792843222618103\n",
      "epoch n°2545 : train_loss = 2.070054531097412, val_loss = 0.7981062531471252\n",
      "epoch n°2546 : train_loss = 2.0769052505493164, val_loss = 0.7954045534133911\n",
      "epoch n°2547 : train_loss = 2.071946144104004, val_loss = 0.797624945640564\n",
      "epoch n°2548 : train_loss = 2.071192741394043, val_loss = 0.7959899306297302\n",
      "epoch n°2549 : train_loss = 2.0705771446228027, val_loss = 0.7973442673683167\n",
      "epoch n°2550 : train_loss = 2.0747976303100586, val_loss = 0.7938878536224365\n",
      "epoch n°2551 : train_loss = 2.081437587738037, val_loss = 0.7981383800506592\n",
      "epoch n°2552 : train_loss = 2.073472499847412, val_loss = 0.7985237240791321\n",
      "epoch n°2553 : train_loss = 2.064816474914551, val_loss = 0.7959428429603577\n",
      "epoch n°2554 : train_loss = 2.066927671432495, val_loss = 0.794476330280304\n",
      "epoch n°2555 : train_loss = 2.0736336708068848, val_loss = 0.7961704134941101\n",
      "epoch n°2556 : train_loss = 2.077237844467163, val_loss = 0.7917775511741638\n",
      "epoch n°2557 : train_loss = 2.077653646469116, val_loss = 0.8012254238128662\n",
      "epoch n°2558 : train_loss = 2.072885513305664, val_loss = 0.7965409755706787\n",
      "epoch n°2559 : train_loss = 2.0723202228546143, val_loss = 0.7953833937644958\n",
      "epoch n°2560 : train_loss = 2.0679454803466797, val_loss = 0.7947993278503418\n",
      "epoch n°2561 : train_loss = 2.0763742923736572, val_loss = 0.7962480187416077\n",
      "epoch n°2562 : train_loss = 2.067286252975464, val_loss = 0.7950279712677002\n",
      "epoch n°2563 : train_loss = 2.0728988647460938, val_loss = 0.7972438335418701\n",
      "epoch n°2564 : train_loss = 2.083099126815796, val_loss = 0.7958142757415771\n",
      "epoch n°2565 : train_loss = 2.0677881240844727, val_loss = 0.7948055267333984\n",
      "epoch n°2566 : train_loss = 2.0691661834716797, val_loss = 0.7992681860923767\n",
      "epoch n°2567 : train_loss = 2.071977138519287, val_loss = 0.7986181378364563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°2568 : train_loss = 2.075230836868286, val_loss = 0.7938255667686462\n",
      "epoch n°2569 : train_loss = 2.063713312149048, val_loss = 0.7947664856910706\n",
      "epoch n°2570 : train_loss = 2.0632686614990234, val_loss = 0.7980457544326782\n",
      "epoch n°2571 : train_loss = 2.069971799850464, val_loss = 0.7970090508460999\n",
      "epoch n°2572 : train_loss = 2.067653179168701, val_loss = 0.7991868853569031\n",
      "epoch n°2573 : train_loss = 2.067411422729492, val_loss = 0.8003013134002686\n",
      "epoch n°2574 : train_loss = 2.0688390731811523, val_loss = 0.7925994992256165\n",
      "epoch n°2575 : train_loss = 2.0709798336029053, val_loss = 0.7960992455482483\n",
      "epoch n°2576 : train_loss = 2.0771448612213135, val_loss = 0.7989016771316528\n",
      "epoch n°2577 : train_loss = 2.07474684715271, val_loss = 0.7996907830238342\n",
      "epoch n°2578 : train_loss = 2.070323944091797, val_loss = 0.7950665950775146\n",
      "epoch n°2579 : train_loss = 2.071214199066162, val_loss = 0.8014276623725891\n",
      "epoch n°2580 : train_loss = 2.075380563735962, val_loss = 0.794247031211853\n",
      "epoch n°2581 : train_loss = 2.0759267807006836, val_loss = 0.7960202097892761\n",
      "epoch n°2582 : train_loss = 2.0706918239593506, val_loss = 0.7945637106895447\n",
      "epoch n°2583 : train_loss = 2.068795680999756, val_loss = 0.8006016612052917\n",
      "epoch n°2584 : train_loss = 2.068530797958374, val_loss = 0.7966083884239197\n",
      "epoch n°2585 : train_loss = 2.0624890327453613, val_loss = 0.7988030314445496\n",
      "epoch n°2586 : train_loss = 2.0645008087158203, val_loss = 0.7967320084571838\n",
      "epoch n°2587 : train_loss = 2.0718138217926025, val_loss = 0.7952280044555664\n",
      "epoch n°2588 : train_loss = 2.063349962234497, val_loss = 0.7967930436134338\n",
      "epoch n°2589 : train_loss = 2.07637357711792, val_loss = 0.8007042407989502\n",
      "epoch n°2590 : train_loss = 2.067992925643921, val_loss = 0.7932040095329285\n",
      "epoch n°2591 : train_loss = 2.080310821533203, val_loss = 0.798289954662323\n",
      "epoch n°2592 : train_loss = 2.0735294818878174, val_loss = 0.7954657077789307\n",
      "epoch n°2593 : train_loss = 2.0786049365997314, val_loss = 0.7973096966743469\n",
      "epoch n°2594 : train_loss = 2.0745909214019775, val_loss = 0.7934901118278503\n",
      "epoch n°2595 : train_loss = 2.060962677001953, val_loss = 0.794791042804718\n",
      "epoch n°2596 : train_loss = 2.0676140785217285, val_loss = 0.7924288511276245\n",
      "epoch n°2597 : train_loss = 2.0677647590637207, val_loss = 0.7991357445716858\n",
      "epoch n°2598 : train_loss = 2.0610644817352295, val_loss = 0.7975149154663086\n",
      "epoch n°2599 : train_loss = 2.067716121673584, val_loss = 0.7985536456108093\n",
      "epoch n°2600 : train_loss = 2.0671775341033936, val_loss = 0.7912402749061584\n",
      "epoch n°2601 : train_loss = 2.060964584350586, val_loss = 0.795936644077301\n",
      "epoch n°2602 : train_loss = 2.0697381496429443, val_loss = 0.8004347681999207\n",
      "epoch n°2603 : train_loss = 2.0704667568206787, val_loss = 0.7935179471969604\n",
      "epoch n°2604 : train_loss = 2.075021743774414, val_loss = 0.8001593351364136\n",
      "epoch n°2605 : train_loss = 2.071988582611084, val_loss = 0.7972702980041504\n",
      "epoch n°2606 : train_loss = 2.071011543273926, val_loss = 0.793267011642456\n",
      "epoch n°2607 : train_loss = 2.068459987640381, val_loss = 0.7987732887268066\n",
      "epoch n°2608 : train_loss = 2.070446252822876, val_loss = 0.7905610203742981\n",
      "epoch n°2609 : train_loss = 2.0702385902404785, val_loss = 0.7980842590332031\n",
      "epoch n°2610 : train_loss = 2.0674493312835693, val_loss = 0.7968607544898987\n",
      "epoch n°2611 : train_loss = 2.068467378616333, val_loss = 0.8000403046607971\n",
      "epoch n°2612 : train_loss = 2.0700013637542725, val_loss = 0.7973847985267639\n",
      "epoch n°2613 : train_loss = 2.0716331005096436, val_loss = 0.7943962812423706\n",
      "epoch n°2614 : train_loss = 2.0713727474212646, val_loss = 0.7940804958343506\n",
      "epoch n°2615 : train_loss = 2.0647120475769043, val_loss = 0.7961753010749817\n",
      "epoch n°2616 : train_loss = 2.0694332122802734, val_loss = 0.7992900013923645\n",
      "epoch n°2617 : train_loss = 2.0795602798461914, val_loss = 0.797601044178009\n",
      "epoch n°2618 : train_loss = 2.074350118637085, val_loss = 0.7983477115631104\n",
      "epoch n°2619 : train_loss = 2.068098545074463, val_loss = 0.7959098815917969\n",
      "epoch n°2620 : train_loss = 2.064573049545288, val_loss = 0.7975593209266663\n",
      "epoch n°2621 : train_loss = 2.0718634128570557, val_loss = 0.7956117987632751\n",
      "epoch n°2622 : train_loss = 2.074336528778076, val_loss = 0.7944373488426208\n",
      "epoch n°2623 : train_loss = 2.0596365928649902, val_loss = 0.798017680644989\n",
      "epoch n°2624 : train_loss = 2.058187484741211, val_loss = 0.7947238683700562\n",
      "epoch n°2625 : train_loss = 2.0711677074432373, val_loss = 0.7935194373130798\n",
      "epoch n°2626 : train_loss = 2.065988540649414, val_loss = 0.7974130511283875\n",
      "epoch n°2627 : train_loss = 2.06770396232605, val_loss = 0.7970661520957947\n",
      "epoch n°2628 : train_loss = 2.066382884979248, val_loss = 0.7995330691337585\n",
      "epoch n°2629 : train_loss = 2.066378355026245, val_loss = 0.7928406596183777\n",
      "epoch n°2630 : train_loss = 2.0758650302886963, val_loss = 0.7936043739318848\n",
      "epoch n°2631 : train_loss = 2.072476387023926, val_loss = 0.7981151938438416\n",
      "epoch n°2632 : train_loss = 2.071636199951172, val_loss = 0.7962923049926758\n",
      "epoch n°2633 : train_loss = 2.079861640930176, val_loss = 0.7937073707580566\n",
      "epoch n°2634 : train_loss = 2.0590367317199707, val_loss = 0.7985970973968506\n",
      "epoch n°2635 : train_loss = 2.071340560913086, val_loss = 0.7952438592910767\n",
      "epoch n°2636 : train_loss = 2.066141128540039, val_loss = 0.7922404408454895\n",
      "epoch n°2637 : train_loss = 2.059258460998535, val_loss = 0.798429548740387\n",
      "epoch n°2638 : train_loss = 2.0750555992126465, val_loss = 0.8005111813545227\n",
      "epoch n°2639 : train_loss = 2.069718599319458, val_loss = 0.7916925549507141\n",
      "epoch n°2640 : train_loss = 2.0720088481903076, val_loss = 0.7945541739463806\n",
      "epoch n°2641 : train_loss = 2.067382335662842, val_loss = 0.7922444343566895\n",
      "epoch n°2642 : train_loss = 2.060943365097046, val_loss = 0.7960382699966431\n",
      "epoch n°2643 : train_loss = 2.0612339973449707, val_loss = 0.7966617345809937\n",
      "epoch n°2644 : train_loss = 2.069132089614868, val_loss = 0.7960977554321289\n",
      "epoch n°2645 : train_loss = 2.062739610671997, val_loss = 0.7974042296409607\n",
      "epoch n°2646 : train_loss = 2.074920177459717, val_loss = 0.7978109121322632\n",
      "epoch n°2647 : train_loss = 2.0724358558654785, val_loss = 0.800373911857605\n",
      "epoch n°2648 : train_loss = 2.0635876655578613, val_loss = 0.7975730299949646\n",
      "epoch n°2649 : train_loss = 2.0742392539978027, val_loss = 0.7943814992904663\n",
      "epoch n°2650 : train_loss = 2.0618677139282227, val_loss = 0.7997868657112122\n",
      "epoch n°2651 : train_loss = 2.0627026557922363, val_loss = 0.7950217723846436\n",
      "epoch n°2652 : train_loss = 2.0616323947906494, val_loss = 0.7912147045135498\n",
      "epoch n°2653 : train_loss = 2.0680816173553467, val_loss = 0.7963155508041382\n",
      "epoch n°2654 : train_loss = 2.0607926845550537, val_loss = 0.7972428798675537\n",
      "epoch n°2655 : train_loss = 2.06952166557312, val_loss = 0.7922763824462891\n",
      "epoch n°2656 : train_loss = 2.064707040786743, val_loss = 0.790463924407959\n",
      "epoch n°2657 : train_loss = 2.0709431171417236, val_loss = 0.7993611097335815\n",
      "epoch n°2658 : train_loss = 2.066932201385498, val_loss = 0.797259509563446\n",
      "epoch n°2659 : train_loss = 2.0620813369750977, val_loss = 0.7968021035194397\n",
      "epoch n°2660 : train_loss = 2.063932180404663, val_loss = 0.7977977991104126\n",
      "epoch n°2661 : train_loss = 2.0609824657440186, val_loss = 0.7980608344078064\n",
      "epoch n°2662 : train_loss = 2.0710034370422363, val_loss = 0.7974514961242676\n",
      "epoch n°2663 : train_loss = 2.066669225692749, val_loss = 0.7930324673652649\n",
      "epoch n°2664 : train_loss = 2.0740270614624023, val_loss = 0.7978516221046448\n",
      "epoch n°2665 : train_loss = 2.069222927093506, val_loss = 0.7954253554344177\n",
      "epoch n°2666 : train_loss = 2.066488265991211, val_loss = 0.7954144477844238\n",
      "epoch n°2667 : train_loss = 2.050916910171509, val_loss = 0.7907972931861877\n",
      "epoch n°2668 : train_loss = 2.0730836391448975, val_loss = 0.795983612537384\n",
      "epoch n°2669 : train_loss = 2.061601400375366, val_loss = 0.8001440763473511\n",
      "epoch n°2670 : train_loss = 2.0775554180145264, val_loss = 0.7942299842834473\n",
      "epoch n°2671 : train_loss = 2.0709047317504883, val_loss = 0.797340989112854\n",
      "epoch n°2672 : train_loss = 2.0720322132110596, val_loss = 0.796596348285675\n",
      "epoch n°2673 : train_loss = 2.0714869499206543, val_loss = 0.7993338108062744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°2674 : train_loss = 2.059185743331909, val_loss = 0.7957046031951904\n",
      "epoch n°2675 : train_loss = 2.068127393722534, val_loss = 0.792363703250885\n",
      "epoch n°2676 : train_loss = 2.0749330520629883, val_loss = 0.7952403426170349\n",
      "epoch n°2677 : train_loss = 2.0626978874206543, val_loss = 0.7938705086708069\n",
      "epoch n°2678 : train_loss = 2.0700910091400146, val_loss = 0.7986981868743896\n",
      "epoch n°2679 : train_loss = 2.0679359436035156, val_loss = 0.7920709848403931\n",
      "epoch n°2680 : train_loss = 2.0661048889160156, val_loss = 0.7937330007553101\n",
      "epoch n°2681 : train_loss = 2.060159921646118, val_loss = 0.7972184419631958\n",
      "epoch n°2682 : train_loss = 2.0639383792877197, val_loss = 0.7965448498725891\n",
      "epoch n°2683 : train_loss = 2.0652170181274414, val_loss = 0.7963851690292358\n",
      "epoch n°2684 : train_loss = 2.0595483779907227, val_loss = 0.7977072596549988\n",
      "epoch n°2685 : train_loss = 2.062922477722168, val_loss = 0.7956396341323853\n",
      "epoch n°2686 : train_loss = 2.0640597343444824, val_loss = 0.7995367646217346\n",
      "epoch n°2687 : train_loss = 2.0716168880462646, val_loss = 0.7935086488723755\n",
      "epoch n°2688 : train_loss = 2.0566632747650146, val_loss = 0.7951446771621704\n",
      "epoch n°2689 : train_loss = 2.0665621757507324, val_loss = 0.7924830317497253\n",
      "epoch n°2690 : train_loss = 2.0711686611175537, val_loss = 0.7919268012046814\n",
      "epoch n°2691 : train_loss = 2.0641918182373047, val_loss = 0.7952327728271484\n",
      "epoch n°2692 : train_loss = 2.0682499408721924, val_loss = 0.7995012402534485\n",
      "epoch n°2693 : train_loss = 2.068812370300293, val_loss = 0.7943386435508728\n",
      "epoch n°2694 : train_loss = 2.0684518814086914, val_loss = 0.7979233264923096\n",
      "epoch n°2695 : train_loss = 2.0584020614624023, val_loss = 0.7969722747802734\n",
      "epoch n°2696 : train_loss = 2.0730209350585938, val_loss = 0.7972710132598877\n",
      "epoch n°2697 : train_loss = 2.063122034072876, val_loss = 0.7944509387016296\n",
      "epoch n°2698 : train_loss = 2.0676445960998535, val_loss = 0.7964410185813904\n",
      "epoch n°2699 : train_loss = 2.0623269081115723, val_loss = 0.7979544401168823\n",
      "epoch n°2700 : train_loss = 2.059786081314087, val_loss = 0.7948182225227356\n",
      "epoch n°2701 : train_loss = 2.0696427822113037, val_loss = 0.8012668490409851\n",
      "epoch n°2702 : train_loss = 2.0559353828430176, val_loss = 0.7925910949707031\n",
      "epoch n°2703 : train_loss = 2.0669915676116943, val_loss = 0.7987838983535767\n",
      "epoch n°2704 : train_loss = 2.066833257675171, val_loss = 0.7995643615722656\n",
      "epoch n°2705 : train_loss = 2.0620038509368896, val_loss = 0.7953790426254272\n",
      "epoch n°2706 : train_loss = 2.0689165592193604, val_loss = 0.798969566822052\n",
      "epoch n°2707 : train_loss = 2.0544755458831787, val_loss = 0.7977761626243591\n",
      "epoch n°2708 : train_loss = 2.0678951740264893, val_loss = 0.7988653779029846\n",
      "epoch n°2709 : train_loss = 2.0627503395080566, val_loss = 0.7977938652038574\n",
      "epoch n°2710 : train_loss = 2.066899538040161, val_loss = 0.8007614612579346\n",
      "epoch n°2711 : train_loss = 2.0668535232543945, val_loss = 0.7937588691711426\n",
      "epoch n°2712 : train_loss = 2.0647027492523193, val_loss = 0.7947381138801575\n",
      "epoch n°2713 : train_loss = 2.0650463104248047, val_loss = 0.7960113286972046\n",
      "epoch n°2714 : train_loss = 2.060661792755127, val_loss = 0.7975103259086609\n",
      "epoch n°2715 : train_loss = 2.0647523403167725, val_loss = 0.8007842898368835\n",
      "epoch n°2716 : train_loss = 2.068286657333374, val_loss = 0.7982616424560547\n",
      "epoch n°2717 : train_loss = 2.053684711456299, val_loss = 0.7968339323997498\n",
      "epoch n°2718 : train_loss = 2.063532590866089, val_loss = 0.7978423237800598\n",
      "epoch n°2719 : train_loss = 2.062167167663574, val_loss = 0.7994452118873596\n",
      "epoch n°2720 : train_loss = 2.059863328933716, val_loss = 0.7933711409568787\n",
      "epoch n°2721 : train_loss = 2.068988561630249, val_loss = 0.7967582941055298\n",
      "epoch n°2722 : train_loss = 2.0572867393493652, val_loss = 0.7979915738105774\n",
      "epoch n°2723 : train_loss = 2.064255475997925, val_loss = 0.7923245429992676\n",
      "epoch n°2724 : train_loss = 2.0727498531341553, val_loss = 0.7970300912857056\n",
      "epoch n°2725 : train_loss = 2.0665791034698486, val_loss = 0.7943199872970581\n",
      "epoch n°2726 : train_loss = 2.0578160285949707, val_loss = 0.7943587899208069\n",
      "epoch n°2727 : train_loss = 2.067288875579834, val_loss = 0.795138418674469\n",
      "epoch n°2728 : train_loss = 2.0641467571258545, val_loss = 0.796323299407959\n",
      "epoch n°2729 : train_loss = 2.06929874420166, val_loss = 0.7958585023880005\n",
      "epoch n°2730 : train_loss = 2.0660135746002197, val_loss = 0.7977839112281799\n",
      "epoch n°2731 : train_loss = 2.0577805042266846, val_loss = 0.798157274723053\n",
      "epoch n°2732 : train_loss = 2.0561108589172363, val_loss = 0.7942308783531189\n",
      "epoch n°2733 : train_loss = 2.066300868988037, val_loss = 0.7959825396537781\n",
      "epoch n°2734 : train_loss = 2.06614351272583, val_loss = 0.798225462436676\n",
      "epoch n°2735 : train_loss = 2.0655155181884766, val_loss = 0.796854555606842\n",
      "epoch n°2736 : train_loss = 2.0583624839782715, val_loss = 0.7946813702583313\n",
      "epoch n°2737 : train_loss = 2.06704044342041, val_loss = 0.7979996800422668\n",
      "epoch n°2738 : train_loss = 2.0594229698181152, val_loss = 0.7937296628952026\n",
      "epoch n°2739 : train_loss = 2.0685648918151855, val_loss = 0.7975354194641113\n",
      "epoch n°2740 : train_loss = 2.0566446781158447, val_loss = 0.7955963015556335\n",
      "epoch n°2741 : train_loss = 2.075946092605591, val_loss = 0.7961570024490356\n",
      "epoch n°2742 : train_loss = 2.069474935531616, val_loss = 0.7957526445388794\n",
      "epoch n°2743 : train_loss = 2.061189651489258, val_loss = 0.7985873222351074\n",
      "epoch n°2744 : train_loss = 2.0635950565338135, val_loss = 0.7968306541442871\n",
      "epoch n°2745 : train_loss = 2.058706283569336, val_loss = 0.7927538752555847\n",
      "epoch n°2746 : train_loss = 2.065896511077881, val_loss = 0.7998549938201904\n",
      "epoch n°2747 : train_loss = 2.0656542778015137, val_loss = 0.7988927960395813\n",
      "epoch n°2748 : train_loss = 2.0665762424468994, val_loss = 0.795836329460144\n",
      "epoch n°2749 : train_loss = 2.068446636199951, val_loss = 0.7941506505012512\n",
      "epoch n°2750 : train_loss = 2.062021493911743, val_loss = 0.7923386096954346\n",
      "epoch n°2751 : train_loss = 2.064164638519287, val_loss = 0.7963377237319946\n",
      "epoch n°2752 : train_loss = 2.0647432804107666, val_loss = 0.7946745753288269\n",
      "epoch n°2753 : train_loss = 2.0545127391815186, val_loss = 0.7963557839393616\n",
      "epoch n°2754 : train_loss = 2.0713255405426025, val_loss = 0.7958120703697205\n",
      "epoch n°2755 : train_loss = 2.061631917953491, val_loss = 0.7973454594612122\n",
      "epoch n°2756 : train_loss = 2.0680527687072754, val_loss = 0.7967517375946045\n",
      "epoch n°2757 : train_loss = 2.057314872741699, val_loss = 0.7970097661018372\n",
      "epoch n°2758 : train_loss = 2.061060905456543, val_loss = 0.7957324981689453\n",
      "epoch n°2759 : train_loss = 2.0612714290618896, val_loss = 0.7947218418121338\n",
      "epoch n°2760 : train_loss = 2.0633280277252197, val_loss = 0.7958796620368958\n",
      "epoch n°2761 : train_loss = 2.0637409687042236, val_loss = 0.7968301177024841\n",
      "epoch n°2762 : train_loss = 2.065830707550049, val_loss = 0.7956960797309875\n",
      "epoch n°2763 : train_loss = 2.0597431659698486, val_loss = 0.7955865859985352\n",
      "epoch n°2764 : train_loss = 2.070742607116699, val_loss = 0.7949010729789734\n",
      "epoch n°2765 : train_loss = 2.063931703567505, val_loss = 0.7921507954597473\n",
      "epoch n°2766 : train_loss = 2.064126491546631, val_loss = 0.7930758595466614\n",
      "epoch n°2767 : train_loss = 2.0650835037231445, val_loss = 0.7994305491447449\n",
      "epoch n°2768 : train_loss = 2.067336320877075, val_loss = 0.7937809228897095\n",
      "epoch n°2769 : train_loss = 2.054049491882324, val_loss = 0.7939070463180542\n",
      "epoch n°2770 : train_loss = 2.0555150508880615, val_loss = 0.7935139536857605\n",
      "epoch n°2771 : train_loss = 2.0770678520202637, val_loss = 0.7920553088188171\n",
      "epoch n°2772 : train_loss = 2.0614025592803955, val_loss = 0.7916774153709412\n",
      "epoch n°2773 : train_loss = 2.06063175201416, val_loss = 0.7990491986274719\n",
      "epoch n°2774 : train_loss = 2.0560474395751953, val_loss = 0.8004223704338074\n",
      "epoch n°2775 : train_loss = 2.0554962158203125, val_loss = 0.796218752861023\n",
      "epoch n°2776 : train_loss = 2.0593180656433105, val_loss = 0.7993387579917908\n",
      "epoch n°2777 : train_loss = 2.063375949859619, val_loss = 0.7928451895713806\n",
      "epoch n°2778 : train_loss = 2.0537495613098145, val_loss = 0.7971073985099792\n",
      "epoch n°2779 : train_loss = 2.055750846862793, val_loss = 0.7973239421844482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°2780 : train_loss = 2.0589022636413574, val_loss = 0.7983339428901672\n",
      "epoch n°2781 : train_loss = 2.068909168243408, val_loss = 0.7957234978675842\n",
      "epoch n°2782 : train_loss = 2.064164161682129, val_loss = 0.7922408580780029\n",
      "epoch n°2783 : train_loss = 2.060079574584961, val_loss = 0.7922322750091553\n",
      "epoch n°2784 : train_loss = 2.058159351348877, val_loss = 0.7963567972183228\n",
      "epoch n°2785 : train_loss = 2.0695581436157227, val_loss = 0.8009668588638306\n",
      "epoch n°2786 : train_loss = 2.067188262939453, val_loss = 0.7976388931274414\n",
      "epoch n°2787 : train_loss = 2.0556812286376953, val_loss = 0.7932628393173218\n",
      "epoch n°2788 : train_loss = 2.0613272190093994, val_loss = 0.7949235439300537\n",
      "epoch n°2789 : train_loss = 2.0605826377868652, val_loss = 0.7965841889381409\n",
      "epoch n°2790 : train_loss = 2.065523386001587, val_loss = 0.7967813611030579\n",
      "epoch n°2791 : train_loss = 2.062368631362915, val_loss = 0.7960109710693359\n",
      "epoch n°2792 : train_loss = 2.058058023452759, val_loss = 0.7911036610603333\n",
      "epoch n°2793 : train_loss = 2.0616700649261475, val_loss = 0.7969886660575867\n",
      "epoch n°2794 : train_loss = 2.057544469833374, val_loss = 0.7943562269210815\n",
      "epoch n°2795 : train_loss = 2.072751760482788, val_loss = 0.7950730919837952\n",
      "epoch n°2796 : train_loss = 2.05731201171875, val_loss = 0.798486053943634\n",
      "epoch n°2797 : train_loss = 2.0669968128204346, val_loss = 0.7977985143661499\n",
      "epoch n°2798 : train_loss = 2.0643057823181152, val_loss = 0.7993778586387634\n",
      "epoch n°2799 : train_loss = 2.060807466506958, val_loss = 0.7985790371894836\n",
      "epoch n°2800 : train_loss = 2.0559844970703125, val_loss = 0.8000184297561646\n",
      "epoch n°2801 : train_loss = 2.0682260990142822, val_loss = 0.7957631945610046\n",
      "epoch n°2802 : train_loss = 2.0608577728271484, val_loss = 0.7959287762641907\n",
      "epoch n°2803 : train_loss = 2.058638572692871, val_loss = 0.7931379079818726\n",
      "epoch n°2804 : train_loss = 2.052656412124634, val_loss = 0.795674204826355\n",
      "epoch n°2805 : train_loss = 2.0615711212158203, val_loss = 0.7954161763191223\n",
      "epoch n°2806 : train_loss = 2.0527074337005615, val_loss = 0.7950586676597595\n",
      "epoch n°2807 : train_loss = 2.061694860458374, val_loss = 0.795595109462738\n",
      "epoch n°2808 : train_loss = 2.061570167541504, val_loss = 0.796076238155365\n",
      "epoch n°2809 : train_loss = 2.04841947555542, val_loss = 0.7933900952339172\n",
      "epoch n°2810 : train_loss = 2.0557384490966797, val_loss = 0.794465184211731\n",
      "epoch n°2811 : train_loss = 2.0519025325775146, val_loss = 0.796724259853363\n",
      "epoch n°2812 : train_loss = 2.0649399757385254, val_loss = 0.7991306781768799\n",
      "epoch n°2813 : train_loss = 2.057760715484619, val_loss = 0.8009853959083557\n",
      "epoch n°2814 : train_loss = 2.0631542205810547, val_loss = 0.7973396182060242\n",
      "epoch n°2815 : train_loss = 2.056278705596924, val_loss = 0.7984837889671326\n",
      "epoch n°2816 : train_loss = 2.0561602115631104, val_loss = 0.7977985739707947\n",
      "epoch n°2817 : train_loss = 2.0668177604675293, val_loss = 0.7969640493392944\n",
      "epoch n°2818 : train_loss = 2.0533039569854736, val_loss = 0.7931815385818481\n",
      "epoch n°2819 : train_loss = 2.063124656677246, val_loss = 0.7953298091888428\n",
      "epoch n°2820 : train_loss = 2.062825918197632, val_loss = 0.7931726574897766\n",
      "epoch n°2821 : train_loss = 2.0635781288146973, val_loss = 0.7963123917579651\n",
      "epoch n°2822 : train_loss = 2.058150291442871, val_loss = 0.7967416048049927\n",
      "epoch n°2823 : train_loss = 2.079041004180908, val_loss = 0.7981615662574768\n",
      "epoch n°2824 : train_loss = 2.064016103744507, val_loss = 0.789091169834137\n",
      "epoch n°2825 : train_loss = 2.055856227874756, val_loss = 0.7922658920288086\n",
      "epoch n°2826 : train_loss = 2.063124895095825, val_loss = 0.7930352687835693\n",
      "epoch n°2827 : train_loss = 2.061929225921631, val_loss = 0.7950538396835327\n",
      "epoch n°2828 : train_loss = 2.060202121734619, val_loss = 0.7966434955596924\n",
      "epoch n°2829 : train_loss = 2.060781955718994, val_loss = 0.7951439023017883\n",
      "epoch n°2830 : train_loss = 2.053061008453369, val_loss = 0.7926200032234192\n",
      "epoch n°2831 : train_loss = 2.059074640274048, val_loss = 0.7962371110916138\n",
      "epoch n°2832 : train_loss = 2.053352117538452, val_loss = 0.7976443767547607\n",
      "epoch n°2833 : train_loss = 2.0469906330108643, val_loss = 0.791571319103241\n",
      "epoch n°2834 : train_loss = 2.0570194721221924, val_loss = 0.7926573157310486\n",
      "epoch n°2835 : train_loss = 2.060356616973877, val_loss = 0.7908913493156433\n",
      "epoch n°2836 : train_loss = 2.0556492805480957, val_loss = 0.7939446568489075\n",
      "epoch n°2837 : train_loss = 2.064303398132324, val_loss = 0.7953294515609741\n",
      "epoch n°2838 : train_loss = 2.054818630218506, val_loss = 0.8001368045806885\n",
      "epoch n°2839 : train_loss = 2.052987575531006, val_loss = 0.7945329546928406\n",
      "epoch n°2840 : train_loss = 2.0555672645568848, val_loss = 0.7955484390258789\n",
      "epoch n°2841 : train_loss = 2.061492443084717, val_loss = 0.792285144329071\n",
      "epoch n°2842 : train_loss = 2.0573678016662598, val_loss = 0.7925663590431213\n",
      "epoch n°2843 : train_loss = 2.0615923404693604, val_loss = 0.7948089241981506\n",
      "epoch n°2844 : train_loss = 2.066315174102783, val_loss = 0.7941651940345764\n",
      "epoch n°2845 : train_loss = 2.0586163997650146, val_loss = 0.7921321988105774\n",
      "epoch n°2846 : train_loss = 2.0647995471954346, val_loss = 0.7957441210746765\n",
      "epoch n°2847 : train_loss = 2.0596702098846436, val_loss = 0.7941997647285461\n",
      "epoch n°2848 : train_loss = 2.0569710731506348, val_loss = 0.7925849556922913\n",
      "epoch n°2849 : train_loss = 2.0633654594421387, val_loss = 0.7982029914855957\n",
      "epoch n°2850 : train_loss = 2.061969757080078, val_loss = 0.7912896275520325\n",
      "epoch n°2851 : train_loss = 2.0660765171051025, val_loss = 0.7949710488319397\n",
      "epoch n°2852 : train_loss = 2.0630407333374023, val_loss = 0.7926024794578552\n",
      "epoch n°2853 : train_loss = 2.0558037757873535, val_loss = 0.7945939302444458\n",
      "epoch n°2854 : train_loss = 2.0577027797698975, val_loss = 0.7938174605369568\n",
      "epoch n°2855 : train_loss = 2.06463360786438, val_loss = 0.7907764911651611\n",
      "epoch n°2856 : train_loss = 2.059744358062744, val_loss = 0.7934325337409973\n",
      "epoch n°2857 : train_loss = 2.064150810241699, val_loss = 0.7953441739082336\n",
      "epoch n°2858 : train_loss = 2.050339937210083, val_loss = 0.7984989881515503\n",
      "epoch n°2859 : train_loss = 2.0578999519348145, val_loss = 0.7927441000938416\n",
      "epoch n°2860 : train_loss = 2.0586836338043213, val_loss = 0.796423614025116\n",
      "epoch n°2861 : train_loss = 2.0502066612243652, val_loss = 0.7932004332542419\n",
      "epoch n°2862 : train_loss = 2.051816701889038, val_loss = 0.7962544560432434\n",
      "epoch n°2863 : train_loss = 2.060474395751953, val_loss = 0.7907848358154297\n",
      "epoch n°2864 : train_loss = 2.0633668899536133, val_loss = 0.7952064871788025\n",
      "epoch n°2865 : train_loss = 2.056657314300537, val_loss = 0.7939659953117371\n",
      "epoch n°2866 : train_loss = 2.059980869293213, val_loss = 0.8012462258338928\n",
      "epoch n°2867 : train_loss = 2.0629448890686035, val_loss = 0.7950565814971924\n",
      "epoch n°2868 : train_loss = 2.0520241260528564, val_loss = 0.7941156029701233\n",
      "epoch n°2869 : train_loss = 2.060725450515747, val_loss = 0.7996368408203125\n",
      "epoch n°2870 : train_loss = 2.05446720123291, val_loss = 0.7976714968681335\n",
      "epoch n°2871 : train_loss = 2.061983108520508, val_loss = 0.7914865612983704\n",
      "epoch n°2872 : train_loss = 2.0549139976501465, val_loss = 0.7942874431610107\n",
      "epoch n°2873 : train_loss = 2.058469533920288, val_loss = 0.796036422252655\n",
      "epoch n°2874 : train_loss = 2.058492660522461, val_loss = 0.7954167723655701\n",
      "epoch n°2875 : train_loss = 2.0604145526885986, val_loss = 0.7986801266670227\n",
      "epoch n°2876 : train_loss = 2.0479395389556885, val_loss = 0.7974568009376526\n",
      "epoch n°2877 : train_loss = 2.055755615234375, val_loss = 0.7943611741065979\n",
      "epoch n°2878 : train_loss = 2.0589311122894287, val_loss = 0.7955603003501892\n",
      "epoch n°2879 : train_loss = 2.062741279602051, val_loss = 0.7953751683235168\n",
      "epoch n°2880 : train_loss = 2.0616471767425537, val_loss = 0.795378565788269\n",
      "epoch n°2881 : train_loss = 2.0593578815460205, val_loss = 0.7947878241539001\n",
      "epoch n°2882 : train_loss = 2.061687707901001, val_loss = 0.7955056428909302\n",
      "epoch n°2883 : train_loss = 2.0503785610198975, val_loss = 0.7952993512153625\n",
      "epoch n°2884 : train_loss = 2.058746099472046, val_loss = 0.7908837795257568\n",
      "epoch n°2885 : train_loss = 2.05530047416687, val_loss = 0.7965627312660217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°2886 : train_loss = 2.062922716140747, val_loss = 0.7930450439453125\n",
      "epoch n°2887 : train_loss = 2.056210994720459, val_loss = 0.795242965221405\n",
      "epoch n°2888 : train_loss = 2.0555453300476074, val_loss = 0.7967782616615295\n",
      "epoch n°2889 : train_loss = 2.0586681365966797, val_loss = 0.8015257120132446\n",
      "epoch n°2890 : train_loss = 2.050412178039551, val_loss = 0.7968536615371704\n",
      "epoch n°2891 : train_loss = 2.0636448860168457, val_loss = 0.7928687334060669\n",
      "epoch n°2892 : train_loss = 2.0508081912994385, val_loss = 0.7957017421722412\n",
      "epoch n°2893 : train_loss = 2.0540359020233154, val_loss = 0.7913984656333923\n",
      "epoch n°2894 : train_loss = 2.060112714767456, val_loss = 0.7935086488723755\n",
      "epoch n°2895 : train_loss = 2.065896511077881, val_loss = 0.7951879501342773\n",
      "epoch n°2896 : train_loss = 2.0629396438598633, val_loss = 0.7981835603713989\n",
      "epoch n°2897 : train_loss = 2.0489211082458496, val_loss = 0.7937324643135071\n",
      "epoch n°2898 : train_loss = 2.051896333694458, val_loss = 0.7932543754577637\n",
      "epoch n°2899 : train_loss = 2.0524425506591797, val_loss = 0.7957699298858643\n",
      "epoch n°2900 : train_loss = 2.0604684352874756, val_loss = 0.7968982458114624\n",
      "epoch n°2901 : train_loss = 2.0580954551696777, val_loss = 0.8009501695632935\n",
      "epoch n°2902 : train_loss = 2.0562896728515625, val_loss = 0.7938345670700073\n",
      "epoch n°2903 : train_loss = 2.044219732284546, val_loss = 0.7971628904342651\n",
      "epoch n°2904 : train_loss = 2.0576860904693604, val_loss = 0.7957326173782349\n",
      "epoch n°2905 : train_loss = 2.0513503551483154, val_loss = 0.7948158383369446\n",
      "epoch n°2906 : train_loss = 2.060486078262329, val_loss = 0.7974614500999451\n",
      "epoch n°2907 : train_loss = 2.0521018505096436, val_loss = 0.7950597405433655\n",
      "epoch n°2908 : train_loss = 2.0593185424804688, val_loss = 0.8001799583435059\n",
      "epoch n°2909 : train_loss = 2.0601069927215576, val_loss = 0.8025711178779602\n",
      "epoch n°2910 : train_loss = 2.057903289794922, val_loss = 0.7966720461845398\n",
      "epoch n°2911 : train_loss = 2.0540552139282227, val_loss = 0.7967713475227356\n",
      "epoch n°2912 : train_loss = 2.048506259918213, val_loss = 0.7958926558494568\n",
      "epoch n°2913 : train_loss = 2.0601789951324463, val_loss = 0.793894350528717\n",
      "epoch n°2914 : train_loss = 2.057854652404785, val_loss = 0.7977038025856018\n",
      "epoch n°2915 : train_loss = 2.054598808288574, val_loss = 0.7994195818901062\n",
      "epoch n°2916 : train_loss = 2.0493814945220947, val_loss = 0.7917501330375671\n",
      "epoch n°2917 : train_loss = 2.050973892211914, val_loss = 0.7988071441650391\n",
      "epoch n°2918 : train_loss = 2.0613903999328613, val_loss = 0.7944215536117554\n",
      "epoch n°2919 : train_loss = 2.0498907566070557, val_loss = 0.7932427525520325\n",
      "epoch n°2920 : train_loss = 2.0532901287078857, val_loss = 0.7921796441078186\n",
      "epoch n°2921 : train_loss = 2.053201198577881, val_loss = 0.7927148342132568\n",
      "epoch n°2922 : train_loss = 2.057436943054199, val_loss = 0.7932295203208923\n",
      "epoch n°2923 : train_loss = 2.0554726123809814, val_loss = 0.7916544675827026\n",
      "epoch n°2924 : train_loss = 2.0466604232788086, val_loss = 0.7982674837112427\n",
      "epoch n°2925 : train_loss = 2.0503106117248535, val_loss = 0.7968599200248718\n",
      "epoch n°2926 : train_loss = 2.0470924377441406, val_loss = 0.7982249855995178\n",
      "epoch n°2927 : train_loss = 2.0517711639404297, val_loss = 0.796065628528595\n",
      "epoch n°2928 : train_loss = 2.0500197410583496, val_loss = 0.7958887219429016\n",
      "epoch n°2929 : train_loss = 2.0591790676116943, val_loss = 0.7944626212120056\n",
      "epoch n°2930 : train_loss = 2.0621349811553955, val_loss = 0.7936654090881348\n",
      "epoch n°2931 : train_loss = 2.0563230514526367, val_loss = 0.7961205840110779\n",
      "epoch n°2932 : train_loss = 2.0533769130706787, val_loss = 0.7954098582267761\n",
      "epoch n°2933 : train_loss = 2.0466468334198, val_loss = 0.7965112924575806\n",
      "epoch n°2934 : train_loss = 2.052154064178467, val_loss = 0.7966518998146057\n",
      "epoch n°2935 : train_loss = 2.0511820316314697, val_loss = 0.7974582314491272\n",
      "epoch n°2936 : train_loss = 2.064910411834717, val_loss = 0.793182373046875\n",
      "epoch n°2937 : train_loss = 2.053661584854126, val_loss = 0.7941784262657166\n",
      "epoch n°2938 : train_loss = 2.0512006282806396, val_loss = 0.7924249172210693\n",
      "epoch n°2939 : train_loss = 2.0536341667175293, val_loss = 0.7975049018859863\n",
      "epoch n°2940 : train_loss = 2.0561676025390625, val_loss = 0.8003199100494385\n",
      "epoch n°2941 : train_loss = 2.0576326847076416, val_loss = 0.7919724583625793\n",
      "epoch n°2942 : train_loss = 2.0564863681793213, val_loss = 0.7924497127532959\n",
      "epoch n°2943 : train_loss = 2.0546953678131104, val_loss = 0.7902007102966309\n",
      "epoch n°2944 : train_loss = 2.0556275844573975, val_loss = 0.7934951782226562\n",
      "epoch n°2945 : train_loss = 2.0606727600097656, val_loss = 0.7944034934043884\n",
      "epoch n°2946 : train_loss = 2.059779405593872, val_loss = 0.7979646325111389\n",
      "epoch n°2947 : train_loss = 2.0408902168273926, val_loss = 0.7967220544815063\n",
      "epoch n°2948 : train_loss = 2.0655899047851562, val_loss = 0.7934166789054871\n",
      "epoch n°2949 : train_loss = 2.054328680038452, val_loss = 0.7954286336898804\n",
      "epoch n°2950 : train_loss = 2.050135850906372, val_loss = 0.7939566969871521\n",
      "epoch n°2951 : train_loss = 2.0559864044189453, val_loss = 0.793269157409668\n",
      "epoch n°2952 : train_loss = 2.0444254875183105, val_loss = 0.7965409755706787\n",
      "epoch n°2953 : train_loss = 2.0563225746154785, val_loss = 0.7950588464736938\n",
      "epoch n°2954 : train_loss = 2.055368661880493, val_loss = 0.7941291928291321\n",
      "epoch n°2955 : train_loss = 2.0476763248443604, val_loss = 0.7965005040168762\n",
      "epoch n°2956 : train_loss = 2.0502545833587646, val_loss = 0.7960851788520813\n",
      "epoch n°2957 : train_loss = 2.052623748779297, val_loss = 0.7976445555686951\n",
      "epoch n°2958 : train_loss = 2.0573315620422363, val_loss = 0.7953753471374512\n",
      "epoch n°2959 : train_loss = 2.0517778396606445, val_loss = 0.7951081991195679\n",
      "epoch n°2960 : train_loss = 2.049734592437744, val_loss = 0.7921050786972046\n",
      "epoch n°2961 : train_loss = 2.0462005138397217, val_loss = 0.7966132164001465\n",
      "epoch n°2962 : train_loss = 2.056513547897339, val_loss = 0.7906724214553833\n",
      "epoch n°2963 : train_loss = 2.060061454772949, val_loss = 0.7979711294174194\n",
      "epoch n°2964 : train_loss = 2.0507359504699707, val_loss = 0.7954641580581665\n",
      "epoch n°2965 : train_loss = 2.0473549365997314, val_loss = 0.7946970462799072\n",
      "epoch n°2966 : train_loss = 2.0481786727905273, val_loss = 0.791703999042511\n",
      "epoch n°2967 : train_loss = 2.051654577255249, val_loss = 0.7909453511238098\n",
      "epoch n°2968 : train_loss = 2.0475292205810547, val_loss = 0.7971796989440918\n",
      "epoch n°2969 : train_loss = 2.048527956008911, val_loss = 0.7910336256027222\n",
      "epoch n°2970 : train_loss = 2.053208827972412, val_loss = 0.7885520458221436\n",
      "epoch n°2971 : train_loss = 2.054917097091675, val_loss = 0.7930548787117004\n",
      "epoch n°2972 : train_loss = 2.053387403488159, val_loss = 0.7962196469306946\n",
      "epoch n°2973 : train_loss = 2.049041986465454, val_loss = 0.7911777496337891\n",
      "epoch n°2974 : train_loss = 2.048452138900757, val_loss = 0.7942046523094177\n",
      "epoch n°2975 : train_loss = 2.05593204498291, val_loss = 0.7955107092857361\n",
      "epoch n°2976 : train_loss = 2.0516135692596436, val_loss = 0.7921268939971924\n",
      "epoch n°2977 : train_loss = 2.0386927127838135, val_loss = 0.794786274433136\n",
      "epoch n°2978 : train_loss = 2.050916910171509, val_loss = 0.7946057319641113\n",
      "epoch n°2979 : train_loss = 2.053713798522949, val_loss = 0.7959228754043579\n",
      "epoch n°2980 : train_loss = 2.0515363216400146, val_loss = 0.7927417159080505\n",
      "epoch n°2981 : train_loss = 2.0503597259521484, val_loss = 0.7950554490089417\n",
      "epoch n°2982 : train_loss = 2.0478994846343994, val_loss = 0.7941073179244995\n",
      "epoch n°2983 : train_loss = 2.0483546257019043, val_loss = 0.794163167476654\n",
      "epoch n°2984 : train_loss = 2.052903652191162, val_loss = 0.7945255637168884\n",
      "epoch n°2985 : train_loss = 2.058239221572876, val_loss = 0.7944515943527222\n",
      "epoch n°2986 : train_loss = 2.054096221923828, val_loss = 0.7926547527313232\n",
      "epoch n°2987 : train_loss = 2.053436517715454, val_loss = 0.7922965288162231\n",
      "epoch n°2988 : train_loss = 2.0483558177948, val_loss = 0.7989756464958191\n",
      "epoch n°2989 : train_loss = 2.045018196105957, val_loss = 0.7972215414047241\n",
      "epoch n°2990 : train_loss = 2.0405967235565186, val_loss = 0.7932912111282349\n",
      "epoch n°2991 : train_loss = 2.0462894439697266, val_loss = 0.7968908548355103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°2992 : train_loss = 2.052018880844116, val_loss = 0.7961575984954834\n",
      "epoch n°2993 : train_loss = 2.0555777549743652, val_loss = 0.7962656617164612\n",
      "epoch n°2994 : train_loss = 2.052090883255005, val_loss = 0.7987576723098755\n",
      "epoch n°2995 : train_loss = 2.054821252822876, val_loss = 0.7909809350967407\n",
      "epoch n°2996 : train_loss = 2.0524425506591797, val_loss = 0.7944893836975098\n",
      "epoch n°2997 : train_loss = 2.0587515830993652, val_loss = 0.7958554029464722\n",
      "epoch n°2998 : train_loss = 2.0475077629089355, val_loss = 0.7930408120155334\n",
      "epoch n°2999 : train_loss = 2.0533831119537354, val_loss = 0.7924979329109192\n",
      "epoch n°3000 : train_loss = 2.051995277404785, val_loss = 0.7943127155303955\n",
      "epoch n°3001 : train_loss = 2.0554938316345215, val_loss = 0.7964287400245667\n",
      "epoch n°3002 : train_loss = 2.0528292655944824, val_loss = 0.7970641255378723\n",
      "epoch n°3003 : train_loss = 2.052628755569458, val_loss = 0.7938731908798218\n",
      "epoch n°3004 : train_loss = 2.0544326305389404, val_loss = 0.7955817580223083\n",
      "epoch n°3005 : train_loss = 2.052802562713623, val_loss = 0.7957807779312134\n",
      "epoch n°3006 : train_loss = 2.057239532470703, val_loss = 0.7944118976593018\n",
      "epoch n°3007 : train_loss = 2.0500130653381348, val_loss = 0.7949928641319275\n",
      "epoch n°3008 : train_loss = 2.050100088119507, val_loss = 0.7945935726165771\n",
      "epoch n°3009 : train_loss = 2.052462577819824, val_loss = 0.7907982468605042\n",
      "epoch n°3010 : train_loss = 2.047752857208252, val_loss = 0.7943013906478882\n",
      "epoch n°3011 : train_loss = 2.0535008907318115, val_loss = 0.792519748210907\n",
      "epoch n°3012 : train_loss = 2.056856870651245, val_loss = 0.789146363735199\n",
      "epoch n°3013 : train_loss = 2.0600767135620117, val_loss = 0.794636070728302\n",
      "epoch n°3014 : train_loss = 2.0495052337646484, val_loss = 0.7927113175392151\n",
      "epoch n°3015 : train_loss = 2.0530989170074463, val_loss = 0.7924936413764954\n",
      "epoch n°3016 : train_loss = 2.057117223739624, val_loss = 0.7970321178436279\n",
      "epoch n°3017 : train_loss = 2.0478739738464355, val_loss = 0.7940196394920349\n",
      "epoch n°3018 : train_loss = 2.048868179321289, val_loss = 0.7928709387779236\n",
      "epoch n°3019 : train_loss = 2.04435396194458, val_loss = 0.7952656745910645\n",
      "epoch n°3020 : train_loss = 2.053069591522217, val_loss = 0.7929426431655884\n",
      "epoch n°3021 : train_loss = 2.0482337474823, val_loss = 0.791851818561554\n",
      "epoch n°3022 : train_loss = 2.048959255218506, val_loss = 0.7927603721618652\n",
      "epoch n°3023 : train_loss = 2.05202317237854, val_loss = 0.7975178360939026\n",
      "epoch n°3024 : train_loss = 2.0494730472564697, val_loss = 0.7960870265960693\n",
      "epoch n°3025 : train_loss = 2.0557544231414795, val_loss = 0.7966837286949158\n",
      "epoch n°3026 : train_loss = 2.041370153427124, val_loss = 0.7900164127349854\n",
      "epoch n°3027 : train_loss = 2.0468034744262695, val_loss = 0.795123279094696\n",
      "epoch n°3028 : train_loss = 2.0537774562835693, val_loss = 0.7958623766899109\n",
      "epoch n°3029 : train_loss = 2.055405616760254, val_loss = 0.7956066131591797\n",
      "epoch n°3030 : train_loss = 2.046380043029785, val_loss = 0.7914681434631348\n",
      "epoch n°3031 : train_loss = 2.0454041957855225, val_loss = 0.7959120869636536\n",
      "epoch n°3032 : train_loss = 2.05826997756958, val_loss = 0.7937479019165039\n",
      "epoch n°3033 : train_loss = 2.048929214477539, val_loss = 0.794915497303009\n",
      "epoch n°3034 : train_loss = 2.043011426925659, val_loss = 0.7907669544219971\n",
      "epoch n°3035 : train_loss = 2.041156768798828, val_loss = 0.791621208190918\n",
      "epoch n°3036 : train_loss = 2.0508694648742676, val_loss = 0.7934739589691162\n",
      "epoch n°3037 : train_loss = 2.042644500732422, val_loss = 0.795518696308136\n",
      "epoch n°3038 : train_loss = 2.0493571758270264, val_loss = 0.7885905504226685\n",
      "epoch n°3039 : train_loss = 2.0426533222198486, val_loss = 0.7925687432289124\n",
      "epoch n°3040 : train_loss = 2.035752058029175, val_loss = 0.7972392439842224\n",
      "epoch n°3041 : train_loss = 2.049595832824707, val_loss = 0.7937576770782471\n",
      "epoch n°3042 : train_loss = 2.051497459411621, val_loss = 0.7957291007041931\n",
      "epoch n°3043 : train_loss = 2.055431604385376, val_loss = 0.7889820337295532\n",
      "epoch n°3044 : train_loss = 2.0409586429595947, val_loss = 0.7988759279251099\n",
      "epoch n°3045 : train_loss = 2.0500402450561523, val_loss = 0.796139121055603\n",
      "epoch n°3046 : train_loss = 2.055846691131592, val_loss = 0.7964854836463928\n",
      "epoch n°3047 : train_loss = 2.0433554649353027, val_loss = 0.7983430624008179\n",
      "epoch n°3048 : train_loss = 2.049633264541626, val_loss = 0.796858012676239\n",
      "epoch n°3049 : train_loss = 2.048671245574951, val_loss = 0.7931016087532043\n",
      "epoch n°3050 : train_loss = 2.049184799194336, val_loss = 0.7922297716140747\n",
      "epoch n°3051 : train_loss = 2.0474650859832764, val_loss = 0.7953038215637207\n",
      "epoch n°3052 : train_loss = 2.0448262691497803, val_loss = 0.7974207401275635\n",
      "epoch n°3053 : train_loss = 2.0522420406341553, val_loss = 0.8017822504043579\n",
      "epoch n°3054 : train_loss = 2.052042245864868, val_loss = 0.7932400107383728\n",
      "epoch n°3055 : train_loss = 2.0502843856811523, val_loss = 0.7953999042510986\n",
      "epoch n°3056 : train_loss = 2.0457372665405273, val_loss = 0.794693648815155\n",
      "epoch n°3057 : train_loss = 2.042858839035034, val_loss = 0.7950347661972046\n",
      "epoch n°3058 : train_loss = 2.048365592956543, val_loss = 0.7903441190719604\n",
      "epoch n°3059 : train_loss = 2.0518805980682373, val_loss = 0.7961004376411438\n",
      "epoch n°3060 : train_loss = 2.05086088180542, val_loss = 0.7930354475975037\n",
      "epoch n°3061 : train_loss = 2.041738748550415, val_loss = 0.7944462299346924\n",
      "epoch n°3062 : train_loss = 2.049326181411743, val_loss = 0.7959344387054443\n",
      "epoch n°3063 : train_loss = 2.0456466674804688, val_loss = 0.7913395762443542\n",
      "epoch n°3064 : train_loss = 2.0458500385284424, val_loss = 0.7904230952262878\n",
      "epoch n°3065 : train_loss = 2.0502562522888184, val_loss = 0.7939226627349854\n",
      "epoch n°3066 : train_loss = 2.0560760498046875, val_loss = 0.7994728088378906\n",
      "epoch n°3067 : train_loss = 2.046902894973755, val_loss = 0.7926251888275146\n",
      "epoch n°3068 : train_loss = 2.053356170654297, val_loss = 0.7945615649223328\n",
      "epoch n°3069 : train_loss = 2.0409505367279053, val_loss = 0.7941688299179077\n",
      "epoch n°3070 : train_loss = 2.045931816101074, val_loss = 0.7970972061157227\n",
      "epoch n°3071 : train_loss = 2.0446698665618896, val_loss = 0.7946774363517761\n",
      "epoch n°3072 : train_loss = 2.04299259185791, val_loss = 0.7925258278846741\n",
      "epoch n°3073 : train_loss = 2.0398294925689697, val_loss = 0.7938855886459351\n",
      "epoch n°3074 : train_loss = 2.053133010864258, val_loss = 0.7922360301017761\n",
      "epoch n°3075 : train_loss = 2.0478270053863525, val_loss = 0.7942104935646057\n",
      "epoch n°3076 : train_loss = 2.047492742538452, val_loss = 0.7945818901062012\n",
      "epoch n°3077 : train_loss = 2.042426824569702, val_loss = 0.7942664623260498\n",
      "epoch n°3078 : train_loss = 2.04775333404541, val_loss = 0.802176833152771\n",
      "epoch n°3079 : train_loss = 2.050647258758545, val_loss = 0.7943553924560547\n",
      "epoch n°3080 : train_loss = 2.0477828979492188, val_loss = 0.7942110896110535\n",
      "epoch n°3081 : train_loss = 2.052870988845825, val_loss = 0.7922611236572266\n",
      "epoch n°3082 : train_loss = 2.055586099624634, val_loss = 0.7972609996795654\n",
      "epoch n°3083 : train_loss = 2.0506014823913574, val_loss = 0.7979202270507812\n",
      "epoch n°3084 : train_loss = 2.0412726402282715, val_loss = 0.7928469181060791\n",
      "epoch n°3085 : train_loss = 2.049302339553833, val_loss = 0.7925312519073486\n",
      "epoch n°3086 : train_loss = 2.049079418182373, val_loss = 0.7927002906799316\n",
      "epoch n°3087 : train_loss = 2.0424704551696777, val_loss = 0.7930076122283936\n",
      "epoch n°3088 : train_loss = 2.0513370037078857, val_loss = 0.7935046553611755\n",
      "epoch n°3089 : train_loss = 2.0321478843688965, val_loss = 0.798865795135498\n",
      "epoch n°3090 : train_loss = 2.047740936279297, val_loss = 0.7946162223815918\n",
      "epoch n°3091 : train_loss = 2.0587210655212402, val_loss = 0.7955435514450073\n",
      "epoch n°3092 : train_loss = 2.045109987258911, val_loss = 0.7918370962142944\n",
      "epoch n°3093 : train_loss = 2.046599864959717, val_loss = 0.7907675504684448\n",
      "epoch n°3094 : train_loss = 2.0488317012786865, val_loss = 0.7926508188247681\n",
      "epoch n°3095 : train_loss = 2.049877643585205, val_loss = 0.7914426326751709\n",
      "epoch n°3096 : train_loss = 2.0460400581359863, val_loss = 0.7906827330589294\n",
      "epoch n°3097 : train_loss = 2.0463762283325195, val_loss = 0.7942006587982178\n",
      "epoch n°3098 : train_loss = 2.044450283050537, val_loss = 0.7973884344100952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°3099 : train_loss = 2.0479636192321777, val_loss = 0.7943697571754456\n",
      "epoch n°3100 : train_loss = 2.0499320030212402, val_loss = 0.7960972189903259\n",
      "epoch n°3101 : train_loss = 2.0437967777252197, val_loss = 0.7969886660575867\n",
      "epoch n°3102 : train_loss = 2.0402848720550537, val_loss = 0.7904528975486755\n",
      "epoch n°3103 : train_loss = 2.045607805252075, val_loss = 0.7944503426551819\n",
      "epoch n°3104 : train_loss = 2.036612033843994, val_loss = 0.7962885499000549\n",
      "epoch n°3105 : train_loss = 2.047360897064209, val_loss = 0.7961916327476501\n",
      "epoch n°3106 : train_loss = 2.0407304763793945, val_loss = 0.7976881861686707\n",
      "epoch n°3107 : train_loss = 2.0419886112213135, val_loss = 0.7956583499908447\n",
      "epoch n°3108 : train_loss = 2.0460970401763916, val_loss = 0.7955296635627747\n",
      "epoch n°3109 : train_loss = 2.0420310497283936, val_loss = 0.7947037220001221\n",
      "epoch n°3110 : train_loss = 2.0543994903564453, val_loss = 0.7920146584510803\n",
      "epoch n°3111 : train_loss = 2.045607328414917, val_loss = 0.7949098944664001\n",
      "epoch n°3112 : train_loss = 2.0403432846069336, val_loss = 0.7953161597251892\n",
      "epoch n°3113 : train_loss = 2.043196201324463, val_loss = 0.7949573993682861\n",
      "epoch n°3114 : train_loss = 2.0527446269989014, val_loss = 0.7956553101539612\n",
      "epoch n°3115 : train_loss = 2.0447585582733154, val_loss = 0.7945922017097473\n",
      "epoch n°3116 : train_loss = 2.0538570880889893, val_loss = 0.7987173795700073\n",
      "epoch n°3117 : train_loss = 2.050333261489868, val_loss = 0.7991428375244141\n",
      "epoch n°3118 : train_loss = 2.0442750453948975, val_loss = 0.7950380444526672\n",
      "epoch n°3119 : train_loss = 2.042722702026367, val_loss = 0.7945182919502258\n",
      "epoch n°3120 : train_loss = 2.046743154525757, val_loss = 0.7960973381996155\n",
      "epoch n°3121 : train_loss = 2.04077410697937, val_loss = 0.7928950190544128\n",
      "epoch n°3122 : train_loss = 2.0445735454559326, val_loss = 0.798608124256134\n",
      "epoch n°3123 : train_loss = 2.0368518829345703, val_loss = 0.7930586338043213\n",
      "epoch n°3124 : train_loss = 2.0406179428100586, val_loss = 0.7951458692550659\n",
      "epoch n°3125 : train_loss = 2.0530004501342773, val_loss = 0.7961648106575012\n",
      "epoch n°3126 : train_loss = 2.043213367462158, val_loss = 0.7958878874778748\n",
      "epoch n°3127 : train_loss = 2.0471913814544678, val_loss = 0.7982762455940247\n",
      "epoch n°3128 : train_loss = 2.0473504066467285, val_loss = 0.7927922606468201\n",
      "epoch n°3129 : train_loss = 2.0409703254699707, val_loss = 0.7930092811584473\n",
      "epoch n°3130 : train_loss = 2.047774076461792, val_loss = 0.7989534735679626\n",
      "epoch n°3131 : train_loss = 2.0457675457000732, val_loss = 0.7968762516975403\n",
      "epoch n°3132 : train_loss = 2.042433500289917, val_loss = 0.7942346334457397\n",
      "epoch n°3133 : train_loss = 2.049647092819214, val_loss = 0.791843056678772\n",
      "epoch n°3134 : train_loss = 2.0406155586242676, val_loss = 0.7926483154296875\n",
      "epoch n°3135 : train_loss = 2.0481395721435547, val_loss = 0.7971694469451904\n",
      "epoch n°3136 : train_loss = 2.0351788997650146, val_loss = 0.7961020469665527\n",
      "epoch n°3137 : train_loss = 2.046191692352295, val_loss = 0.7946073412895203\n",
      "epoch n°3138 : train_loss = 2.0408613681793213, val_loss = 0.7916349172592163\n",
      "epoch n°3139 : train_loss = 2.0444071292877197, val_loss = 0.7944579124450684\n",
      "epoch n°3140 : train_loss = 2.045703887939453, val_loss = 0.7928996682167053\n",
      "epoch n°3141 : train_loss = 2.0440597534179688, val_loss = 0.7975270748138428\n",
      "epoch n°3142 : train_loss = 2.044708490371704, val_loss = 0.7930242419242859\n",
      "epoch n°3143 : train_loss = 2.0495057106018066, val_loss = 0.7923654317855835\n",
      "epoch n°3144 : train_loss = 2.0455222129821777, val_loss = 0.7933782339096069\n",
      "epoch n°3145 : train_loss = 2.0477395057678223, val_loss = 0.7952166199684143\n",
      "epoch n°3146 : train_loss = 2.041245460510254, val_loss = 0.7894375324249268\n",
      "epoch n°3147 : train_loss = 2.04150652885437, val_loss = 0.7958288788795471\n",
      "epoch n°3148 : train_loss = 2.048771619796753, val_loss = 0.7962548732757568\n",
      "epoch n°3149 : train_loss = 2.052920341491699, val_loss = 0.7919558882713318\n",
      "epoch n°3150 : train_loss = 2.0415303707122803, val_loss = 0.7938585877418518\n",
      "epoch n°3151 : train_loss = 2.054351329803467, val_loss = 0.7925099730491638\n",
      "epoch n°3152 : train_loss = 2.044215202331543, val_loss = 0.7949827313423157\n",
      "epoch n°3153 : train_loss = 2.0521790981292725, val_loss = 0.7913949489593506\n",
      "epoch n°3154 : train_loss = 2.0469584465026855, val_loss = 0.797143280506134\n",
      "epoch n°3155 : train_loss = 2.032454013824463, val_loss = 0.7959012389183044\n",
      "epoch n°3156 : train_loss = 2.0401484966278076, val_loss = 0.7945358753204346\n",
      "epoch n°3157 : train_loss = 2.039022445678711, val_loss = 0.7939310073852539\n",
      "epoch n°3158 : train_loss = 2.0443778038024902, val_loss = 0.7944678068161011\n",
      "epoch n°3159 : train_loss = 2.0452229976654053, val_loss = 0.7909083962440491\n",
      "epoch n°3160 : train_loss = 2.043987989425659, val_loss = 0.7944672107696533\n",
      "epoch n°3161 : train_loss = 2.028679132461548, val_loss = 0.7920929789543152\n",
      "epoch n°3162 : train_loss = 2.0393407344818115, val_loss = 0.7952744364738464\n",
      "epoch n°3163 : train_loss = 2.0378589630126953, val_loss = 0.7965505123138428\n",
      "epoch n°3164 : train_loss = 2.044605255126953, val_loss = 0.7923874258995056\n",
      "epoch n°3165 : train_loss = 2.039787769317627, val_loss = 0.7944220900535583\n",
      "epoch n°3166 : train_loss = 2.047010660171509, val_loss = 0.7990801334381104\n",
      "epoch n°3167 : train_loss = 2.038167715072632, val_loss = 0.7918214201927185\n",
      "epoch n°3168 : train_loss = 2.037013292312622, val_loss = 0.7932049036026001\n",
      "epoch n°3169 : train_loss = 2.0393104553222656, val_loss = 0.7947703003883362\n",
      "epoch n°3170 : train_loss = 2.051720142364502, val_loss = 0.7956200242042542\n",
      "epoch n°3171 : train_loss = 2.0431578159332275, val_loss = 0.7962343692779541\n",
      "epoch n°3172 : train_loss = 2.0486862659454346, val_loss = 0.7939395904541016\n",
      "epoch n°3173 : train_loss = 2.039656162261963, val_loss = 0.7930569052696228\n",
      "epoch n°3174 : train_loss = 2.0413708686828613, val_loss = 0.7903565764427185\n",
      "epoch n°3175 : train_loss = 2.0440938472747803, val_loss = 0.7939907908439636\n",
      "epoch n°3176 : train_loss = 2.037135124206543, val_loss = 0.7940067052841187\n",
      "epoch n°3177 : train_loss = 2.0414016246795654, val_loss = 0.7959558963775635\n",
      "epoch n°3178 : train_loss = 2.043766736984253, val_loss = 0.7926874160766602\n",
      "epoch n°3179 : train_loss = 2.0347578525543213, val_loss = 0.7935491800308228\n",
      "epoch n°3180 : train_loss = 2.0398638248443604, val_loss = 0.7917000651359558\n",
      "epoch n°3181 : train_loss = 2.0451138019561768, val_loss = 0.7950932383537292\n",
      "epoch n°3182 : train_loss = 2.041543960571289, val_loss = 0.7943910956382751\n",
      "epoch n°3183 : train_loss = 2.052046537399292, val_loss = 0.7870640158653259\n",
      "epoch n°3184 : train_loss = 2.039703607559204, val_loss = 0.7934296131134033\n",
      "epoch n°3185 : train_loss = 2.045609951019287, val_loss = 0.7929099798202515\n",
      "epoch n°3186 : train_loss = 2.044705390930176, val_loss = 0.7898143529891968\n",
      "epoch n°3187 : train_loss = 2.0365042686462402, val_loss = 0.7956872582435608\n",
      "epoch n°3188 : train_loss = 2.044985771179199, val_loss = 0.7945958375930786\n",
      "epoch n°3189 : train_loss = 2.046457529067993, val_loss = 0.7922248244285583\n",
      "epoch n°3190 : train_loss = 2.0389602184295654, val_loss = 0.7925472855567932\n",
      "epoch n°3191 : train_loss = 2.0387117862701416, val_loss = 0.7921220660209656\n",
      "epoch n°3192 : train_loss = 2.0444107055664062, val_loss = 0.7937143445014954\n",
      "epoch n°3193 : train_loss = 2.0457887649536133, val_loss = 0.7968223690986633\n",
      "epoch n°3194 : train_loss = 2.0445773601531982, val_loss = 0.7920182347297668\n",
      "epoch n°3195 : train_loss = 2.0478780269622803, val_loss = 0.790010929107666\n",
      "epoch n°3196 : train_loss = 2.0507991313934326, val_loss = 0.7981866598129272\n",
      "epoch n°3197 : train_loss = 2.0343358516693115, val_loss = 0.7929836511611938\n",
      "epoch n°3198 : train_loss = 2.0398271083831787, val_loss = 0.7952537536621094\n",
      "epoch n°3199 : train_loss = 2.0415377616882324, val_loss = 0.7933654189109802\n",
      "epoch n°3200 : train_loss = 2.044154167175293, val_loss = 0.7899138331413269\n",
      "epoch n°3201 : train_loss = 2.0388457775115967, val_loss = 0.793283998966217\n",
      "epoch n°3202 : train_loss = 2.042214870452881, val_loss = 0.7926947474479675\n",
      "epoch n°3203 : train_loss = 2.0476956367492676, val_loss = 0.7950354814529419\n",
      "epoch n°3204 : train_loss = 2.0435245037078857, val_loss = 0.79667067527771\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°3205 : train_loss = 2.0517868995666504, val_loss = 0.7933950424194336\n",
      "epoch n°3206 : train_loss = 2.043473720550537, val_loss = 0.795925498008728\n",
      "epoch n°3207 : train_loss = 2.0408530235290527, val_loss = 0.7955000996589661\n",
      "epoch n°3208 : train_loss = 2.037750720977783, val_loss = 0.7938479781150818\n",
      "epoch n°3209 : train_loss = 2.0444464683532715, val_loss = 0.7968344688415527\n",
      "epoch n°3210 : train_loss = 2.038459062576294, val_loss = 0.7953094244003296\n",
      "epoch n°3211 : train_loss = 2.0469255447387695, val_loss = 0.7956381440162659\n",
      "epoch n°3212 : train_loss = 2.042678117752075, val_loss = 0.7938092350959778\n",
      "epoch n°3213 : train_loss = 2.052516460418701, val_loss = 0.7949832081794739\n",
      "epoch n°3214 : train_loss = 2.0437798500061035, val_loss = 0.7883967757225037\n",
      "epoch n°3215 : train_loss = 2.044400215148926, val_loss = 0.7931933999061584\n",
      "epoch n°3216 : train_loss = 2.0392000675201416, val_loss = 0.7938438057899475\n",
      "epoch n°3217 : train_loss = 2.0415446758270264, val_loss = 0.7948884963989258\n",
      "epoch n°3218 : train_loss = 2.0313236713409424, val_loss = 0.7955224514007568\n",
      "epoch n°3219 : train_loss = 2.0424773693084717, val_loss = 0.7932578921318054\n",
      "epoch n°3220 : train_loss = 2.0442707538604736, val_loss = 0.7919756174087524\n",
      "epoch n°3221 : train_loss = 2.0384960174560547, val_loss = 0.7935318946838379\n",
      "epoch n°3222 : train_loss = 2.0417230129241943, val_loss = 0.7948103547096252\n",
      "epoch n°3223 : train_loss = 2.036506414413452, val_loss = 0.7948501706123352\n",
      "epoch n°3224 : train_loss = 2.036571502685547, val_loss = 0.7942190766334534\n",
      "epoch n°3225 : train_loss = 2.0364675521850586, val_loss = 0.7922675013542175\n",
      "epoch n°3226 : train_loss = 2.0444843769073486, val_loss = 0.7952302098274231\n",
      "epoch n°3227 : train_loss = 2.0434024333953857, val_loss = 0.7973537445068359\n",
      "epoch n°3228 : train_loss = 2.037320375442505, val_loss = 0.7971042394638062\n",
      "epoch n°3229 : train_loss = 2.029477119445801, val_loss = 0.7958391904830933\n",
      "epoch n°3230 : train_loss = 2.040837049484253, val_loss = 0.790817141532898\n",
      "epoch n°3231 : train_loss = 2.039112091064453, val_loss = 0.7976880669593811\n",
      "epoch n°3232 : train_loss = 2.037914276123047, val_loss = 0.7905191779136658\n",
      "epoch n°3233 : train_loss = 2.0375046730041504, val_loss = 0.7910403609275818\n",
      "epoch n°3234 : train_loss = 2.0446488857269287, val_loss = 0.795202374458313\n",
      "epoch n°3235 : train_loss = 2.033024549484253, val_loss = 0.7949963212013245\n",
      "epoch n°3236 : train_loss = 2.0426089763641357, val_loss = 0.794262170791626\n",
      "epoch n°3237 : train_loss = 2.0334665775299072, val_loss = 0.7957120537757874\n",
      "epoch n°3238 : train_loss = 2.0345141887664795, val_loss = 0.7963744401931763\n",
      "epoch n°3239 : train_loss = 2.043945074081421, val_loss = 0.7878652811050415\n",
      "epoch n°3240 : train_loss = 2.037278652191162, val_loss = 0.7935137748718262\n",
      "epoch n°3241 : train_loss = 2.0400266647338867, val_loss = 0.7960676550865173\n",
      "epoch n°3242 : train_loss = 2.042518138885498, val_loss = 0.7966403961181641\n",
      "epoch n°3243 : train_loss = 2.0459985733032227, val_loss = 0.7939201593399048\n",
      "epoch n°3244 : train_loss = 2.0457754135131836, val_loss = 0.7913900017738342\n",
      "epoch n°3245 : train_loss = 2.0411441326141357, val_loss = 0.7940075993537903\n",
      "epoch n°3246 : train_loss = 2.045661211013794, val_loss = 0.7943175435066223\n",
      "epoch n°3247 : train_loss = 2.04819655418396, val_loss = 0.7974518537521362\n",
      "epoch n°3248 : train_loss = 2.0356686115264893, val_loss = 0.7951352000236511\n",
      "epoch n°3249 : train_loss = 2.04754900932312, val_loss = 0.791043758392334\n",
      "epoch n°3250 : train_loss = 2.047638177871704, val_loss = 0.787421464920044\n",
      "epoch n°3251 : train_loss = 2.0446701049804688, val_loss = 0.7923298478126526\n",
      "epoch n°3252 : train_loss = 2.048079013824463, val_loss = 0.797568678855896\n",
      "epoch n°3253 : train_loss = 2.0401484966278076, val_loss = 0.7940096855163574\n",
      "epoch n°3254 : train_loss = 2.0381438732147217, val_loss = 0.7955831289291382\n",
      "epoch n°3255 : train_loss = 2.049555540084839, val_loss = 0.7948107123374939\n",
      "epoch n°3256 : train_loss = 2.0378472805023193, val_loss = 0.7932159304618835\n",
      "epoch n°3257 : train_loss = 2.0418455600738525, val_loss = 0.7901979684829712\n",
      "epoch n°3258 : train_loss = 2.0502145290374756, val_loss = 0.791621208190918\n",
      "epoch n°3259 : train_loss = 2.0422842502593994, val_loss = 0.7889025211334229\n",
      "epoch n°3260 : train_loss = 2.046257734298706, val_loss = 0.7900245785713196\n",
      "epoch n°3261 : train_loss = 2.0331501960754395, val_loss = 0.7946538925170898\n",
      "epoch n°3262 : train_loss = 2.041752576828003, val_loss = 0.7929244041442871\n",
      "epoch n°3263 : train_loss = 2.0482242107391357, val_loss = 0.7897100448608398\n",
      "epoch n°3264 : train_loss = 2.0308306217193604, val_loss = 0.7913348078727722\n",
      "epoch n°3265 : train_loss = 2.033947706222534, val_loss = 0.7938570380210876\n",
      "epoch n°3266 : train_loss = 2.0466842651367188, val_loss = 0.7942694425582886\n",
      "epoch n°3267 : train_loss = 2.0423855781555176, val_loss = 0.7929880023002625\n",
      "epoch n°3268 : train_loss = 2.0363287925720215, val_loss = 0.7940772771835327\n",
      "epoch n°3269 : train_loss = 2.0423970222473145, val_loss = 0.7934241890907288\n",
      "epoch n°3270 : train_loss = 2.0442521572113037, val_loss = 0.7950937151908875\n",
      "epoch n°3271 : train_loss = 2.04372239112854, val_loss = 0.7927523851394653\n",
      "epoch n°3272 : train_loss = 2.0402605533599854, val_loss = 0.7907072305679321\n",
      "epoch n°3273 : train_loss = 2.0430824756622314, val_loss = 0.7938477396965027\n",
      "epoch n°3274 : train_loss = 2.034233570098877, val_loss = 0.795386016368866\n",
      "epoch n°3275 : train_loss = 2.0377109050750732, val_loss = 0.7926933765411377\n",
      "epoch n°3276 : train_loss = 2.0313453674316406, val_loss = 0.7935157418251038\n",
      "epoch n°3277 : train_loss = 2.041318416595459, val_loss = 0.7921372056007385\n",
      "epoch n°3278 : train_loss = 2.0388286113739014, val_loss = 0.7888742685317993\n",
      "epoch n°3279 : train_loss = 2.038362741470337, val_loss = 0.7953261733055115\n",
      "epoch n°3280 : train_loss = 2.0366618633270264, val_loss = 0.7934607267379761\n",
      "epoch n°3281 : train_loss = 2.040160655975342, val_loss = 0.7913858890533447\n",
      "epoch n°3282 : train_loss = 2.0388424396514893, val_loss = 0.7932897806167603\n",
      "epoch n°3283 : train_loss = 2.0363054275512695, val_loss = 0.798136293888092\n",
      "epoch n°3284 : train_loss = 2.0325961112976074, val_loss = 0.7915249466896057\n",
      "epoch n°3285 : train_loss = 2.0373287200927734, val_loss = 0.7951776385307312\n",
      "epoch n°3286 : train_loss = 2.0366196632385254, val_loss = 0.7949379086494446\n",
      "epoch n°3287 : train_loss = 2.046708106994629, val_loss = 0.7957278490066528\n",
      "epoch n°3288 : train_loss = 2.030597448348999, val_loss = 0.7956908941268921\n",
      "epoch n°3289 : train_loss = 2.0461807250976562, val_loss = 0.7961184978485107\n",
      "epoch n°3290 : train_loss = 2.0371687412261963, val_loss = 0.7965778112411499\n",
      "epoch n°3291 : train_loss = 2.050147533416748, val_loss = 0.7921566367149353\n",
      "epoch n°3292 : train_loss = 2.0370404720306396, val_loss = 0.7940061092376709\n",
      "epoch n°3293 : train_loss = 2.0381510257720947, val_loss = 0.7923106551170349\n",
      "epoch n°3294 : train_loss = 2.029935598373413, val_loss = 0.7980474233627319\n",
      "epoch n°3295 : train_loss = 2.037364959716797, val_loss = 0.7912031412124634\n",
      "epoch n°3296 : train_loss = 2.0392751693725586, val_loss = 0.787876546382904\n",
      "epoch n°3297 : train_loss = 2.0364394187927246, val_loss = 0.7937133312225342\n",
      "epoch n°3298 : train_loss = 2.042876720428467, val_loss = 0.7906363010406494\n",
      "epoch n°3299 : train_loss = 2.0385711193084717, val_loss = 0.7917619943618774\n",
      "epoch n°3300 : train_loss = 2.035489320755005, val_loss = 0.7917275428771973\n",
      "epoch n°3301 : train_loss = 2.0380237102508545, val_loss = 0.7943482995033264\n",
      "epoch n°3302 : train_loss = 2.0394837856292725, val_loss = 0.7962414622306824\n",
      "epoch n°3303 : train_loss = 2.036773443222046, val_loss = 0.7979009747505188\n",
      "epoch n°3304 : train_loss = 2.0308051109313965, val_loss = 0.7946736812591553\n",
      "epoch n°3305 : train_loss = 2.034872531890869, val_loss = 0.7949783802032471\n",
      "epoch n°3306 : train_loss = 2.04949688911438, val_loss = 0.7942014932632446\n",
      "epoch n°3307 : train_loss = 2.037860870361328, val_loss = 0.792381227016449\n",
      "epoch n°3308 : train_loss = 2.0416619777679443, val_loss = 0.7964379191398621\n",
      "epoch n°3309 : train_loss = 2.0387821197509766, val_loss = 0.7977598905563354\n",
      "epoch n°3310 : train_loss = 2.0436854362487793, val_loss = 0.7984413504600525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°3311 : train_loss = 2.0423271656036377, val_loss = 0.7961525321006775\n",
      "epoch n°3312 : train_loss = 2.020843982696533, val_loss = 0.7969576716423035\n",
      "epoch n°3313 : train_loss = 2.0396881103515625, val_loss = 0.7963072657585144\n",
      "epoch n°3314 : train_loss = 2.043553352355957, val_loss = 0.7910197377204895\n",
      "epoch n°3315 : train_loss = 2.037360191345215, val_loss = 0.7916263341903687\n",
      "epoch n°3316 : train_loss = 2.037257432937622, val_loss = 0.7940471768379211\n",
      "epoch n°3317 : train_loss = 2.0313804149627686, val_loss = 0.7941829562187195\n",
      "epoch n°3318 : train_loss = 2.032597303390503, val_loss = 0.7933343648910522\n",
      "epoch n°3319 : train_loss = 2.0371005535125732, val_loss = 0.7893319725990295\n",
      "epoch n°3320 : train_loss = 2.0362114906311035, val_loss = 0.7959508299827576\n",
      "epoch n°3321 : train_loss = 2.0304691791534424, val_loss = 0.7899873852729797\n",
      "epoch n°3322 : train_loss = 2.040344715118408, val_loss = 0.7936095595359802\n",
      "epoch n°3323 : train_loss = 2.043835401535034, val_loss = 0.8000689148902893\n",
      "epoch n°3324 : train_loss = 2.0383944511413574, val_loss = 0.7945863008499146\n",
      "epoch n°3325 : train_loss = 2.028064727783203, val_loss = 0.7931351661682129\n",
      "epoch n°3326 : train_loss = 2.0374948978424072, val_loss = 0.7911469340324402\n",
      "epoch n°3327 : train_loss = 2.0283286571502686, val_loss = 0.7951174378395081\n",
      "epoch n°3328 : train_loss = 2.0366835594177246, val_loss = 0.7905926704406738\n",
      "epoch n°3329 : train_loss = 2.0347697734832764, val_loss = 0.7907426953315735\n",
      "epoch n°3330 : train_loss = 2.034878730773926, val_loss = 0.7935169339179993\n",
      "epoch n°3331 : train_loss = 2.0317437648773193, val_loss = 0.7926234602928162\n",
      "epoch n°3332 : train_loss = 2.033231019973755, val_loss = 0.7899680137634277\n",
      "epoch n°3333 : train_loss = 2.0339064598083496, val_loss = 0.7923926115036011\n",
      "epoch n°3334 : train_loss = 2.0292584896087646, val_loss = 0.7924070358276367\n",
      "epoch n°3335 : train_loss = 2.037186861038208, val_loss = 0.7951726317405701\n",
      "epoch n°3336 : train_loss = 2.0374720096588135, val_loss = 0.7927126288414001\n",
      "epoch n°3337 : train_loss = 2.0393450260162354, val_loss = 0.7960456013679504\n",
      "epoch n°3338 : train_loss = 2.036970853805542, val_loss = 0.7926434278488159\n",
      "epoch n°3339 : train_loss = 2.03082275390625, val_loss = 0.7902029156684875\n",
      "epoch n°3340 : train_loss = 2.035839319229126, val_loss = 0.788156270980835\n",
      "epoch n°3341 : train_loss = 2.034142255783081, val_loss = 0.7907222509384155\n",
      "epoch n°3342 : train_loss = 2.040228843688965, val_loss = 0.7953842282295227\n",
      "epoch n°3343 : train_loss = 2.0418295860290527, val_loss = 0.7950305342674255\n",
      "epoch n°3344 : train_loss = 2.0333092212677, val_loss = 0.7967000007629395\n",
      "epoch n°3345 : train_loss = 2.032635450363159, val_loss = 0.7926979064941406\n",
      "epoch n°3346 : train_loss = 2.0373213291168213, val_loss = 0.7955353260040283\n",
      "epoch n°3347 : train_loss = 2.0408458709716797, val_loss = 0.7950131893157959\n",
      "epoch n°3348 : train_loss = 2.03733229637146, val_loss = 0.7979853749275208\n",
      "epoch n°3349 : train_loss = 2.0317296981811523, val_loss = 0.7906156778335571\n",
      "epoch n°3350 : train_loss = 2.0267276763916016, val_loss = 0.794040322303772\n",
      "epoch n°3351 : train_loss = 2.0442700386047363, val_loss = 0.7946625351905823\n",
      "epoch n°3352 : train_loss = 2.025075674057007, val_loss = 0.7942711710929871\n",
      "epoch n°3353 : train_loss = 2.036851406097412, val_loss = 0.79539555311203\n",
      "epoch n°3354 : train_loss = 2.033194065093994, val_loss = 0.7936935424804688\n",
      "epoch n°3355 : train_loss = 2.034899950027466, val_loss = 0.7917652130126953\n",
      "epoch n°3356 : train_loss = 2.0389201641082764, val_loss = 0.7931690216064453\n",
      "epoch n°3357 : train_loss = 2.033846855163574, val_loss = 0.7941834330558777\n",
      "epoch n°3358 : train_loss = 2.0344016551971436, val_loss = 0.7930924892425537\n",
      "epoch n°3359 : train_loss = 2.0392496585845947, val_loss = 0.7972643375396729\n",
      "epoch n°3360 : train_loss = 2.034799575805664, val_loss = 0.7970629930496216\n",
      "epoch n°3361 : train_loss = 2.0414652824401855, val_loss = 0.7932561635971069\n",
      "epoch n°3362 : train_loss = 2.0320122241973877, val_loss = 0.7952113151550293\n",
      "epoch n°3363 : train_loss = 2.0387625694274902, val_loss = 0.7902741432189941\n",
      "epoch n°3364 : train_loss = 2.0410377979278564, val_loss = 0.7956171631813049\n",
      "epoch n°3365 : train_loss = 2.0369961261749268, val_loss = 0.7910016775131226\n",
      "epoch n°3366 : train_loss = 2.0378682613372803, val_loss = 0.7917187809944153\n",
      "epoch n°3367 : train_loss = 2.0456814765930176, val_loss = 0.7964361310005188\n",
      "epoch n°3368 : train_loss = 2.022993564605713, val_loss = 0.7955514788627625\n",
      "epoch n°3369 : train_loss = 2.033710241317749, val_loss = 0.7938295006752014\n",
      "epoch n°3370 : train_loss = 2.029569387435913, val_loss = 0.7961939573287964\n",
      "epoch n°3371 : train_loss = 2.0357961654663086, val_loss = 0.7942997813224792\n",
      "epoch n°3372 : train_loss = 2.031294345855713, val_loss = 0.7910154461860657\n",
      "epoch n°3373 : train_loss = 2.036012887954712, val_loss = 0.7949117422103882\n",
      "epoch n°3374 : train_loss = 2.0297911167144775, val_loss = 0.7950076460838318\n",
      "epoch n°3375 : train_loss = 2.037564277648926, val_loss = 0.7957764863967896\n",
      "epoch n°3376 : train_loss = 2.033221960067749, val_loss = 0.7906135320663452\n",
      "epoch n°3377 : train_loss = 2.0413851737976074, val_loss = 0.7949667572975159\n",
      "epoch n°3378 : train_loss = 2.029162645339966, val_loss = 0.7918217778205872\n",
      "epoch n°3379 : train_loss = 2.035245180130005, val_loss = 0.792662501335144\n",
      "epoch n°3380 : train_loss = 2.0406813621520996, val_loss = 0.7902559041976929\n",
      "epoch n°3381 : train_loss = 2.033541440963745, val_loss = 0.7905657887458801\n",
      "epoch n°3382 : train_loss = 2.035489320755005, val_loss = 0.7948125004768372\n",
      "epoch n°3383 : train_loss = 2.027615547180176, val_loss = 0.7939856052398682\n",
      "epoch n°3384 : train_loss = 2.0313942432403564, val_loss = 0.7900430560112\n",
      "epoch n°3385 : train_loss = 2.0286827087402344, val_loss = 0.7924754023551941\n",
      "epoch n°3386 : train_loss = 2.0462660789489746, val_loss = 0.7887584567070007\n",
      "epoch n°3387 : train_loss = 2.0304157733917236, val_loss = 0.7960171103477478\n",
      "epoch n°3388 : train_loss = 2.043415069580078, val_loss = 0.7916491627693176\n",
      "epoch n°3389 : train_loss = 2.039154529571533, val_loss = 0.7905977368354797\n",
      "epoch n°3390 : train_loss = 2.042353868484497, val_loss = 0.7915946841239929\n",
      "epoch n°3391 : train_loss = 2.0459976196289062, val_loss = 0.7979304194450378\n",
      "epoch n°3392 : train_loss = 2.0309078693389893, val_loss = 0.7948486804962158\n",
      "epoch n°3393 : train_loss = 2.0264053344726562, val_loss = 0.791351854801178\n",
      "epoch n°3394 : train_loss = 2.041248083114624, val_loss = 0.8006834983825684\n",
      "epoch n°3395 : train_loss = 2.0298211574554443, val_loss = 0.7953081130981445\n",
      "epoch n°3396 : train_loss = 2.032470464706421, val_loss = 0.7958452701568604\n",
      "epoch n°3397 : train_loss = 2.0323750972747803, val_loss = 0.7943586111068726\n",
      "epoch n°3398 : train_loss = 2.030287981033325, val_loss = 0.7936426997184753\n",
      "epoch n°3399 : train_loss = 2.031625747680664, val_loss = 0.7932642102241516\n",
      "epoch n°3400 : train_loss = 2.03057861328125, val_loss = 0.7948825359344482\n",
      "epoch n°3401 : train_loss = 2.035900831222534, val_loss = 0.793596625328064\n",
      "epoch n°3402 : train_loss = 2.0349268913269043, val_loss = 0.7916301488876343\n",
      "epoch n°3403 : train_loss = 2.0393736362457275, val_loss = 0.7961447834968567\n",
      "epoch n°3404 : train_loss = 2.0303027629852295, val_loss = 0.7936446070671082\n",
      "epoch n°3405 : train_loss = 2.0362324714660645, val_loss = 0.7973107695579529\n",
      "epoch n°3406 : train_loss = 2.0339818000793457, val_loss = 0.7931399941444397\n",
      "epoch n°3407 : train_loss = 2.0325419902801514, val_loss = 0.7954010963439941\n",
      "epoch n°3408 : train_loss = 2.032836675643921, val_loss = 0.7940449118614197\n",
      "epoch n°3409 : train_loss = 2.0339059829711914, val_loss = 0.7937524914741516\n",
      "epoch n°3410 : train_loss = 2.027393341064453, val_loss = 0.7926641702651978\n",
      "epoch n°3411 : train_loss = 2.0251195430755615, val_loss = 0.7965743541717529\n",
      "epoch n°3412 : train_loss = 2.0308940410614014, val_loss = 0.7942181825637817\n",
      "epoch n°3413 : train_loss = 2.022557497024536, val_loss = 0.7923513650894165\n",
      "epoch n°3414 : train_loss = 2.03670597076416, val_loss = 0.793493390083313\n",
      "epoch n°3415 : train_loss = 2.026233196258545, val_loss = 0.7934062480926514\n",
      "epoch n°3416 : train_loss = 2.0437026023864746, val_loss = 0.7944837808609009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°3417 : train_loss = 2.035646677017212, val_loss = 0.7985926866531372\n",
      "epoch n°3418 : train_loss = 2.0303664207458496, val_loss = 0.7910788655281067\n",
      "epoch n°3419 : train_loss = 2.031275749206543, val_loss = 0.7945050597190857\n",
      "epoch n°3420 : train_loss = 2.0382611751556396, val_loss = 0.790749192237854\n",
      "epoch n°3421 : train_loss = 2.039865016937256, val_loss = 0.7941829562187195\n",
      "epoch n°3422 : train_loss = 2.027801036834717, val_loss = 0.794653058052063\n",
      "epoch n°3423 : train_loss = 2.0345230102539062, val_loss = 0.7942235469818115\n",
      "epoch n°3424 : train_loss = 2.0372323989868164, val_loss = 0.7916480302810669\n",
      "epoch n°3425 : train_loss = 2.0328545570373535, val_loss = 0.7960200309753418\n",
      "epoch n°3426 : train_loss = 2.027204990386963, val_loss = 0.7958758473396301\n",
      "epoch n°3427 : train_loss = 2.0282418727874756, val_loss = 0.7888001799583435\n",
      "epoch n°3428 : train_loss = 2.0324785709381104, val_loss = 0.7965801954269409\n",
      "epoch n°3429 : train_loss = 2.035337448120117, val_loss = 0.7903671264648438\n",
      "epoch n°3430 : train_loss = 2.032381772994995, val_loss = 0.7926337718963623\n",
      "epoch n°3431 : train_loss = 2.027475595474243, val_loss = 0.7971490025520325\n",
      "epoch n°3432 : train_loss = 2.0346834659576416, val_loss = 0.7965054512023926\n",
      "epoch n°3433 : train_loss = 2.0331358909606934, val_loss = 0.7925254702568054\n",
      "epoch n°3434 : train_loss = 2.0347909927368164, val_loss = 0.7965360283851624\n",
      "epoch n°3435 : train_loss = 2.042073965072632, val_loss = 0.7995005249977112\n",
      "epoch n°3436 : train_loss = 2.028996229171753, val_loss = 0.7956393361091614\n",
      "epoch n°3437 : train_loss = 2.024350166320801, val_loss = 0.791192352771759\n",
      "epoch n°3438 : train_loss = 2.0362179279327393, val_loss = 0.7948905825614929\n",
      "epoch n°3439 : train_loss = 2.030940294265747, val_loss = 0.7945382595062256\n",
      "epoch n°3440 : train_loss = 2.027301788330078, val_loss = 0.7922086715698242\n",
      "epoch n°3441 : train_loss = 2.023869037628174, val_loss = 0.7908582091331482\n",
      "epoch n°3442 : train_loss = 2.0288033485412598, val_loss = 0.7945384383201599\n",
      "epoch n°3443 : train_loss = 2.0296928882598877, val_loss = 0.7927157282829285\n",
      "epoch n°3444 : train_loss = 2.0318875312805176, val_loss = 0.7872815728187561\n",
      "epoch n°3445 : train_loss = 2.0327208042144775, val_loss = 0.7929108142852783\n",
      "epoch n°3446 : train_loss = 2.028350591659546, val_loss = 0.7938286662101746\n",
      "epoch n°3447 : train_loss = 2.036715269088745, val_loss = 0.793903112411499\n",
      "epoch n°3448 : train_loss = 2.043745517730713, val_loss = 0.7949488162994385\n",
      "epoch n°3449 : train_loss = 2.030604600906372, val_loss = 0.7915905714035034\n",
      "epoch n°3450 : train_loss = 2.0286200046539307, val_loss = 0.7947103381156921\n",
      "epoch n°3451 : train_loss = 2.0306918621063232, val_loss = 0.7922948002815247\n",
      "epoch n°3452 : train_loss = 2.0286355018615723, val_loss = 0.7960525751113892\n",
      "epoch n°3453 : train_loss = 2.0288095474243164, val_loss = 0.7902480363845825\n",
      "epoch n°3454 : train_loss = 2.0304126739501953, val_loss = 0.7910123467445374\n",
      "epoch n°3455 : train_loss = 2.032832384109497, val_loss = 0.79420405626297\n",
      "epoch n°3456 : train_loss = 2.02762508392334, val_loss = 0.7982820868492126\n",
      "epoch n°3457 : train_loss = 2.0336453914642334, val_loss = 0.7948733568191528\n",
      "epoch n°3458 : train_loss = 2.034607172012329, val_loss = 0.7918996214866638\n",
      "epoch n°3459 : train_loss = 2.0321884155273438, val_loss = 0.7895931005477905\n",
      "epoch n°3460 : train_loss = 2.0360472202301025, val_loss = 0.7957194447517395\n",
      "epoch n°3461 : train_loss = 2.027008533477783, val_loss = 0.7930245995521545\n",
      "epoch n°3462 : train_loss = 2.028076410293579, val_loss = 0.794914960861206\n",
      "epoch n°3463 : train_loss = 2.0347564220428467, val_loss = 0.7958541512489319\n",
      "epoch n°3464 : train_loss = 2.0355238914489746, val_loss = 0.7927097082138062\n",
      "epoch n°3465 : train_loss = 2.033411741256714, val_loss = 0.7926684617996216\n",
      "epoch n°3466 : train_loss = 2.027116298675537, val_loss = 0.7918805480003357\n",
      "epoch n°3467 : train_loss = 2.0356087684631348, val_loss = 0.7930062413215637\n",
      "epoch n°3468 : train_loss = 2.032240390777588, val_loss = 0.7913311719894409\n",
      "epoch n°3469 : train_loss = 2.031597137451172, val_loss = 0.7949208617210388\n",
      "epoch n°3470 : train_loss = 2.0354771614074707, val_loss = 0.7958788871765137\n",
      "epoch n°3471 : train_loss = 2.032806873321533, val_loss = 0.795063316822052\n",
      "epoch n°3472 : train_loss = 2.0362308025360107, val_loss = 0.7979419231414795\n",
      "epoch n°3473 : train_loss = 2.0383262634277344, val_loss = 0.796432375907898\n",
      "epoch n°3474 : train_loss = 2.0308427810668945, val_loss = 0.7924663424491882\n",
      "epoch n°3475 : train_loss = 2.0295205116271973, val_loss = 0.7952930927276611\n",
      "epoch n°3476 : train_loss = 2.0296406745910645, val_loss = 0.7985215187072754\n",
      "epoch n°3477 : train_loss = 2.03140926361084, val_loss = 0.7948455214500427\n",
      "epoch n°3478 : train_loss = 2.0364930629730225, val_loss = 0.7964263558387756\n",
      "epoch n°3479 : train_loss = 2.02956223487854, val_loss = 0.7933432459831238\n",
      "epoch n°3480 : train_loss = 2.0328633785247803, val_loss = 0.7902429699897766\n",
      "epoch n°3481 : train_loss = 2.031606674194336, val_loss = 0.7923247218132019\n",
      "epoch n°3482 : train_loss = 2.0297176837921143, val_loss = 0.7908200621604919\n",
      "epoch n°3483 : train_loss = 2.033562183380127, val_loss = 0.7941858768463135\n",
      "epoch n°3484 : train_loss = 2.031033754348755, val_loss = 0.7919489741325378\n",
      "epoch n°3485 : train_loss = 2.025003671646118, val_loss = 0.7919721603393555\n",
      "epoch n°3486 : train_loss = 2.0427045822143555, val_loss = 0.7960450053215027\n",
      "epoch n°3487 : train_loss = 2.0188446044921875, val_loss = 0.7921366691589355\n",
      "epoch n°3488 : train_loss = 2.028351068496704, val_loss = 0.7937571406364441\n",
      "epoch n°3489 : train_loss = 2.026733160018921, val_loss = 0.7975116968154907\n",
      "epoch n°3490 : train_loss = 2.026979684829712, val_loss = 0.7948384881019592\n",
      "epoch n°3491 : train_loss = 2.034727096557617, val_loss = 0.7906070351600647\n",
      "epoch n°3492 : train_loss = 2.0227670669555664, val_loss = 0.7944311499595642\n",
      "epoch n°3493 : train_loss = 2.027099370956421, val_loss = 0.793841540813446\n",
      "epoch n°3494 : train_loss = 2.0388870239257812, val_loss = 0.7937248349189758\n",
      "epoch n°3495 : train_loss = 2.0274298191070557, val_loss = 0.793995201587677\n",
      "epoch n°3496 : train_loss = 2.022125244140625, val_loss = 0.7943336367607117\n",
      "epoch n°3497 : train_loss = 2.0317113399505615, val_loss = 0.7936179041862488\n",
      "epoch n°3498 : train_loss = 2.0296497344970703, val_loss = 0.7981639504432678\n",
      "epoch n°3499 : train_loss = 2.035971164703369, val_loss = 0.7931563258171082\n",
      "epoch n°3500 : train_loss = 2.03641414642334, val_loss = 0.796964168548584\n",
      "epoch n°3501 : train_loss = 2.023184061050415, val_loss = 0.7963446974754333\n",
      "epoch n°3502 : train_loss = 2.0292582511901855, val_loss = 0.7977845668792725\n",
      "epoch n°3503 : train_loss = 2.0165281295776367, val_loss = 0.7934422492980957\n",
      "epoch n°3504 : train_loss = 2.0415337085723877, val_loss = 0.7952792644500732\n",
      "epoch n°3505 : train_loss = 2.0362913608551025, val_loss = 0.797034502029419\n",
      "epoch n°3506 : train_loss = 2.0309228897094727, val_loss = 0.7939269542694092\n",
      "epoch n°3507 : train_loss = 2.022660493850708, val_loss = 0.790911078453064\n",
      "epoch n°3508 : train_loss = 2.0330042839050293, val_loss = 0.794177770614624\n",
      "epoch n°3509 : train_loss = 2.0286035537719727, val_loss = 0.7929365634918213\n",
      "epoch n°3510 : train_loss = 2.032057285308838, val_loss = 0.7882882952690125\n",
      "epoch n°3511 : train_loss = 2.031859874725342, val_loss = 0.7928981184959412\n",
      "epoch n°3512 : train_loss = 2.029689073562622, val_loss = 0.7972813248634338\n",
      "epoch n°3513 : train_loss = 2.0282375812530518, val_loss = 0.7915967702865601\n",
      "epoch n°3514 : train_loss = 2.024247884750366, val_loss = 0.7893140912055969\n",
      "epoch n°3515 : train_loss = 2.030703067779541, val_loss = 0.7943369150161743\n",
      "epoch n°3516 : train_loss = 2.024775743484497, val_loss = 0.7982428073883057\n",
      "epoch n°3517 : train_loss = 2.0335769653320312, val_loss = 0.7923774719238281\n",
      "epoch n°3518 : train_loss = 2.027690887451172, val_loss = 0.7976822257041931\n",
      "epoch n°3519 : train_loss = 2.024761199951172, val_loss = 0.7952984571456909\n",
      "epoch n°3520 : train_loss = 2.0388360023498535, val_loss = 0.7951958775520325\n",
      "epoch n°3521 : train_loss = 2.032594680786133, val_loss = 0.7976627349853516\n",
      "epoch n°3522 : train_loss = 2.0266952514648438, val_loss = 0.7925302386283875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°3523 : train_loss = 2.0267231464385986, val_loss = 0.7988036870956421\n",
      "epoch n°3524 : train_loss = 2.0274479389190674, val_loss = 0.7928510308265686\n",
      "epoch n°3525 : train_loss = 2.0279407501220703, val_loss = 0.791693925857544\n",
      "epoch n°3526 : train_loss = 2.031822681427002, val_loss = 0.7912110090255737\n",
      "epoch n°3527 : train_loss = 2.0284006595611572, val_loss = 0.789838433265686\n",
      "epoch n°3528 : train_loss = 2.033374071121216, val_loss = 0.7906245589256287\n",
      "epoch n°3529 : train_loss = 2.025266408920288, val_loss = 0.7944456338882446\n",
      "epoch n°3530 : train_loss = 2.026498317718506, val_loss = 0.79371178150177\n",
      "epoch n°3531 : train_loss = 2.0375804901123047, val_loss = 0.7926081418991089\n",
      "epoch n°3532 : train_loss = 2.0258681774139404, val_loss = 0.7925310134887695\n",
      "epoch n°3533 : train_loss = 2.038869857788086, val_loss = 0.7902916073799133\n",
      "epoch n°3534 : train_loss = 2.0279431343078613, val_loss = 0.792610764503479\n",
      "epoch n°3535 : train_loss = 2.032461166381836, val_loss = 0.7972854375839233\n",
      "epoch n°3536 : train_loss = 2.0278713703155518, val_loss = 0.7954608798027039\n",
      "epoch n°3537 : train_loss = 2.0311965942382812, val_loss = 0.7894654273986816\n",
      "epoch n°3538 : train_loss = 2.03518009185791, val_loss = 0.7892006635665894\n",
      "epoch n°3539 : train_loss = 2.038332939147949, val_loss = 0.7921885848045349\n",
      "epoch n°3540 : train_loss = 2.03580904006958, val_loss = 0.7927494049072266\n",
      "epoch n°3541 : train_loss = 2.032113552093506, val_loss = 0.7942042350769043\n",
      "epoch n°3542 : train_loss = 2.036024570465088, val_loss = 0.7948299050331116\n",
      "epoch n°3543 : train_loss = 2.0284125804901123, val_loss = 0.7926573157310486\n",
      "epoch n°3544 : train_loss = 2.0246806144714355, val_loss = 0.793263852596283\n",
      "epoch n°3545 : train_loss = 2.024252414703369, val_loss = 0.7948858141899109\n",
      "epoch n°3546 : train_loss = 2.0235579013824463, val_loss = 0.7930832505226135\n",
      "epoch n°3547 : train_loss = 2.0256619453430176, val_loss = 0.796320378780365\n",
      "epoch n°3548 : train_loss = 2.029103994369507, val_loss = 0.7928056716918945\n",
      "epoch n°3549 : train_loss = 2.0355474948883057, val_loss = 0.7922477126121521\n",
      "epoch n°3550 : train_loss = 2.028643846511841, val_loss = 0.7935247421264648\n",
      "epoch n°3551 : train_loss = 2.027052402496338, val_loss = 0.7979797124862671\n",
      "epoch n°3552 : train_loss = 2.0321366786956787, val_loss = 0.7917541861534119\n",
      "epoch n°3553 : train_loss = 2.0309481620788574, val_loss = 0.7945096492767334\n",
      "epoch n°3554 : train_loss = 2.0220117568969727, val_loss = 0.7914107441902161\n",
      "epoch n°3555 : train_loss = 2.0183544158935547, val_loss = 0.7923405170440674\n",
      "epoch n°3556 : train_loss = 2.023343324661255, val_loss = 0.7922150492668152\n",
      "epoch n°3557 : train_loss = 2.0336010456085205, val_loss = 0.7959942817687988\n",
      "epoch n°3558 : train_loss = 2.030179500579834, val_loss = 0.7962268590927124\n",
      "epoch n°3559 : train_loss = 2.0295417308807373, val_loss = 0.7944523096084595\n",
      "epoch n°3560 : train_loss = 2.0215301513671875, val_loss = 0.7930018901824951\n",
      "epoch n°3561 : train_loss = 2.032435894012451, val_loss = 0.7965033650398254\n",
      "epoch n°3562 : train_loss = 2.0326778888702393, val_loss = 0.7950399518013\n",
      "epoch n°3563 : train_loss = 2.0264365673065186, val_loss = 0.796748697757721\n",
      "epoch n°3564 : train_loss = 2.030902862548828, val_loss = 0.7927371859550476\n",
      "epoch n°3565 : train_loss = 2.027390956878662, val_loss = 0.789727509021759\n",
      "epoch n°3566 : train_loss = 2.0248606204986572, val_loss = 0.7915364503860474\n",
      "epoch n°3567 : train_loss = 2.0200560092926025, val_loss = 0.7942977547645569\n",
      "epoch n°3568 : train_loss = 2.0308759212493896, val_loss = 0.7956528663635254\n",
      "epoch n°3569 : train_loss = 2.0302767753601074, val_loss = 0.7929713726043701\n",
      "epoch n°3570 : train_loss = 2.0168521404266357, val_loss = 0.7883933782577515\n",
      "epoch n°3571 : train_loss = 2.0261428356170654, val_loss = 0.7921077609062195\n",
      "epoch n°3572 : train_loss = 2.034865617752075, val_loss = 0.790684700012207\n",
      "epoch n°3573 : train_loss = 2.0304455757141113, val_loss = 0.7927394509315491\n",
      "epoch n°3574 : train_loss = 2.0225346088409424, val_loss = 0.7920900583267212\n",
      "epoch n°3575 : train_loss = 2.0333571434020996, val_loss = 0.7948037981987\n",
      "epoch n°3576 : train_loss = 2.030242681503296, val_loss = 0.7909227609634399\n",
      "epoch n°3577 : train_loss = 2.025113105773926, val_loss = 0.7920519113540649\n",
      "epoch n°3578 : train_loss = 2.030805826187134, val_loss = 0.7887161374092102\n",
      "epoch n°3579 : train_loss = 2.0341501235961914, val_loss = 0.7959720492362976\n",
      "epoch n°3580 : train_loss = 2.0276219844818115, val_loss = 0.789534330368042\n",
      "epoch n°3581 : train_loss = 2.032745122909546, val_loss = 0.7889592051506042\n",
      "epoch n°3582 : train_loss = 2.0298681259155273, val_loss = 0.7939426898956299\n",
      "epoch n°3583 : train_loss = 2.0297181606292725, val_loss = 0.7922735214233398\n",
      "epoch n°3584 : train_loss = 2.029553174972534, val_loss = 0.7943558692932129\n",
      "epoch n°3585 : train_loss = 2.0287058353424072, val_loss = 0.7946900129318237\n",
      "epoch n°3586 : train_loss = 2.0206236839294434, val_loss = 0.7956545948982239\n",
      "epoch n°3587 : train_loss = 2.0232484340667725, val_loss = 0.7926409840583801\n",
      "epoch n°3588 : train_loss = 2.025554656982422, val_loss = 0.795506477355957\n",
      "epoch n°3589 : train_loss = 2.0230870246887207, val_loss = 0.7926665544509888\n",
      "epoch n°3590 : train_loss = 2.0230038166046143, val_loss = 0.7902001738548279\n",
      "epoch n°3591 : train_loss = 2.0200626850128174, val_loss = 0.7903995513916016\n",
      "epoch n°3592 : train_loss = 2.0270707607269287, val_loss = 0.7941819429397583\n",
      "epoch n°3593 : train_loss = 2.032989740371704, val_loss = 0.7936288118362427\n",
      "epoch n°3594 : train_loss = 2.0215911865234375, val_loss = 0.7942889928817749\n",
      "epoch n°3595 : train_loss = 2.0200414657592773, val_loss = 0.7938268184661865\n",
      "epoch n°3596 : train_loss = 2.028106451034546, val_loss = 0.794786810874939\n",
      "epoch n°3597 : train_loss = 2.0338785648345947, val_loss = 0.7934754490852356\n",
      "epoch n°3598 : train_loss = 2.0280330181121826, val_loss = 0.7971101403236389\n",
      "epoch n°3599 : train_loss = 2.0237061977386475, val_loss = 0.7939849495887756\n",
      "epoch n°3600 : train_loss = 2.0206546783447266, val_loss = 0.7929506897926331\n",
      "epoch n°3601 : train_loss = 2.0257136821746826, val_loss = 0.7918187975883484\n",
      "epoch n°3602 : train_loss = 2.0221188068389893, val_loss = 0.7922115921974182\n",
      "epoch n°3603 : train_loss = 2.0275957584381104, val_loss = 0.7948931455612183\n",
      "epoch n°3604 : train_loss = 2.024327516555786, val_loss = 0.7950565814971924\n",
      "epoch n°3605 : train_loss = 2.021564483642578, val_loss = 0.7912094593048096\n",
      "epoch n°3606 : train_loss = 2.0212244987487793, val_loss = 0.7904221415519714\n",
      "epoch n°3607 : train_loss = 2.0149028301239014, val_loss = 0.7932820916175842\n",
      "epoch n°3608 : train_loss = 2.0197880268096924, val_loss = 0.7915403842926025\n",
      "epoch n°3609 : train_loss = 2.0214807987213135, val_loss = 0.7930390238761902\n",
      "epoch n°3610 : train_loss = 2.032573699951172, val_loss = 0.7972142696380615\n",
      "epoch n°3611 : train_loss = 2.0230822563171387, val_loss = 0.7921108603477478\n",
      "epoch n°3612 : train_loss = 2.0276970863342285, val_loss = 0.7947341799736023\n",
      "epoch n°3613 : train_loss = 2.0233654975891113, val_loss = 0.7919806241989136\n",
      "epoch n°3614 : train_loss = 2.032022714614868, val_loss = 0.7940885424613953\n",
      "epoch n°3615 : train_loss = 2.030062675476074, val_loss = 0.7952308058738708\n",
      "epoch n°3616 : train_loss = 2.019855499267578, val_loss = 0.7948920130729675\n",
      "epoch n°3617 : train_loss = 2.029062032699585, val_loss = 0.7954062819480896\n",
      "epoch n°3618 : train_loss = 2.0222864151000977, val_loss = 0.790752649307251\n",
      "epoch n°3619 : train_loss = 2.0186948776245117, val_loss = 0.7906115651130676\n",
      "epoch n°3620 : train_loss = 2.026637077331543, val_loss = 0.7915926575660706\n",
      "epoch n°3621 : train_loss = 2.021847724914551, val_loss = 0.7973397374153137\n",
      "epoch n°3622 : train_loss = 2.031100273132324, val_loss = 0.791189968585968\n",
      "epoch n°3623 : train_loss = 2.0214967727661133, val_loss = 0.7930211424827576\n",
      "epoch n°3624 : train_loss = 2.024958610534668, val_loss = 0.7955811023712158\n",
      "epoch n°3625 : train_loss = 2.02221417427063, val_loss = 0.7944231033325195\n",
      "epoch n°3626 : train_loss = 2.0173773765563965, val_loss = 0.7922494411468506\n",
      "epoch n°3627 : train_loss = 2.018420457839966, val_loss = 0.7950187921524048\n",
      "epoch n°3628 : train_loss = 2.0256383419036865, val_loss = 0.7942296862602234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°3629 : train_loss = 2.02406644821167, val_loss = 0.7927650213241577\n",
      "epoch n°3630 : train_loss = 2.024961233139038, val_loss = 0.7954533696174622\n",
      "epoch n°3631 : train_loss = 2.033294916152954, val_loss = 0.7962217926979065\n",
      "epoch n°3632 : train_loss = 2.0261383056640625, val_loss = 0.7896167039871216\n",
      "epoch n°3633 : train_loss = 2.022979497909546, val_loss = 0.7941028475761414\n",
      "epoch n°3634 : train_loss = 2.021341323852539, val_loss = 0.7919877767562866\n",
      "epoch n°3635 : train_loss = 2.0227596759796143, val_loss = 0.7924894094467163\n",
      "epoch n°3636 : train_loss = 2.031231641769409, val_loss = 0.7905187606811523\n",
      "epoch n°3637 : train_loss = 2.0222413539886475, val_loss = 0.7968685030937195\n",
      "epoch n°3638 : train_loss = 2.033381700515747, val_loss = 0.7986780405044556\n",
      "epoch n°3639 : train_loss = 2.0328915119171143, val_loss = 0.7912062406539917\n",
      "epoch n°3640 : train_loss = 2.026611089706421, val_loss = 0.7939014434814453\n",
      "epoch n°3641 : train_loss = 2.0225143432617188, val_loss = 0.7896419763565063\n",
      "epoch n°3642 : train_loss = 2.028191566467285, val_loss = 0.7900795340538025\n",
      "epoch n°3643 : train_loss = 2.031369924545288, val_loss = 0.7882886528968811\n",
      "epoch n°3644 : train_loss = 2.0266377925872803, val_loss = 0.7949621081352234\n",
      "epoch n°3645 : train_loss = 2.0233523845672607, val_loss = 0.7925081253051758\n",
      "epoch n°3646 : train_loss = 2.026190757751465, val_loss = 0.7942978143692017\n",
      "epoch n°3647 : train_loss = 2.0263671875, val_loss = 0.7928979396820068\n",
      "epoch n°3648 : train_loss = 2.026780605316162, val_loss = 0.796688973903656\n",
      "epoch n°3649 : train_loss = 2.0261733531951904, val_loss = 0.7990896105766296\n",
      "epoch n°3650 : train_loss = 2.0170695781707764, val_loss = 0.7944211363792419\n",
      "epoch n°3651 : train_loss = 2.0300261974334717, val_loss = 0.7923598885536194\n",
      "epoch n°3652 : train_loss = 2.0244288444519043, val_loss = 0.7923406958580017\n",
      "epoch n°3653 : train_loss = 2.021899461746216, val_loss = 0.7896715402603149\n",
      "epoch n°3654 : train_loss = 2.0249369144439697, val_loss = 0.7939995527267456\n",
      "epoch n°3655 : train_loss = 2.020291805267334, val_loss = 0.7907309532165527\n",
      "epoch n°3656 : train_loss = 2.029553174972534, val_loss = 0.7945445775985718\n",
      "epoch n°3657 : train_loss = 2.0199661254882812, val_loss = 0.7953152656555176\n",
      "epoch n°3658 : train_loss = 2.023571252822876, val_loss = 0.7961711287498474\n",
      "epoch n°3659 : train_loss = 2.0202226638793945, val_loss = 0.7875679135322571\n",
      "epoch n°3660 : train_loss = 2.0222411155700684, val_loss = 0.7903327345848083\n",
      "epoch n°3661 : train_loss = 2.027712106704712, val_loss = 0.7946360111236572\n",
      "epoch n°3662 : train_loss = 2.0227749347686768, val_loss = 0.7879711985588074\n",
      "epoch n°3663 : train_loss = 2.0282788276672363, val_loss = 0.7943770289421082\n",
      "epoch n°3664 : train_loss = 2.0216267108917236, val_loss = 0.7940834164619446\n",
      "epoch n°3665 : train_loss = 2.019185781478882, val_loss = 0.7962749004364014\n",
      "epoch n°3666 : train_loss = 2.0195789337158203, val_loss = 0.792943000793457\n",
      "epoch n°3667 : train_loss = 2.021860361099243, val_loss = 0.7896490097045898\n",
      "epoch n°3668 : train_loss = 2.020596504211426, val_loss = 0.7969786524772644\n",
      "epoch n°3669 : train_loss = 2.0226268768310547, val_loss = 0.7916203141212463\n",
      "epoch n°3670 : train_loss = 2.021634101867676, val_loss = 0.7933119535446167\n",
      "epoch n°3671 : train_loss = 2.027094841003418, val_loss = 0.7910552024841309\n",
      "epoch n°3672 : train_loss = 2.013009548187256, val_loss = 0.7910680770874023\n",
      "epoch n°3673 : train_loss = 2.021317481994629, val_loss = 0.7938176989555359\n",
      "epoch n°3674 : train_loss = 2.0257904529571533, val_loss = 0.7917773723602295\n",
      "epoch n°3675 : train_loss = 2.0216729640960693, val_loss = 0.7949290871620178\n",
      "epoch n°3676 : train_loss = 2.0268752574920654, val_loss = 0.7916096448898315\n",
      "epoch n°3677 : train_loss = 2.0179710388183594, val_loss = 0.7977921366691589\n",
      "epoch n°3678 : train_loss = 2.016542673110962, val_loss = 0.7940423488616943\n",
      "epoch n°3679 : train_loss = 2.0304436683654785, val_loss = 0.7927886247634888\n",
      "epoch n°3680 : train_loss = 2.0323121547698975, val_loss = 0.7916567921638489\n",
      "epoch n°3681 : train_loss = 2.0298211574554443, val_loss = 0.7941805720329285\n",
      "epoch n°3682 : train_loss = 2.0170843601226807, val_loss = 0.7946334481239319\n",
      "epoch n°3683 : train_loss = 2.028141975402832, val_loss = 0.7899736166000366\n",
      "epoch n°3684 : train_loss = 2.0223684310913086, val_loss = 0.7933261394500732\n",
      "epoch n°3685 : train_loss = 2.029296636581421, val_loss = 0.7934423089027405\n",
      "epoch n°3686 : train_loss = 2.0267105102539062, val_loss = 0.7974319458007812\n",
      "epoch n°3687 : train_loss = 2.022531032562256, val_loss = 0.7973713874816895\n",
      "epoch n°3688 : train_loss = 2.016092538833618, val_loss = 0.7946799993515015\n",
      "epoch n°3689 : train_loss = 2.028667688369751, val_loss = 0.7899547219276428\n",
      "epoch n°3690 : train_loss = 2.0260205268859863, val_loss = 0.7930232882499695\n",
      "epoch n°3691 : train_loss = 2.023736000061035, val_loss = 0.7931184768676758\n",
      "epoch n°3692 : train_loss = 2.0245258808135986, val_loss = 0.788973331451416\n",
      "epoch n°3693 : train_loss = 2.025831699371338, val_loss = 0.7927401065826416\n",
      "epoch n°3694 : train_loss = 2.028130531311035, val_loss = 0.7917822599411011\n",
      "epoch n°3695 : train_loss = 2.0331871509552, val_loss = 0.7940528392791748\n",
      "epoch n°3696 : train_loss = 2.0325005054473877, val_loss = 0.7893251180648804\n",
      "epoch n°3697 : train_loss = 2.02183198928833, val_loss = 0.7960494756698608\n",
      "epoch n°3698 : train_loss = 2.025268793106079, val_loss = 0.7966448068618774\n",
      "epoch n°3699 : train_loss = 2.0279924869537354, val_loss = 0.7905308604240417\n",
      "epoch n°3700 : train_loss = 2.0320968627929688, val_loss = 0.7907168865203857\n",
      "epoch n°3701 : train_loss = 2.019603967666626, val_loss = 0.7933515906333923\n",
      "epoch n°3702 : train_loss = 2.02980899810791, val_loss = 0.7903718948364258\n",
      "epoch n°3703 : train_loss = 2.0126681327819824, val_loss = 0.7957752346992493\n",
      "epoch n°3704 : train_loss = 2.0173277854919434, val_loss = 0.7913140058517456\n",
      "epoch n°3705 : train_loss = 2.019362449645996, val_loss = 0.7938955426216125\n",
      "epoch n°3706 : train_loss = 2.0208258628845215, val_loss = 0.7935256361961365\n",
      "epoch n°3707 : train_loss = 2.0296318531036377, val_loss = 0.7960195541381836\n",
      "epoch n°3708 : train_loss = 2.0255117416381836, val_loss = 0.7940027713775635\n",
      "epoch n°3709 : train_loss = 2.0255751609802246, val_loss = 0.7925670742988586\n",
      "epoch n°3710 : train_loss = 2.0187759399414062, val_loss = 0.7962197661399841\n",
      "epoch n°3711 : train_loss = 2.0270206928253174, val_loss = 0.7934809923171997\n",
      "epoch n°3712 : train_loss = 2.0203824043273926, val_loss = 0.7917730808258057\n",
      "epoch n°3713 : train_loss = 2.0275938510894775, val_loss = 0.788646936416626\n",
      "epoch n°3714 : train_loss = 2.0262231826782227, val_loss = 0.7929682731628418\n",
      "epoch n°3715 : train_loss = 2.0159738063812256, val_loss = 0.7905827760696411\n",
      "epoch n°3716 : train_loss = 2.022456169128418, val_loss = 0.7918468117713928\n",
      "epoch n°3717 : train_loss = 2.023970365524292, val_loss = 0.7938470244407654\n",
      "epoch n°3718 : train_loss = 2.0196964740753174, val_loss = 0.7900229692459106\n",
      "epoch n°3719 : train_loss = 2.022932767868042, val_loss = 0.7934592962265015\n",
      "epoch n°3720 : train_loss = 2.0269057750701904, val_loss = 0.7918931245803833\n",
      "epoch n°3721 : train_loss = 2.023756742477417, val_loss = 0.792405366897583\n",
      "epoch n°3722 : train_loss = 2.0218679904937744, val_loss = 0.7927391529083252\n",
      "epoch n°3723 : train_loss = 2.0222771167755127, val_loss = 0.7890231013298035\n",
      "epoch n°3724 : train_loss = 2.0356268882751465, val_loss = 0.7938669919967651\n",
      "epoch n°3725 : train_loss = 2.0233006477355957, val_loss = 0.7887411117553711\n",
      "epoch n°3726 : train_loss = 2.0211446285247803, val_loss = 0.7921629548072815\n",
      "epoch n°3727 : train_loss = 2.037245988845825, val_loss = 0.7931007742881775\n",
      "epoch n°3728 : train_loss = 2.022368907928467, val_loss = 0.7903738617897034\n",
      "epoch n°3729 : train_loss = 2.033513307571411, val_loss = 0.7949444055557251\n",
      "epoch n°3730 : train_loss = 2.0233964920043945, val_loss = 0.7955738306045532\n",
      "epoch n°3731 : train_loss = 2.026777744293213, val_loss = 0.7924553751945496\n",
      "epoch n°3732 : train_loss = 2.023055076599121, val_loss = 0.7915551662445068\n",
      "epoch n°3733 : train_loss = 2.027217149734497, val_loss = 0.7895620465278625\n",
      "epoch n°3734 : train_loss = 2.0306906700134277, val_loss = 0.79554682970047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°3735 : train_loss = 2.0344974994659424, val_loss = 0.7904360294342041\n",
      "epoch n°3736 : train_loss = 2.0191712379455566, val_loss = 0.7949942350387573\n",
      "epoch n°3737 : train_loss = 2.0206875801086426, val_loss = 0.7970260381698608\n",
      "epoch n°3738 : train_loss = 2.0185728073120117, val_loss = 0.792550265789032\n",
      "epoch n°3739 : train_loss = 2.025104284286499, val_loss = 0.7914957404136658\n",
      "epoch n°3740 : train_loss = 2.0297064781188965, val_loss = 0.7909014821052551\n",
      "epoch n°3741 : train_loss = 2.030972719192505, val_loss = 0.7932351231575012\n",
      "epoch n°3742 : train_loss = 2.0321311950683594, val_loss = 0.7930687665939331\n",
      "epoch n°3743 : train_loss = 2.017394781112671, val_loss = 0.7897439002990723\n",
      "epoch n°3744 : train_loss = 2.0276496410369873, val_loss = 0.7933703064918518\n",
      "epoch n°3745 : train_loss = 2.0205674171447754, val_loss = 0.7945448160171509\n",
      "epoch n°3746 : train_loss = 2.0231215953826904, val_loss = 0.7940093278884888\n",
      "epoch n°3747 : train_loss = 2.023016929626465, val_loss = 0.7950010895729065\n",
      "epoch n°3748 : train_loss = 2.0265660285949707, val_loss = 0.7914159297943115\n",
      "epoch n°3749 : train_loss = 2.02580189704895, val_loss = 0.790474534034729\n",
      "epoch n°3750 : train_loss = 2.019385814666748, val_loss = 0.7917835712432861\n",
      "epoch n°3751 : train_loss = 2.0276758670806885, val_loss = 0.7966126799583435\n",
      "epoch n°3752 : train_loss = 2.0245308876037598, val_loss = 0.7936208844184875\n",
      "epoch n°3753 : train_loss = 2.0162858963012695, val_loss = 0.7880203723907471\n",
      "epoch n°3754 : train_loss = 2.020672082901001, val_loss = 0.7951274514198303\n",
      "epoch n°3755 : train_loss = 2.020751714706421, val_loss = 0.7937477827072144\n",
      "epoch n°3756 : train_loss = 2.018828868865967, val_loss = 0.7872009873390198\n",
      "epoch n°3757 : train_loss = 2.0213494300842285, val_loss = 0.794806718826294\n",
      "epoch n°3758 : train_loss = 2.0249056816101074, val_loss = 0.7890554666519165\n",
      "epoch n°3759 : train_loss = 2.024365186691284, val_loss = 0.7918382883071899\n",
      "epoch n°3760 : train_loss = 2.0308616161346436, val_loss = 0.792288601398468\n",
      "epoch n°3761 : train_loss = 2.023773431777954, val_loss = 0.791036069393158\n",
      "epoch n°3762 : train_loss = 2.019096851348877, val_loss = 0.7918597459793091\n",
      "epoch n°3763 : train_loss = 2.020843982696533, val_loss = 0.7942261099815369\n",
      "epoch n°3764 : train_loss = 2.016845941543579, val_loss = 0.7969033122062683\n",
      "epoch n°3765 : train_loss = 2.025813102722168, val_loss = 0.790237545967102\n",
      "epoch n°3766 : train_loss = 2.023498773574829, val_loss = 0.791362464427948\n",
      "epoch n°3767 : train_loss = 2.0173356533050537, val_loss = 0.7900377511978149\n",
      "epoch n°3768 : train_loss = 2.025481939315796, val_loss = 0.7916702032089233\n",
      "epoch n°3769 : train_loss = 2.0225017070770264, val_loss = 0.7924728393554688\n",
      "epoch n°3770 : train_loss = 2.0116355419158936, val_loss = 0.7899264097213745\n",
      "epoch n°3771 : train_loss = 2.0259344577789307, val_loss = 0.792953610420227\n",
      "epoch n°3772 : train_loss = 2.0224764347076416, val_loss = 0.7968449592590332\n",
      "epoch n°3773 : train_loss = 2.0271942615509033, val_loss = 0.7958899140357971\n",
      "epoch n°3774 : train_loss = 2.024915933609009, val_loss = 0.7959575057029724\n",
      "epoch n°3775 : train_loss = 2.017510175704956, val_loss = 0.791125476360321\n",
      "epoch n°3776 : train_loss = 2.0240583419799805, val_loss = 0.790862500667572\n",
      "epoch n°3777 : train_loss = 2.0247490406036377, val_loss = 0.7962644696235657\n",
      "epoch n°3778 : train_loss = 2.019167900085449, val_loss = 0.7910640835762024\n",
      "epoch n°3779 : train_loss = 2.019247531890869, val_loss = 0.7945505976676941\n",
      "epoch n°3780 : train_loss = 2.024956703186035, val_loss = 0.7979366779327393\n",
      "epoch n°3781 : train_loss = 2.0248920917510986, val_loss = 0.7939940094947815\n",
      "epoch n°3782 : train_loss = 2.024574041366577, val_loss = 0.7958851456642151\n",
      "epoch n°3783 : train_loss = 2.0095536708831787, val_loss = 0.7917363047599792\n",
      "epoch n°3784 : train_loss = 2.016652822494507, val_loss = 0.7916717529296875\n",
      "epoch n°3785 : train_loss = 2.0186336040496826, val_loss = 0.7925193905830383\n",
      "epoch n°3786 : train_loss = 2.0230367183685303, val_loss = 0.7945443987846375\n",
      "epoch n°3787 : train_loss = 2.0214061737060547, val_loss = 0.7870646715164185\n",
      "epoch n°3788 : train_loss = 2.014951705932617, val_loss = 0.7962929606437683\n",
      "epoch n°3789 : train_loss = 2.0258781909942627, val_loss = 0.7918034195899963\n",
      "epoch n°3790 : train_loss = 2.02461838722229, val_loss = 0.793577253818512\n",
      "epoch n°3791 : train_loss = 2.0212883949279785, val_loss = 0.789340615272522\n",
      "epoch n°3792 : train_loss = 2.0205330848693848, val_loss = 0.7948325276374817\n",
      "epoch n°3793 : train_loss = 2.0248777866363525, val_loss = 0.7941359877586365\n",
      "epoch n°3794 : train_loss = 2.0190560817718506, val_loss = 0.7933807969093323\n",
      "epoch n°3795 : train_loss = 2.014369010925293, val_loss = 0.7978255152702332\n",
      "epoch n°3796 : train_loss = 2.0203280448913574, val_loss = 0.7926700115203857\n",
      "epoch n°3797 : train_loss = 2.0299551486968994, val_loss = 0.7935817241668701\n",
      "epoch n°3798 : train_loss = 2.015827178955078, val_loss = 0.7892880439758301\n",
      "epoch n°3799 : train_loss = 2.0174942016601562, val_loss = 0.7932515144348145\n",
      "epoch n°3800 : train_loss = 2.0116679668426514, val_loss = 0.7928877472877502\n",
      "epoch n°3801 : train_loss = 2.025887966156006, val_loss = 0.7905094623565674\n",
      "epoch n°3802 : train_loss = 2.020587921142578, val_loss = 0.7914116978645325\n",
      "epoch n°3803 : train_loss = 2.0180575847625732, val_loss = 0.7912905216217041\n",
      "epoch n°3804 : train_loss = 2.0153050422668457, val_loss = 0.7903432250022888\n",
      "epoch n°3805 : train_loss = 2.027352809906006, val_loss = 0.7925505042076111\n",
      "epoch n°3806 : train_loss = 2.0101571083068848, val_loss = 0.7918143272399902\n",
      "epoch n°3807 : train_loss = 2.017277479171753, val_loss = 0.7912979125976562\n",
      "epoch n°3808 : train_loss = 2.0261294841766357, val_loss = 0.7899476885795593\n",
      "epoch n°3809 : train_loss = 2.021871566772461, val_loss = 0.7909163236618042\n",
      "epoch n°3810 : train_loss = 2.0296168327331543, val_loss = 0.7952489852905273\n",
      "epoch n°3811 : train_loss = 2.0222201347351074, val_loss = 0.7903538942337036\n",
      "epoch n°3812 : train_loss = 2.0169684886932373, val_loss = 0.7949250936508179\n",
      "epoch n°3813 : train_loss = 2.0265917778015137, val_loss = 0.7891893982887268\n",
      "epoch n°3814 : train_loss = 2.0248610973358154, val_loss = 0.79375821352005\n",
      "epoch n°3815 : train_loss = 2.0302064418792725, val_loss = 0.7961611747741699\n",
      "epoch n°3816 : train_loss = 2.0232598781585693, val_loss = 0.7929200530052185\n",
      "epoch n°3817 : train_loss = 2.015989303588867, val_loss = 0.7957573533058167\n",
      "epoch n°3818 : train_loss = 2.021292209625244, val_loss = 0.7919893264770508\n",
      "epoch n°3819 : train_loss = 2.0225508213043213, val_loss = 0.7879804372787476\n",
      "epoch n°3820 : train_loss = 2.017453908920288, val_loss = 0.7923255562782288\n",
      "epoch n°3821 : train_loss = 2.0210483074188232, val_loss = 0.7920297384262085\n",
      "epoch n°3822 : train_loss = 2.0240657329559326, val_loss = 0.7913031578063965\n",
      "epoch n°3823 : train_loss = 2.0222976207733154, val_loss = 0.7944697737693787\n",
      "epoch n°3824 : train_loss = 2.0177576541900635, val_loss = 0.7955849766731262\n",
      "epoch n°3825 : train_loss = 2.0196573734283447, val_loss = 0.7905932664871216\n",
      "epoch n°3826 : train_loss = 2.019394636154175, val_loss = 0.7907001972198486\n",
      "epoch n°3827 : train_loss = 2.016925811767578, val_loss = 0.7897074222564697\n",
      "epoch n°3828 : train_loss = 2.019956111907959, val_loss = 0.7943322658538818\n",
      "epoch n°3829 : train_loss = 2.0199499130249023, val_loss = 0.790742039680481\n",
      "epoch n°3830 : train_loss = 2.0171337127685547, val_loss = 0.7934904098510742\n",
      "epoch n°3831 : train_loss = 2.019253730773926, val_loss = 0.7938635945320129\n",
      "epoch n°3832 : train_loss = 2.019643783569336, val_loss = 0.7900624871253967\n",
      "epoch n°3833 : train_loss = 2.0256288051605225, val_loss = 0.7930029630661011\n",
      "epoch n°3834 : train_loss = 2.0256307125091553, val_loss = 0.7986205220222473\n",
      "epoch n°3835 : train_loss = 2.028057098388672, val_loss = 0.7905501127243042\n",
      "epoch n°3836 : train_loss = 2.027663469314575, val_loss = 0.792485237121582\n",
      "epoch n°3837 : train_loss = 2.0213873386383057, val_loss = 0.7880358099937439\n",
      "epoch n°3838 : train_loss = 2.013582944869995, val_loss = 0.7918817400932312\n",
      "epoch n°3839 : train_loss = 2.0213892459869385, val_loss = 0.796562910079956\n",
      "epoch n°3840 : train_loss = 2.0263237953186035, val_loss = 0.7884342074394226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°3841 : train_loss = 2.026115655899048, val_loss = 0.7945634722709656\n",
      "epoch n°3842 : train_loss = 2.025484085083008, val_loss = 0.793971836566925\n",
      "epoch n°3843 : train_loss = 2.017622709274292, val_loss = 0.7887458801269531\n",
      "epoch n°3844 : train_loss = 2.0215234756469727, val_loss = 0.7948873043060303\n",
      "epoch n°3845 : train_loss = 2.024970054626465, val_loss = 0.7947527766227722\n",
      "epoch n°3846 : train_loss = 2.0247151851654053, val_loss = 0.7911383509635925\n",
      "epoch n°3847 : train_loss = 2.0231237411499023, val_loss = 0.7950313687324524\n",
      "epoch n°3848 : train_loss = 2.024340867996216, val_loss = 0.7907354831695557\n",
      "epoch n°3849 : train_loss = 2.017099380493164, val_loss = 0.7911548614501953\n",
      "epoch n°3850 : train_loss = 2.0190272331237793, val_loss = 0.7947898507118225\n",
      "epoch n°3851 : train_loss = 2.014549732208252, val_loss = 0.7904676795005798\n",
      "epoch n°3852 : train_loss = 2.019467353820801, val_loss = 0.7961552739143372\n",
      "epoch n°3853 : train_loss = 2.0184006690979004, val_loss = 0.7925106883049011\n",
      "epoch n°3854 : train_loss = 2.023808240890503, val_loss = 0.7953134179115295\n",
      "epoch n°3855 : train_loss = 2.028665065765381, val_loss = 0.793178915977478\n",
      "epoch n°3856 : train_loss = 2.0196914672851562, val_loss = 0.7906314730644226\n",
      "epoch n°3857 : train_loss = 2.0275185108184814, val_loss = 0.7903035283088684\n",
      "epoch n°3858 : train_loss = 2.018711805343628, val_loss = 0.7918767333030701\n",
      "epoch n°3859 : train_loss = 2.0279321670532227, val_loss = 0.7932310700416565\n",
      "epoch n°3860 : train_loss = 2.022692918777466, val_loss = 0.7933841943740845\n",
      "epoch n°3861 : train_loss = 2.0177412033081055, val_loss = 0.7929885387420654\n",
      "epoch n°3862 : train_loss = 2.0332446098327637, val_loss = 0.7949029207229614\n",
      "epoch n°3863 : train_loss = 2.016430616378784, val_loss = 0.7929431200027466\n",
      "epoch n°3864 : train_loss = 2.01812481880188, val_loss = 0.7933605909347534\n",
      "epoch n°3865 : train_loss = 2.0260109901428223, val_loss = 0.7956756353378296\n",
      "epoch n°3866 : train_loss = 2.030710220336914, val_loss = 0.7980450391769409\n",
      "epoch n°3867 : train_loss = 2.0186657905578613, val_loss = 0.7944185733795166\n",
      "epoch n°3868 : train_loss = 2.0210442543029785, val_loss = 0.7931571006774902\n",
      "epoch n°3869 : train_loss = 2.016788959503174, val_loss = 0.7921392321586609\n",
      "epoch n°3870 : train_loss = 2.026282787322998, val_loss = 0.7916571497917175\n",
      "epoch n°3871 : train_loss = 2.0220794677734375, val_loss = 0.7966724038124084\n",
      "epoch n°3872 : train_loss = 2.024200916290283, val_loss = 0.796840488910675\n",
      "epoch n°3873 : train_loss = 2.023819923400879, val_loss = 0.7916069626808167\n",
      "epoch n°3874 : train_loss = 2.014930248260498, val_loss = 0.7943359017372131\n",
      "epoch n°3875 : train_loss = 2.0256216526031494, val_loss = 0.790816068649292\n",
      "epoch n°3876 : train_loss = 2.0243475437164307, val_loss = 0.7925916910171509\n",
      "epoch n°3877 : train_loss = 2.033292293548584, val_loss = 0.7945272326469421\n",
      "epoch n°3878 : train_loss = 2.019442319869995, val_loss = 0.7914356589317322\n",
      "epoch n°3879 : train_loss = 2.0220983028411865, val_loss = 0.79557865858078\n",
      "epoch n°3880 : train_loss = 2.022313356399536, val_loss = 0.7899291515350342\n",
      "epoch n°3881 : train_loss = 2.0291004180908203, val_loss = 0.7927490472793579\n",
      "epoch n°3882 : train_loss = 2.023042678833008, val_loss = 0.7882853746414185\n",
      "epoch n°3883 : train_loss = 2.016934394836426, val_loss = 0.7920515537261963\n",
      "epoch n°3884 : train_loss = 2.0161123275756836, val_loss = 0.7951925992965698\n",
      "epoch n°3885 : train_loss = 2.017897367477417, val_loss = 0.7948591113090515\n",
      "epoch n°3886 : train_loss = 2.0205390453338623, val_loss = 0.7888076305389404\n",
      "epoch n°3887 : train_loss = 2.0119969844818115, val_loss = 0.7959914803504944\n",
      "epoch n°3888 : train_loss = 2.0181946754455566, val_loss = 0.7905642986297607\n",
      "epoch n°3889 : train_loss = 2.0147311687469482, val_loss = 0.7933328151702881\n",
      "epoch n°3890 : train_loss = 2.0238823890686035, val_loss = 0.7886818051338196\n",
      "epoch n°3891 : train_loss = 2.0140905380249023, val_loss = 0.7914482951164246\n",
      "epoch n°3892 : train_loss = 2.018425464630127, val_loss = 0.7911912798881531\n",
      "epoch n°3893 : train_loss = 2.021444082260132, val_loss = 0.7906617522239685\n",
      "epoch n°3894 : train_loss = 2.021329402923584, val_loss = 0.7888641357421875\n",
      "epoch n°3895 : train_loss = 2.0216400623321533, val_loss = 0.7915014028549194\n",
      "epoch n°3896 : train_loss = 2.023359537124634, val_loss = 0.7898609042167664\n",
      "epoch n°3897 : train_loss = 2.0295541286468506, val_loss = 0.7965269684791565\n",
      "epoch n°3898 : train_loss = 2.0249078273773193, val_loss = 0.7941712141036987\n",
      "epoch n°3899 : train_loss = 2.0198938846588135, val_loss = 0.7951252460479736\n",
      "epoch n°3900 : train_loss = 2.0241236686706543, val_loss = 0.7902107238769531\n",
      "epoch n°3901 : train_loss = 2.0189096927642822, val_loss = 0.7971935272216797\n",
      "epoch n°3902 : train_loss = 2.0217692852020264, val_loss = 0.7946065068244934\n",
      "epoch n°3903 : train_loss = 2.0127387046813965, val_loss = 0.7890231013298035\n",
      "epoch n°3904 : train_loss = 2.0188236236572266, val_loss = 0.7897111773490906\n",
      "epoch n°3905 : train_loss = 2.017575979232788, val_loss = 0.7935280799865723\n",
      "epoch n°3906 : train_loss = 2.0157580375671387, val_loss = 0.7906481623649597\n",
      "epoch n°3907 : train_loss = 2.0143167972564697, val_loss = 0.7951940894126892\n",
      "epoch n°3908 : train_loss = 2.0224039554595947, val_loss = 0.791018009185791\n",
      "epoch n°3909 : train_loss = 2.0215389728546143, val_loss = 0.7914137244224548\n",
      "epoch n°3910 : train_loss = 2.019254446029663, val_loss = 0.7926926612854004\n",
      "epoch n°3911 : train_loss = 2.0225274562835693, val_loss = 0.791874349117279\n",
      "epoch n°3912 : train_loss = 2.0208544731140137, val_loss = 0.7942578792572021\n",
      "epoch n°3913 : train_loss = 2.013746738433838, val_loss = 0.7913957834243774\n",
      "epoch n°3914 : train_loss = 2.010344982147217, val_loss = 0.7895573377609253\n",
      "epoch n°3915 : train_loss = 2.028660535812378, val_loss = 0.7948838472366333\n",
      "epoch n°3916 : train_loss = 2.015489101409912, val_loss = 0.7933145761489868\n",
      "epoch n°3917 : train_loss = 2.030231475830078, val_loss = 0.7936416864395142\n",
      "epoch n°3918 : train_loss = 2.0256786346435547, val_loss = 0.792665421962738\n",
      "epoch n°3919 : train_loss = 2.0233891010284424, val_loss = 0.7925481200218201\n",
      "epoch n°3920 : train_loss = 2.0265250205993652, val_loss = 0.7942332625389099\n",
      "epoch n°3921 : train_loss = 2.0236473083496094, val_loss = 0.793060839176178\n",
      "epoch n°3922 : train_loss = 2.0236175060272217, val_loss = 0.7885984182357788\n",
      "epoch n°3923 : train_loss = 2.0276360511779785, val_loss = 0.7887517213821411\n",
      "epoch n°3924 : train_loss = 2.0195789337158203, val_loss = 0.7911617159843445\n",
      "epoch n°3925 : train_loss = 2.0161988735198975, val_loss = 0.792945146560669\n",
      "epoch n°3926 : train_loss = 2.0241506099700928, val_loss = 0.7955989837646484\n",
      "epoch n°3927 : train_loss = 2.019289493560791, val_loss = 0.7932305335998535\n",
      "epoch n°3928 : train_loss = 2.026721954345703, val_loss = 0.7924080491065979\n",
      "epoch n°3929 : train_loss = 2.0290701389312744, val_loss = 0.7981886863708496\n",
      "epoch n°3930 : train_loss = 2.0255541801452637, val_loss = 0.7941939830780029\n",
      "epoch n°3931 : train_loss = 2.021348476409912, val_loss = 0.7912328839302063\n",
      "epoch n°3932 : train_loss = 2.0230560302734375, val_loss = 0.796840488910675\n",
      "epoch n°3933 : train_loss = 2.0258686542510986, val_loss = 0.7923198342323303\n",
      "epoch n°3934 : train_loss = 2.0144176483154297, val_loss = 0.7966364026069641\n",
      "epoch n°3935 : train_loss = 2.018073081970215, val_loss = 0.7889772057533264\n",
      "epoch n°3936 : train_loss = 2.02646803855896, val_loss = 0.7920894026756287\n",
      "epoch n°3937 : train_loss = 2.027336597442627, val_loss = 0.791017472743988\n",
      "epoch n°3938 : train_loss = 2.0209109783172607, val_loss = 0.7920669913291931\n",
      "epoch n°3939 : train_loss = 2.019904375076294, val_loss = 0.791484534740448\n",
      "epoch n°3940 : train_loss = 2.013143301010132, val_loss = 0.7945458292961121\n",
      "epoch n°3941 : train_loss = 2.0256412029266357, val_loss = 0.7948866486549377\n",
      "epoch n°3942 : train_loss = 2.027252674102783, val_loss = 0.7930997610092163\n",
      "epoch n°3943 : train_loss = 2.0185914039611816, val_loss = 0.7908128499984741\n",
      "epoch n°3944 : train_loss = 2.0193660259246826, val_loss = 0.7936264276504517\n",
      "epoch n°3945 : train_loss = 2.0178706645965576, val_loss = 0.7944085001945496\n",
      "epoch n°3946 : train_loss = 2.0235204696655273, val_loss = 0.7955319285392761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°3947 : train_loss = 2.0137414932250977, val_loss = 0.790359377861023\n",
      "epoch n°3948 : train_loss = 2.016389846801758, val_loss = 0.7906278967857361\n",
      "epoch n°3949 : train_loss = 2.025355339050293, val_loss = 0.7911612391471863\n",
      "epoch n°3950 : train_loss = 2.024991035461426, val_loss = 0.791376531124115\n",
      "epoch n°3951 : train_loss = 2.024533271789551, val_loss = 0.7958576679229736\n",
      "epoch n°3952 : train_loss = 2.016995906829834, val_loss = 0.7896574139595032\n",
      "epoch n°3953 : train_loss = 2.019347906112671, val_loss = 0.7920740842819214\n",
      "epoch n°3954 : train_loss = 2.01788592338562, val_loss = 0.7879757285118103\n",
      "epoch n°3955 : train_loss = 2.023345947265625, val_loss = 0.7905037999153137\n",
      "epoch n°3956 : train_loss = 2.024041175842285, val_loss = 0.7911445498466492\n",
      "epoch n°3957 : train_loss = 2.029890537261963, val_loss = 0.792719304561615\n",
      "epoch n°3958 : train_loss = 2.0141100883483887, val_loss = 0.7947094440460205\n",
      "epoch n°3959 : train_loss = 2.0207667350769043, val_loss = 0.7934000492095947\n",
      "epoch n°3960 : train_loss = 2.0243349075317383, val_loss = 0.7954598665237427\n",
      "epoch n°3961 : train_loss = 2.013045310974121, val_loss = 0.7918214201927185\n",
      "epoch n°3962 : train_loss = 2.015000820159912, val_loss = 0.7914047241210938\n",
      "epoch n°3963 : train_loss = 2.019055128097534, val_loss = 0.7953813672065735\n",
      "epoch n°3964 : train_loss = 2.0162932872772217, val_loss = 0.790856659412384\n",
      "epoch n°3965 : train_loss = 2.0291647911071777, val_loss = 0.7955379486083984\n",
      "epoch n°3966 : train_loss = 2.0229125022888184, val_loss = 0.793167233467102\n",
      "epoch n°3967 : train_loss = 2.027784824371338, val_loss = 0.7913795113563538\n",
      "epoch n°3968 : train_loss = 2.0215401649475098, val_loss = 0.792168140411377\n",
      "epoch n°3969 : train_loss = 2.0183475017547607, val_loss = 0.7959617376327515\n",
      "epoch n°3970 : train_loss = 2.013015031814575, val_loss = 0.7935473322868347\n",
      "epoch n°3971 : train_loss = 2.023871660232544, val_loss = 0.7915219664573669\n",
      "epoch n°3972 : train_loss = 2.0225186347961426, val_loss = 0.7906640768051147\n",
      "epoch n°3973 : train_loss = 2.024846076965332, val_loss = 0.7913349866867065\n",
      "epoch n°3974 : train_loss = 2.0279996395111084, val_loss = 0.7918133735656738\n",
      "epoch n°3975 : train_loss = 2.024855136871338, val_loss = 0.7959514260292053\n",
      "epoch n°3976 : train_loss = 2.0183725357055664, val_loss = 0.7955331206321716\n",
      "epoch n°3977 : train_loss = 2.0132954120635986, val_loss = 0.793156087398529\n",
      "epoch n°3978 : train_loss = 2.027339220046997, val_loss = 0.7912734746932983\n",
      "epoch n°3979 : train_loss = 2.012629747390747, val_loss = 0.7937113046646118\n",
      "epoch n°3980 : train_loss = 2.0204827785491943, val_loss = 0.791440486907959\n",
      "epoch n°3981 : train_loss = 2.0269200801849365, val_loss = 0.7946621775627136\n",
      "epoch n°3982 : train_loss = 2.02079176902771, val_loss = 0.7880573272705078\n",
      "epoch n°3983 : train_loss = 2.019083023071289, val_loss = 0.7960377335548401\n",
      "epoch n°3984 : train_loss = 2.0302340984344482, val_loss = 0.7914553284645081\n",
      "epoch n°3985 : train_loss = 2.0156397819519043, val_loss = 0.7936978936195374\n",
      "epoch n°3986 : train_loss = 2.0199663639068604, val_loss = 0.7923445105552673\n",
      "epoch n°3987 : train_loss = 2.023005485534668, val_loss = 0.7924913763999939\n",
      "epoch n°3988 : train_loss = 2.023829460144043, val_loss = 0.7913172841072083\n",
      "epoch n°3989 : train_loss = 2.0293145179748535, val_loss = 0.7917067408561707\n",
      "epoch n°3990 : train_loss = 2.023580312728882, val_loss = 0.792885422706604\n",
      "epoch n°3991 : train_loss = 2.0264339447021484, val_loss = 0.7918334007263184\n",
      "epoch n°3992 : train_loss = 2.0220043659210205, val_loss = 0.7924627661705017\n",
      "epoch n°3993 : train_loss = 2.0253374576568604, val_loss = 0.7900872826576233\n",
      "epoch n°3994 : train_loss = 2.029330015182495, val_loss = 0.7902324795722961\n",
      "epoch n°3995 : train_loss = 2.011768102645874, val_loss = 0.792637825012207\n",
      "epoch n°3996 : train_loss = 2.0227832794189453, val_loss = 0.7898492217063904\n",
      "epoch n°3997 : train_loss = 2.0174427032470703, val_loss = 0.7951529026031494\n",
      "epoch n°3998 : train_loss = 2.0227112770080566, val_loss = 0.7889707088470459\n",
      "epoch n°3999 : train_loss = 2.0231971740722656, val_loss = 0.791540265083313\n",
      "epoch n°4000 : train_loss = 2.0241928100585938, val_loss = 0.792693018913269\n",
      "epoch n°4001 : train_loss = 2.016683340072632, val_loss = 0.7885810732841492\n",
      "epoch n°4002 : train_loss = 2.018864393234253, val_loss = 0.7940509915351868\n",
      "epoch n°4003 : train_loss = 2.0201871395111084, val_loss = 0.7941518425941467\n",
      "epoch n°4004 : train_loss = 2.0209665298461914, val_loss = 0.7905940413475037\n",
      "epoch n°4005 : train_loss = 2.014976978302002, val_loss = 0.7879876494407654\n",
      "epoch n°4006 : train_loss = 2.0208239555358887, val_loss = 0.7929556965827942\n",
      "epoch n°4007 : train_loss = 2.0222980976104736, val_loss = 0.7946599125862122\n",
      "epoch n°4008 : train_loss = 2.02998423576355, val_loss = 0.7943297028541565\n",
      "epoch n°4009 : train_loss = 2.021087884902954, val_loss = 0.7929699420928955\n",
      "epoch n°4010 : train_loss = 2.0169122219085693, val_loss = 0.7927755117416382\n",
      "epoch n°4011 : train_loss = 2.0144214630126953, val_loss = 0.792578399181366\n",
      "epoch n°4012 : train_loss = 2.021604537963867, val_loss = 0.7911995053291321\n",
      "epoch n°4013 : train_loss = 2.0241832733154297, val_loss = 0.7944889068603516\n",
      "epoch n°4014 : train_loss = 2.023247718811035, val_loss = 0.792910635471344\n",
      "epoch n°4015 : train_loss = 2.0278525352478027, val_loss = 0.7920821905136108\n",
      "epoch n°4016 : train_loss = 2.020975351333618, val_loss = 0.7941266894340515\n",
      "epoch n°4017 : train_loss = 2.0213568210601807, val_loss = 0.7913862466812134\n",
      "epoch n°4018 : train_loss = 2.015885591506958, val_loss = 0.790271520614624\n",
      "epoch n°4019 : train_loss = 2.013939142227173, val_loss = 0.7926598787307739\n",
      "epoch n°4020 : train_loss = 2.0248589515686035, val_loss = 0.7955449223518372\n",
      "epoch n°4021 : train_loss = 2.028247594833374, val_loss = 0.7931700348854065\n",
      "epoch n°4022 : train_loss = 2.0231995582580566, val_loss = 0.7923506498336792\n",
      "epoch n°4023 : train_loss = 2.0128674507141113, val_loss = 0.7913284301757812\n",
      "epoch n°4024 : train_loss = 2.0201566219329834, val_loss = 0.7881839871406555\n",
      "epoch n°4025 : train_loss = 2.0222573280334473, val_loss = 0.7917834520339966\n",
      "epoch n°4026 : train_loss = 2.0200278759002686, val_loss = 0.7919877767562866\n",
      "epoch n°4027 : train_loss = 2.0182158946990967, val_loss = 0.7948256134986877\n",
      "epoch n°4028 : train_loss = 2.0317726135253906, val_loss = 0.7922470569610596\n",
      "epoch n°4029 : train_loss = 2.014275550842285, val_loss = 0.7941533923149109\n",
      "epoch n°4030 : train_loss = 2.021327257156372, val_loss = 0.7929810881614685\n",
      "epoch n°4031 : train_loss = 2.021280527114868, val_loss = 0.7898409962654114\n",
      "epoch n°4032 : train_loss = 2.025125741958618, val_loss = 0.7937925457954407\n",
      "epoch n°4033 : train_loss = 2.024919033050537, val_loss = 0.7951614260673523\n",
      "epoch n°4034 : train_loss = 2.02569842338562, val_loss = 0.792314887046814\n",
      "epoch n°4035 : train_loss = 2.0225493907928467, val_loss = 0.7937140464782715\n",
      "epoch n°4036 : train_loss = 2.0246129035949707, val_loss = 0.7908396124839783\n",
      "epoch n°4037 : train_loss = 2.0218117237091064, val_loss = 0.7907813191413879\n",
      "epoch n°4038 : train_loss = 2.0202202796936035, val_loss = 0.7937271595001221\n",
      "epoch n°4039 : train_loss = 2.021221876144409, val_loss = 0.7899748086929321\n",
      "epoch n°4040 : train_loss = 2.02702260017395, val_loss = 0.7921856641769409\n",
      "epoch n°4041 : train_loss = 2.0167434215545654, val_loss = 0.7923507690429688\n",
      "epoch n°4042 : train_loss = 2.0280559062957764, val_loss = 0.788567304611206\n",
      "epoch n°4043 : train_loss = 2.01542592048645, val_loss = 0.7928707599639893\n",
      "epoch n°4044 : train_loss = 2.018643379211426, val_loss = 0.7956505417823792\n",
      "epoch n°4045 : train_loss = 2.0222396850585938, val_loss = 0.7930238842964172\n",
      "epoch n°4046 : train_loss = 2.0160300731658936, val_loss = 0.793238639831543\n",
      "epoch n°4047 : train_loss = 2.0218050479888916, val_loss = 0.7953562140464783\n",
      "epoch n°4048 : train_loss = 2.020430088043213, val_loss = 0.790756106376648\n",
      "epoch n°4049 : train_loss = 2.0305614471435547, val_loss = 0.7929010391235352\n",
      "epoch n°4050 : train_loss = 2.022351026535034, val_loss = 0.7906328439712524\n",
      "epoch n°4051 : train_loss = 2.0208580493927, val_loss = 0.7933212518692017\n",
      "epoch n°4052 : train_loss = 2.021008014678955, val_loss = 0.7958017587661743\n",
      "epoch n°4053 : train_loss = 2.0226242542266846, val_loss = 0.7923368811607361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°4054 : train_loss = 2.011915445327759, val_loss = 0.7915656566619873\n",
      "epoch n°4055 : train_loss = 2.019590139389038, val_loss = 0.7918469905853271\n",
      "epoch n°4056 : train_loss = 2.015407085418701, val_loss = 0.7925393581390381\n",
      "epoch n°4057 : train_loss = 2.0242538452148438, val_loss = 0.7963223457336426\n",
      "epoch n°4058 : train_loss = 2.0255000591278076, val_loss = 0.7936877012252808\n",
      "epoch n°4059 : train_loss = 2.0272185802459717, val_loss = 0.793529748916626\n",
      "epoch n°4060 : train_loss = 2.01326060295105, val_loss = 0.7948840260505676\n",
      "epoch n°4061 : train_loss = 2.0312740802764893, val_loss = 0.7959507703781128\n",
      "epoch n°4062 : train_loss = 2.016033411026001, val_loss = 0.7936291694641113\n",
      "epoch n°4063 : train_loss = 2.0246336460113525, val_loss = 0.7954610586166382\n",
      "epoch n°4064 : train_loss = 2.0139195919036865, val_loss = 0.7941614985466003\n",
      "epoch n°4065 : train_loss = 2.032139778137207, val_loss = 0.7926588654518127\n",
      "epoch n°4066 : train_loss = 2.018894910812378, val_loss = 0.793250322341919\n",
      "epoch n°4067 : train_loss = 2.0293705463409424, val_loss = 0.7953593134880066\n",
      "epoch n°4068 : train_loss = 2.018730640411377, val_loss = 0.794751763343811\n",
      "epoch n°4069 : train_loss = 2.0169260501861572, val_loss = 0.7958335280418396\n",
      "epoch n°4070 : train_loss = 2.0116586685180664, val_loss = 0.7933432459831238\n",
      "epoch n°4071 : train_loss = 2.022080183029175, val_loss = 0.7974352240562439\n",
      "epoch n°4072 : train_loss = 2.023519515991211, val_loss = 0.7941077947616577\n",
      "epoch n°4073 : train_loss = 2.019618034362793, val_loss = 0.7880491018295288\n",
      "epoch n°4074 : train_loss = 2.0201995372772217, val_loss = 0.7957627177238464\n",
      "epoch n°4075 : train_loss = 2.019441843032837, val_loss = 0.790336012840271\n",
      "epoch n°4076 : train_loss = 2.021109104156494, val_loss = 0.7909429669380188\n",
      "epoch n°4077 : train_loss = 2.0194013118743896, val_loss = 0.7910044193267822\n",
      "epoch n°4078 : train_loss = 2.0171101093292236, val_loss = 0.7966443300247192\n",
      "epoch n°4079 : train_loss = 2.022557020187378, val_loss = 0.7928314208984375\n",
      "55018.66205525398\n"
     ]
    }
   ],
   "source": [
    "params = get_params(32,4,8,32,4,0.1)\n",
    "model = AttNet(*params,clf_dims=[1024,256,64])\n",
    "model = model.to(device)\n",
    "optim = torch.optim.AdamW(model.parameters(),lr = 0.0003)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optim,16,2)\n",
    "state = State(model,optim,scheduler)\n",
    "\n",
    "fname = \"models/stateATT_4L_fixed.pth\" \n",
    "start = time.time()\n",
    "Train,Eval,_ = main(train_dataloader, val_dataloader,fname=fname,epochs=4080,state=state,use_mut=False)\n",
    "stop = time.time()\n",
    "print(stop-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7c09303e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f487bdbe970>]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(len(Train)),Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7c0f6a20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f489062ed30>]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(len(Eval)),Eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d1c37ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVALUATING ON TRAIN DATA : \n",
      "score_train = 0.7223265171051025\n",
      "\n",
      "EVALUATING ON TEST DATA : \n",
      "score_test = 0.8075515031814575\n",
      "\n",
      "EVALUATING ON VAL DATA : \n",
      "score_val = 0.7921802997589111\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fname = \"models/stateATT_4L_fixed.pth\" \n",
    "SCORES = eval_model(fname,train_dataloader,test_dataloader,val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d22da8f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVALUATING ON TRAIN DATA : \n",
      "score_train = 0.7441562414169312\n",
      "\n",
      "EVALUATING ON TEST DATA : \n",
      "score_test = 0.8092960715293884\n",
      "\n",
      "EVALUATING ON VAL DATA : \n",
      "score_val = 0.7950857877731323\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fname = \"models/stateATT_4L_fixed_best.pth\" \n",
    "SCORES = eval_model(fname,train_dataloader,test_dataloader,val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "846e0e7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°0 : train_loss = 2.7893388271331787, val_loss = 0.8839114904403687\n",
      "epoch n°1 : train_loss = 2.4898018836975098, val_loss = 0.8373404145240784\n",
      "epoch n°2 : train_loss = 2.390526294708252, val_loss = 0.8265328407287598\n",
      "epoch n°3 : train_loss = 2.3613243103027344, val_loss = 0.8177996873855591\n",
      "epoch n°4 : train_loss = 2.3465216159820557, val_loss = 0.8149544596672058\n",
      "epoch n°5 : train_loss = 2.3262195587158203, val_loss = 0.8174319267272949\n",
      "epoch n°6 : train_loss = 2.3259148597717285, val_loss = 0.8157039284706116\n",
      "epoch n°7 : train_loss = 2.326080799102783, val_loss = 0.8144814968109131\n",
      "epoch n°8 : train_loss = 2.3109731674194336, val_loss = 0.811331033706665\n",
      "epoch n°9 : train_loss = 2.3017523288726807, val_loss = 0.810633659362793\n",
      "epoch n°10 : train_loss = 2.298412322998047, val_loss = 0.8130637407302856\n",
      "epoch n°11 : train_loss = 2.295822858810425, val_loss = 0.8089595437049866\n",
      "epoch n°12 : train_loss = 2.2931954860687256, val_loss = 0.8039268851280212\n",
      "epoch n°13 : train_loss = 2.2879607677459717, val_loss = 0.8048185110092163\n",
      "epoch n°14 : train_loss = 2.286160469055176, val_loss = 0.807779848575592\n",
      "epoch n°15 : train_loss = 2.2938997745513916, val_loss = 0.8047848343849182\n",
      "epoch n°16 : train_loss = 2.3164172172546387, val_loss = 0.8155310153961182\n",
      "epoch n°17 : train_loss = 2.3158953189849854, val_loss = 0.8096640706062317\n",
      "epoch n°18 : train_loss = 2.297165632247925, val_loss = 0.8103508949279785\n",
      "epoch n°19 : train_loss = 2.3031201362609863, val_loss = 0.8112130761146545\n",
      "epoch n°20 : train_loss = 2.29646372795105, val_loss = 0.8112418055534363\n",
      "epoch n°21 : train_loss = 2.2959845066070557, val_loss = 0.8098022937774658\n",
      "epoch n°22 : train_loss = 2.2922234535217285, val_loss = 0.8098325729370117\n",
      "epoch n°23 : train_loss = 2.293717622756958, val_loss = 0.8045814037322998\n",
      "epoch n°24 : train_loss = 2.2720701694488525, val_loss = 0.8079321980476379\n",
      "epoch n°25 : train_loss = 2.2802255153656006, val_loss = 0.8068377375602722\n",
      "epoch n°26 : train_loss = 2.2797985076904297, val_loss = 0.8062649369239807\n",
      "epoch n°27 : train_loss = 2.2643306255340576, val_loss = 0.8045995235443115\n",
      "epoch n°28 : train_loss = 2.2727396488189697, val_loss = 0.804632842540741\n",
      "epoch n°29 : train_loss = 2.259165048599243, val_loss = 0.8071660995483398\n",
      "epoch n°30 : train_loss = 2.2573788166046143, val_loss = 0.8069589138031006\n",
      "epoch n°31 : train_loss = 2.2541232109069824, val_loss = 0.8046479821205139\n",
      "epoch n°32 : train_loss = 2.2586517333984375, val_loss = 0.8050678372383118\n",
      "epoch n°33 : train_loss = 2.2442405223846436, val_loss = 0.8029561042785645\n",
      "epoch n°34 : train_loss = 2.249525308609009, val_loss = 0.7988607883453369\n",
      "epoch n°35 : train_loss = 2.252915143966675, val_loss = 0.8039697408676147\n",
      "epoch n°36 : train_loss = 2.245807647705078, val_loss = 0.7992875576019287\n",
      "epoch n°37 : train_loss = 2.2467143535614014, val_loss = 0.7978991270065308\n",
      "epoch n°38 : train_loss = 2.247450590133667, val_loss = 0.7996751666069031\n",
      "epoch n°39 : train_loss = 2.2541849613189697, val_loss = 0.8052897453308105\n",
      "epoch n°40 : train_loss = 2.2394728660583496, val_loss = 0.8012807369232178\n",
      "epoch n°41 : train_loss = 2.2466883659362793, val_loss = 0.8002413511276245\n",
      "epoch n°42 : train_loss = 2.241407871246338, val_loss = 0.8020609617233276\n",
      "epoch n°43 : train_loss = 2.2356863021850586, val_loss = 0.8005143404006958\n",
      "epoch n°44 : train_loss = 2.247807264328003, val_loss = 0.796440601348877\n",
      "epoch n°45 : train_loss = 2.232215404510498, val_loss = 0.7993123531341553\n",
      "epoch n°46 : train_loss = 2.227173328399658, val_loss = 0.8002817630767822\n",
      "epoch n°47 : train_loss = 2.22809100151062, val_loss = 0.8020580410957336\n",
      "epoch n°48 : train_loss = 2.254528760910034, val_loss = 0.8053920865058899\n",
      "epoch n°49 : train_loss = 2.2519497871398926, val_loss = 0.8072658181190491\n",
      "epoch n°50 : train_loss = 2.256714344024658, val_loss = 0.8016602396965027\n",
      "epoch n°51 : train_loss = 2.265313148498535, val_loss = 0.8039627075195312\n",
      "epoch n°52 : train_loss = 2.252675771713257, val_loss = 0.8039575219154358\n",
      "epoch n°53 : train_loss = 2.2547414302825928, val_loss = 0.8030911684036255\n",
      "epoch n°54 : train_loss = 2.258504629135132, val_loss = 0.803953230381012\n",
      "epoch n°55 : train_loss = 2.250537395477295, val_loss = 0.8071383833885193\n",
      "epoch n°56 : train_loss = 2.248152017593384, val_loss = 0.7998761534690857\n",
      "epoch n°57 : train_loss = 2.2419514656066895, val_loss = 0.8079667687416077\n",
      "epoch n°58 : train_loss = 2.243366003036499, val_loss = 0.8035622239112854\n",
      "epoch n°59 : train_loss = 2.2473104000091553, val_loss = 0.8008348941802979\n",
      "epoch n°60 : train_loss = 2.250121593475342, val_loss = 0.8040560483932495\n",
      "epoch n°61 : train_loss = 2.233426094055176, val_loss = 0.8050318360328674\n",
      "epoch n°62 : train_loss = 2.240983724594116, val_loss = 0.8021906614303589\n",
      "epoch n°63 : train_loss = 2.238006830215454, val_loss = 0.800773024559021\n",
      "epoch n°64 : train_loss = 2.2385268211364746, val_loss = 0.801062822341919\n",
      "epoch n°65 : train_loss = 2.236950159072876, val_loss = 0.802711009979248\n",
      "epoch n°66 : train_loss = 2.23834490776062, val_loss = 0.8050060272216797\n",
      "epoch n°67 : train_loss = 2.2422845363616943, val_loss = 0.8028672933578491\n",
      "epoch n°68 : train_loss = 2.2362332344055176, val_loss = 0.8009079694747925\n",
      "epoch n°69 : train_loss = 2.234379529953003, val_loss = 0.7990145683288574\n",
      "epoch n°70 : train_loss = 2.228734016418457, val_loss = 0.7983298301696777\n",
      "epoch n°71 : train_loss = 2.236903190612793, val_loss = 0.8025715947151184\n",
      "epoch n°72 : train_loss = 2.2406184673309326, val_loss = 0.8025815486907959\n",
      "epoch n°73 : train_loss = 2.2267866134643555, val_loss = 0.8006616234779358\n",
      "epoch n°74 : train_loss = 2.2276651859283447, val_loss = 0.8057438731193542\n",
      "epoch n°75 : train_loss = 2.2357895374298096, val_loss = 0.8002171516418457\n",
      "epoch n°76 : train_loss = 2.230407238006592, val_loss = 0.7988361716270447\n",
      "epoch n°77 : train_loss = 2.2278687953948975, val_loss = 0.8025425672531128\n",
      "epoch n°78 : train_loss = 2.2202956676483154, val_loss = 0.7979305982589722\n",
      "epoch n°79 : train_loss = 2.219428777694702, val_loss = 0.8018122315406799\n",
      "epoch n°80 : train_loss = 2.225421190261841, val_loss = 0.8012047410011292\n",
      "epoch n°81 : train_loss = 2.2134273052215576, val_loss = 0.8003658056259155\n",
      "epoch n°82 : train_loss = 2.2125751972198486, val_loss = 0.7988031506538391\n",
      "epoch n°83 : train_loss = 2.2166123390197754, val_loss = 0.8000462651252747\n",
      "epoch n°84 : train_loss = 2.2163944244384766, val_loss = 0.7955529093742371\n",
      "epoch n°85 : train_loss = 2.217750072479248, val_loss = 0.7989006042480469\n",
      "epoch n°86 : train_loss = 2.2211618423461914, val_loss = 0.8006942868232727\n",
      "epoch n°87 : train_loss = 2.2212789058685303, val_loss = 0.7987470030784607\n",
      "epoch n°88 : train_loss = 2.2183403968811035, val_loss = 0.7983897924423218\n",
      "epoch n°89 : train_loss = 2.20983624458313, val_loss = 0.7985774874687195\n",
      "epoch n°90 : train_loss = 2.2081871032714844, val_loss = 0.7993360161781311\n",
      "epoch n°91 : train_loss = 2.2105748653411865, val_loss = 0.7972619533538818\n",
      "epoch n°92 : train_loss = 2.2133634090423584, val_loss = 0.804203987121582\n",
      "epoch n°93 : train_loss = 2.2072396278381348, val_loss = 0.7983841896057129\n",
      "epoch n°94 : train_loss = 2.2152297496795654, val_loss = 0.799788236618042\n",
      "epoch n°95 : train_loss = 2.2009241580963135, val_loss = 0.7976682782173157\n",
      "epoch n°96 : train_loss = 2.2007226943969727, val_loss = 0.7972981929779053\n",
      "epoch n°97 : train_loss = 2.2041263580322266, val_loss = 0.7945941090583801\n",
      "epoch n°98 : train_loss = 2.202498197555542, val_loss = 0.7983781695365906\n",
      "epoch n°99 : train_loss = 2.2079522609710693, val_loss = 0.8000661730766296\n",
      "epoch n°100 : train_loss = 2.2031993865966797, val_loss = 0.794899046421051\n",
      "epoch n°101 : train_loss = 2.2026238441467285, val_loss = 0.7948073744773865\n",
      "epoch n°102 : train_loss = 2.2007811069488525, val_loss = 0.796191394329071\n",
      "epoch n°103 : train_loss = 2.1938157081604004, val_loss = 0.7979274392127991\n",
      "epoch n°104 : train_loss = 2.195467710494995, val_loss = 0.7965552806854248\n",
      "epoch n°105 : train_loss = 2.2041983604431152, val_loss = 0.7972970008850098\n",
      "epoch n°106 : train_loss = 2.19748854637146, val_loss = 0.7990993857383728\n",
      "epoch n°107 : train_loss = 2.21089506149292, val_loss = 0.7951217889785767\n",
      "epoch n°108 : train_loss = 2.2058379650115967, val_loss = 0.7952207922935486\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°109 : train_loss = 2.2077887058258057, val_loss = 0.7981290817260742\n",
      "epoch n°110 : train_loss = 2.19580078125, val_loss = 0.7910687327384949\n",
      "epoch n°111 : train_loss = 2.195767641067505, val_loss = 0.7927121520042419\n",
      "epoch n°112 : train_loss = 2.2199482917785645, val_loss = 0.8004888892173767\n",
      "epoch n°113 : train_loss = 2.219757080078125, val_loss = 0.8028534650802612\n",
      "epoch n°114 : train_loss = 2.2275664806365967, val_loss = 0.7997846603393555\n",
      "epoch n°115 : train_loss = 2.2217085361480713, val_loss = 0.8028562664985657\n",
      "epoch n°116 : train_loss = 2.225337028503418, val_loss = 0.7983916997909546\n",
      "epoch n°117 : train_loss = 2.224213123321533, val_loss = 0.8058229684829712\n",
      "epoch n°118 : train_loss = 2.2159183025360107, val_loss = 0.7965304255485535\n",
      "epoch n°119 : train_loss = 2.222975254058838, val_loss = 0.7993043661117554\n",
      "epoch n°120 : train_loss = 2.2240231037139893, val_loss = 0.8014844059944153\n",
      "epoch n°121 : train_loss = 2.2223763465881348, val_loss = 0.8041383624076843\n",
      "epoch n°122 : train_loss = 2.2223775386810303, val_loss = 0.7996618151664734\n",
      "epoch n°123 : train_loss = 2.217999219894409, val_loss = 0.8067009449005127\n",
      "epoch n°124 : train_loss = 2.22432541847229, val_loss = 0.8017907738685608\n",
      "epoch n°125 : train_loss = 2.2196526527404785, val_loss = 0.8006638884544373\n",
      "epoch n°126 : train_loss = 2.2216219902038574, val_loss = 0.7992029786109924\n",
      "epoch n°127 : train_loss = 2.211562156677246, val_loss = 0.8030370473861694\n",
      "epoch n°128 : train_loss = 2.221652030944824, val_loss = 0.8048185110092163\n",
      "epoch n°129 : train_loss = 2.2192554473876953, val_loss = 0.8024930357933044\n",
      "epoch n°130 : train_loss = 2.2151448726654053, val_loss = 0.8012833595275879\n",
      "epoch n°131 : train_loss = 2.2134575843811035, val_loss = 0.8010954260826111\n",
      "epoch n°132 : train_loss = 2.207435131072998, val_loss = 0.8026264309883118\n",
      "epoch n°133 : train_loss = 2.214066982269287, val_loss = 0.801318883895874\n",
      "epoch n°134 : train_loss = 2.2214622497558594, val_loss = 0.7978482246398926\n",
      "epoch n°135 : train_loss = 2.2102043628692627, val_loss = 0.8006542325019836\n",
      "epoch n°136 : train_loss = 2.2249279022216797, val_loss = 0.80179762840271\n",
      "epoch n°137 : train_loss = 2.21877384185791, val_loss = 0.8002709150314331\n",
      "epoch n°138 : train_loss = 2.216622829437256, val_loss = 0.8029717803001404\n",
      "epoch n°139 : train_loss = 2.217061996459961, val_loss = 0.8009283542633057\n",
      "epoch n°140 : train_loss = 2.2148380279541016, val_loss = 0.7991784811019897\n",
      "epoch n°141 : train_loss = 2.204289436340332, val_loss = 0.7997912168502808\n",
      "epoch n°142 : train_loss = 2.2064311504364014, val_loss = 0.8054123520851135\n",
      "epoch n°143 : train_loss = 2.2101387977600098, val_loss = 0.8023170828819275\n",
      "epoch n°144 : train_loss = 2.214597463607788, val_loss = 0.7980644106864929\n",
      "epoch n°145 : train_loss = 2.2047178745269775, val_loss = 0.803561270236969\n",
      "epoch n°146 : train_loss = 2.20094895362854, val_loss = 0.7977370023727417\n",
      "epoch n°147 : train_loss = 2.2008774280548096, val_loss = 0.7986702919006348\n",
      "epoch n°148 : train_loss = 2.2084596157073975, val_loss = 0.8011786937713623\n",
      "epoch n°149 : train_loss = 2.2095837593078613, val_loss = 0.797349750995636\n",
      "epoch n°150 : train_loss = 2.2095377445220947, val_loss = 0.7998768091201782\n",
      "epoch n°151 : train_loss = 2.2054378986358643, val_loss = 0.8028526306152344\n",
      "epoch n°152 : train_loss = 2.199942111968994, val_loss = 0.7992743849754333\n",
      "epoch n°153 : train_loss = 2.2015860080718994, val_loss = 0.8026503324508667\n",
      "epoch n°154 : train_loss = 2.199021577835083, val_loss = 0.8017392158508301\n",
      "epoch n°155 : train_loss = 2.2028093338012695, val_loss = 0.7976293563842773\n",
      "epoch n°156 : train_loss = 2.1900415420532227, val_loss = 0.7953971028327942\n",
      "epoch n°157 : train_loss = 2.1947855949401855, val_loss = 0.7988136410713196\n",
      "epoch n°158 : train_loss = 2.1986238956451416, val_loss = 0.793977677822113\n",
      "epoch n°159 : train_loss = 2.192049264907837, val_loss = 0.8034939765930176\n",
      "epoch n°160 : train_loss = 2.195009231567383, val_loss = 0.7948578000068665\n",
      "epoch n°161 : train_loss = 2.1947362422943115, val_loss = 0.7992877960205078\n",
      "epoch n°162 : train_loss = 2.1978847980499268, val_loss = 0.802065372467041\n",
      "epoch n°163 : train_loss = 2.1938369274139404, val_loss = 0.7951363325119019\n",
      "epoch n°164 : train_loss = 2.1956584453582764, val_loss = 0.8021218180656433\n",
      "epoch n°165 : train_loss = 2.1862621307373047, val_loss = 0.8000980019569397\n",
      "epoch n°166 : train_loss = 2.19079327583313, val_loss = 0.798545241355896\n",
      "epoch n°167 : train_loss = 2.2011053562164307, val_loss = 0.8012475371360779\n",
      "epoch n°168 : train_loss = 2.182159185409546, val_loss = 0.7998730540275574\n",
      "epoch n°169 : train_loss = 2.1967005729675293, val_loss = 0.797960638999939\n",
      "epoch n°170 : train_loss = 2.189786195755005, val_loss = 0.7968456149101257\n",
      "epoch n°171 : train_loss = 2.189967155456543, val_loss = 0.7992323637008667\n",
      "epoch n°172 : train_loss = 2.1930108070373535, val_loss = 0.7997872233390808\n",
      "epoch n°173 : train_loss = 2.1991465091705322, val_loss = 0.7948715090751648\n",
      "epoch n°174 : train_loss = 2.195720672607422, val_loss = 0.796809732913971\n",
      "epoch n°175 : train_loss = 2.1950719356536865, val_loss = 0.8015065789222717\n",
      "epoch n°176 : train_loss = 2.191122531890869, val_loss = 0.8027273416519165\n",
      "epoch n°177 : train_loss = 2.192882776260376, val_loss = 0.7957106828689575\n",
      "epoch n°178 : train_loss = 2.187676429748535, val_loss = 0.7975558638572693\n",
      "epoch n°179 : train_loss = 2.18656325340271, val_loss = 0.7974739670753479\n",
      "epoch n°180 : train_loss = 2.183708429336548, val_loss = 0.7934137582778931\n",
      "epoch n°181 : train_loss = 2.173243284225464, val_loss = 0.7947881817817688\n",
      "epoch n°182 : train_loss = 2.1761410236358643, val_loss = 0.7992858290672302\n",
      "epoch n°183 : train_loss = 2.1726276874542236, val_loss = 0.7974214553833008\n",
      "epoch n°184 : train_loss = 2.1803505420684814, val_loss = 0.798091471195221\n",
      "epoch n°185 : train_loss = 2.1826884746551514, val_loss = 0.798941433429718\n",
      "epoch n°186 : train_loss = 2.1843559741973877, val_loss = 0.796868085861206\n",
      "epoch n°187 : train_loss = 2.1758625507354736, val_loss = 0.7956730127334595\n",
      "epoch n°188 : train_loss = 2.188699960708618, val_loss = 0.7945760488510132\n",
      "epoch n°189 : train_loss = 2.1652133464813232, val_loss = 0.8007605075836182\n",
      "epoch n°190 : train_loss = 2.1770570278167725, val_loss = 0.7996550798416138\n",
      "epoch n°191 : train_loss = 2.179520845413208, val_loss = 0.7931028008460999\n",
      "epoch n°192 : train_loss = 2.178837299346924, val_loss = 0.795881986618042\n",
      "epoch n°193 : train_loss = 2.1783344745635986, val_loss = 0.7972849607467651\n",
      "epoch n°194 : train_loss = 2.175123691558838, val_loss = 0.7976887226104736\n",
      "epoch n°195 : train_loss = 2.175168037414551, val_loss = 0.7946537733078003\n",
      "epoch n°196 : train_loss = 2.1734087467193604, val_loss = 0.7985396981239319\n",
      "epoch n°197 : train_loss = 2.1751294136047363, val_loss = 0.7990785241127014\n",
      "epoch n°198 : train_loss = 2.1761913299560547, val_loss = 0.7983896136283875\n",
      "epoch n°199 : train_loss = 2.1770801544189453, val_loss = 0.7973593473434448\n",
      "epoch n°200 : train_loss = 2.1762797832489014, val_loss = 0.7953691482543945\n",
      "epoch n°201 : train_loss = 2.167365074157715, val_loss = 0.795340895652771\n",
      "epoch n°202 : train_loss = 2.181256055831909, val_loss = 0.7965003252029419\n",
      "epoch n°203 : train_loss = 2.1723997592926025, val_loss = 0.7990787625312805\n",
      "epoch n°204 : train_loss = 2.171250104904175, val_loss = 0.7992032170295715\n",
      "epoch n°205 : train_loss = 2.171342134475708, val_loss = 0.7956389784812927\n",
      "epoch n°206 : train_loss = 2.1705822944641113, val_loss = 0.7965806126594543\n",
      "epoch n°207 : train_loss = 2.1768839359283447, val_loss = 0.7987878918647766\n",
      "epoch n°208 : train_loss = 2.164008140563965, val_loss = 0.7995103001594543\n",
      "epoch n°209 : train_loss = 2.170337438583374, val_loss = 0.793329656124115\n",
      "epoch n°210 : train_loss = 2.170217275619507, val_loss = 0.7975031137466431\n",
      "epoch n°211 : train_loss = 2.169790506362915, val_loss = 0.7924119830131531\n",
      "epoch n°212 : train_loss = 2.164177894592285, val_loss = 0.7955544590950012\n",
      "epoch n°213 : train_loss = 2.1771767139434814, val_loss = 0.7963098883628845\n",
      "epoch n°214 : train_loss = 2.1728641986846924, val_loss = 0.7928692102432251\n",
      "epoch n°215 : train_loss = 2.1712276935577393, val_loss = 0.7947084307670593\n",
      "epoch n°216 : train_loss = 2.165802478790283, val_loss = 0.7951785326004028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°217 : train_loss = 2.1714529991149902, val_loss = 0.7947762608528137\n",
      "epoch n°218 : train_loss = 2.16259503364563, val_loss = 0.7965410351753235\n",
      "epoch n°219 : train_loss = 2.163959503173828, val_loss = 0.7942761182785034\n",
      "epoch n°220 : train_loss = 2.175962209701538, val_loss = 0.7930330038070679\n",
      "epoch n°221 : train_loss = 2.1706016063690186, val_loss = 0.7956581115722656\n",
      "epoch n°222 : train_loss = 2.1627562046051025, val_loss = 0.7975071668624878\n",
      "epoch n°223 : train_loss = 2.1708924770355225, val_loss = 0.793503999710083\n",
      "epoch n°224 : train_loss = 2.1674094200134277, val_loss = 0.7983896732330322\n",
      "epoch n°225 : train_loss = 2.16163969039917, val_loss = 0.7964968681335449\n",
      "epoch n°226 : train_loss = 2.161153793334961, val_loss = 0.7957410216331482\n",
      "epoch n°227 : train_loss = 2.16245436668396, val_loss = 0.7898058891296387\n",
      "epoch n°228 : train_loss = 2.1568570137023926, val_loss = 0.7924051284790039\n",
      "epoch n°229 : train_loss = 2.1658012866973877, val_loss = 0.797581672668457\n",
      "epoch n°230 : train_loss = 2.1685264110565186, val_loss = 0.7937449812889099\n",
      "epoch n°231 : train_loss = 2.1579737663269043, val_loss = 0.7935594916343689\n",
      "epoch n°232 : train_loss = 2.161794424057007, val_loss = 0.7940225601196289\n",
      "epoch n°233 : train_loss = 2.157742977142334, val_loss = 0.7932872176170349\n",
      "epoch n°234 : train_loss = 2.1671247482299805, val_loss = 0.7989999651908875\n",
      "epoch n°235 : train_loss = 2.167665719985962, val_loss = 0.7943903803825378\n",
      "epoch n°236 : train_loss = 2.1688830852508545, val_loss = 0.7986934185028076\n",
      "epoch n°237 : train_loss = 2.168579578399658, val_loss = 0.799191951751709\n",
      "epoch n°238 : train_loss = 2.1617825031280518, val_loss = 0.7964937686920166\n",
      "epoch n°239 : train_loss = 2.1721184253692627, val_loss = 0.7943147420883179\n",
      "epoch n°240 : train_loss = 2.1864285469055176, val_loss = 0.8000196218490601\n",
      "epoch n°241 : train_loss = 2.1965219974517822, val_loss = 0.7991980314254761\n",
      "epoch n°242 : train_loss = 2.1829516887664795, val_loss = 0.7971959114074707\n",
      "epoch n°243 : train_loss = 2.19378924369812, val_loss = 0.7976250648498535\n",
      "epoch n°244 : train_loss = 2.1867411136627197, val_loss = 0.8000826835632324\n",
      "epoch n°245 : train_loss = 2.195441961288452, val_loss = 0.797265887260437\n",
      "epoch n°246 : train_loss = 2.185215711593628, val_loss = 0.800094723701477\n",
      "epoch n°247 : train_loss = 2.1855146884918213, val_loss = 0.7974618673324585\n",
      "epoch n°248 : train_loss = 2.1886582374572754, val_loss = 0.7969494462013245\n",
      "epoch n°249 : train_loss = 2.1906261444091797, val_loss = 0.799171507358551\n",
      "epoch n°250 : train_loss = 2.183100700378418, val_loss = 0.7989081740379333\n",
      "epoch n°251 : train_loss = 2.1920785903930664, val_loss = 0.8045530915260315\n",
      "epoch n°252 : train_loss = 2.1903975009918213, val_loss = 0.8003197312355042\n",
      "epoch n°253 : train_loss = 2.189408540725708, val_loss = 0.801800012588501\n",
      "epoch n°254 : train_loss = 2.1918418407440186, val_loss = 0.8003025650978088\n",
      "epoch n°255 : train_loss = 2.188861608505249, val_loss = 0.8012922406196594\n",
      "epoch n°256 : train_loss = 2.189605951309204, val_loss = 0.7980281710624695\n",
      "epoch n°257 : train_loss = 2.192305088043213, val_loss = 0.8023881912231445\n",
      "epoch n°258 : train_loss = 2.1897709369659424, val_loss = 0.7959528565406799\n",
      "epoch n°259 : train_loss = 2.1884803771972656, val_loss = 0.8003668189048767\n",
      "epoch n°260 : train_loss = 2.1957573890686035, val_loss = 0.8006372451782227\n",
      "epoch n°261 : train_loss = 2.18974232673645, val_loss = 0.8013404011726379\n",
      "epoch n°262 : train_loss = 2.1885430812835693, val_loss = 0.8011423349380493\n",
      "epoch n°263 : train_loss = 2.1842730045318604, val_loss = 0.8021552562713623\n",
      "epoch n°264 : train_loss = 2.187659978866577, val_loss = 0.797581136226654\n",
      "epoch n°265 : train_loss = 2.1838009357452393, val_loss = 0.7958744168281555\n",
      "epoch n°266 : train_loss = 2.1856703758239746, val_loss = 0.803464412689209\n",
      "epoch n°267 : train_loss = 2.1829020977020264, val_loss = 0.7965824604034424\n",
      "epoch n°268 : train_loss = 2.1788382530212402, val_loss = 0.7970685958862305\n",
      "epoch n°269 : train_loss = 2.1836471557617188, val_loss = 0.7989941835403442\n",
      "epoch n°270 : train_loss = 2.186985969543457, val_loss = 0.8026212453842163\n",
      "epoch n°271 : train_loss = 2.172329902648926, val_loss = 0.7981603741645813\n",
      "epoch n°272 : train_loss = 2.1827242374420166, val_loss = 0.8017215132713318\n",
      "epoch n°273 : train_loss = 2.1868510246276855, val_loss = 0.8021202087402344\n",
      "epoch n°274 : train_loss = 2.18274188041687, val_loss = 0.7996775507926941\n",
      "epoch n°275 : train_loss = 2.179049015045166, val_loss = 0.8015810251235962\n",
      "epoch n°276 : train_loss = 2.1746068000793457, val_loss = 0.7969507575035095\n",
      "epoch n°277 : train_loss = 2.1880509853363037, val_loss = 0.7984100580215454\n",
      "epoch n°278 : train_loss = 2.1844890117645264, val_loss = 0.798682689666748\n",
      "epoch n°279 : train_loss = 2.180365800857544, val_loss = 0.7958794236183167\n",
      "epoch n°280 : train_loss = 2.1834826469421387, val_loss = 0.8012722730636597\n",
      "epoch n°281 : train_loss = 2.1786394119262695, val_loss = 0.8009932041168213\n",
      "epoch n°282 : train_loss = 2.184796094894409, val_loss = 0.8020411133766174\n",
      "epoch n°283 : train_loss = 2.1814355850219727, val_loss = 0.8041127324104309\n",
      "epoch n°284 : train_loss = 2.1805694103240967, val_loss = 0.7987107038497925\n",
      "epoch n°285 : train_loss = 2.1779775619506836, val_loss = 0.8006693720817566\n",
      "epoch n°286 : train_loss = 2.176335334777832, val_loss = 0.7953281998634338\n",
      "epoch n°287 : train_loss = 2.1775341033935547, val_loss = 0.7989776134490967\n",
      "epoch n°288 : train_loss = 2.1766982078552246, val_loss = 0.8011445999145508\n",
      "epoch n°289 : train_loss = 2.1682090759277344, val_loss = 0.8001075983047485\n",
      "epoch n°290 : train_loss = 2.1817872524261475, val_loss = 0.7961461544036865\n",
      "epoch n°291 : train_loss = 2.176846742630005, val_loss = 0.795920729637146\n",
      "epoch n°292 : train_loss = 2.177327871322632, val_loss = 0.7969534993171692\n",
      "epoch n°293 : train_loss = 2.1779656410217285, val_loss = 0.8017037510871887\n",
      "epoch n°294 : train_loss = 2.180314540863037, val_loss = 0.8002642393112183\n",
      "epoch n°295 : train_loss = 2.1792867183685303, val_loss = 0.7987377047538757\n",
      "epoch n°296 : train_loss = 2.1882522106170654, val_loss = 0.8008466958999634\n",
      "epoch n°297 : train_loss = 2.1816482543945312, val_loss = 0.8006411194801331\n",
      "epoch n°298 : train_loss = 2.176848888397217, val_loss = 0.7976911067962646\n",
      "epoch n°299 : train_loss = 2.1796367168426514, val_loss = 0.7961307168006897\n",
      "epoch n°300 : train_loss = 2.1758487224578857, val_loss = 0.800656795501709\n",
      "epoch n°301 : train_loss = 2.1769394874572754, val_loss = 0.7993823289871216\n",
      "epoch n°302 : train_loss = 2.178582191467285, val_loss = 0.7964427471160889\n",
      "epoch n°303 : train_loss = 2.1742329597473145, val_loss = 0.7984026670455933\n",
      "epoch n°304 : train_loss = 2.175719976425171, val_loss = 0.8010868430137634\n",
      "epoch n°305 : train_loss = 2.1683359146118164, val_loss = 0.7952297329902649\n",
      "epoch n°306 : train_loss = 2.1754343509674072, val_loss = 0.7974727749824524\n",
      "epoch n°307 : train_loss = 2.1693243980407715, val_loss = 0.7991383671760559\n",
      "epoch n°308 : train_loss = 2.1692583560943604, val_loss = 0.7989802956581116\n",
      "epoch n°309 : train_loss = 2.172116279602051, val_loss = 0.7969179153442383\n",
      "epoch n°310 : train_loss = 2.17490291595459, val_loss = 0.7992640733718872\n",
      "epoch n°311 : train_loss = 2.164022922515869, val_loss = 0.7956346273422241\n",
      "epoch n°312 : train_loss = 2.1756930351257324, val_loss = 0.7959575057029724\n",
      "epoch n°313 : train_loss = 2.175119638442993, val_loss = 0.8011761903762817\n",
      "epoch n°314 : train_loss = 2.1721110343933105, val_loss = 0.8024234771728516\n",
      "epoch n°315 : train_loss = 2.16473126411438, val_loss = 0.7918301820755005\n",
      "epoch n°316 : train_loss = 2.159332513809204, val_loss = 0.8024711012840271\n",
      "epoch n°317 : train_loss = 2.1535191535949707, val_loss = 0.79578697681427\n",
      "epoch n°318 : train_loss = 2.1742746829986572, val_loss = 0.7950978875160217\n",
      "epoch n°319 : train_loss = 2.1602303981781006, val_loss = 0.7969937324523926\n",
      "epoch n°320 : train_loss = 2.1691482067108154, val_loss = 0.7997269034385681\n",
      "epoch n°321 : train_loss = 2.165586233139038, val_loss = 0.7996631264686584\n",
      "epoch n°322 : train_loss = 2.163353204727173, val_loss = 0.8006054162979126\n",
      "epoch n°323 : train_loss = 2.175245523452759, val_loss = 0.7978044152259827\n",
      "epoch n°324 : train_loss = 2.166944980621338, val_loss = 0.7944453954696655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°325 : train_loss = 2.171231985092163, val_loss = 0.7984471917152405\n",
      "epoch n°326 : train_loss = 2.1702802181243896, val_loss = 0.7958157062530518\n",
      "epoch n°327 : train_loss = 2.1684372425079346, val_loss = 0.7941774129867554\n",
      "epoch n°328 : train_loss = 2.1715078353881836, val_loss = 0.7973924279212952\n",
      "epoch n°329 : train_loss = 2.160848379135132, val_loss = 0.8007664680480957\n",
      "epoch n°330 : train_loss = 2.162865400314331, val_loss = 0.8000602126121521\n",
      "epoch n°331 : train_loss = 2.162724494934082, val_loss = 0.7952494621276855\n",
      "epoch n°332 : train_loss = 2.160372018814087, val_loss = 0.7970333099365234\n",
      "epoch n°333 : train_loss = 2.1574959754943848, val_loss = 0.7973373532295227\n",
      "epoch n°334 : train_loss = 2.1662521362304688, val_loss = 0.8012180328369141\n",
      "epoch n°335 : train_loss = 2.1610734462738037, val_loss = 0.7953050136566162\n",
      "epoch n°336 : train_loss = 2.166476011276245, val_loss = 0.7972519397735596\n",
      "epoch n°337 : train_loss = 2.1666955947875977, val_loss = 0.7956675291061401\n",
      "epoch n°338 : train_loss = 2.165818691253662, val_loss = 0.7980401515960693\n",
      "epoch n°339 : train_loss = 2.1584911346435547, val_loss = 0.7971464395523071\n",
      "epoch n°340 : train_loss = 2.15567684173584, val_loss = 0.7981536388397217\n",
      "epoch n°341 : train_loss = 2.1571173667907715, val_loss = 0.7956297397613525\n",
      "epoch n°342 : train_loss = 2.165529727935791, val_loss = 0.7991768717765808\n",
      "epoch n°343 : train_loss = 2.1660892963409424, val_loss = 0.7971522808074951\n",
      "epoch n°344 : train_loss = 2.155086040496826, val_loss = 0.7989758253097534\n",
      "epoch n°345 : train_loss = 2.1654136180877686, val_loss = 0.798560380935669\n",
      "epoch n°346 : train_loss = 2.1572163105010986, val_loss = 0.7963860034942627\n",
      "epoch n°347 : train_loss = 2.155824899673462, val_loss = 0.798409640789032\n",
      "epoch n°348 : train_loss = 2.1641552448272705, val_loss = 0.7932723164558411\n",
      "epoch n°349 : train_loss = 2.1567087173461914, val_loss = 0.7996922135353088\n",
      "epoch n°350 : train_loss = 2.1555519104003906, val_loss = 0.7985174059867859\n",
      "epoch n°351 : train_loss = 2.1559479236602783, val_loss = 0.794258177280426\n",
      "epoch n°352 : train_loss = 2.1641592979431152, val_loss = 0.798275351524353\n",
      "epoch n°353 : train_loss = 2.1550228595733643, val_loss = 0.7959017753601074\n",
      "epoch n°354 : train_loss = 2.1566898822784424, val_loss = 0.7984285354614258\n",
      "epoch n°355 : train_loss = 2.1638646125793457, val_loss = 0.7968502640724182\n",
      "epoch n°356 : train_loss = 2.157599449157715, val_loss = 0.7961459159851074\n",
      "epoch n°357 : train_loss = 2.165027141571045, val_loss = 0.796884298324585\n",
      "epoch n°358 : train_loss = 2.1472859382629395, val_loss = 0.7999642491340637\n",
      "epoch n°359 : train_loss = 2.155651807785034, val_loss = 0.7969542145729065\n",
      "epoch n°360 : train_loss = 2.1594722270965576, val_loss = 0.7973560690879822\n",
      "epoch n°361 : train_loss = 2.1530251502990723, val_loss = 0.7977285385131836\n",
      "epoch n°362 : train_loss = 2.148008108139038, val_loss = 0.7927818894386292\n",
      "epoch n°363 : train_loss = 2.1545937061309814, val_loss = 0.7977079153060913\n",
      "epoch n°364 : train_loss = 2.1558287143707275, val_loss = 0.7940171957015991\n",
      "epoch n°365 : train_loss = 2.148059844970703, val_loss = 0.7925142645835876\n",
      "epoch n°366 : train_loss = 2.145059108734131, val_loss = 0.7938407063484192\n",
      "epoch n°367 : train_loss = 2.141066312789917, val_loss = 0.7941513657569885\n",
      "epoch n°368 : train_loss = 2.1506636142730713, val_loss = 0.7973970174789429\n",
      "epoch n°369 : train_loss = 2.149932384490967, val_loss = 0.7961646318435669\n",
      "epoch n°370 : train_loss = 2.149679183959961, val_loss = 0.7968277335166931\n",
      "epoch n°371 : train_loss = 2.159010410308838, val_loss = 0.7987478971481323\n",
      "epoch n°372 : train_loss = 2.1484622955322266, val_loss = 0.7970902323722839\n",
      "epoch n°373 : train_loss = 2.1469509601593018, val_loss = 0.7965214848518372\n",
      "epoch n°374 : train_loss = 2.1389591693878174, val_loss = 0.795801043510437\n",
      "epoch n°375 : train_loss = 2.1517550945281982, val_loss = 0.7988895177841187\n",
      "epoch n°376 : train_loss = 2.147568702697754, val_loss = 0.7994714379310608\n",
      "epoch n°377 : train_loss = 2.146991729736328, val_loss = 0.8009839057922363\n",
      "epoch n°378 : train_loss = 2.1424241065979004, val_loss = 0.7996605634689331\n",
      "epoch n°379 : train_loss = 2.1464412212371826, val_loss = 0.7960484027862549\n",
      "epoch n°380 : train_loss = 2.149972438812256, val_loss = 0.7941179871559143\n",
      "epoch n°381 : train_loss = 2.1424036026000977, val_loss = 0.801415205001831\n",
      "epoch n°382 : train_loss = 2.1420772075653076, val_loss = 0.7952550053596497\n",
      "epoch n°383 : train_loss = 2.1390490531921387, val_loss = 0.7909247279167175\n",
      "epoch n°384 : train_loss = 2.1417078971862793, val_loss = 0.7981056571006775\n",
      "epoch n°385 : train_loss = 2.1483068466186523, val_loss = 0.7970622181892395\n",
      "epoch n°386 : train_loss = 2.1365482807159424, val_loss = 0.7939664125442505\n",
      "epoch n°387 : train_loss = 2.1432693004608154, val_loss = 0.7940765023231506\n",
      "epoch n°388 : train_loss = 2.1413583755493164, val_loss = 0.7930514216423035\n",
      "epoch n°389 : train_loss = 2.1395339965820312, val_loss = 0.7959961891174316\n",
      "epoch n°390 : train_loss = 2.1424386501312256, val_loss = 0.792597770690918\n",
      "epoch n°391 : train_loss = 2.146087884902954, val_loss = 0.7941651940345764\n",
      "epoch n°392 : train_loss = 2.138688325881958, val_loss = 0.7948142290115356\n",
      "epoch n°393 : train_loss = 2.140233039855957, val_loss = 0.796570897102356\n",
      "epoch n°394 : train_loss = 2.1481773853302, val_loss = 0.7993879914283752\n",
      "epoch n°395 : train_loss = 2.141301393508911, val_loss = 0.7986435294151306\n",
      "epoch n°396 : train_loss = 2.153961420059204, val_loss = 0.7953957319259644\n",
      "epoch n°397 : train_loss = 2.1343061923980713, val_loss = 0.7935404181480408\n",
      "epoch n°398 : train_loss = 2.141906976699829, val_loss = 0.7962299585342407\n",
      "epoch n°399 : train_loss = 2.1406054496765137, val_loss = 0.7971450090408325\n",
      "epoch n°400 : train_loss = 2.1436517238616943, val_loss = 0.7974461317062378\n",
      "epoch n°401 : train_loss = 2.134749174118042, val_loss = 0.7959334254264832\n",
      "epoch n°402 : train_loss = 2.136892318725586, val_loss = 0.7925673723220825\n",
      "epoch n°403 : train_loss = 2.1445682048797607, val_loss = 0.794636070728302\n",
      "epoch n°404 : train_loss = 2.1418910026550293, val_loss = 0.796048104763031\n",
      "epoch n°405 : train_loss = 2.1379613876342773, val_loss = 0.796267569065094\n",
      "epoch n°406 : train_loss = 2.1376378536224365, val_loss = 0.7928940057754517\n",
      "epoch n°407 : train_loss = 2.138606548309326, val_loss = 0.7916887402534485\n",
      "epoch n°408 : train_loss = 2.1262733936309814, val_loss = 0.7977367043495178\n",
      "epoch n°409 : train_loss = 2.133784294128418, val_loss = 0.7968111038208008\n",
      "epoch n°410 : train_loss = 2.133639335632324, val_loss = 0.7958266735076904\n",
      "epoch n°411 : train_loss = 2.1429996490478516, val_loss = 0.7982755303382874\n",
      "epoch n°412 : train_loss = 2.1402480602264404, val_loss = 0.7925618886947632\n",
      "epoch n°413 : train_loss = 2.126523017883301, val_loss = 0.7985970973968506\n",
      "epoch n°414 : train_loss = 2.1328790187835693, val_loss = 0.7967902421951294\n",
      "epoch n°415 : train_loss = 2.1380903720855713, val_loss = 0.7953514456748962\n",
      "epoch n°416 : train_loss = 2.1307144165039062, val_loss = 0.7973099946975708\n",
      "epoch n°417 : train_loss = 2.130031108856201, val_loss = 0.7926843166351318\n",
      "epoch n°418 : train_loss = 2.1345603466033936, val_loss = 0.7951700687408447\n",
      "epoch n°419 : train_loss = 2.1320595741271973, val_loss = 0.7972699403762817\n",
      "epoch n°420 : train_loss = 2.1331844329833984, val_loss = 0.7966630458831787\n",
      "epoch n°421 : train_loss = 2.12863826751709, val_loss = 0.7947218418121338\n",
      "epoch n°422 : train_loss = 2.1356632709503174, val_loss = 0.7935400605201721\n",
      "epoch n°423 : train_loss = 2.127983570098877, val_loss = 0.7939677834510803\n",
      "epoch n°424 : train_loss = 2.1282694339752197, val_loss = 0.7977531552314758\n",
      "epoch n°425 : train_loss = 2.1297945976257324, val_loss = 0.7967659831047058\n",
      "epoch n°426 : train_loss = 2.1230967044830322, val_loss = 0.7957905530929565\n",
      "epoch n°427 : train_loss = 2.1334335803985596, val_loss = 0.7961257696151733\n",
      "epoch n°428 : train_loss = 2.129382610321045, val_loss = 0.7931066155433655\n",
      "epoch n°429 : train_loss = 2.1278727054595947, val_loss = 0.7955422401428223\n",
      "epoch n°430 : train_loss = 2.1319057941436768, val_loss = 0.7928966879844666\n",
      "epoch n°431 : train_loss = 2.1361846923828125, val_loss = 0.796949565410614\n",
      "epoch n°432 : train_loss = 2.123940944671631, val_loss = 0.7949495911598206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°433 : train_loss = 2.1327576637268066, val_loss = 0.7962858080863953\n",
      "epoch n°434 : train_loss = 2.127346992492676, val_loss = 0.7945098876953125\n",
      "epoch n°435 : train_loss = 2.1321144104003906, val_loss = 0.797280490398407\n",
      "epoch n°436 : train_loss = 2.1337358951568604, val_loss = 0.7950136661529541\n",
      "epoch n°437 : train_loss = 2.1380555629730225, val_loss = 0.7926307916641235\n",
      "epoch n°438 : train_loss = 2.12937068939209, val_loss = 0.7967123985290527\n",
      "epoch n°439 : train_loss = 2.1312339305877686, val_loss = 0.7921052575111389\n",
      "epoch n°440 : train_loss = 2.1264288425445557, val_loss = 0.7962164878845215\n",
      "epoch n°441 : train_loss = 2.1314918994903564, val_loss = 0.7994046807289124\n",
      "epoch n°442 : train_loss = 2.1300771236419678, val_loss = 0.7979183197021484\n",
      "epoch n°443 : train_loss = 2.1387085914611816, val_loss = 0.7974043488502502\n",
      "epoch n°444 : train_loss = 2.130009412765503, val_loss = 0.7951362133026123\n",
      "epoch n°445 : train_loss = 2.13191294670105, val_loss = 0.7953706383705139\n",
      "epoch n°446 : train_loss = 2.1231577396392822, val_loss = 0.8007625341415405\n",
      "epoch n°447 : train_loss = 2.1287732124328613, val_loss = 0.7933142185211182\n",
      "epoch n°448 : train_loss = 2.130349636077881, val_loss = 0.7936952710151672\n",
      "epoch n°449 : train_loss = 2.126852512359619, val_loss = 0.7922900319099426\n",
      "epoch n°450 : train_loss = 2.1324124336242676, val_loss = 0.7960363626480103\n",
      "epoch n°451 : train_loss = 2.1318299770355225, val_loss = 0.7981142997741699\n",
      "epoch n°452 : train_loss = 2.125488758087158, val_loss = 0.79135662317276\n",
      "epoch n°453 : train_loss = 2.120927095413208, val_loss = 0.7946282625198364\n",
      "epoch n°454 : train_loss = 2.130990505218506, val_loss = 0.7920546531677246\n",
      "epoch n°455 : train_loss = 2.1280689239501953, val_loss = 0.7982245087623596\n",
      "epoch n°456 : train_loss = 2.127984046936035, val_loss = 0.7973198294639587\n",
      "epoch n°457 : train_loss = 2.1163084506988525, val_loss = 0.7960757613182068\n",
      "epoch n°458 : train_loss = 2.127070903778076, val_loss = 0.7922513484954834\n",
      "epoch n°459 : train_loss = 2.1207103729248047, val_loss = 0.7926603555679321\n",
      "epoch n°460 : train_loss = 2.132986545562744, val_loss = 0.7921002507209778\n",
      "epoch n°461 : train_loss = 2.1245062351226807, val_loss = 0.792482316493988\n",
      "epoch n°462 : train_loss = 2.1279942989349365, val_loss = 0.7930299043655396\n",
      "epoch n°463 : train_loss = 2.116762638092041, val_loss = 0.7990818023681641\n",
      "epoch n°464 : train_loss = 2.124739170074463, val_loss = 0.7952935099601746\n",
      "epoch n°465 : train_loss = 2.129209280014038, val_loss = 0.793468713760376\n",
      "epoch n°466 : train_loss = 2.13252329826355, val_loss = 0.7948300838470459\n",
      "epoch n°467 : train_loss = 2.1225743293762207, val_loss = 0.7943692207336426\n",
      "epoch n°468 : train_loss = 2.1192076206207275, val_loss = 0.7957437038421631\n",
      "epoch n°469 : train_loss = 2.123070240020752, val_loss = 0.7897929549217224\n",
      "epoch n°470 : train_loss = 2.1337718963623047, val_loss = 0.7933096289634705\n",
      "epoch n°471 : train_loss = 2.1225903034210205, val_loss = 0.7953818440437317\n",
      "epoch n°472 : train_loss = 2.136754035949707, val_loss = 0.794038712978363\n",
      "epoch n°473 : train_loss = 2.1304068565368652, val_loss = 0.7912138104438782\n",
      "epoch n°474 : train_loss = 2.1267406940460205, val_loss = 0.7948005795478821\n",
      "epoch n°475 : train_loss = 2.1230640411376953, val_loss = 0.7903858423233032\n",
      "epoch n°476 : train_loss = 2.129455327987671, val_loss = 0.796646237373352\n",
      "epoch n°477 : train_loss = 2.118454694747925, val_loss = 0.7950301170349121\n",
      "epoch n°478 : train_loss = 2.1277289390563965, val_loss = 0.7988134622573853\n",
      "epoch n°479 : train_loss = 2.135554552078247, val_loss = 0.7958511114120483\n",
      "epoch n°480 : train_loss = 2.130091905593872, val_loss = 0.797818660736084\n",
      "epoch n°481 : train_loss = 2.118941068649292, val_loss = 0.8004577159881592\n",
      "epoch n°482 : train_loss = 2.1315858364105225, val_loss = 0.8010485172271729\n",
      "epoch n°483 : train_loss = 2.1271777153015137, val_loss = 0.7935031652450562\n",
      "epoch n°484 : train_loss = 2.126883029937744, val_loss = 0.7943128943443298\n",
      "epoch n°485 : train_loss = 2.125035285949707, val_loss = 0.7954471707344055\n",
      "epoch n°486 : train_loss = 2.130197286605835, val_loss = 0.7931207418441772\n",
      "epoch n°487 : train_loss = 2.1200733184814453, val_loss = 0.7958404421806335\n",
      "epoch n°488 : train_loss = 2.118666887283325, val_loss = 0.793112576007843\n",
      "epoch n°489 : train_loss = 2.1238632202148438, val_loss = 0.7939794659614563\n",
      "epoch n°490 : train_loss = 2.127394437789917, val_loss = 0.7919989824295044\n",
      "epoch n°491 : train_loss = 2.131343126296997, val_loss = 0.7914364337921143\n",
      "epoch n°492 : train_loss = 2.124857187271118, val_loss = 0.7944971323013306\n",
      "epoch n°493 : train_loss = 2.1258773803710938, val_loss = 0.7945082783699036\n",
      "epoch n°494 : train_loss = 2.122204065322876, val_loss = 0.7955688238143921\n",
      "epoch n°495 : train_loss = 2.1298325061798096, val_loss = 0.7984061241149902\n",
      "epoch n°496 : train_loss = 2.1504178047180176, val_loss = 0.7967241406440735\n",
      "epoch n°497 : train_loss = 2.149817705154419, val_loss = 0.7930850982666016\n",
      "epoch n°498 : train_loss = 2.1570427417755127, val_loss = 0.7968325614929199\n",
      "epoch n°499 : train_loss = 2.15732479095459, val_loss = 0.7997147440910339\n",
      "epoch n°500 : train_loss = 2.1491551399230957, val_loss = 0.799374520778656\n",
      "epoch n°501 : train_loss = 2.154287099838257, val_loss = 0.8032532930374146\n",
      "epoch n°502 : train_loss = 2.1561760902404785, val_loss = 0.8027822971343994\n",
      "epoch n°503 : train_loss = 2.1545722484588623, val_loss = 0.801079273223877\n",
      "epoch n°504 : train_loss = 2.1436707973480225, val_loss = 0.7895181179046631\n",
      "epoch n°505 : train_loss = 2.1513051986694336, val_loss = 0.7954278588294983\n",
      "epoch n°506 : train_loss = 2.15330171585083, val_loss = 0.797023355960846\n",
      "epoch n°507 : train_loss = 2.1541054248809814, val_loss = 0.7962476015090942\n",
      "epoch n°508 : train_loss = 2.1584744453430176, val_loss = 0.7995195984840393\n",
      "epoch n°509 : train_loss = 2.1544253826141357, val_loss = 0.7931690216064453\n",
      "epoch n°510 : train_loss = 2.162576198577881, val_loss = 0.7930896282196045\n",
      "epoch n°511 : train_loss = 2.152284860610962, val_loss = 0.7991971969604492\n",
      "epoch n°512 : train_loss = 2.1455211639404297, val_loss = 0.8016712665557861\n",
      "epoch n°513 : train_loss = 2.148228645324707, val_loss = 0.7962993383407593\n",
      "epoch n°514 : train_loss = 2.1588544845581055, val_loss = 0.8001323342323303\n",
      "epoch n°515 : train_loss = 2.1581060886383057, val_loss = 0.795984148979187\n",
      "epoch n°516 : train_loss = 2.150369167327881, val_loss = 0.794773519039154\n",
      "epoch n°517 : train_loss = 2.1512224674224854, val_loss = 0.7934218645095825\n",
      "epoch n°518 : train_loss = 2.1528804302215576, val_loss = 0.8004530668258667\n",
      "epoch n°519 : train_loss = 2.156985282897949, val_loss = 0.797572672367096\n",
      "epoch n°520 : train_loss = 2.1464555263519287, val_loss = 0.7975982427597046\n",
      "epoch n°521 : train_loss = 2.1501502990722656, val_loss = 0.795676589012146\n",
      "epoch n°522 : train_loss = 2.1555662155151367, val_loss = 0.8023520708084106\n",
      "epoch n°523 : train_loss = 2.149090528488159, val_loss = 0.8002529144287109\n",
      "epoch n°524 : train_loss = 2.150195837020874, val_loss = 0.7997696995735168\n",
      "epoch n°525 : train_loss = 2.1495959758758545, val_loss = 0.7950642108917236\n",
      "epoch n°526 : train_loss = 2.1459765434265137, val_loss = 0.7955363392829895\n",
      "epoch n°527 : train_loss = 2.1490516662597656, val_loss = 0.7988308668136597\n",
      "epoch n°528 : train_loss = 2.158111333847046, val_loss = 0.7970965504646301\n",
      "epoch n°529 : train_loss = 2.1539783477783203, val_loss = 0.7969569563865662\n",
      "epoch n°530 : train_loss = 2.152224540710449, val_loss = 0.7984446287155151\n",
      "epoch n°531 : train_loss = 2.144472122192383, val_loss = 0.7983843684196472\n",
      "epoch n°532 : train_loss = 2.152973175048828, val_loss = 0.8008716106414795\n",
      "epoch n°533 : train_loss = 2.1457102298736572, val_loss = 0.7984382510185242\n",
      "epoch n°534 : train_loss = 2.1561405658721924, val_loss = 0.7982953190803528\n",
      "epoch n°535 : train_loss = 2.1540868282318115, val_loss = 0.8002267479896545\n",
      "epoch n°536 : train_loss = 2.1501452922821045, val_loss = 0.7992129325866699\n",
      "epoch n°537 : train_loss = 2.1468558311462402, val_loss = 0.7968452572822571\n",
      "epoch n°538 : train_loss = 2.1507089138031006, val_loss = 0.7987428307533264\n",
      "epoch n°539 : train_loss = 2.139916181564331, val_loss = 0.8036763072013855\n",
      "epoch n°540 : train_loss = 2.1456668376922607, val_loss = 0.796897828578949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°541 : train_loss = 2.1460824012756348, val_loss = 0.7968258857727051\n",
      "epoch n°542 : train_loss = 2.1466314792633057, val_loss = 0.7959109544754028\n",
      "epoch n°543 : train_loss = 2.152994394302368, val_loss = 0.7971335649490356\n",
      "epoch n°544 : train_loss = 2.1454012393951416, val_loss = 0.7996086478233337\n",
      "epoch n°545 : train_loss = 2.1504454612731934, val_loss = 0.8012098073959351\n",
      "epoch n°546 : train_loss = 2.1449639797210693, val_loss = 0.7984911799430847\n",
      "epoch n°547 : train_loss = 2.154914140701294, val_loss = 0.7976940274238586\n",
      "epoch n°548 : train_loss = 2.146500825881958, val_loss = 0.7946913838386536\n",
      "epoch n°549 : train_loss = 2.153780698776245, val_loss = 0.7984902262687683\n",
      "epoch n°550 : train_loss = 2.152303457260132, val_loss = 0.7983263731002808\n",
      "epoch n°551 : train_loss = 2.163076162338257, val_loss = 0.7988974452018738\n",
      "epoch n°552 : train_loss = 2.1491785049438477, val_loss = 0.7965046167373657\n",
      "epoch n°553 : train_loss = 2.153499126434326, val_loss = 0.796617329120636\n",
      "epoch n°554 : train_loss = 2.1411612033843994, val_loss = 0.7984738349914551\n",
      "epoch n°555 : train_loss = 2.1551613807678223, val_loss = 0.7951798439025879\n",
      "epoch n°556 : train_loss = 2.1557493209838867, val_loss = 0.8002962470054626\n",
      "epoch n°557 : train_loss = 2.146740674972534, val_loss = 0.8028010129928589\n",
      "epoch n°558 : train_loss = 2.1517443656921387, val_loss = 0.7964691519737244\n",
      "epoch n°559 : train_loss = 2.1391513347625732, val_loss = 0.7983095645904541\n",
      "epoch n°560 : train_loss = 2.143176794052124, val_loss = 0.7962946891784668\n",
      "epoch n°561 : train_loss = 2.1432154178619385, val_loss = 0.8007652759552002\n",
      "epoch n°562 : train_loss = 2.1482489109039307, val_loss = 0.7957053184509277\n",
      "epoch n°563 : train_loss = 2.1424388885498047, val_loss = 0.7985303997993469\n",
      "epoch n°564 : train_loss = 2.1508777141571045, val_loss = 0.7933766841888428\n",
      "epoch n°565 : train_loss = 2.1510767936706543, val_loss = 0.793535590171814\n",
      "epoch n°566 : train_loss = 2.158902406692505, val_loss = 0.7983589172363281\n",
      "epoch n°567 : train_loss = 2.1501541137695312, val_loss = 0.7963100671768188\n",
      "epoch n°568 : train_loss = 2.1533660888671875, val_loss = 0.796970546245575\n",
      "epoch n°569 : train_loss = 2.1392767429351807, val_loss = 0.7900336384773254\n",
      "epoch n°570 : train_loss = 2.13517689704895, val_loss = 0.7961883544921875\n",
      "epoch n°571 : train_loss = 2.140599250793457, val_loss = 0.7979611158370972\n",
      "epoch n°572 : train_loss = 2.141869306564331, val_loss = 0.7940254807472229\n",
      "epoch n°573 : train_loss = 2.1465535163879395, val_loss = 0.7958701848983765\n",
      "epoch n°574 : train_loss = 2.1518077850341797, val_loss = 0.796687126159668\n",
      "epoch n°575 : train_loss = 2.1449921131134033, val_loss = 0.7958483695983887\n",
      "epoch n°576 : train_loss = 2.149265766143799, val_loss = 0.7974406480789185\n",
      "epoch n°577 : train_loss = 2.1410717964172363, val_loss = 0.7971503138542175\n",
      "epoch n°578 : train_loss = 2.1474015712738037, val_loss = 0.8004559278488159\n",
      "epoch n°579 : train_loss = 2.134084463119507, val_loss = 0.7956249117851257\n",
      "epoch n°580 : train_loss = 2.143906831741333, val_loss = 0.79706871509552\n",
      "epoch n°581 : train_loss = 2.1419594287872314, val_loss = 0.7997215986251831\n",
      "epoch n°582 : train_loss = 2.1438705921173096, val_loss = 0.8015033006668091\n",
      "epoch n°583 : train_loss = 2.1446635723114014, val_loss = 0.7947998642921448\n",
      "epoch n°584 : train_loss = 2.1470789909362793, val_loss = 0.7965602278709412\n",
      "epoch n°585 : train_loss = 2.144789457321167, val_loss = 0.8003627061843872\n",
      "epoch n°586 : train_loss = 2.1416170597076416, val_loss = 0.7991684079170227\n",
      "epoch n°587 : train_loss = 2.1426842212677, val_loss = 0.7963036894798279\n",
      "epoch n°588 : train_loss = 2.1388628482818604, val_loss = 0.7952252626419067\n",
      "epoch n°589 : train_loss = 2.1473922729492188, val_loss = 0.7952568531036377\n",
      "epoch n°590 : train_loss = 2.1398303508758545, val_loss = 0.7943479418754578\n",
      "epoch n°591 : train_loss = 2.142439365386963, val_loss = 0.7956007719039917\n",
      "epoch n°592 : train_loss = 2.14389967918396, val_loss = 0.7990657091140747\n",
      "epoch n°593 : train_loss = 2.1456775665283203, val_loss = 0.7953504323959351\n",
      "epoch n°594 : train_loss = 2.1438283920288086, val_loss = 0.8002238273620605\n",
      "epoch n°595 : train_loss = 2.1447789669036865, val_loss = 0.7979674935340881\n",
      "epoch n°596 : train_loss = 2.144562005996704, val_loss = 0.7923530340194702\n",
      "epoch n°597 : train_loss = 2.1386005878448486, val_loss = 0.7941848635673523\n",
      "epoch n°598 : train_loss = 2.14197039604187, val_loss = 0.7980369925498962\n",
      "epoch n°599 : train_loss = 2.144385576248169, val_loss = 0.7984750270843506\n",
      "epoch n°600 : train_loss = 2.142801284790039, val_loss = 0.794046938419342\n",
      "epoch n°601 : train_loss = 2.14278244972229, val_loss = 0.7984248995780945\n",
      "epoch n°602 : train_loss = 2.1322696208953857, val_loss = 0.7959199547767639\n",
      "epoch n°603 : train_loss = 2.1478419303894043, val_loss = 0.798423707485199\n",
      "epoch n°604 : train_loss = 2.1358156204223633, val_loss = 0.7962225079536438\n",
      "epoch n°605 : train_loss = 2.141010284423828, val_loss = 0.7933092713356018\n",
      "epoch n°606 : train_loss = 2.139477014541626, val_loss = 0.7976269721984863\n",
      "epoch n°607 : train_loss = 2.1352853775024414, val_loss = 0.7996731400489807\n",
      "epoch n°608 : train_loss = 2.1435959339141846, val_loss = 0.8007784485816956\n",
      "epoch n°609 : train_loss = 2.1410458087921143, val_loss = 0.7927733063697815\n",
      "epoch n°610 : train_loss = 2.13690447807312, val_loss = 0.7927007675170898\n",
      "epoch n°611 : train_loss = 2.1392152309417725, val_loss = 0.7990615963935852\n",
      "epoch n°612 : train_loss = 2.1350033283233643, val_loss = 0.7950400114059448\n",
      "epoch n°613 : train_loss = 2.143977165222168, val_loss = 0.7954203486442566\n",
      "epoch n°614 : train_loss = 2.13988995552063, val_loss = 0.7971917390823364\n",
      "epoch n°615 : train_loss = 2.142742395401001, val_loss = 0.7931925058364868\n",
      "epoch n°616 : train_loss = 2.1411776542663574, val_loss = 0.7989599108695984\n",
      "epoch n°617 : train_loss = 2.1360719203948975, val_loss = 0.7971774935722351\n",
      "epoch n°618 : train_loss = 2.1355936527252197, val_loss = 0.7987052798271179\n",
      "epoch n°619 : train_loss = 2.1437292098999023, val_loss = 0.8008635640144348\n",
      "epoch n°620 : train_loss = 2.1347646713256836, val_loss = 0.7965570092201233\n",
      "epoch n°621 : train_loss = 2.140150785446167, val_loss = 0.7963573336601257\n",
      "epoch n°622 : train_loss = 2.1284923553466797, val_loss = 0.7965085506439209\n",
      "epoch n°623 : train_loss = 2.133659839630127, val_loss = 0.7923212051391602\n",
      "epoch n°624 : train_loss = 2.139526844024658, val_loss = 0.7961541414260864\n",
      "epoch n°625 : train_loss = 2.1341445446014404, val_loss = 0.7999895811080933\n",
      "epoch n°626 : train_loss = 2.13782000541687, val_loss = 0.7970314025878906\n",
      "epoch n°627 : train_loss = 2.1383132934570312, val_loss = 0.7969059348106384\n",
      "epoch n°628 : train_loss = 2.1406631469726562, val_loss = 0.792846143245697\n",
      "epoch n°629 : train_loss = 2.14029598236084, val_loss = 0.7946767210960388\n",
      "epoch n°630 : train_loss = 2.129885673522949, val_loss = 0.7938843369483948\n",
      "epoch n°631 : train_loss = 2.140721559524536, val_loss = 0.7948108315467834\n",
      "epoch n°632 : train_loss = 2.1370089054107666, val_loss = 0.7993282675743103\n",
      "epoch n°633 : train_loss = 2.137943983078003, val_loss = 0.7970336675643921\n",
      "epoch n°634 : train_loss = 2.130051851272583, val_loss = 0.7928822636604309\n",
      "epoch n°635 : train_loss = 2.1249027252197266, val_loss = 0.7961755990982056\n",
      "epoch n°636 : train_loss = 2.135721445083618, val_loss = 0.7955822348594666\n",
      "epoch n°637 : train_loss = 2.132733106613159, val_loss = 0.7929092645645142\n",
      "epoch n°638 : train_loss = 2.1365840435028076, val_loss = 0.7980013489723206\n",
      "epoch n°639 : train_loss = 2.1362717151641846, val_loss = 0.7909880876541138\n",
      "epoch n°640 : train_loss = 2.133836269378662, val_loss = 0.7985338568687439\n",
      "epoch n°641 : train_loss = 2.126377582550049, val_loss = 0.7916048765182495\n",
      "epoch n°642 : train_loss = 2.126755475997925, val_loss = 0.797022819519043\n",
      "epoch n°643 : train_loss = 2.1288650035858154, val_loss = 0.7976089715957642\n",
      "epoch n°644 : train_loss = 2.122593879699707, val_loss = 0.7996963262557983\n",
      "epoch n°645 : train_loss = 2.1313891410827637, val_loss = 0.7957531213760376\n",
      "epoch n°646 : train_loss = 2.136888265609741, val_loss = 0.7949791550636292\n",
      "epoch n°647 : train_loss = 2.1323654651641846, val_loss = 0.8004322052001953\n",
      "epoch n°648 : train_loss = 2.1289756298065186, val_loss = 0.7962464094161987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°649 : train_loss = 2.1285977363586426, val_loss = 0.8003093004226685\n",
      "epoch n°650 : train_loss = 2.131225824356079, val_loss = 0.7955506443977356\n",
      "epoch n°651 : train_loss = 2.1260128021240234, val_loss = 0.800746500492096\n",
      "epoch n°652 : train_loss = 2.1265673637390137, val_loss = 0.7950026392936707\n",
      "epoch n°653 : train_loss = 2.1287968158721924, val_loss = 0.7932735085487366\n",
      "epoch n°654 : train_loss = 2.133496046066284, val_loss = 0.7995939254760742\n",
      "epoch n°655 : train_loss = 2.1297240257263184, val_loss = 0.795788049697876\n",
      "epoch n°656 : train_loss = 2.1249823570251465, val_loss = 0.794378936290741\n",
      "epoch n°657 : train_loss = 2.122936248779297, val_loss = 0.7957945466041565\n",
      "epoch n°658 : train_loss = 2.1354129314422607, val_loss = 0.7969191670417786\n",
      "epoch n°659 : train_loss = 2.126760721206665, val_loss = 0.792942464351654\n",
      "epoch n°660 : train_loss = 2.119473934173584, val_loss = 0.7955562472343445\n",
      "epoch n°661 : train_loss = 2.129974603652954, val_loss = 0.7982526421546936\n",
      "epoch n°662 : train_loss = 2.1287436485290527, val_loss = 0.8000208735466003\n",
      "epoch n°663 : train_loss = 2.1288816928863525, val_loss = 0.7991783022880554\n",
      "epoch n°664 : train_loss = 2.1167094707489014, val_loss = 0.7995551824569702\n",
      "epoch n°665 : train_loss = 2.1262707710266113, val_loss = 0.7985981106758118\n",
      "epoch n°666 : train_loss = 2.1245110034942627, val_loss = 0.7958759665489197\n",
      "epoch n°667 : train_loss = 2.130966901779175, val_loss = 0.7969971895217896\n",
      "epoch n°668 : train_loss = 2.1288275718688965, val_loss = 0.7938826680183411\n",
      "epoch n°669 : train_loss = 2.1282176971435547, val_loss = 0.7960984706878662\n",
      "epoch n°670 : train_loss = 2.132290840148926, val_loss = 0.794282078742981\n",
      "epoch n°671 : train_loss = 2.1214993000030518, val_loss = 0.7960337996482849\n",
      "epoch n°672 : train_loss = 2.1228253841400146, val_loss = 0.7953366041183472\n",
      "epoch n°673 : train_loss = 2.120575428009033, val_loss = 0.7966319918632507\n",
      "epoch n°674 : train_loss = 2.1280887126922607, val_loss = 0.7931239604949951\n",
      "epoch n°675 : train_loss = 2.1236255168914795, val_loss = 0.7961004972457886\n",
      "epoch n°676 : train_loss = 2.128369092941284, val_loss = 0.7983788251876831\n",
      "epoch n°677 : train_loss = 2.1305720806121826, val_loss = 0.7951805591583252\n",
      "epoch n°678 : train_loss = 2.117105722427368, val_loss = 0.7926055192947388\n",
      "epoch n°679 : train_loss = 2.1330018043518066, val_loss = 0.7967270016670227\n",
      "epoch n°680 : train_loss = 2.1304030418395996, val_loss = 0.8001519441604614\n",
      "epoch n°681 : train_loss = 2.1240074634552, val_loss = 0.7936220765113831\n",
      "epoch n°682 : train_loss = 2.121661424636841, val_loss = 0.7979578375816345\n",
      "epoch n°683 : train_loss = 2.1274120807647705, val_loss = 0.7963254451751709\n",
      "epoch n°684 : train_loss = 2.126408338546753, val_loss = 0.7950767874717712\n",
      "epoch n°685 : train_loss = 2.128004789352417, val_loss = 0.7951001524925232\n",
      "epoch n°686 : train_loss = 2.121565341949463, val_loss = 0.797399640083313\n",
      "epoch n°687 : train_loss = 2.1267895698547363, val_loss = 0.7962610125541687\n",
      "epoch n°688 : train_loss = 2.118804931640625, val_loss = 0.7978559136390686\n",
      "epoch n°689 : train_loss = 2.116715669631958, val_loss = 0.7984408140182495\n",
      "epoch n°690 : train_loss = 2.1269819736480713, val_loss = 0.8010445833206177\n",
      "epoch n°691 : train_loss = 2.119637966156006, val_loss = 0.7925465703010559\n",
      "epoch n°692 : train_loss = 2.119839668273926, val_loss = 0.7939450144767761\n",
      "epoch n°693 : train_loss = 2.1174261569976807, val_loss = 0.7985902428627014\n",
      "epoch n°694 : train_loss = 2.1202762126922607, val_loss = 0.7937408685684204\n",
      "epoch n°695 : train_loss = 2.1221890449523926, val_loss = 0.7981142997741699\n",
      "epoch n°696 : train_loss = 2.123997688293457, val_loss = 0.7996573448181152\n",
      "epoch n°697 : train_loss = 2.12884783744812, val_loss = 0.7947809100151062\n",
      "epoch n°698 : train_loss = 2.129318952560425, val_loss = 0.7940992712974548\n",
      "epoch n°699 : train_loss = 2.1181249618530273, val_loss = 0.7927175760269165\n",
      "epoch n°700 : train_loss = 2.1171441078186035, val_loss = 0.7965876460075378\n",
      "epoch n°701 : train_loss = 2.1177520751953125, val_loss = 0.7953670620918274\n",
      "epoch n°702 : train_loss = 2.120124101638794, val_loss = 0.7959139943122864\n",
      "epoch n°703 : train_loss = 2.1249008178710938, val_loss = 0.7968916893005371\n",
      "epoch n°704 : train_loss = 2.119161367416382, val_loss = 0.7973794937133789\n",
      "epoch n°705 : train_loss = 2.114104986190796, val_loss = 0.7978160977363586\n",
      "epoch n°706 : train_loss = 2.125227451324463, val_loss = 0.7949081063270569\n",
      "epoch n°707 : train_loss = 2.118607997894287, val_loss = 0.7943029403686523\n",
      "epoch n°708 : train_loss = 2.11972975730896, val_loss = 0.7949411273002625\n",
      "epoch n°709 : train_loss = 2.115577220916748, val_loss = 0.7956483960151672\n",
      "epoch n°710 : train_loss = 2.1156046390533447, val_loss = 0.7981613874435425\n",
      "epoch n°711 : train_loss = 2.1236817836761475, val_loss = 0.7971631288528442\n",
      "epoch n°712 : train_loss = 2.1148362159729004, val_loss = 0.7936513423919678\n",
      "epoch n°713 : train_loss = 2.1160824298858643, val_loss = 0.791851282119751\n",
      "epoch n°714 : train_loss = 2.1162025928497314, val_loss = 0.7973858714103699\n",
      "epoch n°715 : train_loss = 2.1165928840637207, val_loss = 0.7995912432670593\n",
      "epoch n°716 : train_loss = 2.11232852935791, val_loss = 0.7934204936027527\n",
      "epoch n°717 : train_loss = 2.1110925674438477, val_loss = 0.7982093691825867\n",
      "epoch n°718 : train_loss = 2.1158788204193115, val_loss = 0.7954643368721008\n",
      "epoch n°719 : train_loss = 2.1150434017181396, val_loss = 0.7929741144180298\n",
      "epoch n°720 : train_loss = 2.1080574989318848, val_loss = 0.7945595979690552\n",
      "epoch n°721 : train_loss = 2.1074392795562744, val_loss = 0.7962886691093445\n",
      "epoch n°722 : train_loss = 2.1094071865081787, val_loss = 0.7943181991577148\n",
      "epoch n°723 : train_loss = 2.1155080795288086, val_loss = 0.7986534833908081\n",
      "epoch n°724 : train_loss = 2.117992401123047, val_loss = 0.7894430756568909\n",
      "epoch n°725 : train_loss = 2.1201658248901367, val_loss = 0.7960249781608582\n",
      "epoch n°726 : train_loss = 2.110646963119507, val_loss = 0.7957838773727417\n",
      "epoch n°727 : train_loss = 2.1122889518737793, val_loss = 0.7979439496994019\n",
      "epoch n°728 : train_loss = 2.103994846343994, val_loss = 0.7959653735160828\n",
      "epoch n°729 : train_loss = 2.117084503173828, val_loss = 0.7965355515480042\n",
      "epoch n°730 : train_loss = 2.1160547733306885, val_loss = 0.7951524257659912\n",
      "epoch n°731 : train_loss = 2.1070683002471924, val_loss = 0.7943459153175354\n",
      "epoch n°732 : train_loss = 2.1161248683929443, val_loss = 0.7911859154701233\n",
      "epoch n°733 : train_loss = 2.112377405166626, val_loss = 0.7936250567436218\n",
      "epoch n°734 : train_loss = 2.1082253456115723, val_loss = 0.7940828800201416\n",
      "epoch n°735 : train_loss = 2.115321636199951, val_loss = 0.7945652604103088\n",
      "epoch n°736 : train_loss = 2.1018600463867188, val_loss = 0.7921358346939087\n",
      "epoch n°737 : train_loss = 2.113345146179199, val_loss = 0.7983514666557312\n",
      "epoch n°738 : train_loss = 2.1087305545806885, val_loss = 0.8005481958389282\n",
      "epoch n°739 : train_loss = 2.1131231784820557, val_loss = 0.7938197255134583\n",
      "epoch n°740 : train_loss = 2.1201112270355225, val_loss = 0.7945622801780701\n",
      "epoch n°741 : train_loss = 2.1155409812927246, val_loss = 0.7954634428024292\n",
      "epoch n°742 : train_loss = 2.1094305515289307, val_loss = 0.7968031764030457\n",
      "epoch n°743 : train_loss = 2.10541033744812, val_loss = 0.7983169555664062\n",
      "epoch n°744 : train_loss = 2.104692220687866, val_loss = 0.7937663197517395\n",
      "epoch n°745 : train_loss = 2.109820604324341, val_loss = 0.798549473285675\n",
      "epoch n°746 : train_loss = 2.1125128269195557, val_loss = 0.8005127310752869\n",
      "epoch n°747 : train_loss = 2.1139724254608154, val_loss = 0.7957645058631897\n",
      "epoch n°748 : train_loss = 2.1037774085998535, val_loss = 0.802182674407959\n",
      "epoch n°749 : train_loss = 2.1129355430603027, val_loss = 0.7956620454788208\n",
      "epoch n°750 : train_loss = 2.1067042350769043, val_loss = 0.7983008027076721\n",
      "epoch n°751 : train_loss = 2.111804485321045, val_loss = 0.7954504489898682\n",
      "epoch n°752 : train_loss = 2.115812301635742, val_loss = 0.7927075028419495\n",
      "epoch n°753 : train_loss = 2.1118180751800537, val_loss = 0.7946063280105591\n",
      "epoch n°754 : train_loss = 2.120150566101074, val_loss = 0.8007112741470337\n",
      "epoch n°755 : train_loss = 2.112921953201294, val_loss = 0.79225093126297\n",
      "epoch n°756 : train_loss = 2.110218048095703, val_loss = 0.7936394810676575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°757 : train_loss = 2.1118052005767822, val_loss = 0.7914087772369385\n",
      "epoch n°758 : train_loss = 2.102585792541504, val_loss = 0.7938733696937561\n",
      "epoch n°759 : train_loss = 2.1011946201324463, val_loss = 0.795521080493927\n",
      "epoch n°760 : train_loss = 2.098843574523926, val_loss = 0.7955009341239929\n",
      "epoch n°761 : train_loss = 2.107776403427124, val_loss = 0.7955762147903442\n",
      "epoch n°762 : train_loss = 2.101983070373535, val_loss = 0.7967072129249573\n",
      "epoch n°763 : train_loss = 2.1047921180725098, val_loss = 0.7951056361198425\n",
      "epoch n°764 : train_loss = 2.1156134605407715, val_loss = 0.794945478439331\n",
      "epoch n°765 : train_loss = 2.108927011489868, val_loss = 0.7961836457252502\n",
      "epoch n°766 : train_loss = 2.1074931621551514, val_loss = 0.7948161363601685\n",
      "epoch n°767 : train_loss = 2.1075217723846436, val_loss = 0.7953230738639832\n",
      "epoch n°768 : train_loss = 2.1068599224090576, val_loss = 0.7967889308929443\n",
      "epoch n°769 : train_loss = 2.1046125888824463, val_loss = 0.7956051230430603\n",
      "epoch n°770 : train_loss = 2.108729124069214, val_loss = 0.7904207110404968\n",
      "epoch n°771 : train_loss = 2.102405548095703, val_loss = 0.7921323776245117\n",
      "epoch n°772 : train_loss = 2.10699200630188, val_loss = 0.7967054843902588\n",
      "epoch n°773 : train_loss = 2.102409839630127, val_loss = 0.7993021607398987\n",
      "epoch n°774 : train_loss = 2.1121726036071777, val_loss = 0.7937027215957642\n",
      "epoch n°775 : train_loss = 2.0978095531463623, val_loss = 0.7954332232475281\n",
      "epoch n°776 : train_loss = 2.106018543243408, val_loss = 0.796244204044342\n",
      "epoch n°777 : train_loss = 2.100287437438965, val_loss = 0.7960288524627686\n",
      "epoch n°778 : train_loss = 2.104365587234497, val_loss = 0.7971208095550537\n",
      "epoch n°779 : train_loss = 2.1015944480895996, val_loss = 0.7987966537475586\n",
      "epoch n°780 : train_loss = 2.1008949279785156, val_loss = 0.7958337664604187\n",
      "epoch n°781 : train_loss = 2.1058506965637207, val_loss = 0.7926449179649353\n",
      "epoch n°782 : train_loss = 2.085423469543457, val_loss = 0.7928786873817444\n",
      "epoch n°783 : train_loss = 2.11004376411438, val_loss = 0.793286919593811\n",
      "epoch n°784 : train_loss = 2.102527618408203, val_loss = 0.7939504384994507\n",
      "epoch n°785 : train_loss = 2.097160816192627, val_loss = 0.7953488230705261\n",
      "epoch n°786 : train_loss = 2.095827341079712, val_loss = 0.8004744648933411\n",
      "epoch n°787 : train_loss = 2.1037065982818604, val_loss = 0.7940338850021362\n",
      "epoch n°788 : train_loss = 2.104492664337158, val_loss = 0.7970149517059326\n",
      "epoch n°789 : train_loss = 2.099679470062256, val_loss = 0.7944085001945496\n",
      "epoch n°790 : train_loss = 2.1030426025390625, val_loss = 0.7950188517570496\n",
      "epoch n°791 : train_loss = 2.10215163230896, val_loss = 0.7913421988487244\n",
      "epoch n°792 : train_loss = 2.1164963245391846, val_loss = 0.793281614780426\n",
      "epoch n°793 : train_loss = 2.103334426879883, val_loss = 0.7977739572525024\n",
      "epoch n°794 : train_loss = 2.1037375926971436, val_loss = 0.7923309206962585\n",
      "epoch n°795 : train_loss = 2.094477653503418, val_loss = 0.7934577465057373\n",
      "epoch n°796 : train_loss = 2.1007771492004395, val_loss = 0.7937740087509155\n",
      "epoch n°797 : train_loss = 2.097475051879883, val_loss = 0.7922902703285217\n",
      "epoch n°798 : train_loss = 2.0860655307769775, val_loss = 0.7935000061988831\n",
      "epoch n°799 : train_loss = 2.100942611694336, val_loss = 0.7922148704528809\n",
      "epoch n°800 : train_loss = 2.105633497238159, val_loss = 0.7941329479217529\n",
      "epoch n°801 : train_loss = 2.09765887260437, val_loss = 0.7916062474250793\n",
      "epoch n°802 : train_loss = 2.1039137840270996, val_loss = 0.7928498387336731\n",
      "epoch n°803 : train_loss = 2.1077163219451904, val_loss = 0.7937983870506287\n",
      "epoch n°804 : train_loss = 2.097709894180298, val_loss = 0.791519045829773\n",
      "epoch n°805 : train_loss = 2.098104238510132, val_loss = 0.794858455657959\n",
      "epoch n°806 : train_loss = 2.096468210220337, val_loss = 0.7954818606376648\n",
      "epoch n°807 : train_loss = 2.099515199661255, val_loss = 0.7905429005622864\n",
      "epoch n°808 : train_loss = 2.1034305095672607, val_loss = 0.7984814643859863\n",
      "epoch n°809 : train_loss = 2.100069284439087, val_loss = 0.7950494289398193\n",
      "epoch n°810 : train_loss = 2.0954513549804688, val_loss = 0.797739565372467\n",
      "epoch n°811 : train_loss = 2.0945496559143066, val_loss = 0.7942245602607727\n",
      "epoch n°812 : train_loss = 2.107754945755005, val_loss = 0.793642520904541\n",
      "epoch n°813 : train_loss = 2.1015608310699463, val_loss = 0.7957318425178528\n",
      "epoch n°814 : train_loss = 2.0903704166412354, val_loss = 0.7948746085166931\n",
      "epoch n°815 : train_loss = 2.099360704421997, val_loss = 0.7920340895652771\n",
      "epoch n°816 : train_loss = 2.10514497756958, val_loss = 0.7929718494415283\n",
      "epoch n°817 : train_loss = 2.100586175918579, val_loss = 0.7956916093826294\n",
      "epoch n°818 : train_loss = 2.094468116760254, val_loss = 0.7898262143135071\n",
      "epoch n°819 : train_loss = 2.0930562019348145, val_loss = 0.7962275147438049\n",
      "epoch n°820 : train_loss = 2.093212842941284, val_loss = 0.7924836874008179\n",
      "epoch n°821 : train_loss = 2.097369432449341, val_loss = 0.795240044593811\n",
      "epoch n°822 : train_loss = 2.0975050926208496, val_loss = 0.7911266088485718\n",
      "epoch n°823 : train_loss = 2.103193998336792, val_loss = 0.7934055328369141\n",
      "epoch n°824 : train_loss = 2.098403215408325, val_loss = 0.7914132475852966\n",
      "epoch n°825 : train_loss = 2.0981411933898926, val_loss = 0.7944375276565552\n",
      "epoch n°826 : train_loss = 2.097475528717041, val_loss = 0.7956922650337219\n",
      "epoch n°827 : train_loss = 2.0957772731781006, val_loss = 0.7948057055473328\n",
      "epoch n°828 : train_loss = 2.092989683151245, val_loss = 0.792535126209259\n",
      "epoch n°829 : train_loss = 2.0987446308135986, val_loss = 0.7948604822158813\n",
      "epoch n°830 : train_loss = 2.089376211166382, val_loss = 0.7943717241287231\n",
      "epoch n°831 : train_loss = 2.09812068939209, val_loss = 0.7966446876525879\n",
      "epoch n°832 : train_loss = 2.090902805328369, val_loss = 0.7951602339744568\n",
      "epoch n°833 : train_loss = 2.100789785385132, val_loss = 0.7925814986228943\n",
      "epoch n°834 : train_loss = 2.097897529602051, val_loss = 0.7936014533042908\n",
      "epoch n°835 : train_loss = 2.0849859714508057, val_loss = 0.7936973571777344\n",
      "epoch n°836 : train_loss = 2.0969457626342773, val_loss = 0.7912432551383972\n",
      "epoch n°837 : train_loss = 2.096254587173462, val_loss = 0.7952386736869812\n",
      "epoch n°838 : train_loss = 2.087200403213501, val_loss = 0.7947028875350952\n",
      "epoch n°839 : train_loss = 2.09189510345459, val_loss = 0.7939388751983643\n",
      "epoch n°840 : train_loss = 2.1025543212890625, val_loss = 0.7908381223678589\n",
      "epoch n°841 : train_loss = 2.086968421936035, val_loss = 0.7975243330001831\n",
      "epoch n°842 : train_loss = 2.0906918048858643, val_loss = 0.7945631742477417\n",
      "epoch n°843 : train_loss = 2.0964696407318115, val_loss = 0.797039270401001\n",
      "epoch n°844 : train_loss = 2.0958478450775146, val_loss = 0.7915794253349304\n",
      "epoch n°845 : train_loss = 2.0983622074127197, val_loss = 0.7951536178588867\n",
      "epoch n°846 : train_loss = 2.0874452590942383, val_loss = 0.7973338961601257\n",
      "epoch n°847 : train_loss = 2.0830509662628174, val_loss = 0.7923195958137512\n",
      "epoch n°848 : train_loss = 2.1005420684814453, val_loss = 0.7904283404350281\n",
      "epoch n°849 : train_loss = 2.0994796752929688, val_loss = 0.7949838042259216\n",
      "epoch n°850 : train_loss = 2.0867466926574707, val_loss = 0.7955552339553833\n",
      "epoch n°851 : train_loss = 2.097447156906128, val_loss = 0.7933228611946106\n",
      "epoch n°852 : train_loss = 2.096012592315674, val_loss = 0.7982622981071472\n",
      "epoch n°853 : train_loss = 2.091560125350952, val_loss = 0.7918438911437988\n",
      "epoch n°854 : train_loss = 2.0877463817596436, val_loss = 0.793538510799408\n",
      "epoch n°855 : train_loss = 2.0911667346954346, val_loss = 0.7936939001083374\n",
      "epoch n°856 : train_loss = 2.084209442138672, val_loss = 0.7967863082885742\n",
      "epoch n°857 : train_loss = 2.0897724628448486, val_loss = 0.7945865392684937\n",
      "epoch n°858 : train_loss = 2.092851400375366, val_loss = 0.7961683869361877\n",
      "epoch n°859 : train_loss = 2.0878262519836426, val_loss = 0.7909489870071411\n",
      "epoch n°860 : train_loss = 2.0944061279296875, val_loss = 0.7939693331718445\n",
      "epoch n°861 : train_loss = 2.0968563556671143, val_loss = 0.7971051931381226\n",
      "epoch n°862 : train_loss = 2.0943350791931152, val_loss = 0.7926915287971497\n",
      "epoch n°863 : train_loss = 2.084900379180908, val_loss = 0.7955542206764221\n",
      "epoch n°864 : train_loss = 2.102360725402832, val_loss = 0.7942718267440796\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°865 : train_loss = 2.0891072750091553, val_loss = 0.796015739440918\n",
      "epoch n°866 : train_loss = 2.090073347091675, val_loss = 0.7931612730026245\n",
      "epoch n°867 : train_loss = 2.087911605834961, val_loss = 0.7915206551551819\n",
      "epoch n°868 : train_loss = 2.0954997539520264, val_loss = 0.7928173542022705\n",
      "epoch n°869 : train_loss = 2.0786361694335938, val_loss = 0.7947854399681091\n",
      "epoch n°870 : train_loss = 2.0899531841278076, val_loss = 0.7946581840515137\n",
      "epoch n°871 : train_loss = 2.0917727947235107, val_loss = 0.7929120063781738\n",
      "epoch n°872 : train_loss = 2.0969481468200684, val_loss = 0.7924547791481018\n",
      "epoch n°873 : train_loss = 2.0909101963043213, val_loss = 0.7892622351646423\n",
      "epoch n°874 : train_loss = 2.091083288192749, val_loss = 0.7951991558074951\n",
      "epoch n°875 : train_loss = 2.0858850479125977, val_loss = 0.7951076626777649\n",
      "epoch n°876 : train_loss = 2.0871386528015137, val_loss = 0.7969390749931335\n",
      "epoch n°877 : train_loss = 2.082737922668457, val_loss = 0.7916211485862732\n",
      "epoch n°878 : train_loss = 2.0906331539154053, val_loss = 0.7928532958030701\n",
      "epoch n°879 : train_loss = 2.090620279312134, val_loss = 0.7913322448730469\n",
      "epoch n°880 : train_loss = 2.1002557277679443, val_loss = 0.794178307056427\n",
      "epoch n°881 : train_loss = 2.0906014442443848, val_loss = 0.789513349533081\n",
      "epoch n°882 : train_loss = 2.0872838497161865, val_loss = 0.7964572906494141\n",
      "epoch n°883 : train_loss = 2.0879178047180176, val_loss = 0.7963612675666809\n",
      "epoch n°884 : train_loss = 2.0851118564605713, val_loss = 0.793904185295105\n",
      "epoch n°885 : train_loss = 2.0849814414978027, val_loss = 0.7889286279678345\n",
      "epoch n°886 : train_loss = 2.0856094360351562, val_loss = 0.7931779623031616\n",
      "epoch n°887 : train_loss = 2.09531307220459, val_loss = 0.7938897609710693\n",
      "epoch n°888 : train_loss = 2.095172882080078, val_loss = 0.7905266284942627\n",
      "epoch n°889 : train_loss = 2.0852503776550293, val_loss = 0.7931550741195679\n",
      "epoch n°890 : train_loss = 2.092829942703247, val_loss = 0.794401228427887\n",
      "epoch n°891 : train_loss = 2.0809972286224365, val_loss = 0.7946033477783203\n",
      "epoch n°892 : train_loss = 2.0808041095733643, val_loss = 0.7927213907241821\n",
      "epoch n°893 : train_loss = 2.0851187705993652, val_loss = 0.7941268682479858\n",
      "epoch n°894 : train_loss = 2.0841946601867676, val_loss = 0.7949289083480835\n",
      "epoch n°895 : train_loss = 2.092620372772217, val_loss = 0.7953599691390991\n",
      "epoch n°896 : train_loss = 2.089646100997925, val_loss = 0.7918791174888611\n",
      "epoch n°897 : train_loss = 2.0909531116485596, val_loss = 0.79563969373703\n",
      "epoch n°898 : train_loss = 2.0919909477233887, val_loss = 0.7942771315574646\n",
      "epoch n°899 : train_loss = 2.0916144847869873, val_loss = 0.7928128838539124\n",
      "epoch n°900 : train_loss = 2.091041326522827, val_loss = 0.7930508852005005\n",
      "epoch n°901 : train_loss = 2.0874903202056885, val_loss = 0.7934138774871826\n",
      "epoch n°902 : train_loss = 2.0850448608398438, val_loss = 0.7972768545150757\n",
      "epoch n°903 : train_loss = 2.0881388187408447, val_loss = 0.790645182132721\n",
      "epoch n°904 : train_loss = 2.0791850090026855, val_loss = 0.7949740886688232\n",
      "epoch n°905 : train_loss = 2.0776901245117188, val_loss = 0.7939296364784241\n",
      "epoch n°906 : train_loss = 2.0922250747680664, val_loss = 0.7920923233032227\n",
      "epoch n°907 : train_loss = 2.080676317214966, val_loss = 0.7940517663955688\n",
      "epoch n°908 : train_loss = 2.0837390422821045, val_loss = 0.7955162525177002\n",
      "epoch n°909 : train_loss = 2.0831596851348877, val_loss = 0.791231632232666\n",
      "epoch n°910 : train_loss = 2.081641674041748, val_loss = 0.7913032174110413\n",
      "epoch n°911 : train_loss = 2.080159902572632, val_loss = 0.794521689414978\n",
      "epoch n°912 : train_loss = 2.084766387939453, val_loss = 0.7933149337768555\n",
      "epoch n°913 : train_loss = 2.088311195373535, val_loss = 0.7928114533424377\n",
      "epoch n°914 : train_loss = 2.076413154602051, val_loss = 0.793697714805603\n",
      "epoch n°915 : train_loss = 2.093644380569458, val_loss = 0.799630343914032\n",
      "epoch n°916 : train_loss = 2.08540415763855, val_loss = 0.7934570908546448\n",
      "epoch n°917 : train_loss = 2.092268943786621, val_loss = 0.7933967709541321\n",
      "epoch n°918 : train_loss = 2.0851027965545654, val_loss = 0.7929779887199402\n",
      "epoch n°919 : train_loss = 2.0798137187957764, val_loss = 0.7914749383926392\n",
      "epoch n°920 : train_loss = 2.087862491607666, val_loss = 0.7952436208724976\n",
      "epoch n°921 : train_loss = 2.0794730186462402, val_loss = 0.7942845821380615\n",
      "epoch n°922 : train_loss = 2.087010383605957, val_loss = 0.7902889251708984\n",
      "epoch n°923 : train_loss = 2.0838992595672607, val_loss = 0.7927209138870239\n",
      "epoch n°924 : train_loss = 2.075685501098633, val_loss = 0.7936223745346069\n",
      "epoch n°925 : train_loss = 2.0907442569732666, val_loss = 0.7950215935707092\n",
      "epoch n°926 : train_loss = 2.078822135925293, val_loss = 0.793463945388794\n",
      "epoch n°927 : train_loss = 2.078075408935547, val_loss = 0.7907785773277283\n",
      "epoch n°928 : train_loss = 2.0813724994659424, val_loss = 0.7986196279525757\n",
      "epoch n°929 : train_loss = 2.0893192291259766, val_loss = 0.7931755781173706\n",
      "epoch n°930 : train_loss = 2.080777645111084, val_loss = 0.7919479012489319\n",
      "epoch n°931 : train_loss = 2.0839385986328125, val_loss = 0.7890506386756897\n",
      "epoch n°932 : train_loss = 2.079437494277954, val_loss = 0.7942066788673401\n",
      "epoch n°933 : train_loss = 2.0753870010375977, val_loss = 0.7922190427780151\n",
      "epoch n°934 : train_loss = 2.0828475952148438, val_loss = 0.7933657765388489\n",
      "epoch n°935 : train_loss = 2.084500312805176, val_loss = 0.7941229343414307\n",
      "epoch n°936 : train_loss = 2.0865206718444824, val_loss = 0.7955739498138428\n",
      "epoch n°937 : train_loss = 2.0879623889923096, val_loss = 0.7935335636138916\n",
      "epoch n°938 : train_loss = 2.0818493366241455, val_loss = 0.7997773885726929\n",
      "epoch n°939 : train_loss = 2.083071708679199, val_loss = 0.7941169738769531\n",
      "epoch n°940 : train_loss = 2.084437131881714, val_loss = 0.7949225306510925\n",
      "epoch n°941 : train_loss = 2.091503858566284, val_loss = 0.7976892590522766\n",
      "epoch n°942 : train_loss = 2.089109420776367, val_loss = 0.7913222908973694\n",
      "epoch n°943 : train_loss = 2.087249279022217, val_loss = 0.7898741364479065\n",
      "epoch n°944 : train_loss = 2.080416679382324, val_loss = 0.7925707101821899\n",
      "epoch n°945 : train_loss = 2.0826547145843506, val_loss = 0.7894485592842102\n",
      "epoch n°946 : train_loss = 2.0789194107055664, val_loss = 0.7968523502349854\n",
      "epoch n°947 : train_loss = 2.0858678817749023, val_loss = 0.794744610786438\n",
      "epoch n°948 : train_loss = 2.0830743312835693, val_loss = 0.7990416288375854\n",
      "epoch n°949 : train_loss = 2.0929791927337646, val_loss = 0.7900241613388062\n",
      "epoch n°950 : train_loss = 2.0902507305145264, val_loss = 0.7928879857063293\n",
      "epoch n°951 : train_loss = 2.078028917312622, val_loss = 0.7942568063735962\n",
      "epoch n°952 : train_loss = 2.0860366821289062, val_loss = 0.7955085635185242\n",
      "epoch n°953 : train_loss = 2.089059352874756, val_loss = 0.7942611575126648\n",
      "epoch n°954 : train_loss = 2.0993735790252686, val_loss = 0.7894913554191589\n",
      "epoch n°955 : train_loss = 2.0820937156677246, val_loss = 0.7923890352249146\n",
      "epoch n°956 : train_loss = 2.079824447631836, val_loss = 0.7968377470970154\n",
      "epoch n°957 : train_loss = 2.075009822845459, val_loss = 0.7947616577148438\n",
      "epoch n°958 : train_loss = 2.0840158462524414, val_loss = 0.7898297905921936\n",
      "epoch n°959 : train_loss = 2.0808682441711426, val_loss = 0.7909414172172546\n",
      "epoch n°960 : train_loss = 2.083956003189087, val_loss = 0.7907827496528625\n",
      "epoch n°961 : train_loss = 2.0898215770721436, val_loss = 0.7896671891212463\n",
      "epoch n°962 : train_loss = 2.077669143676758, val_loss = 0.7943082451820374\n",
      "epoch n°963 : train_loss = 2.084566831588745, val_loss = 0.7915387153625488\n",
      "epoch n°964 : train_loss = 2.0874717235565186, val_loss = 0.785694420337677\n",
      "epoch n°965 : train_loss = 2.083590269088745, val_loss = 0.7950590252876282\n",
      "epoch n°966 : train_loss = 2.086362600326538, val_loss = 0.7964353561401367\n",
      "epoch n°967 : train_loss = 2.0806097984313965, val_loss = 0.7893106937408447\n",
      "epoch n°968 : train_loss = 2.082034111022949, val_loss = 0.79413241147995\n",
      "epoch n°969 : train_loss = 2.0834953784942627, val_loss = 0.794732928276062\n",
      "epoch n°970 : train_loss = 2.0753917694091797, val_loss = 0.791634738445282\n",
      "epoch n°971 : train_loss = 2.0777533054351807, val_loss = 0.7977896332740784\n",
      "epoch n°972 : train_loss = 2.080070972442627, val_loss = 0.7921467423439026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°973 : train_loss = 2.0807435512542725, val_loss = 0.7913111448287964\n",
      "epoch n°974 : train_loss = 2.080427646636963, val_loss = 0.7943079471588135\n",
      "epoch n°975 : train_loss = 2.08441424369812, val_loss = 0.7921202778816223\n",
      "epoch n°976 : train_loss = 2.079874277114868, val_loss = 0.7922267317771912\n",
      "epoch n°977 : train_loss = 2.0800249576568604, val_loss = 0.7899177670478821\n",
      "epoch n°978 : train_loss = 2.0826973915100098, val_loss = 0.7942233681678772\n",
      "epoch n°979 : train_loss = 2.0790364742279053, val_loss = 0.7937131524085999\n",
      "epoch n°980 : train_loss = 2.0773496627807617, val_loss = 0.7912003993988037\n",
      "epoch n°981 : train_loss = 2.0757811069488525, val_loss = 0.7882147431373596\n",
      "epoch n°982 : train_loss = 2.075315237045288, val_loss = 0.7953120470046997\n",
      "epoch n°983 : train_loss = 2.077910900115967, val_loss = 0.7933682203292847\n",
      "epoch n°984 : train_loss = 2.083664655685425, val_loss = 0.7914401292800903\n",
      "epoch n°985 : train_loss = 2.087423324584961, val_loss = 0.7946136593818665\n",
      "epoch n°986 : train_loss = 2.069826126098633, val_loss = 0.7955598831176758\n",
      "epoch n°987 : train_loss = 2.0872802734375, val_loss = 0.799882173538208\n",
      "epoch n°988 : train_loss = 2.0820834636688232, val_loss = 0.7940645217895508\n",
      "epoch n°989 : train_loss = 2.083883047103882, val_loss = 0.7925395369529724\n",
      "epoch n°990 : train_loss = 2.088193416595459, val_loss = 0.7947482466697693\n",
      "epoch n°991 : train_loss = 2.0888659954071045, val_loss = 0.7936714291572571\n",
      "epoch n°992 : train_loss = 2.0822179317474365, val_loss = 0.7938718795776367\n",
      "epoch n°993 : train_loss = 2.0832042694091797, val_loss = 0.7931201457977295\n",
      "epoch n°994 : train_loss = 2.084331750869751, val_loss = 0.7942281365394592\n",
      "epoch n°995 : train_loss = 2.081521511077881, val_loss = 0.7981663346290588\n",
      "epoch n°996 : train_loss = 2.0867326259613037, val_loss = 0.7923725247383118\n",
      "epoch n°997 : train_loss = 2.0867271423339844, val_loss = 0.7950083017349243\n",
      "epoch n°998 : train_loss = 2.0892138481140137, val_loss = 0.7943391799926758\n",
      "epoch n°999 : train_loss = 2.092026948928833, val_loss = 0.7933515906333923\n",
      "epoch n°1000 : train_loss = 2.0788538455963135, val_loss = 0.7888473272323608\n",
      "epoch n°1001 : train_loss = 2.079169273376465, val_loss = 0.7933123111724854\n",
      "epoch n°1002 : train_loss = 2.088479995727539, val_loss = 0.7918131351470947\n",
      "epoch n°1003 : train_loss = 2.088392972946167, val_loss = 0.7895858883857727\n",
      "epoch n°1004 : train_loss = 2.090557336807251, val_loss = 0.7907212376594543\n",
      "epoch n°1005 : train_loss = 2.079029083251953, val_loss = 0.7932532429695129\n",
      "epoch n°1006 : train_loss = 2.0915513038635254, val_loss = 0.7918241620063782\n",
      "epoch n°1007 : train_loss = 2.0806691646575928, val_loss = 0.7932943105697632\n",
      "epoch n°1008 : train_loss = 2.1092581748962402, val_loss = 0.7909989953041077\n",
      "epoch n°1009 : train_loss = 2.125206232070923, val_loss = 0.7995381951332092\n",
      "epoch n°1010 : train_loss = 2.1076183319091797, val_loss = 0.798430860042572\n",
      "epoch n°1011 : train_loss = 2.1103193759918213, val_loss = 0.7942413687705994\n",
      "epoch n°1012 : train_loss = 2.1144461631774902, val_loss = 0.7966759204864502\n",
      "epoch n°1013 : train_loss = 2.1122167110443115, val_loss = 0.8015468120574951\n",
      "epoch n°1014 : train_loss = 2.1077027320861816, val_loss = 0.7957773208618164\n",
      "epoch n°1015 : train_loss = 2.1165127754211426, val_loss = 0.7984744310379028\n",
      "epoch n°1016 : train_loss = 2.1133642196655273, val_loss = 0.8014036417007446\n",
      "epoch n°1017 : train_loss = 2.1080522537231445, val_loss = 0.7946625351905823\n",
      "epoch n°1018 : train_loss = 2.1115829944610596, val_loss = 0.8002325892448425\n",
      "epoch n°1019 : train_loss = 2.1241185665130615, val_loss = 0.7969935536384583\n",
      "epoch n°1020 : train_loss = 2.104555368423462, val_loss = 0.7967567443847656\n",
      "epoch n°1021 : train_loss = 2.11711049079895, val_loss = 0.7978863716125488\n",
      "epoch n°1022 : train_loss = 2.112816333770752, val_loss = 0.7962292432785034\n",
      "epoch n°1023 : train_loss = 2.1162610054016113, val_loss = 0.7937209010124207\n",
      "epoch n°1024 : train_loss = 2.117600202560425, val_loss = 0.7970408201217651\n",
      "epoch n°1025 : train_loss = 2.109783887863159, val_loss = 0.7969038486480713\n",
      "epoch n°1026 : train_loss = 2.116436719894409, val_loss = 0.7996877431869507\n",
      "epoch n°1027 : train_loss = 2.1204659938812256, val_loss = 0.7968820929527283\n",
      "epoch n°1028 : train_loss = 2.115772008895874, val_loss = 0.7973192930221558\n",
      "epoch n°1029 : train_loss = 2.118093967437744, val_loss = 0.7949584722518921\n",
      "epoch n°1030 : train_loss = 2.110926866531372, val_loss = 0.7956828474998474\n",
      "epoch n°1031 : train_loss = 2.121955394744873, val_loss = 0.7985295653343201\n",
      "epoch n°1032 : train_loss = 2.11497163772583, val_loss = 0.7963284254074097\n",
      "epoch n°1033 : train_loss = 2.1126952171325684, val_loss = 0.7953928709030151\n",
      "epoch n°1034 : train_loss = 2.1145126819610596, val_loss = 0.7994541525840759\n",
      "epoch n°1035 : train_loss = 2.1125802993774414, val_loss = 0.7971755862236023\n",
      "epoch n°1036 : train_loss = 2.1140007972717285, val_loss = 0.7934955954551697\n",
      "epoch n°1037 : train_loss = 2.112743854522705, val_loss = 0.7994850277900696\n",
      "epoch n°1038 : train_loss = 2.121829032897949, val_loss = 0.7952114939689636\n",
      "epoch n°1039 : train_loss = 2.112461805343628, val_loss = 0.7977795004844666\n",
      "epoch n°1040 : train_loss = 2.1202945709228516, val_loss = 0.7921335101127625\n",
      "epoch n°1041 : train_loss = 2.119981527328491, val_loss = 0.7964573502540588\n",
      "epoch n°1042 : train_loss = 2.1143977642059326, val_loss = 0.7986094355583191\n",
      "epoch n°1043 : train_loss = 2.115769863128662, val_loss = 0.7976194620132446\n",
      "epoch n°1044 : train_loss = 2.118302345275879, val_loss = 0.7968562841415405\n",
      "epoch n°1045 : train_loss = 2.108999252319336, val_loss = 0.793662428855896\n",
      "epoch n°1046 : train_loss = 2.1177620887756348, val_loss = 0.7956857085227966\n",
      "epoch n°1047 : train_loss = 2.1168839931488037, val_loss = 0.7965822815895081\n",
      "epoch n°1048 : train_loss = 2.112332582473755, val_loss = 0.7999531030654907\n",
      "epoch n°1049 : train_loss = 2.1214118003845215, val_loss = 0.79904705286026\n",
      "epoch n°1050 : train_loss = 2.1134872436523438, val_loss = 0.7929396629333496\n",
      "epoch n°1051 : train_loss = 2.1144886016845703, val_loss = 0.7969785928726196\n",
      "epoch n°1052 : train_loss = 2.1058478355407715, val_loss = 0.7949489951133728\n",
      "epoch n°1053 : train_loss = 2.1155691146850586, val_loss = 0.7955432534217834\n",
      "epoch n°1054 : train_loss = 2.1216888427734375, val_loss = 0.7941309809684753\n",
      "epoch n°1055 : train_loss = 2.1178841590881348, val_loss = 0.7978244423866272\n",
      "epoch n°1056 : train_loss = 2.1182663440704346, val_loss = 0.7946600914001465\n",
      "epoch n°1057 : train_loss = 2.1175262928009033, val_loss = 0.7982591986656189\n",
      "epoch n°1058 : train_loss = 2.1204230785369873, val_loss = 0.7925847172737122\n",
      "epoch n°1059 : train_loss = 2.1125104427337646, val_loss = 0.7949995994567871\n",
      "epoch n°1060 : train_loss = 2.114337205886841, val_loss = 0.7994979619979858\n",
      "epoch n°1061 : train_loss = 2.114794969558716, val_loss = 0.7984140515327454\n",
      "epoch n°1062 : train_loss = 2.109835147857666, val_loss = 0.7920857667922974\n",
      "epoch n°1063 : train_loss = 2.116307258605957, val_loss = 0.7980066537857056\n",
      "epoch n°1064 : train_loss = 2.1106514930725098, val_loss = 0.7995445132255554\n",
      "epoch n°1065 : train_loss = 2.1117916107177734, val_loss = 0.7967627644538879\n",
      "epoch n°1066 : train_loss = 2.1119985580444336, val_loss = 0.7966349124908447\n",
      "epoch n°1067 : train_loss = 2.112457275390625, val_loss = 0.7960802316665649\n",
      "epoch n°1068 : train_loss = 2.117558002471924, val_loss = 0.7980314493179321\n",
      "epoch n°1069 : train_loss = 2.1118323802948, val_loss = 0.794779360294342\n",
      "epoch n°1070 : train_loss = 2.1270670890808105, val_loss = 0.796604573726654\n",
      "epoch n°1071 : train_loss = 2.110757350921631, val_loss = 0.7967307567596436\n",
      "epoch n°1072 : train_loss = 2.1178388595581055, val_loss = 0.7942149043083191\n",
      "epoch n°1073 : train_loss = 2.115185022354126, val_loss = 0.7951618432998657\n",
      "epoch n°1074 : train_loss = 2.120319366455078, val_loss = 0.7959852814674377\n",
      "epoch n°1075 : train_loss = 2.113938093185425, val_loss = 0.7969458699226379\n",
      "epoch n°1076 : train_loss = 2.11061954498291, val_loss = 0.7973375916481018\n",
      "epoch n°1077 : train_loss = 2.1153957843780518, val_loss = 0.7927269339561462\n",
      "epoch n°1078 : train_loss = 2.1152212619781494, val_loss = 0.7988737225532532\n",
      "epoch n°1079 : train_loss = 2.1175954341888428, val_loss = 0.7950755953788757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°1080 : train_loss = 2.118396043777466, val_loss = 0.7952908873558044\n",
      "epoch n°1081 : train_loss = 2.1148664951324463, val_loss = 0.7966376543045044\n",
      "epoch n°1082 : train_loss = 2.1215274333953857, val_loss = 0.7963247895240784\n",
      "epoch n°1083 : train_loss = 2.1174674034118652, val_loss = 0.7973765134811401\n",
      "epoch n°1084 : train_loss = 2.1133625507354736, val_loss = 0.798900842666626\n",
      "epoch n°1085 : train_loss = 2.1098124980926514, val_loss = 0.7953512072563171\n",
      "epoch n°1086 : train_loss = 2.1099581718444824, val_loss = 0.7982258796691895\n",
      "epoch n°1087 : train_loss = 2.1105308532714844, val_loss = 0.7939500212669373\n",
      "epoch n°1088 : train_loss = 2.1157331466674805, val_loss = 0.7940219044685364\n",
      "epoch n°1089 : train_loss = 2.121769666671753, val_loss = 0.7975455522537231\n",
      "epoch n°1090 : train_loss = 2.120384454727173, val_loss = 0.7983177900314331\n",
      "epoch n°1091 : train_loss = 2.1141088008880615, val_loss = 0.7989121675491333\n",
      "epoch n°1092 : train_loss = 2.117875337600708, val_loss = 0.7987926006317139\n",
      "epoch n°1093 : train_loss = 2.1106996536254883, val_loss = 0.7996112704277039\n",
      "epoch n°1094 : train_loss = 2.1164050102233887, val_loss = 0.7960609197616577\n",
      "epoch n°1095 : train_loss = 2.1089749336242676, val_loss = 0.7982175946235657\n",
      "epoch n°1096 : train_loss = 2.119328737258911, val_loss = 0.7956314086914062\n",
      "epoch n°1097 : train_loss = 2.1191070079803467, val_loss = 0.7937121391296387\n",
      "epoch n°1098 : train_loss = 2.1146037578582764, val_loss = 0.796990156173706\n",
      "epoch n°1099 : train_loss = 2.1124322414398193, val_loss = 0.7955743670463562\n",
      "epoch n°1100 : train_loss = 2.1146011352539062, val_loss = 0.8007780313491821\n",
      "epoch n°1101 : train_loss = 2.114269971847534, val_loss = 0.7982032895088196\n",
      "epoch n°1102 : train_loss = 2.1065938472747803, val_loss = 0.796528697013855\n",
      "epoch n°1103 : train_loss = 2.114271879196167, val_loss = 0.7945690155029297\n",
      "epoch n°1104 : train_loss = 2.1117968559265137, val_loss = 0.8010136485099792\n",
      "epoch n°1105 : train_loss = 2.119596242904663, val_loss = 0.7978406548500061\n",
      "epoch n°1106 : train_loss = 2.13061785697937, val_loss = 0.7984480857849121\n",
      "epoch n°1107 : train_loss = 2.1219372749328613, val_loss = 0.7961604595184326\n",
      "epoch n°1108 : train_loss = 2.1256656646728516, val_loss = 0.7948628664016724\n",
      "epoch n°1109 : train_loss = 2.109473943710327, val_loss = 0.7985984683036804\n",
      "epoch n°1110 : train_loss = 2.117877960205078, val_loss = 0.7955210208892822\n",
      "epoch n°1111 : train_loss = 2.115910768508911, val_loss = 0.7947341799736023\n",
      "epoch n°1112 : train_loss = 2.117856979370117, val_loss = 0.795714259147644\n",
      "epoch n°1113 : train_loss = 2.117061138153076, val_loss = 0.8001782894134521\n",
      "epoch n°1114 : train_loss = 2.107400417327881, val_loss = 0.797225296497345\n",
      "epoch n°1115 : train_loss = 2.107053279876709, val_loss = 0.7989466786384583\n",
      "epoch n°1116 : train_loss = 2.1087684631347656, val_loss = 0.7997641563415527\n",
      "epoch n°1117 : train_loss = 2.1147563457489014, val_loss = 0.7963986992835999\n",
      "epoch n°1118 : train_loss = 2.1034936904907227, val_loss = 0.7965478897094727\n",
      "epoch n°1119 : train_loss = 2.118273973464966, val_loss = 0.7956988215446472\n",
      "epoch n°1120 : train_loss = 2.1083836555480957, val_loss = 0.7951660752296448\n",
      "epoch n°1121 : train_loss = 2.11029052734375, val_loss = 0.8003316521644592\n",
      "epoch n°1122 : train_loss = 2.103105306625366, val_loss = 0.7968249320983887\n",
      "epoch n°1123 : train_loss = 2.116393566131592, val_loss = 0.795787513256073\n",
      "epoch n°1124 : train_loss = 2.1026265621185303, val_loss = 0.7996581792831421\n",
      "epoch n°1125 : train_loss = 2.1106529235839844, val_loss = 0.798222541809082\n",
      "epoch n°1126 : train_loss = 2.102745532989502, val_loss = 0.7981292605400085\n",
      "epoch n°1127 : train_loss = 2.120098114013672, val_loss = 0.7987444400787354\n",
      "epoch n°1128 : train_loss = 2.111842632293701, val_loss = 0.7958617806434631\n",
      "epoch n°1129 : train_loss = 2.110044240951538, val_loss = 0.7998515367507935\n",
      "epoch n°1130 : train_loss = 2.119030237197876, val_loss = 0.8014232516288757\n",
      "epoch n°1131 : train_loss = 2.109997510910034, val_loss = 0.7956867814064026\n",
      "epoch n°1132 : train_loss = 2.1129727363586426, val_loss = 0.794934093952179\n",
      "epoch n°1133 : train_loss = 2.1131668090820312, val_loss = 0.7970849871635437\n",
      "epoch n°1134 : train_loss = 2.1034226417541504, val_loss = 0.7951177954673767\n",
      "epoch n°1135 : train_loss = 2.1132633686065674, val_loss = 0.7896480560302734\n",
      "epoch n°1136 : train_loss = 2.104522228240967, val_loss = 0.7960444688796997\n",
      "epoch n°1137 : train_loss = 2.108833074569702, val_loss = 0.7930001616477966\n",
      "epoch n°1138 : train_loss = 2.1154513359069824, val_loss = 0.7965973615646362\n",
      "epoch n°1139 : train_loss = 2.1100332736968994, val_loss = 0.7943035960197449\n",
      "epoch n°1140 : train_loss = 2.1068503856658936, val_loss = 0.7972411513328552\n",
      "epoch n°1141 : train_loss = 2.113774299621582, val_loss = 0.7942080497741699\n",
      "epoch n°1142 : train_loss = 2.1128013134002686, val_loss = 0.8020610809326172\n",
      "epoch n°1143 : train_loss = 2.1133482456207275, val_loss = 0.7946054339408875\n",
      "epoch n°1144 : train_loss = 2.1056063175201416, val_loss = 0.7958685755729675\n",
      "epoch n°1145 : train_loss = 2.1103105545043945, val_loss = 0.7971419095993042\n",
      "epoch n°1146 : train_loss = 2.0963146686553955, val_loss = 0.7971503138542175\n",
      "epoch n°1147 : train_loss = 2.111466884613037, val_loss = 0.7917772531509399\n",
      "epoch n°1148 : train_loss = 2.0998706817626953, val_loss = 0.8022171854972839\n",
      "epoch n°1149 : train_loss = 2.115504503250122, val_loss = 0.7980259656906128\n",
      "epoch n°1150 : train_loss = 2.1063268184661865, val_loss = 0.7947854399681091\n",
      "epoch n°1151 : train_loss = 2.118804454803467, val_loss = 0.7942880988121033\n",
      "epoch n°1152 : train_loss = 2.1089422702789307, val_loss = 0.7958335280418396\n",
      "epoch n°1153 : train_loss = 2.1152396202087402, val_loss = 0.794180691242218\n",
      "epoch n°1154 : train_loss = 2.0952088832855225, val_loss = 0.7963651418685913\n",
      "epoch n°1155 : train_loss = 2.1009647846221924, val_loss = 0.7907940149307251\n",
      "epoch n°1156 : train_loss = 2.1037211418151855, val_loss = 0.7946382164955139\n",
      "epoch n°1157 : train_loss = 2.1104178428649902, val_loss = 0.7942649722099304\n",
      "epoch n°1158 : train_loss = 2.1078455448150635, val_loss = 0.794921875\n",
      "epoch n°1159 : train_loss = 2.101961374282837, val_loss = 0.7913982272148132\n",
      "epoch n°1160 : train_loss = 2.0969440937042236, val_loss = 0.7987774610519409\n",
      "epoch n°1161 : train_loss = 2.099529504776001, val_loss = 0.7943809032440186\n",
      "epoch n°1162 : train_loss = 2.103334665298462, val_loss = 0.7955960035324097\n",
      "epoch n°1163 : train_loss = 2.1020634174346924, val_loss = 0.7981463074684143\n",
      "epoch n°1164 : train_loss = 2.109938383102417, val_loss = 0.7992665767669678\n",
      "epoch n°1165 : train_loss = 2.1088576316833496, val_loss = 0.7934837341308594\n",
      "epoch n°1166 : train_loss = 2.1140096187591553, val_loss = 0.7962837219238281\n",
      "epoch n°1167 : train_loss = 2.113330841064453, val_loss = 0.7920507192611694\n",
      "epoch n°1168 : train_loss = 2.116396903991699, val_loss = 0.8015298247337341\n",
      "epoch n°1169 : train_loss = 2.105560064315796, val_loss = 0.7954214215278625\n",
      "epoch n°1170 : train_loss = 2.1021647453308105, val_loss = 0.7978526949882507\n",
      "epoch n°1171 : train_loss = 2.1108574867248535, val_loss = 0.7951711416244507\n",
      "epoch n°1172 : train_loss = 2.111567735671997, val_loss = 0.7962355613708496\n",
      "epoch n°1173 : train_loss = 2.1133782863616943, val_loss = 0.795590877532959\n",
      "epoch n°1174 : train_loss = 2.1029417514801025, val_loss = 0.7947884798049927\n",
      "epoch n°1175 : train_loss = 2.104017972946167, val_loss = 0.8013216257095337\n",
      "epoch n°1176 : train_loss = 2.1094918251037598, val_loss = 0.7998325824737549\n",
      "epoch n°1177 : train_loss = 2.1027989387512207, val_loss = 0.793900728225708\n",
      "epoch n°1178 : train_loss = 2.109618663787842, val_loss = 0.7952946424484253\n",
      "epoch n°1179 : train_loss = 2.1104896068573, val_loss = 0.7982397079467773\n",
      "epoch n°1180 : train_loss = 2.1033034324645996, val_loss = 0.796331524848938\n",
      "epoch n°1181 : train_loss = 2.1144464015960693, val_loss = 0.7992716431617737\n",
      "epoch n°1182 : train_loss = 2.1128969192504883, val_loss = 0.7946985960006714\n",
      "epoch n°1183 : train_loss = 2.11039662361145, val_loss = 0.7986708879470825\n",
      "epoch n°1184 : train_loss = 2.1069090366363525, val_loss = 0.7960796356201172\n",
      "epoch n°1185 : train_loss = 2.10488224029541, val_loss = 0.7963196635246277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°1186 : train_loss = 2.1102447509765625, val_loss = 0.7909876108169556\n",
      "epoch n°1187 : train_loss = 2.1137287616729736, val_loss = 0.8002837896347046\n",
      "epoch n°1188 : train_loss = 2.1147797107696533, val_loss = 0.7977218627929688\n",
      "epoch n°1189 : train_loss = 2.1151909828186035, val_loss = 0.7978308200836182\n",
      "epoch n°1190 : train_loss = 2.110332727432251, val_loss = 0.7953202724456787\n",
      "epoch n°1191 : train_loss = 2.104767322540283, val_loss = 0.7937140464782715\n",
      "epoch n°1192 : train_loss = 2.103728771209717, val_loss = 0.7984472513198853\n",
      "epoch n°1193 : train_loss = 2.100921630859375, val_loss = 0.7955068349838257\n",
      "epoch n°1194 : train_loss = 2.1061623096466064, val_loss = 0.7954395413398743\n",
      "epoch n°1195 : train_loss = 2.105813980102539, val_loss = 0.7915809154510498\n",
      "epoch n°1196 : train_loss = 2.109797716140747, val_loss = 0.7956885099411011\n",
      "epoch n°1197 : train_loss = 2.102970838546753, val_loss = 0.7978602647781372\n",
      "epoch n°1198 : train_loss = 2.106682300567627, val_loss = 0.801886796951294\n",
      "epoch n°1199 : train_loss = 2.108539581298828, val_loss = 0.7973973751068115\n",
      "epoch n°1200 : train_loss = 2.1085257530212402, val_loss = 0.7984965443611145\n",
      "epoch n°1201 : train_loss = 2.09315824508667, val_loss = 0.7938257455825806\n",
      "epoch n°1202 : train_loss = 2.1085779666900635, val_loss = 0.7945041656494141\n",
      "epoch n°1203 : train_loss = 2.106595039367676, val_loss = 0.7946574687957764\n",
      "epoch n°1204 : train_loss = 2.1052534580230713, val_loss = 0.7989735007286072\n",
      "epoch n°1205 : train_loss = 2.098771333694458, val_loss = 0.7965481281280518\n",
      "epoch n°1206 : train_loss = 2.1094133853912354, val_loss = 0.7906813621520996\n",
      "epoch n°1207 : train_loss = 2.097536087036133, val_loss = 0.7960419058799744\n",
      "epoch n°1208 : train_loss = 2.102729320526123, val_loss = 0.7969791293144226\n",
      "epoch n°1209 : train_loss = 2.0988783836364746, val_loss = 0.7990826368331909\n",
      "epoch n°1210 : train_loss = 2.1079938411712646, val_loss = 0.7925149202346802\n",
      "epoch n°1211 : train_loss = 2.097383975982666, val_loss = 0.7966822981834412\n",
      "epoch n°1212 : train_loss = 2.1122264862060547, val_loss = 0.7948505878448486\n",
      "epoch n°1213 : train_loss = 2.1142005920410156, val_loss = 0.7943748831748962\n",
      "epoch n°1214 : train_loss = 2.105842113494873, val_loss = 0.7968106865882874\n",
      "epoch n°1215 : train_loss = 2.10441517829895, val_loss = 0.7989401817321777\n",
      "epoch n°1216 : train_loss = 2.1144044399261475, val_loss = 0.7968027591705322\n",
      "epoch n°1217 : train_loss = 2.103977918624878, val_loss = 0.7969786524772644\n",
      "epoch n°1218 : train_loss = 2.095602035522461, val_loss = 0.7973153591156006\n",
      "epoch n°1219 : train_loss = 2.1052358150482178, val_loss = 0.7970463633537292\n",
      "epoch n°1220 : train_loss = 2.0976414680480957, val_loss = 0.7978730797767639\n",
      "epoch n°1221 : train_loss = 2.1101326942443848, val_loss = 0.794373095035553\n",
      "epoch n°1222 : train_loss = 2.1030478477478027, val_loss = 0.7921105027198792\n",
      "epoch n°1223 : train_loss = 2.0956783294677734, val_loss = 0.7984960675239563\n",
      "epoch n°1224 : train_loss = 2.1079869270324707, val_loss = 0.7929344177246094\n",
      "epoch n°1225 : train_loss = 2.106912851333618, val_loss = 0.7965720891952515\n",
      "epoch n°1226 : train_loss = 2.0992400646209717, val_loss = 0.7963098287582397\n",
      "epoch n°1227 : train_loss = 2.102090835571289, val_loss = 0.7957289218902588\n",
      "epoch n°1228 : train_loss = 2.0987346172332764, val_loss = 0.7927109599113464\n",
      "epoch n°1229 : train_loss = 2.0901427268981934, val_loss = 0.799237072467804\n",
      "epoch n°1230 : train_loss = 2.1020431518554688, val_loss = 0.7977390289306641\n",
      "epoch n°1231 : train_loss = 2.0931732654571533, val_loss = 0.7918550968170166\n",
      "epoch n°1232 : train_loss = 2.1021058559417725, val_loss = 0.7964086532592773\n",
      "epoch n°1233 : train_loss = 2.105149030685425, val_loss = 0.8000163435935974\n",
      "epoch n°1234 : train_loss = 2.108130931854248, val_loss = 0.7965849041938782\n",
      "epoch n°1235 : train_loss = 2.0996689796447754, val_loss = 0.7921386957168579\n",
      "epoch n°1236 : train_loss = 2.0966203212738037, val_loss = 0.7918648719787598\n",
      "epoch n°1237 : train_loss = 2.1008834838867188, val_loss = 0.7964069843292236\n",
      "epoch n°1238 : train_loss = 2.0923268795013428, val_loss = 0.7938677072525024\n",
      "epoch n°1239 : train_loss = 2.1012039184570312, val_loss = 0.7932623028755188\n",
      "epoch n°1240 : train_loss = 2.0914671421051025, val_loss = 0.7943127155303955\n",
      "epoch n°1241 : train_loss = 2.094059944152832, val_loss = 0.800464928150177\n",
      "epoch n°1242 : train_loss = 2.102578639984131, val_loss = 0.7966933250427246\n",
      "epoch n°1243 : train_loss = 2.1010701656341553, val_loss = 0.7967601418495178\n",
      "epoch n°1244 : train_loss = 2.099348306655884, val_loss = 0.7992732524871826\n",
      "epoch n°1245 : train_loss = 2.1016199588775635, val_loss = 0.7971972823143005\n",
      "epoch n°1246 : train_loss = 2.107672929763794, val_loss = 0.7939819693565369\n",
      "epoch n°1247 : train_loss = 2.102163314819336, val_loss = 0.7951083779335022\n",
      "epoch n°1248 : train_loss = 2.095698356628418, val_loss = 0.8001901507377625\n",
      "epoch n°1249 : train_loss = 2.0975606441497803, val_loss = 0.7964397668838501\n",
      "epoch n°1250 : train_loss = 2.099627733230591, val_loss = 0.7958794832229614\n",
      "epoch n°1251 : train_loss = 2.100938320159912, val_loss = 0.7947620749473572\n",
      "epoch n°1252 : train_loss = 2.098846435546875, val_loss = 0.7989927530288696\n",
      "epoch n°1253 : train_loss = 2.098113536834717, val_loss = 0.7926863431930542\n",
      "epoch n°1254 : train_loss = 2.0992021560668945, val_loss = 0.7957245707511902\n",
      "epoch n°1255 : train_loss = 2.097673177719116, val_loss = 0.7966082096099854\n",
      "epoch n°1256 : train_loss = 2.1102583408355713, val_loss = 0.795498251914978\n",
      "epoch n°1257 : train_loss = 2.094844102859497, val_loss = 0.798319399356842\n",
      "epoch n°1258 : train_loss = 2.1022186279296875, val_loss = 0.7948580980300903\n",
      "epoch n°1259 : train_loss = 2.101378917694092, val_loss = 0.7981129288673401\n",
      "epoch n°1260 : train_loss = 2.1050686836242676, val_loss = 0.7956063747406006\n",
      "epoch n°1261 : train_loss = 2.096331834793091, val_loss = 0.7957145571708679\n",
      "epoch n°1262 : train_loss = 2.1068644523620605, val_loss = 0.7993979454040527\n",
      "epoch n°1263 : train_loss = 2.091324806213379, val_loss = 0.7964411377906799\n",
      "epoch n°1264 : train_loss = 2.090731143951416, val_loss = 0.7951796650886536\n",
      "epoch n°1265 : train_loss = 2.1079859733581543, val_loss = 0.7975745797157288\n",
      "epoch n°1266 : train_loss = 2.103081226348877, val_loss = 0.796123206615448\n",
      "epoch n°1267 : train_loss = 2.099994659423828, val_loss = 0.7952934503555298\n",
      "epoch n°1268 : train_loss = 2.099925994873047, val_loss = 0.7945913076400757\n",
      "epoch n°1269 : train_loss = 2.1016275882720947, val_loss = 0.7944139242172241\n",
      "epoch n°1270 : train_loss = 2.096010684967041, val_loss = 0.7964102625846863\n",
      "epoch n°1271 : train_loss = 2.0945560932159424, val_loss = 0.7944308519363403\n",
      "epoch n°1272 : train_loss = 2.100288152694702, val_loss = 0.7953185439109802\n",
      "epoch n°1273 : train_loss = 2.0868911743164062, val_loss = 0.7948689460754395\n",
      "epoch n°1274 : train_loss = 2.0977683067321777, val_loss = 0.7985838651657104\n",
      "epoch n°1275 : train_loss = 2.104623317718506, val_loss = 0.7991957664489746\n",
      "epoch n°1276 : train_loss = 2.093492269515991, val_loss = 0.7979509830474854\n",
      "epoch n°1277 : train_loss = 2.095568895339966, val_loss = 0.7952938079833984\n",
      "epoch n°1278 : train_loss = 2.09983491897583, val_loss = 0.7984577417373657\n",
      "epoch n°1279 : train_loss = 2.0931718349456787, val_loss = 0.7994964122772217\n",
      "epoch n°1280 : train_loss = 2.101569414138794, val_loss = 0.7971091270446777\n",
      "epoch n°1281 : train_loss = 2.101536989212036, val_loss = 0.7994396686553955\n",
      "epoch n°1282 : train_loss = 2.1033685207366943, val_loss = 0.7970465421676636\n",
      "epoch n°1283 : train_loss = 2.0996532440185547, val_loss = 0.7947368025779724\n",
      "epoch n°1284 : train_loss = 2.0987632274627686, val_loss = 0.7931023240089417\n",
      "epoch n°1285 : train_loss = 2.100891590118408, val_loss = 0.7936540842056274\n",
      "epoch n°1286 : train_loss = 2.089134693145752, val_loss = 0.7904959917068481\n",
      "epoch n°1287 : train_loss = 2.090698480606079, val_loss = 0.7952178120613098\n",
      "epoch n°1288 : train_loss = 2.09240984916687, val_loss = 0.7998171448707581\n",
      "epoch n°1289 : train_loss = 2.1029748916625977, val_loss = 0.7942981123924255\n",
      "epoch n°1290 : train_loss = 2.09655499458313, val_loss = 0.7966424226760864\n",
      "epoch n°1291 : train_loss = 2.0953261852264404, val_loss = 0.7975664734840393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°1292 : train_loss = 2.0897867679595947, val_loss = 0.79648357629776\n",
      "epoch n°1293 : train_loss = 2.095048427581787, val_loss = 0.7987921833992004\n",
      "epoch n°1294 : train_loss = 2.096526622772217, val_loss = 0.7982348203659058\n",
      "epoch n°1295 : train_loss = 2.0956876277923584, val_loss = 0.7961321473121643\n",
      "epoch n°1296 : train_loss = 2.0806145668029785, val_loss = 0.7900908589363098\n",
      "epoch n°1297 : train_loss = 2.0906360149383545, val_loss = 0.7968196272850037\n",
      "epoch n°1298 : train_loss = 2.098008394241333, val_loss = 0.7958675622940063\n",
      "epoch n°1299 : train_loss = 2.0953805446624756, val_loss = 0.7906678915023804\n",
      "epoch n°1300 : train_loss = 2.0997376441955566, val_loss = 0.7932131290435791\n",
      "epoch n°1301 : train_loss = 2.092089891433716, val_loss = 0.7981998324394226\n",
      "epoch n°1302 : train_loss = 2.098555564880371, val_loss = 0.7943008542060852\n",
      "epoch n°1303 : train_loss = 2.1045114994049072, val_loss = 0.7990081310272217\n",
      "epoch n°1304 : train_loss = 2.0978612899780273, val_loss = 0.7959485650062561\n",
      "epoch n°1305 : train_loss = 2.0992517471313477, val_loss = 0.7963829040527344\n",
      "epoch n°1306 : train_loss = 2.094749689102173, val_loss = 0.7918810844421387\n",
      "epoch n°1307 : train_loss = 2.092979907989502, val_loss = 0.7953998446464539\n",
      "epoch n°1308 : train_loss = 2.0890724658966064, val_loss = 0.7976359128952026\n",
      "epoch n°1309 : train_loss = 2.097299098968506, val_loss = 0.7989896535873413\n",
      "epoch n°1310 : train_loss = 2.0941600799560547, val_loss = 0.7976128458976746\n",
      "epoch n°1311 : train_loss = 2.082797050476074, val_loss = 0.7946874499320984\n",
      "epoch n°1312 : train_loss = 2.099820852279663, val_loss = 0.8007640838623047\n",
      "epoch n°1313 : train_loss = 2.0902700424194336, val_loss = 0.7898528575897217\n",
      "epoch n°1314 : train_loss = 2.094752311706543, val_loss = 0.7954357862472534\n",
      "epoch n°1315 : train_loss = 2.094370126724243, val_loss = 0.7949497699737549\n",
      "epoch n°1316 : train_loss = 2.089590549468994, val_loss = 0.7965998649597168\n",
      "epoch n°1317 : train_loss = 2.1010382175445557, val_loss = 0.7929399013519287\n",
      "epoch n°1318 : train_loss = 2.091907501220703, val_loss = 0.7900609374046326\n",
      "epoch n°1319 : train_loss = 2.0934622287750244, val_loss = 0.7928415536880493\n",
      "epoch n°1320 : train_loss = 2.1013779640197754, val_loss = 0.793914258480072\n",
      "epoch n°1321 : train_loss = 2.0897812843322754, val_loss = 0.7908868789672852\n",
      "epoch n°1322 : train_loss = 2.089132070541382, val_loss = 0.796953022480011\n",
      "epoch n°1323 : train_loss = 2.0985615253448486, val_loss = 0.7916990518569946\n",
      "epoch n°1324 : train_loss = 2.1007235050201416, val_loss = 0.7986894249916077\n",
      "epoch n°1325 : train_loss = 2.088670015335083, val_loss = 0.797148585319519\n",
      "epoch n°1326 : train_loss = 2.099614143371582, val_loss = 0.7911938428878784\n",
      "epoch n°1327 : train_loss = 2.09499454498291, val_loss = 0.799575686454773\n",
      "epoch n°1328 : train_loss = 2.0874440670013428, val_loss = 0.7977654933929443\n",
      "epoch n°1329 : train_loss = 2.091171979904175, val_loss = 0.791793704032898\n",
      "epoch n°1330 : train_loss = 2.0925111770629883, val_loss = 0.7962052822113037\n",
      "epoch n°1331 : train_loss = 2.0975215435028076, val_loss = 0.7909169793128967\n",
      "epoch n°1332 : train_loss = 2.090068817138672, val_loss = 0.7969013452529907\n",
      "epoch n°1333 : train_loss = 2.088822364807129, val_loss = 0.7957147359848022\n",
      "epoch n°1334 : train_loss = 2.101402759552002, val_loss = 0.7937491536140442\n",
      "epoch n°1335 : train_loss = 2.0974795818328857, val_loss = 0.7959221005439758\n",
      "epoch n°1336 : train_loss = 2.0870635509490967, val_loss = 0.7935314774513245\n",
      "epoch n°1337 : train_loss = 2.0950748920440674, val_loss = 0.7924637198448181\n",
      "epoch n°1338 : train_loss = 2.0922131538391113, val_loss = 0.7985197305679321\n",
      "epoch n°1339 : train_loss = 2.092399835586548, val_loss = 0.7986298203468323\n",
      "epoch n°1340 : train_loss = 2.0852913856506348, val_loss = 0.7946674823760986\n",
      "epoch n°1341 : train_loss = 2.095048189163208, val_loss = 0.7976354360580444\n",
      "epoch n°1342 : train_loss = 2.089982271194458, val_loss = 0.7998834848403931\n",
      "epoch n°1343 : train_loss = 2.091088056564331, val_loss = 0.7941992878913879\n",
      "epoch n°1344 : train_loss = 2.087588310241699, val_loss = 0.7959684729576111\n",
      "epoch n°1345 : train_loss = 2.0927653312683105, val_loss = 0.7934077382087708\n",
      "epoch n°1346 : train_loss = 2.094082832336426, val_loss = 0.7935264706611633\n",
      "epoch n°1347 : train_loss = 2.087615728378296, val_loss = 0.7974061369895935\n",
      "epoch n°1348 : train_loss = 2.083869457244873, val_loss = 0.7931610345840454\n",
      "epoch n°1349 : train_loss = 2.097421884536743, val_loss = 0.7934739589691162\n",
      "epoch n°1350 : train_loss = 2.088164806365967, val_loss = 0.7956549525260925\n",
      "epoch n°1351 : train_loss = 2.09167742729187, val_loss = 0.795722484588623\n",
      "epoch n°1352 : train_loss = 2.0824410915374756, val_loss = 0.7967105507850647\n",
      "epoch n°1353 : train_loss = 2.0923798084259033, val_loss = 0.7958179116249084\n",
      "epoch n°1354 : train_loss = 2.082754611968994, val_loss = 0.7943084239959717\n",
      "epoch n°1355 : train_loss = 2.0768508911132812, val_loss = 0.7950535416603088\n",
      "epoch n°1356 : train_loss = 2.089355230331421, val_loss = 0.7951743602752686\n",
      "epoch n°1357 : train_loss = 2.0890543460845947, val_loss = 0.7944146394729614\n",
      "epoch n°1358 : train_loss = 2.0942678451538086, val_loss = 0.7956358790397644\n",
      "epoch n°1359 : train_loss = 2.0907301902770996, val_loss = 0.7965656518936157\n",
      "epoch n°1360 : train_loss = 2.084812879562378, val_loss = 0.7916842103004456\n",
      "epoch n°1361 : train_loss = 2.0941855907440186, val_loss = 0.7901185750961304\n",
      "epoch n°1362 : train_loss = 2.086465835571289, val_loss = 0.7954153418540955\n",
      "epoch n°1363 : train_loss = 2.080878496170044, val_loss = 0.7912706732749939\n",
      "epoch n°1364 : train_loss = 2.085418701171875, val_loss = 0.791857898235321\n",
      "epoch n°1365 : train_loss = 2.0856893062591553, val_loss = 0.7944937348365784\n",
      "epoch n°1366 : train_loss = 2.0876996517181396, val_loss = 0.7964439392089844\n",
      "epoch n°1367 : train_loss = 2.0867130756378174, val_loss = 0.7960944175720215\n",
      "epoch n°1368 : train_loss = 2.0938735008239746, val_loss = 0.7978395819664001\n",
      "epoch n°1369 : train_loss = 2.092564105987549, val_loss = 0.7925220727920532\n",
      "epoch n°1370 : train_loss = 2.091132640838623, val_loss = 0.7972707152366638\n",
      "epoch n°1371 : train_loss = 2.093693733215332, val_loss = 0.7929749488830566\n",
      "epoch n°1372 : train_loss = 2.0951485633850098, val_loss = 0.7920280694961548\n",
      "epoch n°1373 : train_loss = 2.09448504447937, val_loss = 0.7964423894882202\n",
      "epoch n°1374 : train_loss = 2.0918021202087402, val_loss = 0.7986817955970764\n",
      "epoch n°1375 : train_loss = 2.0967636108398438, val_loss = 0.7914506196975708\n",
      "epoch n°1376 : train_loss = 2.091853141784668, val_loss = 0.795940637588501\n",
      "epoch n°1377 : train_loss = 2.090453624725342, val_loss = 0.79662024974823\n",
      "epoch n°1378 : train_loss = 2.0838911533355713, val_loss = 0.7977773547172546\n",
      "epoch n°1379 : train_loss = 2.085998058319092, val_loss = 0.797686755657196\n",
      "epoch n°1380 : train_loss = 2.0900580883026123, val_loss = 0.794097900390625\n",
      "epoch n°1381 : train_loss = 2.094003200531006, val_loss = 0.7939367890357971\n",
      "epoch n°1382 : train_loss = 2.080770254135132, val_loss = 0.7962637543678284\n",
      "epoch n°1383 : train_loss = 2.086444139480591, val_loss = 0.7985917925834656\n",
      "epoch n°1384 : train_loss = 2.079871892929077, val_loss = 0.7932739853858948\n",
      "epoch n°1385 : train_loss = 2.0874876976013184, val_loss = 0.7992348074913025\n",
      "epoch n°1386 : train_loss = 2.078155040740967, val_loss = 0.7977874875068665\n",
      "epoch n°1387 : train_loss = 2.086930751800537, val_loss = 0.7931007146835327\n",
      "epoch n°1388 : train_loss = 2.087625026702881, val_loss = 0.7966896891593933\n",
      "epoch n°1389 : train_loss = 2.0873610973358154, val_loss = 0.7934603095054626\n",
      "epoch n°1390 : train_loss = 2.0828452110290527, val_loss = 0.796093225479126\n",
      "epoch n°1391 : train_loss = 2.0818965435028076, val_loss = 0.7956483960151672\n",
      "epoch n°1392 : train_loss = 2.0822689533233643, val_loss = 0.7964267730712891\n",
      "epoch n°1393 : train_loss = 2.082418203353882, val_loss = 0.7964611053466797\n",
      "epoch n°1394 : train_loss = 2.0959062576293945, val_loss = 0.7951781749725342\n",
      "epoch n°1395 : train_loss = 2.082706928253174, val_loss = 0.7958219051361084\n",
      "epoch n°1396 : train_loss = 2.088568687438965, val_loss = 0.7975142598152161\n",
      "epoch n°1397 : train_loss = 2.082354784011841, val_loss = 0.7953404188156128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°1398 : train_loss = 2.0755786895751953, val_loss = 0.7948784232139587\n",
      "epoch n°1399 : train_loss = 2.0810177326202393, val_loss = 0.7961321473121643\n",
      "epoch n°1400 : train_loss = 2.083085536956787, val_loss = 0.7933714389801025\n",
      "epoch n°1401 : train_loss = 2.0832555294036865, val_loss = 0.7979635000228882\n",
      "epoch n°1402 : train_loss = 2.0811407566070557, val_loss = 0.7945514917373657\n",
      "epoch n°1403 : train_loss = 2.090336561203003, val_loss = 0.7908786535263062\n",
      "epoch n°1404 : train_loss = 2.0727434158325195, val_loss = 0.7969651222229004\n",
      "epoch n°1405 : train_loss = 2.0865299701690674, val_loss = 0.7943229079246521\n",
      "epoch n°1406 : train_loss = 2.0799965858459473, val_loss = 0.7937803864479065\n",
      "epoch n°1407 : train_loss = 2.088902473449707, val_loss = 0.7994890213012695\n",
      "epoch n°1408 : train_loss = 2.0820491313934326, val_loss = 0.7954838871955872\n",
      "epoch n°1409 : train_loss = 2.085573673248291, val_loss = 0.7914484739303589\n",
      "epoch n°1410 : train_loss = 2.0754287242889404, val_loss = 0.7945737838745117\n",
      "epoch n°1411 : train_loss = 2.084611177444458, val_loss = 0.7940292358398438\n",
      "epoch n°1412 : train_loss = 2.083760976791382, val_loss = 0.7953222393989563\n",
      "epoch n°1413 : train_loss = 2.0814530849456787, val_loss = 0.7948436737060547\n",
      "epoch n°1414 : train_loss = 2.0830721855163574, val_loss = 0.7933751344680786\n",
      "epoch n°1415 : train_loss = 2.08870792388916, val_loss = 0.7963575720787048\n",
      "epoch n°1416 : train_loss = 2.0917372703552246, val_loss = 0.7985434532165527\n",
      "epoch n°1417 : train_loss = 2.0800139904022217, val_loss = 0.7968043088912964\n",
      "epoch n°1418 : train_loss = 2.0896847248077393, val_loss = 0.7940219044685364\n",
      "epoch n°1419 : train_loss = 2.075002431869507, val_loss = 0.7959532141685486\n",
      "epoch n°1420 : train_loss = 2.077305316925049, val_loss = 0.7968253493309021\n",
      "epoch n°1421 : train_loss = 2.089359998703003, val_loss = 0.7929929494857788\n",
      "epoch n°1422 : train_loss = 2.084223985671997, val_loss = 0.7973184585571289\n",
      "epoch n°1423 : train_loss = 2.0845253467559814, val_loss = 0.793631374835968\n",
      "epoch n°1424 : train_loss = 2.0767364501953125, val_loss = 0.79851233959198\n",
      "epoch n°1425 : train_loss = 2.077636241912842, val_loss = 0.7943835258483887\n",
      "epoch n°1426 : train_loss = 2.079414129257202, val_loss = 0.7910596132278442\n",
      "epoch n°1427 : train_loss = 2.081862449645996, val_loss = 0.7888838648796082\n",
      "epoch n°1428 : train_loss = 2.079366683959961, val_loss = 0.799476683139801\n",
      "epoch n°1429 : train_loss = 2.081299066543579, val_loss = 0.7967849373817444\n",
      "epoch n°1430 : train_loss = 2.0897464752197266, val_loss = 0.7947714328765869\n",
      "epoch n°1431 : train_loss = 2.0814945697784424, val_loss = 0.7916332483291626\n",
      "epoch n°1432 : train_loss = 2.082671880722046, val_loss = 0.792034924030304\n",
      "epoch n°1433 : train_loss = 2.073489189147949, val_loss = 0.7997162342071533\n",
      "epoch n°1434 : train_loss = 2.079101324081421, val_loss = 0.7977540493011475\n",
      "epoch n°1435 : train_loss = 2.0887343883514404, val_loss = 0.7914459705352783\n",
      "epoch n°1436 : train_loss = 2.077939033508301, val_loss = 0.7927809357643127\n",
      "epoch n°1437 : train_loss = 2.088017463684082, val_loss = 0.7916219830513\n",
      "epoch n°1438 : train_loss = 2.0822792053222656, val_loss = 0.7959339022636414\n",
      "epoch n°1439 : train_loss = 2.0820038318634033, val_loss = 0.7927581667900085\n",
      "epoch n°1440 : train_loss = 2.083772897720337, val_loss = 0.7909148931503296\n",
      "epoch n°1441 : train_loss = 2.0740694999694824, val_loss = 0.7946740388870239\n",
      "epoch n°1442 : train_loss = 2.0877702236175537, val_loss = 0.793793261051178\n",
      "epoch n°1443 : train_loss = 2.0854551792144775, val_loss = 0.7965085506439209\n",
      "epoch n°1444 : train_loss = 2.082760810852051, val_loss = 0.7974568009376526\n",
      "epoch n°1445 : train_loss = 2.08219838142395, val_loss = 0.7960537672042847\n",
      "epoch n°1446 : train_loss = 2.0807085037231445, val_loss = 0.7947006225585938\n",
      "epoch n°1447 : train_loss = 2.079521656036377, val_loss = 0.7948355674743652\n",
      "epoch n°1448 : train_loss = 2.0761682987213135, val_loss = 0.7950676679611206\n",
      "epoch n°1449 : train_loss = 2.0894384384155273, val_loss = 0.795719563961029\n",
      "epoch n°1450 : train_loss = 2.0801069736480713, val_loss = 0.7943438291549683\n",
      "epoch n°1451 : train_loss = 2.0811057090759277, val_loss = 0.794310450553894\n",
      "epoch n°1452 : train_loss = 2.0799472332000732, val_loss = 0.7950942516326904\n",
      "epoch n°1453 : train_loss = 2.0822112560272217, val_loss = 0.7966156601905823\n",
      "epoch n°1454 : train_loss = 2.0881507396698, val_loss = 0.7962574362754822\n",
      "epoch n°1455 : train_loss = 2.0803263187408447, val_loss = 0.7962780594825745\n",
      "epoch n°1456 : train_loss = 2.076847791671753, val_loss = 0.7938912510871887\n",
      "epoch n°1457 : train_loss = 2.0766448974609375, val_loss = 0.7947317957878113\n",
      "epoch n°1458 : train_loss = 2.0759565830230713, val_loss = 0.7967240810394287\n",
      "epoch n°1459 : train_loss = 2.084792137145996, val_loss = 0.7970441579818726\n",
      "epoch n°1460 : train_loss = 2.0823137760162354, val_loss = 0.7917017936706543\n",
      "epoch n°1461 : train_loss = 2.084083318710327, val_loss = 0.7954367995262146\n",
      "epoch n°1462 : train_loss = 2.0782926082611084, val_loss = 0.7959383726119995\n",
      "epoch n°1463 : train_loss = 2.08040452003479, val_loss = 0.7967590093612671\n",
      "epoch n°1464 : train_loss = 2.0785202980041504, val_loss = 0.7927426695823669\n",
      "epoch n°1465 : train_loss = 2.0858912467956543, val_loss = 0.7947615385055542\n",
      "epoch n°1466 : train_loss = 2.087873935699463, val_loss = 0.7963332533836365\n",
      "epoch n°1467 : train_loss = 2.082435131072998, val_loss = 0.7923310399055481\n",
      "epoch n°1468 : train_loss = 2.0662343502044678, val_loss = 0.7978478670120239\n",
      "epoch n°1469 : train_loss = 2.0768861770629883, val_loss = 0.7953230738639832\n",
      "epoch n°1470 : train_loss = 2.070831298828125, val_loss = 0.7919429540634155\n",
      "epoch n°1471 : train_loss = 2.0820255279541016, val_loss = 0.7965510487556458\n",
      "epoch n°1472 : train_loss = 2.0776987075805664, val_loss = 0.7956603169441223\n",
      "epoch n°1473 : train_loss = 2.079312562942505, val_loss = 0.7925464510917664\n",
      "epoch n°1474 : train_loss = 2.080495595932007, val_loss = 0.7925752997398376\n",
      "epoch n°1475 : train_loss = 2.079651117324829, val_loss = 0.7951996326446533\n",
      "epoch n°1476 : train_loss = 2.0792396068573, val_loss = 0.7932940721511841\n",
      "epoch n°1477 : train_loss = 2.076335906982422, val_loss = 0.7953605055809021\n",
      "epoch n°1478 : train_loss = 2.0707976818084717, val_loss = 0.7923386693000793\n",
      "epoch n°1479 : train_loss = 2.0663070678710938, val_loss = 0.7930672764778137\n",
      "epoch n°1480 : train_loss = 2.0771002769470215, val_loss = 0.7975326180458069\n",
      "epoch n°1481 : train_loss = 2.070981025695801, val_loss = 0.7945827841758728\n",
      "epoch n°1482 : train_loss = 2.0799789428710938, val_loss = 0.7898367047309875\n",
      "epoch n°1483 : train_loss = 2.0778839588165283, val_loss = 0.7886587381362915\n",
      "epoch n°1484 : train_loss = 2.0829102993011475, val_loss = 0.7919434905052185\n",
      "epoch n°1485 : train_loss = 2.0781402587890625, val_loss = 0.7955334186553955\n",
      "epoch n°1486 : train_loss = 2.0743117332458496, val_loss = 0.7940719127655029\n",
      "epoch n°1487 : train_loss = 2.0769364833831787, val_loss = 0.7949963212013245\n",
      "epoch n°1488 : train_loss = 2.0728759765625, val_loss = 0.7963564395904541\n",
      "epoch n°1489 : train_loss = 2.078911066055298, val_loss = 0.7966541051864624\n",
      "epoch n°1490 : train_loss = 2.0771772861480713, val_loss = 0.7960330843925476\n",
      "epoch n°1491 : train_loss = 2.077601194381714, val_loss = 0.7878947257995605\n",
      "epoch n°1492 : train_loss = 2.0695159435272217, val_loss = 0.7954118847846985\n",
      "epoch n°1493 : train_loss = 2.067263603210449, val_loss = 0.7967801094055176\n",
      "epoch n°1494 : train_loss = 2.075850009918213, val_loss = 0.7945398092269897\n",
      "epoch n°1495 : train_loss = 2.074753522872925, val_loss = 0.7943130731582642\n",
      "epoch n°1496 : train_loss = 2.077883005142212, val_loss = 0.7923555970191956\n",
      "epoch n°1497 : train_loss = 2.0693986415863037, val_loss = 0.7949132919311523\n",
      "epoch n°1498 : train_loss = 2.0745770931243896, val_loss = 0.794421911239624\n",
      "epoch n°1499 : train_loss = 2.066162347793579, val_loss = 0.7958146929740906\n",
      "epoch n°1500 : train_loss = 2.073800563812256, val_loss = 0.7955963611602783\n",
      "epoch n°1501 : train_loss = 2.0841257572174072, val_loss = 0.7914343476295471\n",
      "epoch n°1502 : train_loss = 2.070162057876587, val_loss = 0.7971768379211426\n",
      "epoch n°1503 : train_loss = 2.075732946395874, val_loss = 0.7958222031593323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°1504 : train_loss = 2.0805022716522217, val_loss = 0.7919948101043701\n",
      "epoch n°1505 : train_loss = 2.0759804248809814, val_loss = 0.793653666973114\n",
      "epoch n°1506 : train_loss = 2.068202018737793, val_loss = 0.7967839241027832\n",
      "epoch n°1507 : train_loss = 2.0686070919036865, val_loss = 0.7930369973182678\n",
      "epoch n°1508 : train_loss = 2.074924945831299, val_loss = 0.7952510118484497\n",
      "epoch n°1509 : train_loss = 2.0784404277801514, val_loss = 0.7926990985870361\n",
      "epoch n°1510 : train_loss = 2.0729868412017822, val_loss = 0.7963452339172363\n",
      "epoch n°1511 : train_loss = 2.0786118507385254, val_loss = 0.7989960312843323\n",
      "epoch n°1512 : train_loss = 2.066610336303711, val_loss = 0.7943823337554932\n",
      "epoch n°1513 : train_loss = 2.081754446029663, val_loss = 0.7949397563934326\n",
      "epoch n°1514 : train_loss = 2.0806214809417725, val_loss = 0.794717013835907\n",
      "epoch n°1515 : train_loss = 2.0795340538024902, val_loss = 0.7937161326408386\n",
      "epoch n°1516 : train_loss = 2.0775349140167236, val_loss = 0.7939539551734924\n",
      "epoch n°1517 : train_loss = 2.0691206455230713, val_loss = 0.7945497035980225\n",
      "epoch n°1518 : train_loss = 2.0729658603668213, val_loss = 0.7969232797622681\n",
      "epoch n°1519 : train_loss = 2.0700013637542725, val_loss = 0.7913796305656433\n",
      "epoch n°1520 : train_loss = 2.0700151920318604, val_loss = 0.7907710075378418\n",
      "epoch n°1521 : train_loss = 2.0812182426452637, val_loss = 0.7956032156944275\n",
      "epoch n°1522 : train_loss = 2.06414532661438, val_loss = 0.7940630912780762\n",
      "epoch n°1523 : train_loss = 2.0813100337982178, val_loss = 0.7913375496864319\n",
      "epoch n°1524 : train_loss = 2.0763072967529297, val_loss = 0.7963722348213196\n",
      "epoch n°1525 : train_loss = 2.0806829929351807, val_loss = 0.791222095489502\n",
      "epoch n°1526 : train_loss = 2.064382314682007, val_loss = 0.7912340760231018\n",
      "epoch n°1527 : train_loss = 2.069666862487793, val_loss = 0.7936633825302124\n",
      "epoch n°1528 : train_loss = 2.071481704711914, val_loss = 0.79383385181427\n",
      "epoch n°1529 : train_loss = 2.0751678943634033, val_loss = 0.7908925414085388\n",
      "epoch n°1530 : train_loss = 2.073183298110962, val_loss = 0.7912596464157104\n",
      "epoch n°1531 : train_loss = 2.0693984031677246, val_loss = 0.7968908548355103\n",
      "epoch n°1532 : train_loss = 2.074258327484131, val_loss = 0.7913588881492615\n",
      "epoch n°1533 : train_loss = 2.062211275100708, val_loss = 0.7932179570198059\n",
      "epoch n°1534 : train_loss = 2.067758560180664, val_loss = 0.7947584390640259\n",
      "epoch n°1535 : train_loss = 2.0774168968200684, val_loss = 0.7923719882965088\n",
      "epoch n°1536 : train_loss = 2.0724802017211914, val_loss = 0.7969299554824829\n",
      "epoch n°1537 : train_loss = 2.0769710540771484, val_loss = 0.7950193285942078\n",
      "epoch n°1538 : train_loss = 2.064960479736328, val_loss = 0.7916509509086609\n",
      "epoch n°1539 : train_loss = 2.080779790878296, val_loss = 0.7902959585189819\n",
      "epoch n°1540 : train_loss = 2.071810722351074, val_loss = 0.7939496636390686\n",
      "epoch n°1541 : train_loss = 2.065706968307495, val_loss = 0.7914315462112427\n",
      "epoch n°1542 : train_loss = 2.0672802925109863, val_loss = 0.793121874332428\n",
      "epoch n°1543 : train_loss = 2.0667669773101807, val_loss = 0.7959491014480591\n",
      "epoch n°1544 : train_loss = 2.0553014278411865, val_loss = 0.793665885925293\n",
      "epoch n°1545 : train_loss = 2.0660653114318848, val_loss = 0.7968019247055054\n",
      "epoch n°1546 : train_loss = 2.066868543624878, val_loss = 0.7901914119720459\n",
      "epoch n°1547 : train_loss = 2.066511869430542, val_loss = 0.7862748503684998\n",
      "epoch n°1548 : train_loss = 2.073798179626465, val_loss = 0.7908285856246948\n",
      "epoch n°1549 : train_loss = 2.063790798187256, val_loss = 0.7976104617118835\n",
      "epoch n°1550 : train_loss = 2.0675461292266846, val_loss = 0.7999728322029114\n",
      "epoch n°1551 : train_loss = 2.0755083560943604, val_loss = 0.7949869632720947\n",
      "epoch n°1552 : train_loss = 2.0655837059020996, val_loss = 0.7927793264389038\n",
      "epoch n°1553 : train_loss = 2.0636658668518066, val_loss = 0.7934229969978333\n",
      "epoch n°1554 : train_loss = 2.0639970302581787, val_loss = 0.7936031818389893\n",
      "epoch n°1555 : train_loss = 2.068385124206543, val_loss = 0.7909903526306152\n",
      "epoch n°1556 : train_loss = 2.0777928829193115, val_loss = 0.7947103381156921\n",
      "epoch n°1557 : train_loss = 2.072543144226074, val_loss = 0.7931697368621826\n",
      "epoch n°1558 : train_loss = 2.062408208847046, val_loss = 0.7920883893966675\n",
      "epoch n°1559 : train_loss = 2.062626838684082, val_loss = 0.7919787168502808\n",
      "epoch n°1560 : train_loss = 2.063873767852783, val_loss = 0.7943433523178101\n",
      "epoch n°1561 : train_loss = 2.0621988773345947, val_loss = 0.794742226600647\n",
      "epoch n°1562 : train_loss = 2.070908546447754, val_loss = 0.7918165922164917\n",
      "epoch n°1563 : train_loss = 2.0676119327545166, val_loss = 0.7918851971626282\n",
      "epoch n°1564 : train_loss = 2.0645670890808105, val_loss = 0.7912894487380981\n",
      "epoch n°1565 : train_loss = 2.0667359828948975, val_loss = 0.7927416563034058\n",
      "epoch n°1566 : train_loss = 2.0657424926757812, val_loss = 0.79684978723526\n",
      "epoch n°1567 : train_loss = 2.0695230960845947, val_loss = 0.7919920682907104\n",
      "epoch n°1568 : train_loss = 2.061723470687866, val_loss = 0.7927757501602173\n",
      "epoch n°1569 : train_loss = 2.0627105236053467, val_loss = 0.7956188321113586\n",
      "epoch n°1570 : train_loss = 2.0794923305511475, val_loss = 0.7946838140487671\n",
      "epoch n°1571 : train_loss = 2.0608432292938232, val_loss = 0.7931236624717712\n",
      "epoch n°1572 : train_loss = 2.068725824356079, val_loss = 0.7934611439704895\n",
      "epoch n°1573 : train_loss = 2.0682225227355957, val_loss = 0.7949842810630798\n",
      "epoch n°1574 : train_loss = 2.0703771114349365, val_loss = 0.7926130890846252\n",
      "epoch n°1575 : train_loss = 2.073112964630127, val_loss = 0.7937599420547485\n",
      "epoch n°1576 : train_loss = 2.064656972885132, val_loss = 0.7943905591964722\n",
      "epoch n°1577 : train_loss = 2.070272207260132, val_loss = 0.7944125533103943\n",
      "epoch n°1578 : train_loss = 2.0695807933807373, val_loss = 0.7948595285415649\n",
      "epoch n°1579 : train_loss = 2.0661027431488037, val_loss = 0.7960294485092163\n",
      "epoch n°1580 : train_loss = 2.065096855163574, val_loss = 0.7935593128204346\n",
      "epoch n°1581 : train_loss = 2.0630507469177246, val_loss = 0.7901203036308289\n",
      "epoch n°1582 : train_loss = 2.063060760498047, val_loss = 0.794259250164032\n",
      "epoch n°1583 : train_loss = 2.0680506229400635, val_loss = 0.7925359606742859\n",
      "epoch n°1584 : train_loss = 2.067711353302002, val_loss = 0.7931756973266602\n",
      "epoch n°1585 : train_loss = 2.0642611980438232, val_loss = 0.7957092523574829\n",
      "epoch n°1586 : train_loss = 2.0713887214660645, val_loss = 0.7956252098083496\n",
      "epoch n°1587 : train_loss = 2.0660765171051025, val_loss = 0.7968753576278687\n",
      "epoch n°1588 : train_loss = 2.0711705684661865, val_loss = 0.7953459620475769\n",
      "epoch n°1589 : train_loss = 2.065511703491211, val_loss = 0.7933285236358643\n",
      "epoch n°1590 : train_loss = 2.0759074687957764, val_loss = 0.7912213206291199\n",
      "epoch n°1591 : train_loss = 2.063183307647705, val_loss = 0.7942041158676147\n",
      "epoch n°1592 : train_loss = 2.062943935394287, val_loss = 0.7946382164955139\n",
      "epoch n°1593 : train_loss = 2.0615956783294678, val_loss = 0.7915460467338562\n",
      "epoch n°1594 : train_loss = 2.073590040206909, val_loss = 0.7929688692092896\n",
      "epoch n°1595 : train_loss = 2.067108392715454, val_loss = 0.7920272946357727\n",
      "epoch n°1596 : train_loss = 2.065415859222412, val_loss = 0.7886738777160645\n",
      "epoch n°1597 : train_loss = 2.068833827972412, val_loss = 0.7881177663803101\n",
      "epoch n°1598 : train_loss = 2.0601541996002197, val_loss = 0.7964473962783813\n",
      "epoch n°1599 : train_loss = 2.0623130798339844, val_loss = 0.7952954173088074\n",
      "epoch n°1600 : train_loss = 2.0784480571746826, val_loss = 0.7958113551139832\n",
      "epoch n°1601 : train_loss = 2.065758228302002, val_loss = 0.7950810790061951\n",
      "epoch n°1602 : train_loss = 2.072019100189209, val_loss = 0.794111430644989\n",
      "epoch n°1603 : train_loss = 2.068765878677368, val_loss = 0.7929165363311768\n",
      "epoch n°1604 : train_loss = 2.069990634918213, val_loss = 0.7890282869338989\n",
      "epoch n°1605 : train_loss = 2.062371253967285, val_loss = 0.7909888625144958\n",
      "epoch n°1606 : train_loss = 2.0677599906921387, val_loss = 0.7972694635391235\n",
      "epoch n°1607 : train_loss = 2.060152769088745, val_loss = 0.7912712693214417\n",
      "epoch n°1608 : train_loss = 2.068296194076538, val_loss = 0.7954643964767456\n",
      "epoch n°1609 : train_loss = 2.060635566711426, val_loss = 0.7968660593032837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°1610 : train_loss = 2.065650463104248, val_loss = 0.7924673557281494\n",
      "epoch n°1611 : train_loss = 2.064899444580078, val_loss = 0.7915642857551575\n",
      "epoch n°1612 : train_loss = 2.059776544570923, val_loss = 0.7918389439582825\n",
      "epoch n°1613 : train_loss = 2.0567123889923096, val_loss = 0.7938201427459717\n",
      "epoch n°1614 : train_loss = 2.061237335205078, val_loss = 0.7929803133010864\n",
      "epoch n°1615 : train_loss = 2.059628486633301, val_loss = 0.7933230400085449\n",
      "epoch n°1616 : train_loss = 2.0658199787139893, val_loss = 0.7923156023025513\n",
      "epoch n°1617 : train_loss = 2.065325975418091, val_loss = 0.7930849194526672\n",
      "epoch n°1618 : train_loss = 2.0621790885925293, val_loss = 0.7925106287002563\n",
      "epoch n°1619 : train_loss = 2.0606822967529297, val_loss = 0.7943443655967712\n",
      "epoch n°1620 : train_loss = 2.056267261505127, val_loss = 0.7959619760513306\n",
      "epoch n°1621 : train_loss = 2.05960750579834, val_loss = 0.7932773232460022\n",
      "epoch n°1622 : train_loss = 2.06494402885437, val_loss = 0.7944226861000061\n",
      "epoch n°1623 : train_loss = 2.064927577972412, val_loss = 0.7933001518249512\n",
      "epoch n°1624 : train_loss = 2.0664985179901123, val_loss = 0.7939049601554871\n",
      "epoch n°1625 : train_loss = 2.0566821098327637, val_loss = 0.7966063022613525\n",
      "epoch n°1626 : train_loss = 2.0666964054107666, val_loss = 0.7904248833656311\n",
      "epoch n°1627 : train_loss = 2.072366952896118, val_loss = 0.790951132774353\n",
      "epoch n°1628 : train_loss = 2.06506085395813, val_loss = 0.7942297458648682\n",
      "epoch n°1629 : train_loss = 2.0657846927642822, val_loss = 0.7946138978004456\n",
      "epoch n°1630 : train_loss = 2.0661654472351074, val_loss = 0.7949017286300659\n",
      "epoch n°1631 : train_loss = 2.0613651275634766, val_loss = 0.7963410019874573\n",
      "epoch n°1632 : train_loss = 2.0651185512542725, val_loss = 0.7954797744750977\n",
      "epoch n°1633 : train_loss = 2.051952600479126, val_loss = 0.7937231063842773\n",
      "epoch n°1634 : train_loss = 2.0701777935028076, val_loss = 0.7920850515365601\n",
      "epoch n°1635 : train_loss = 2.0672459602355957, val_loss = 0.7952855825424194\n",
      "epoch n°1636 : train_loss = 2.06144642829895, val_loss = 0.7950614094734192\n",
      "epoch n°1637 : train_loss = 2.0594418048858643, val_loss = 0.7925907373428345\n",
      "epoch n°1638 : train_loss = 2.058753490447998, val_loss = 0.7929324507713318\n",
      "epoch n°1639 : train_loss = 2.0625452995300293, val_loss = 0.7960439920425415\n",
      "epoch n°1640 : train_loss = 2.0545239448547363, val_loss = 0.7915816903114319\n",
      "epoch n°1641 : train_loss = 2.0618650913238525, val_loss = 0.7985144257545471\n",
      "epoch n°1642 : train_loss = 2.063295841217041, val_loss = 0.7932597994804382\n",
      "epoch n°1643 : train_loss = 2.0699310302734375, val_loss = 0.7913819551467896\n",
      "epoch n°1644 : train_loss = 2.066399574279785, val_loss = 0.7965454459190369\n",
      "epoch n°1645 : train_loss = 2.0594024658203125, val_loss = 0.7919374108314514\n",
      "epoch n°1646 : train_loss = 2.0568366050720215, val_loss = 0.7955684661865234\n",
      "epoch n°1647 : train_loss = 2.0620505809783936, val_loss = 0.7903909683227539\n",
      "epoch n°1648 : train_loss = 2.0651421546936035, val_loss = 0.7966536283493042\n",
      "epoch n°1649 : train_loss = 2.059725046157837, val_loss = 0.7957268357276917\n",
      "epoch n°1650 : train_loss = 2.064716339111328, val_loss = 0.792855441570282\n",
      "epoch n°1651 : train_loss = 2.0595991611480713, val_loss = 0.791037917137146\n",
      "epoch n°1652 : train_loss = 2.055989980697632, val_loss = 0.7909651398658752\n",
      "epoch n°1653 : train_loss = 2.0587856769561768, val_loss = 0.7941616177558899\n",
      "epoch n°1654 : train_loss = 2.060591697692871, val_loss = 0.794808566570282\n",
      "epoch n°1655 : train_loss = 2.049466848373413, val_loss = 0.7951977849006653\n",
      "epoch n°1656 : train_loss = 2.0665509700775146, val_loss = 0.7948077321052551\n",
      "epoch n°1657 : train_loss = 2.073119878768921, val_loss = 0.7906120419502258\n",
      "epoch n°1658 : train_loss = 2.0585591793060303, val_loss = 0.79417484998703\n",
      "epoch n°1659 : train_loss = 2.05785870552063, val_loss = 0.7914237976074219\n",
      "epoch n°1660 : train_loss = 2.06286883354187, val_loss = 0.7954156994819641\n",
      "epoch n°1661 : train_loss = 2.060199022293091, val_loss = 0.795455276966095\n",
      "epoch n°1662 : train_loss = 2.059927225112915, val_loss = 0.7921949028968811\n",
      "epoch n°1663 : train_loss = 2.0584278106689453, val_loss = 0.7942125201225281\n",
      "epoch n°1664 : train_loss = 2.064425468444824, val_loss = 0.7923552989959717\n",
      "epoch n°1665 : train_loss = 2.0606741905212402, val_loss = 0.7969733476638794\n",
      "epoch n°1666 : train_loss = 2.058736562728882, val_loss = 0.7966133952140808\n",
      "epoch n°1667 : train_loss = 2.064027786254883, val_loss = 0.7893586754798889\n",
      "epoch n°1668 : train_loss = 2.057285785675049, val_loss = 0.7933229804039001\n",
      "epoch n°1669 : train_loss = 2.065606117248535, val_loss = 0.7910454869270325\n",
      "epoch n°1670 : train_loss = 2.0619733333587646, val_loss = 0.7935720682144165\n",
      "epoch n°1671 : train_loss = 2.0619888305664062, val_loss = 0.789158046245575\n",
      "epoch n°1672 : train_loss = 2.054831027984619, val_loss = 0.7899781465530396\n",
      "epoch n°1673 : train_loss = 2.063227891921997, val_loss = 0.7927035689353943\n",
      "epoch n°1674 : train_loss = 2.054748773574829, val_loss = 0.7925390005111694\n",
      "epoch n°1675 : train_loss = 2.061213731765747, val_loss = 0.7944899797439575\n",
      "epoch n°1676 : train_loss = 2.0570340156555176, val_loss = 0.7965712547302246\n",
      "epoch n°1677 : train_loss = 2.056281089782715, val_loss = 0.7949680685997009\n",
      "epoch n°1678 : train_loss = 2.0643320083618164, val_loss = 0.794374942779541\n",
      "epoch n°1679 : train_loss = 2.0481114387512207, val_loss = 0.791762113571167\n",
      "epoch n°1680 : train_loss = 2.057072639465332, val_loss = 0.7886090874671936\n",
      "epoch n°1681 : train_loss = 2.06101131439209, val_loss = 0.7898607850074768\n",
      "epoch n°1682 : train_loss = 2.0522942543029785, val_loss = 0.7935110330581665\n",
      "epoch n°1683 : train_loss = 2.0618879795074463, val_loss = 0.7955284118652344\n",
      "epoch n°1684 : train_loss = 2.058497667312622, val_loss = 0.7939742803573608\n",
      "epoch n°1685 : train_loss = 2.0512168407440186, val_loss = 0.7899848818778992\n",
      "epoch n°1686 : train_loss = 2.0552332401275635, val_loss = 0.7990931272506714\n",
      "epoch n°1687 : train_loss = 2.058159828186035, val_loss = 0.7945660352706909\n",
      "epoch n°1688 : train_loss = 2.059433698654175, val_loss = 0.7872611880302429\n",
      "epoch n°1689 : train_loss = 2.052682638168335, val_loss = 0.7981050610542297\n",
      "epoch n°1690 : train_loss = 2.062253713607788, val_loss = 0.7892889976501465\n",
      "epoch n°1691 : train_loss = 2.054842710494995, val_loss = 0.7916929721832275\n",
      "epoch n°1692 : train_loss = 2.0458920001983643, val_loss = 0.7937308549880981\n",
      "epoch n°1693 : train_loss = 2.0491814613342285, val_loss = 0.7917320728302002\n",
      "epoch n°1694 : train_loss = 2.0569472312927246, val_loss = 0.7941054105758667\n",
      "epoch n°1695 : train_loss = 2.0509374141693115, val_loss = 0.7957481741905212\n",
      "epoch n°1696 : train_loss = 2.058133125305176, val_loss = 0.7928243279457092\n",
      "epoch n°1697 : train_loss = 2.049551486968994, val_loss = 0.7928266525268555\n",
      "epoch n°1698 : train_loss = 2.06168270111084, val_loss = 0.7917705774307251\n",
      "epoch n°1699 : train_loss = 2.0541436672210693, val_loss = 0.7949061989784241\n",
      "epoch n°1700 : train_loss = 2.060626268386841, val_loss = 0.7911545038223267\n",
      "epoch n°1701 : train_loss = 2.053513765335083, val_loss = 0.7957133650779724\n",
      "epoch n°1702 : train_loss = 2.0545058250427246, val_loss = 0.7925464510917664\n",
      "epoch n°1703 : train_loss = 2.0570785999298096, val_loss = 0.7918177843093872\n",
      "epoch n°1704 : train_loss = 2.0540688037872314, val_loss = 0.7884177565574646\n",
      "epoch n°1705 : train_loss = 2.0562472343444824, val_loss = 0.7933866381645203\n",
      "epoch n°1706 : train_loss = 2.053168296813965, val_loss = 0.7971593141555786\n",
      "epoch n°1707 : train_loss = 2.0572376251220703, val_loss = 0.7923391461372375\n",
      "epoch n°1708 : train_loss = 2.06190824508667, val_loss = 0.7923970222473145\n",
      "epoch n°1709 : train_loss = 2.0603713989257812, val_loss = 0.7954863905906677\n",
      "epoch n°1710 : train_loss = 2.055663824081421, val_loss = 0.792101263999939\n",
      "epoch n°1711 : train_loss = 2.054676055908203, val_loss = 0.7915716767311096\n",
      "epoch n°1712 : train_loss = 2.053107261657715, val_loss = 0.7895181775093079\n",
      "epoch n°1713 : train_loss = 2.057626962661743, val_loss = 0.7935159802436829\n",
      "epoch n°1714 : train_loss = 2.0591542720794678, val_loss = 0.7876184582710266\n",
      "epoch n°1715 : train_loss = 2.060544013977051, val_loss = 0.7958369851112366\n",
      "epoch n°1716 : train_loss = 2.056375503540039, val_loss = 0.7937588691711426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°1717 : train_loss = 2.068243980407715, val_loss = 0.7936872243881226\n",
      "epoch n°1718 : train_loss = 2.0562968254089355, val_loss = 0.7965421080589294\n",
      "epoch n°1719 : train_loss = 2.0535271167755127, val_loss = 0.7919670343399048\n",
      "epoch n°1720 : train_loss = 2.0548095703125, val_loss = 0.7939345240592957\n",
      "epoch n°1721 : train_loss = 2.0560076236724854, val_loss = 0.7945517897605896\n",
      "epoch n°1722 : train_loss = 2.0515875816345215, val_loss = 0.7918714880943298\n",
      "epoch n°1723 : train_loss = 2.0615830421447754, val_loss = 0.7925341725349426\n",
      "epoch n°1724 : train_loss = 2.0540661811828613, val_loss = 0.7936169505119324\n",
      "epoch n°1725 : train_loss = 2.052110433578491, val_loss = 0.7926763296127319\n",
      "epoch n°1726 : train_loss = 2.0593767166137695, val_loss = 0.7964803576469421\n",
      "epoch n°1727 : train_loss = 2.053755283355713, val_loss = 0.7946432828903198\n",
      "epoch n°1728 : train_loss = 2.050009250640869, val_loss = 0.7958309650421143\n",
      "epoch n°1729 : train_loss = 2.056324005126953, val_loss = 0.7943634390830994\n",
      "epoch n°1730 : train_loss = 2.0548593997955322, val_loss = 0.7893416881561279\n",
      "epoch n°1731 : train_loss = 2.0569441318511963, val_loss = 0.791113555431366\n",
      "epoch n°1732 : train_loss = 2.053985595703125, val_loss = 0.7972728610038757\n",
      "epoch n°1733 : train_loss = 2.064412832260132, val_loss = 0.7918921113014221\n",
      "epoch n°1734 : train_loss = 2.0534870624542236, val_loss = 0.7948319911956787\n",
      "epoch n°1735 : train_loss = 2.0582938194274902, val_loss = 0.7948769927024841\n",
      "epoch n°1736 : train_loss = 2.06260347366333, val_loss = 0.7920050024986267\n",
      "epoch n°1737 : train_loss = 2.0506937503814697, val_loss = 0.7941563129425049\n",
      "epoch n°1738 : train_loss = 2.063077926635742, val_loss = 0.7956174612045288\n",
      "epoch n°1739 : train_loss = 2.052999258041382, val_loss = 0.7924536466598511\n",
      "epoch n°1740 : train_loss = 2.0564372539520264, val_loss = 0.7936543822288513\n",
      "epoch n°1741 : train_loss = 2.0533506870269775, val_loss = 0.7930970191955566\n",
      "epoch n°1742 : train_loss = 2.0560996532440186, val_loss = 0.790783703327179\n",
      "epoch n°1743 : train_loss = 2.0555801391601562, val_loss = 0.7951489090919495\n",
      "epoch n°1744 : train_loss = 2.046388626098633, val_loss = 0.7939313054084778\n",
      "epoch n°1745 : train_loss = 2.0528435707092285, val_loss = 0.7867652773857117\n",
      "epoch n°1746 : train_loss = 2.0563395023345947, val_loss = 0.7873955368995667\n",
      "epoch n°1747 : train_loss = 2.0515170097351074, val_loss = 0.7934933304786682\n",
      "epoch n°1748 : train_loss = 2.0476346015930176, val_loss = 0.7937976121902466\n",
      "epoch n°1749 : train_loss = 2.044766426086426, val_loss = 0.7925510406494141\n",
      "epoch n°1750 : train_loss = 2.052069664001465, val_loss = 0.793920636177063\n",
      "epoch n°1751 : train_loss = 2.058490753173828, val_loss = 0.7905071973800659\n",
      "epoch n°1752 : train_loss = 2.0623533725738525, val_loss = 0.7932167649269104\n",
      "epoch n°1753 : train_loss = 2.0574779510498047, val_loss = 0.79334557056427\n",
      "epoch n°1754 : train_loss = 2.0544235706329346, val_loss = 0.7925419211387634\n",
      "epoch n°1755 : train_loss = 2.050769329071045, val_loss = 0.7951535582542419\n",
      "epoch n°1756 : train_loss = 2.054133415222168, val_loss = 0.7937065958976746\n",
      "epoch n°1757 : train_loss = 2.0615720748901367, val_loss = 0.7901684045791626\n",
      "epoch n°1758 : train_loss = 2.0540196895599365, val_loss = 0.7971685528755188\n",
      "epoch n°1759 : train_loss = 2.051516056060791, val_loss = 0.7894602417945862\n",
      "epoch n°1760 : train_loss = 2.0500378608703613, val_loss = 0.7903226017951965\n",
      "epoch n°1761 : train_loss = 2.051909923553467, val_loss = 0.788299024105072\n",
      "epoch n°1762 : train_loss = 2.0496697425842285, val_loss = 0.7965829372406006\n",
      "epoch n°1763 : train_loss = 2.0433528423309326, val_loss = 0.7950164079666138\n",
      "epoch n°1764 : train_loss = 2.0564963817596436, val_loss = 0.7885469794273376\n",
      "epoch n°1765 : train_loss = 2.0557286739349365, val_loss = 0.7938524484634399\n",
      "epoch n°1766 : train_loss = 2.0554587841033936, val_loss = 0.7917637228965759\n",
      "epoch n°1767 : train_loss = 2.053149938583374, val_loss = 0.7926578521728516\n",
      "epoch n°1768 : train_loss = 2.04923677444458, val_loss = 0.7963694334030151\n",
      "epoch n°1769 : train_loss = 2.0578672885894775, val_loss = 0.7988240122795105\n",
      "epoch n°1770 : train_loss = 2.047686815261841, val_loss = 0.7946656346321106\n",
      "epoch n°1771 : train_loss = 2.0572588443756104, val_loss = 0.794036865234375\n",
      "epoch n°1772 : train_loss = 2.0541813373565674, val_loss = 0.793566882610321\n",
      "epoch n°1773 : train_loss = 2.0505261421203613, val_loss = 0.7932994365692139\n",
      "epoch n°1774 : train_loss = 2.0568761825561523, val_loss = 0.7927556037902832\n",
      "epoch n°1775 : train_loss = 2.0585546493530273, val_loss = 0.7973093390464783\n",
      "epoch n°1776 : train_loss = 2.0511362552642822, val_loss = 0.7914138436317444\n",
      "epoch n°1777 : train_loss = 2.048698902130127, val_loss = 0.7896921038627625\n",
      "epoch n°1778 : train_loss = 2.0594141483306885, val_loss = 0.7919214367866516\n",
      "epoch n°1779 : train_loss = 2.050017833709717, val_loss = 0.7943328022956848\n",
      "epoch n°1780 : train_loss = 2.059194803237915, val_loss = 0.7950186729431152\n",
      "epoch n°1781 : train_loss = 2.0485517978668213, val_loss = 0.7940502166748047\n",
      "epoch n°1782 : train_loss = 2.051464319229126, val_loss = 0.7967619299888611\n",
      "epoch n°1783 : train_loss = 2.048330068588257, val_loss = 0.7939988970756531\n",
      "epoch n°1784 : train_loss = 2.0458743572235107, val_loss = 0.7934125661849976\n",
      "epoch n°1785 : train_loss = 2.053234815597534, val_loss = 0.7962395548820496\n",
      "epoch n°1786 : train_loss = 2.0552384853363037, val_loss = 0.7942575812339783\n",
      "epoch n°1787 : train_loss = 2.0453104972839355, val_loss = 0.7931041717529297\n",
      "epoch n°1788 : train_loss = 2.0561513900756836, val_loss = 0.7933288216590881\n",
      "epoch n°1789 : train_loss = 2.053256034851074, val_loss = 0.7944385409355164\n",
      "epoch n°1790 : train_loss = 2.0615293979644775, val_loss = 0.7969258427619934\n",
      "epoch n°1791 : train_loss = 2.0458812713623047, val_loss = 0.792789101600647\n",
      "epoch n°1792 : train_loss = 2.0505759716033936, val_loss = 0.796536922454834\n",
      "epoch n°1793 : train_loss = 2.0554401874542236, val_loss = 0.7912261486053467\n",
      "epoch n°1794 : train_loss = 2.0534729957580566, val_loss = 0.7889809012413025\n",
      "epoch n°1795 : train_loss = 2.0523123741149902, val_loss = 0.7914218306541443\n",
      "epoch n°1796 : train_loss = 2.0564582347869873, val_loss = 0.7938752174377441\n",
      "epoch n°1797 : train_loss = 2.0495545864105225, val_loss = 0.7970598936080933\n",
      "epoch n°1798 : train_loss = 2.053013563156128, val_loss = 0.792149543762207\n",
      "epoch n°1799 : train_loss = 2.048515796661377, val_loss = 0.7946080565452576\n",
      "epoch n°1800 : train_loss = 2.0432794094085693, val_loss = 0.7916676998138428\n",
      "epoch n°1801 : train_loss = 2.0437185764312744, val_loss = 0.7927368879318237\n",
      "epoch n°1802 : train_loss = 2.052917003631592, val_loss = 0.7923474311828613\n",
      "epoch n°1803 : train_loss = 2.046168088912964, val_loss = 0.7956955432891846\n",
      "epoch n°1804 : train_loss = 2.050415277481079, val_loss = 0.7887295484542847\n",
      "epoch n°1805 : train_loss = 2.0481021404266357, val_loss = 0.7905460000038147\n",
      "epoch n°1806 : train_loss = 2.0425267219543457, val_loss = 0.7927156090736389\n",
      "epoch n°1807 : train_loss = 2.0417234897613525, val_loss = 0.7942219376564026\n",
      "epoch n°1808 : train_loss = 2.038228988647461, val_loss = 0.7933798432350159\n",
      "epoch n°1809 : train_loss = 2.05061674118042, val_loss = 0.7937225103378296\n",
      "epoch n°1810 : train_loss = 2.057555913925171, val_loss = 0.7963880896568298\n",
      "epoch n°1811 : train_loss = 2.0386807918548584, val_loss = 0.7911359667778015\n",
      "epoch n°1812 : train_loss = 2.0464251041412354, val_loss = 0.793021023273468\n",
      "epoch n°1813 : train_loss = 2.053095817565918, val_loss = 0.7921321988105774\n",
      "epoch n°1814 : train_loss = 2.0443952083587646, val_loss = 0.7925695180892944\n",
      "epoch n°1815 : train_loss = 2.043241262435913, val_loss = 0.7927059531211853\n",
      "epoch n°1816 : train_loss = 2.0488009452819824, val_loss = 0.7915999889373779\n",
      "epoch n°1817 : train_loss = 2.0524725914001465, val_loss = 0.7929202914237976\n",
      "epoch n°1818 : train_loss = 2.0478482246398926, val_loss = 0.7920652031898499\n",
      "epoch n°1819 : train_loss = 2.0532424449920654, val_loss = 0.794357180595398\n",
      "epoch n°1820 : train_loss = 2.0496530532836914, val_loss = 0.7888350486755371\n",
      "epoch n°1821 : train_loss = 2.05204176902771, val_loss = 0.7965841293334961\n",
      "epoch n°1822 : train_loss = 2.054842948913574, val_loss = 0.7958890199661255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°1823 : train_loss = 2.044855833053589, val_loss = 0.7924646139144897\n",
      "epoch n°1824 : train_loss = 2.056574821472168, val_loss = 0.7925589680671692\n",
      "epoch n°1825 : train_loss = 2.040947198867798, val_loss = 0.7947389483451843\n",
      "epoch n°1826 : train_loss = 2.0458805561065674, val_loss = 0.7934871912002563\n",
      "epoch n°1827 : train_loss = 2.0536797046661377, val_loss = 0.7895676493644714\n",
      "epoch n°1828 : train_loss = 2.0531296730041504, val_loss = 0.7937980890274048\n",
      "epoch n°1829 : train_loss = 2.047450065612793, val_loss = 0.7917565703392029\n",
      "epoch n°1830 : train_loss = 2.0483648777008057, val_loss = 0.7953317761421204\n",
      "epoch n°1831 : train_loss = 2.0499980449676514, val_loss = 0.7926672101020813\n",
      "epoch n°1832 : train_loss = 2.048748254776001, val_loss = 0.7919589281082153\n",
      "epoch n°1833 : train_loss = 2.051140785217285, val_loss = 0.792823851108551\n",
      "epoch n°1834 : train_loss = 2.0579593181610107, val_loss = 0.7941624522209167\n",
      "epoch n°1835 : train_loss = 2.053013801574707, val_loss = 0.7949807047843933\n",
      "epoch n°1836 : train_loss = 2.0544464588165283, val_loss = 0.7954500913619995\n",
      "epoch n°1837 : train_loss = 2.0519473552703857, val_loss = 0.7911726832389832\n",
      "epoch n°1838 : train_loss = 2.0492441654205322, val_loss = 0.7935791611671448\n",
      "epoch n°1839 : train_loss = 2.0494208335876465, val_loss = 0.7917932271957397\n",
      "epoch n°1840 : train_loss = 2.047330856323242, val_loss = 0.7919185757637024\n",
      "epoch n°1841 : train_loss = 2.043189764022827, val_loss = 0.7924448251724243\n",
      "epoch n°1842 : train_loss = 2.0549514293670654, val_loss = 0.7981359958648682\n",
      "epoch n°1843 : train_loss = 2.056641101837158, val_loss = 0.7921057343482971\n",
      "epoch n°1844 : train_loss = 2.0530261993408203, val_loss = 0.7921139597892761\n",
      "epoch n°1845 : train_loss = 2.0513906478881836, val_loss = 0.7938119769096375\n",
      "epoch n°1846 : train_loss = 2.046492099761963, val_loss = 0.7908456325531006\n",
      "epoch n°1847 : train_loss = 2.05465030670166, val_loss = 0.7904506325721741\n",
      "epoch n°1848 : train_loss = 2.057241439819336, val_loss = 0.7935776114463806\n",
      "epoch n°1849 : train_loss = 2.0495445728302, val_loss = 0.7952904105186462\n",
      "epoch n°1850 : train_loss = 2.0539486408233643, val_loss = 0.792108416557312\n",
      "epoch n°1851 : train_loss = 2.038431167602539, val_loss = 0.794960081577301\n",
      "epoch n°1852 : train_loss = 2.045646905899048, val_loss = 0.794363796710968\n",
      "epoch n°1853 : train_loss = 2.0530455112457275, val_loss = 0.7917213439941406\n",
      "epoch n°1854 : train_loss = 2.044402837753296, val_loss = 0.7947218418121338\n",
      "epoch n°1855 : train_loss = 2.046250581741333, val_loss = 0.794270396232605\n",
      "epoch n°1856 : train_loss = 2.0574424266815186, val_loss = 0.7901191115379333\n",
      "epoch n°1857 : train_loss = 2.049166440963745, val_loss = 0.7927209138870239\n",
      "epoch n°1858 : train_loss = 2.041538715362549, val_loss = 0.7938657999038696\n",
      "epoch n°1859 : train_loss = 2.0399982929229736, val_loss = 0.7938430905342102\n",
      "epoch n°1860 : train_loss = 2.0533676147460938, val_loss = 0.7907624244689941\n",
      "epoch n°1861 : train_loss = 2.0507802963256836, val_loss = 0.7922002077102661\n",
      "epoch n°1862 : train_loss = 2.049813985824585, val_loss = 0.792500913143158\n",
      "epoch n°1863 : train_loss = 2.0571837425231934, val_loss = 0.787934422492981\n",
      "epoch n°1864 : train_loss = 2.045311689376831, val_loss = 0.7883722186088562\n",
      "epoch n°1865 : train_loss = 2.055201292037964, val_loss = 0.793648362159729\n",
      "epoch n°1866 : train_loss = 2.0440597534179688, val_loss = 0.7893700003623962\n",
      "epoch n°1867 : train_loss = 2.0499093532562256, val_loss = 0.7907392382621765\n",
      "epoch n°1868 : train_loss = 2.051287889480591, val_loss = 0.7924013733863831\n",
      "epoch n°1869 : train_loss = 2.0509612560272217, val_loss = 0.791230320930481\n",
      "epoch n°1870 : train_loss = 2.0426032543182373, val_loss = 0.7893726229667664\n",
      "epoch n°1871 : train_loss = 2.0509142875671387, val_loss = 0.7920907735824585\n",
      "epoch n°1872 : train_loss = 2.0443785190582275, val_loss = 0.7946387529373169\n",
      "epoch n°1873 : train_loss = 2.0467917919158936, val_loss = 0.7934467196464539\n",
      "epoch n°1874 : train_loss = 2.0445618629455566, val_loss = 0.7939567565917969\n",
      "epoch n°1875 : train_loss = 2.0455594062805176, val_loss = 0.7945274114608765\n",
      "epoch n°1876 : train_loss = 2.0545876026153564, val_loss = 0.7932716608047485\n",
      "epoch n°1877 : train_loss = 2.0429770946502686, val_loss = 0.7922256588935852\n",
      "epoch n°1878 : train_loss = 2.052290678024292, val_loss = 0.786935567855835\n",
      "epoch n°1879 : train_loss = 2.0512914657592773, val_loss = 0.7896223664283752\n",
      "epoch n°1880 : train_loss = 2.0479812622070312, val_loss = 0.7911787033081055\n",
      "epoch n°1881 : train_loss = 2.0479671955108643, val_loss = 0.7909047603607178\n",
      "epoch n°1882 : train_loss = 2.0545501708984375, val_loss = 0.7932203412055969\n",
      "epoch n°1883 : train_loss = 2.0379185676574707, val_loss = 0.7917777895927429\n",
      "epoch n°1884 : train_loss = 2.044930934906006, val_loss = 0.7930808663368225\n",
      "epoch n°1885 : train_loss = 2.046661138534546, val_loss = 0.790673553943634\n",
      "epoch n°1886 : train_loss = 2.048719644546509, val_loss = 0.7872735261917114\n",
      "epoch n°1887 : train_loss = 2.049224853515625, val_loss = 0.7918331027030945\n",
      "epoch n°1888 : train_loss = 2.054767608642578, val_loss = 0.7924032211303711\n",
      "epoch n°1889 : train_loss = 2.0504612922668457, val_loss = 0.792818546295166\n",
      "epoch n°1890 : train_loss = 2.051497220993042, val_loss = 0.7927027940750122\n",
      "epoch n°1891 : train_loss = 2.0518672466278076, val_loss = 0.7932724356651306\n",
      "epoch n°1892 : train_loss = 2.04960036277771, val_loss = 0.8003197312355042\n",
      "epoch n°1893 : train_loss = 2.0432775020599365, val_loss = 0.7892327904701233\n",
      "epoch n°1894 : train_loss = 2.0460071563720703, val_loss = 0.7895389199256897\n",
      "epoch n°1895 : train_loss = 2.054326057434082, val_loss = 0.8000798225402832\n",
      "epoch n°1896 : train_loss = 2.037208080291748, val_loss = 0.7944439053535461\n",
      "epoch n°1897 : train_loss = 2.043644428253174, val_loss = 0.7941554188728333\n",
      "epoch n°1898 : train_loss = 2.0488924980163574, val_loss = 0.7896838784217834\n",
      "epoch n°1899 : train_loss = 2.0467259883880615, val_loss = 0.7928304076194763\n",
      "epoch n°1900 : train_loss = 2.044731616973877, val_loss = 0.793931782245636\n",
      "epoch n°1901 : train_loss = 2.0508577823638916, val_loss = 0.790410041809082\n",
      "epoch n°1902 : train_loss = 2.057755708694458, val_loss = 0.7931554317474365\n",
      "epoch n°1903 : train_loss = 2.047288179397583, val_loss = 0.7906118631362915\n",
      "epoch n°1904 : train_loss = 2.047177314758301, val_loss = 0.7904428839683533\n",
      "epoch n°1905 : train_loss = 2.0469250679016113, val_loss = 0.7923891544342041\n",
      "epoch n°1906 : train_loss = 2.0501649379730225, val_loss = 0.7935375571250916\n",
      "epoch n°1907 : train_loss = 2.043051242828369, val_loss = 0.7928748726844788\n",
      "epoch n°1908 : train_loss = 2.0533595085144043, val_loss = 0.7939358949661255\n",
      "epoch n°1909 : train_loss = 2.0491788387298584, val_loss = 0.7917365431785583\n",
      "epoch n°1910 : train_loss = 2.0445990562438965, val_loss = 0.7920010685920715\n",
      "epoch n°1911 : train_loss = 2.052018642425537, val_loss = 0.7921651601791382\n",
      "epoch n°1912 : train_loss = 2.0467793941497803, val_loss = 0.7882725596427917\n",
      "epoch n°1913 : train_loss = 2.0460331439971924, val_loss = 0.7939648032188416\n",
      "epoch n°1914 : train_loss = 2.047335624694824, val_loss = 0.7920852303504944\n",
      "epoch n°1915 : train_loss = 2.049686908721924, val_loss = 0.7981021404266357\n",
      "epoch n°1916 : train_loss = 2.0499820709228516, val_loss = 0.7905537486076355\n",
      "epoch n°1917 : train_loss = 2.048220157623291, val_loss = 0.7938236594200134\n",
      "epoch n°1918 : train_loss = 2.038050889968872, val_loss = 0.7943969368934631\n",
      "epoch n°1919 : train_loss = 2.0411829948425293, val_loss = 0.7948839068412781\n",
      "epoch n°1920 : train_loss = 2.047818899154663, val_loss = 0.7903669476509094\n",
      "epoch n°1921 : train_loss = 2.041499137878418, val_loss = 0.7940047383308411\n",
      "epoch n°1922 : train_loss = 2.050178050994873, val_loss = 0.7921144366264343\n",
      "epoch n°1923 : train_loss = 2.0435101985931396, val_loss = 0.7851306796073914\n",
      "epoch n°1924 : train_loss = 2.032431125640869, val_loss = 0.7926588654518127\n",
      "epoch n°1925 : train_loss = 2.045644998550415, val_loss = 0.7901725172996521\n",
      "epoch n°1926 : train_loss = 2.041964530944824, val_loss = 0.7981268167495728\n",
      "epoch n°1927 : train_loss = 2.0401878356933594, val_loss = 0.7964025139808655\n",
      "epoch n°1928 : train_loss = 2.0511646270751953, val_loss = 0.7924532294273376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°1929 : train_loss = 2.0492196083068848, val_loss = 0.7900041341781616\n",
      "epoch n°1930 : train_loss = 2.050733804702759, val_loss = 0.7920708060264587\n",
      "epoch n°1931 : train_loss = 2.0534536838531494, val_loss = 0.7978560924530029\n",
      "epoch n°1932 : train_loss = 2.041900157928467, val_loss = 0.789429783821106\n",
      "epoch n°1933 : train_loss = 2.0497426986694336, val_loss = 0.7912083268165588\n",
      "epoch n°1934 : train_loss = 2.0493359565734863, val_loss = 0.7927737832069397\n",
      "epoch n°1935 : train_loss = 2.048037052154541, val_loss = 0.7936314940452576\n",
      "epoch n°1936 : train_loss = 2.0467512607574463, val_loss = 0.7922686338424683\n",
      "epoch n°1937 : train_loss = 2.05639386177063, val_loss = 0.7892985343933105\n",
      "epoch n°1938 : train_loss = 2.05220890045166, val_loss = 0.7949965000152588\n",
      "epoch n°1939 : train_loss = 2.0474226474761963, val_loss = 0.7970625162124634\n",
      "epoch n°1940 : train_loss = 2.045362949371338, val_loss = 0.7897254824638367\n",
      "epoch n°1941 : train_loss = 2.0555222034454346, val_loss = 0.7912636399269104\n",
      "epoch n°1942 : train_loss = 2.047478199005127, val_loss = 0.7925539612770081\n",
      "epoch n°1943 : train_loss = 2.0564122200012207, val_loss = 0.7899987697601318\n",
      "epoch n°1944 : train_loss = 2.050243377685547, val_loss = 0.7911400198936462\n",
      "epoch n°1945 : train_loss = 2.0398526191711426, val_loss = 0.7896219491958618\n",
      "epoch n°1946 : train_loss = 2.041670560836792, val_loss = 0.7914292216300964\n",
      "epoch n°1947 : train_loss = 2.0504159927368164, val_loss = 0.7946676015853882\n",
      "epoch n°1948 : train_loss = 2.0455052852630615, val_loss = 0.7946049571037292\n",
      "epoch n°1949 : train_loss = 2.048513889312744, val_loss = 0.7956429719924927\n",
      "epoch n°1950 : train_loss = 2.045790433883667, val_loss = 0.793096661567688\n",
      "epoch n°1951 : train_loss = 2.0482795238494873, val_loss = 0.790606677532196\n",
      "epoch n°1952 : train_loss = 2.043484687805176, val_loss = 0.7886841893196106\n",
      "epoch n°1953 : train_loss = 2.045839786529541, val_loss = 0.7952445149421692\n",
      "epoch n°1954 : train_loss = 2.0409207344055176, val_loss = 0.7923465371131897\n",
      "epoch n°1955 : train_loss = 2.0462522506713867, val_loss = 0.7883543372154236\n",
      "epoch n°1956 : train_loss = 2.041658639907837, val_loss = 0.7935408353805542\n",
      "epoch n°1957 : train_loss = 2.0539512634277344, val_loss = 0.79264235496521\n",
      "epoch n°1958 : train_loss = 2.0377817153930664, val_loss = 0.7935290932655334\n",
      "epoch n°1959 : train_loss = 2.0391275882720947, val_loss = 0.7933729887008667\n",
      "epoch n°1960 : train_loss = 2.04925799369812, val_loss = 0.7985227108001709\n",
      "epoch n°1961 : train_loss = 2.047109603881836, val_loss = 0.7931870222091675\n",
      "epoch n°1962 : train_loss = 2.047849655151367, val_loss = 0.7908737659454346\n",
      "epoch n°1963 : train_loss = 2.048611640930176, val_loss = 0.7937123775482178\n",
      "epoch n°1964 : train_loss = 2.050112009048462, val_loss = 0.7942111492156982\n",
      "epoch n°1965 : train_loss = 2.0488202571868896, val_loss = 0.7922767400741577\n",
      "epoch n°1966 : train_loss = 2.0519633293151855, val_loss = 0.7902665138244629\n",
      "epoch n°1967 : train_loss = 2.039039134979248, val_loss = 0.7949599027633667\n",
      "epoch n°1968 : train_loss = 2.0450456142425537, val_loss = 0.7954602241516113\n",
      "epoch n°1969 : train_loss = 2.0411911010742188, val_loss = 0.7910750508308411\n",
      "epoch n°1970 : train_loss = 2.050032377243042, val_loss = 0.7921313047409058\n",
      "epoch n°1971 : train_loss = 2.0480966567993164, val_loss = 0.789921760559082\n",
      "epoch n°1972 : train_loss = 2.0477957725524902, val_loss = 0.7958528399467468\n",
      "epoch n°1973 : train_loss = 2.045781373977661, val_loss = 0.7955046892166138\n",
      "epoch n°1974 : train_loss = 2.0524892807006836, val_loss = 0.7964497804641724\n",
      "epoch n°1975 : train_loss = 2.048076629638672, val_loss = 0.7903282046318054\n",
      "epoch n°1976 : train_loss = 2.0504415035247803, val_loss = 0.7931236028671265\n",
      "epoch n°1977 : train_loss = 2.0449976921081543, val_loss = 0.7912076711654663\n",
      "epoch n°1978 : train_loss = 2.0401110649108887, val_loss = 0.7923787236213684\n",
      "epoch n°1979 : train_loss = 2.044595241546631, val_loss = 0.7900214791297913\n",
      "epoch n°1980 : train_loss = 2.048893928527832, val_loss = 0.792995035648346\n",
      "epoch n°1981 : train_loss = 2.0416388511657715, val_loss = 0.7937281131744385\n",
      "epoch n°1982 : train_loss = 2.035707473754883, val_loss = 0.7935662269592285\n",
      "epoch n°1983 : train_loss = 2.0428638458251953, val_loss = 0.7895779609680176\n",
      "epoch n°1984 : train_loss = 2.0492804050445557, val_loss = 0.793050229549408\n",
      "epoch n°1985 : train_loss = 2.0409131050109863, val_loss = 0.7904092073440552\n",
      "epoch n°1986 : train_loss = 2.0449435710906982, val_loss = 0.7938982844352722\n",
      "epoch n°1987 : train_loss = 2.0468358993530273, val_loss = 0.7909440994262695\n",
      "epoch n°1988 : train_loss = 2.049787759780884, val_loss = 0.7914161086082458\n",
      "epoch n°1989 : train_loss = 2.048565626144409, val_loss = 0.7886872887611389\n",
      "epoch n°1990 : train_loss = 2.0407869815826416, val_loss = 0.7954878807067871\n",
      "epoch n°1991 : train_loss = 2.0478711128234863, val_loss = 0.7871942520141602\n",
      "epoch n°1992 : train_loss = 2.0438504219055176, val_loss = 0.7959004640579224\n",
      "epoch n°1993 : train_loss = 2.0493674278259277, val_loss = 0.7978849411010742\n",
      "epoch n°1994 : train_loss = 2.0446343421936035, val_loss = 0.7910844087600708\n",
      "epoch n°1995 : train_loss = 2.039229393005371, val_loss = 0.7931631207466125\n",
      "epoch n°1996 : train_loss = 2.041228771209717, val_loss = 0.7937127947807312\n",
      "epoch n°1997 : train_loss = 2.041001796722412, val_loss = 0.7904566526412964\n",
      "epoch n°1998 : train_loss = 2.04034686088562, val_loss = 0.7909128069877625\n",
      "epoch n°1999 : train_loss = 2.0402865409851074, val_loss = 0.7918011546134949\n",
      "epoch n°2000 : train_loss = 2.044149398803711, val_loss = 0.7898069024085999\n",
      "epoch n°2001 : train_loss = 2.043794870376587, val_loss = 0.7966338992118835\n",
      "epoch n°2002 : train_loss = 2.050902843475342, val_loss = 0.7962160110473633\n",
      "epoch n°2003 : train_loss = 2.049790859222412, val_loss = 0.7958120107650757\n",
      "epoch n°2004 : train_loss = 2.044603109359741, val_loss = 0.7937171459197998\n",
      "epoch n°2005 : train_loss = 2.0522358417510986, val_loss = 0.790563702583313\n",
      "epoch n°2006 : train_loss = 2.0419514179229736, val_loss = 0.7919670343399048\n",
      "epoch n°2007 : train_loss = 2.0448076725006104, val_loss = 0.790874183177948\n",
      "epoch n°2008 : train_loss = 2.046187162399292, val_loss = 0.7898098826408386\n",
      "epoch n°2009 : train_loss = 2.0567338466644287, val_loss = 0.791874349117279\n",
      "epoch n°2010 : train_loss = 2.0483205318450928, val_loss = 0.7938901782035828\n",
      "epoch n°2011 : train_loss = 2.0479483604431152, val_loss = 0.7928819060325623\n",
      "epoch n°2012 : train_loss = 2.0446455478668213, val_loss = 0.7928422689437866\n",
      "epoch n°2013 : train_loss = 2.0459001064300537, val_loss = 0.7889540791511536\n",
      "epoch n°2014 : train_loss = 2.0465340614318848, val_loss = 0.7885900139808655\n",
      "epoch n°2015 : train_loss = 2.049806833267212, val_loss = 0.7886337637901306\n",
      "epoch n°2016 : train_loss = 2.0377392768859863, val_loss = 0.7963889241218567\n",
      "epoch n°2017 : train_loss = 2.0504415035247803, val_loss = 0.7937160730361938\n",
      "epoch n°2018 : train_loss = 2.048912525177002, val_loss = 0.7935550808906555\n",
      "epoch n°2019 : train_loss = 2.0521063804626465, val_loss = 0.7952498197555542\n",
      "epoch n°2020 : train_loss = 2.0461230278015137, val_loss = 0.7906801104545593\n",
      "epoch n°2021 : train_loss = 2.0470595359802246, val_loss = 0.7932944893836975\n",
      "epoch n°2022 : train_loss = 2.0459368228912354, val_loss = 0.7914115190505981\n",
      "epoch n°2023 : train_loss = 2.0414316654205322, val_loss = 0.7929058074951172\n",
      "epoch n°2024 : train_loss = 2.0518527030944824, val_loss = 0.7903147339820862\n",
      "epoch n°2025 : train_loss = 2.0499024391174316, val_loss = 0.7930447459220886\n",
      "epoch n°2026 : train_loss = 2.0469117164611816, val_loss = 0.7926232814788818\n",
      "epoch n°2027 : train_loss = 2.039376735687256, val_loss = 0.7931464314460754\n",
      "epoch n°2028 : train_loss = 2.0546977519989014, val_loss = 0.7913655638694763\n",
      "epoch n°2029 : train_loss = 2.0382556915283203, val_loss = 0.7966718673706055\n",
      "epoch n°2030 : train_loss = 2.038803815841675, val_loss = 0.7908255457878113\n",
      "epoch n°2031 : train_loss = 2.0538322925567627, val_loss = 0.791818380355835\n",
      "epoch n°2032 : train_loss = 2.0897138118743896, val_loss = 0.7998312711715698\n",
      "epoch n°2033 : train_loss = 2.1098783016204834, val_loss = 0.7980197072029114\n",
      "epoch n°2034 : train_loss = 2.0741255283355713, val_loss = 0.7927536964416504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°2035 : train_loss = 2.062694549560547, val_loss = 0.795486569404602\n",
      "epoch n°2036 : train_loss = 2.07812237739563, val_loss = 0.7945098876953125\n",
      "epoch n°2037 : train_loss = 2.087322950363159, val_loss = 0.797387957572937\n",
      "epoch n°2038 : train_loss = 2.0718681812286377, val_loss = 0.7940722107887268\n",
      "epoch n°2039 : train_loss = 2.072890043258667, val_loss = 0.7942395210266113\n",
      "epoch n°2040 : train_loss = 2.0829765796661377, val_loss = 0.7960038781166077\n",
      "epoch n°2041 : train_loss = 2.080418109893799, val_loss = 0.7960658073425293\n",
      "epoch n°2042 : train_loss = 2.077899217605591, val_loss = 0.7981109023094177\n",
      "epoch n°2043 : train_loss = 2.078753709793091, val_loss = 0.7972661852836609\n",
      "epoch n°2044 : train_loss = 2.0836896896362305, val_loss = 0.7975793480873108\n",
      "epoch n°2045 : train_loss = 2.0757243633270264, val_loss = 0.795183002948761\n",
      "epoch n°2046 : train_loss = 2.0846521854400635, val_loss = 0.7998738884925842\n",
      "epoch n°2047 : train_loss = 2.079918622970581, val_loss = 0.7956659197807312\n",
      "epoch n°2048 : train_loss = 2.078397750854492, val_loss = 0.7954546809196472\n",
      "epoch n°2049 : train_loss = 2.070986747741699, val_loss = 0.7960504293441772\n",
      "epoch n°2050 : train_loss = 2.0765273571014404, val_loss = 0.7986819744110107\n",
      "epoch n°2051 : train_loss = 2.0763566493988037, val_loss = 0.7979181408882141\n",
      "epoch n°2052 : train_loss = 2.0811548233032227, val_loss = 0.8010785579681396\n",
      "epoch n°2053 : train_loss = 2.0746254920959473, val_loss = 0.7984815835952759\n",
      "epoch n°2054 : train_loss = 2.0903806686401367, val_loss = 0.7969545722007751\n",
      "epoch n°2055 : train_loss = 2.0755691528320312, val_loss = 0.7953594923019409\n",
      "epoch n°2056 : train_loss = 2.0785090923309326, val_loss = 0.7913205027580261\n",
      "epoch n°2057 : train_loss = 2.0831830501556396, val_loss = 0.7925684452056885\n",
      "epoch n°2058 : train_loss = 2.080747365951538, val_loss = 0.7957161068916321\n",
      "epoch n°2059 : train_loss = 2.07912540435791, val_loss = 0.7931903600692749\n",
      "epoch n°2060 : train_loss = 2.079444646835327, val_loss = 0.793445885181427\n",
      "epoch n°2061 : train_loss = 2.0837674140930176, val_loss = 0.795688271522522\n",
      "epoch n°2062 : train_loss = 2.0888640880584717, val_loss = 0.7988284826278687\n",
      "epoch n°2063 : train_loss = 2.0869362354278564, val_loss = 0.7968191504478455\n",
      "epoch n°2064 : train_loss = 2.0858709812164307, val_loss = 0.7931380867958069\n",
      "epoch n°2065 : train_loss = 2.0866801738739014, val_loss = 0.7950669527053833\n",
      "epoch n°2066 : train_loss = 2.081543445587158, val_loss = 0.7972704768180847\n",
      "epoch n°2067 : train_loss = 2.0769569873809814, val_loss = 0.7999442219734192\n",
      "epoch n°2068 : train_loss = 2.0855584144592285, val_loss = 0.7960984706878662\n",
      "epoch n°2069 : train_loss = 2.0818028450012207, val_loss = 0.7955532073974609\n",
      "epoch n°2070 : train_loss = 2.072246551513672, val_loss = 0.7959241271018982\n",
      "epoch n°2071 : train_loss = 2.084967613220215, val_loss = 0.7921575903892517\n",
      "epoch n°2072 : train_loss = 2.0816802978515625, val_loss = 0.8002978563308716\n",
      "epoch n°2073 : train_loss = 2.110041856765747, val_loss = 0.7976776957511902\n",
      "epoch n°2074 : train_loss = 2.086362600326538, val_loss = 0.7931557297706604\n",
      "epoch n°2075 : train_loss = 2.086428165435791, val_loss = 0.7997287511825562\n",
      "epoch n°2076 : train_loss = 2.0846457481384277, val_loss = 0.7995025515556335\n",
      "epoch n°2077 : train_loss = 2.0856378078460693, val_loss = 0.7905159592628479\n",
      "epoch n°2078 : train_loss = 2.0836660861968994, val_loss = 0.7995927929878235\n",
      "epoch n°2079 : train_loss = 2.0827345848083496, val_loss = 0.796024739742279\n",
      "epoch n°2080 : train_loss = 2.0855000019073486, val_loss = 0.7930644750595093\n",
      "epoch n°2081 : train_loss = 2.0911829471588135, val_loss = 0.7985982894897461\n",
      "epoch n°2082 : train_loss = 2.079446792602539, val_loss = 0.798290491104126\n",
      "epoch n°2083 : train_loss = 2.083462715148926, val_loss = 0.8006373643875122\n",
      "epoch n°2084 : train_loss = 2.0833630561828613, val_loss = 0.7984116673469543\n",
      "epoch n°2085 : train_loss = 2.083143711090088, val_loss = 0.7926973104476929\n",
      "epoch n°2086 : train_loss = 2.082042694091797, val_loss = 0.7999398708343506\n",
      "epoch n°2087 : train_loss = 2.0873501300811768, val_loss = 0.795714259147644\n",
      "epoch n°2088 : train_loss = 2.080190896987915, val_loss = 0.7992302179336548\n",
      "epoch n°2089 : train_loss = 2.077260732650757, val_loss = 0.792879045009613\n",
      "epoch n°2090 : train_loss = 2.0761783123016357, val_loss = 0.7959732413291931\n",
      "epoch n°2091 : train_loss = 2.0731542110443115, val_loss = 0.7952888607978821\n",
      "epoch n°2092 : train_loss = 2.0835139751434326, val_loss = 0.7968372106552124\n",
      "epoch n°2093 : train_loss = 2.085650682449341, val_loss = 0.7941064834594727\n",
      "epoch n°2094 : train_loss = 2.086118459701538, val_loss = 0.7958574891090393\n",
      "epoch n°2095 : train_loss = 2.0878617763519287, val_loss = 0.7930534482002258\n",
      "epoch n°2096 : train_loss = 2.0801780223846436, val_loss = 0.7936169505119324\n",
      "epoch n°2097 : train_loss = 2.0856258869171143, val_loss = 0.7905592918395996\n",
      "epoch n°2098 : train_loss = 2.075303077697754, val_loss = 0.7949005961418152\n",
      "epoch n°2099 : train_loss = 2.0871849060058594, val_loss = 0.7987966537475586\n",
      "epoch n°2100 : train_loss = 2.092633008956909, val_loss = 0.7993180155754089\n",
      "epoch n°2101 : train_loss = 2.079284906387329, val_loss = 0.7937167882919312\n",
      "epoch n°2102 : train_loss = 2.087010383605957, val_loss = 0.7951546311378479\n",
      "epoch n°2103 : train_loss = 2.0793185234069824, val_loss = 0.7952988147735596\n",
      "epoch n°2104 : train_loss = 2.085799217224121, val_loss = 0.7925493717193604\n",
      "epoch n°2105 : train_loss = 2.0918502807617188, val_loss = 0.7969709634780884\n",
      "epoch n°2106 : train_loss = 2.0992047786712646, val_loss = 0.7965219020843506\n",
      "epoch n°2107 : train_loss = 2.081118583679199, val_loss = 0.7948739528656006\n",
      "epoch n°2108 : train_loss = 2.0786690711975098, val_loss = 0.7984960675239563\n",
      "epoch n°2109 : train_loss = 2.089874505996704, val_loss = 0.7942726612091064\n",
      "epoch n°2110 : train_loss = 2.0852725505828857, val_loss = 0.7913365364074707\n",
      "epoch n°2111 : train_loss = 2.092212438583374, val_loss = 0.797173023223877\n",
      "epoch n°2112 : train_loss = 2.0808212757110596, val_loss = 0.7961604595184326\n",
      "epoch n°2113 : train_loss = 2.0871903896331787, val_loss = 0.7983664274215698\n",
      "epoch n°2114 : train_loss = 2.091484785079956, val_loss = 0.7939013838768005\n",
      "epoch n°2115 : train_loss = 2.092761278152466, val_loss = 0.7920020222663879\n",
      "epoch n°2116 : train_loss = 2.084244966506958, val_loss = 0.8006752133369446\n",
      "epoch n°2117 : train_loss = 2.087700843811035, val_loss = 0.7941813468933105\n",
      "epoch n°2118 : train_loss = 2.092573881149292, val_loss = 0.793023407459259\n",
      "epoch n°2119 : train_loss = 2.0825719833374023, val_loss = 0.7937171459197998\n",
      "epoch n°2120 : train_loss = 2.0807435512542725, val_loss = 0.7950605750083923\n",
      "epoch n°2121 : train_loss = 2.0792884826660156, val_loss = 0.7981225252151489\n",
      "epoch n°2122 : train_loss = 2.093318223953247, val_loss = 0.7958115935325623\n",
      "epoch n°2123 : train_loss = 2.0737180709838867, val_loss = 0.7985588312149048\n",
      "epoch n°2124 : train_loss = 2.0739221572875977, val_loss = 0.7986448407173157\n",
      "epoch n°2125 : train_loss = 2.0840342044830322, val_loss = 0.7961231470108032\n",
      "epoch n°2126 : train_loss = 2.0786094665527344, val_loss = 0.79609614610672\n",
      "epoch n°2127 : train_loss = 2.0898690223693848, val_loss = 0.7943491339683533\n",
      "epoch n°2128 : train_loss = 2.0777716636657715, val_loss = 0.7965839505195618\n",
      "epoch n°2129 : train_loss = 2.0880165100097656, val_loss = 0.7987600564956665\n",
      "epoch n°2130 : train_loss = 2.0860202312469482, val_loss = 0.7943283915519714\n",
      "epoch n°2131 : train_loss = 2.094273567199707, val_loss = 0.7985351085662842\n",
      "epoch n°2132 : train_loss = 2.0799520015716553, val_loss = 0.798591136932373\n",
      "epoch n°2133 : train_loss = 2.0907976627349854, val_loss = 0.7989221215248108\n",
      "epoch n°2134 : train_loss = 2.0874135494232178, val_loss = 0.7966175675392151\n",
      "epoch n°2135 : train_loss = 2.0907254219055176, val_loss = 0.7948048114776611\n",
      "epoch n°2136 : train_loss = 2.087012529373169, val_loss = 0.7940523028373718\n",
      "epoch n°2137 : train_loss = 2.0856049060821533, val_loss = 0.7943391799926758\n",
      "epoch n°2138 : train_loss = 2.081425428390503, val_loss = 0.795569658279419\n",
      "epoch n°2139 : train_loss = 2.0861754417419434, val_loss = 0.8011320233345032\n",
      "epoch n°2140 : train_loss = 2.0931921005249023, val_loss = 0.8028333783149719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°2141 : train_loss = 2.1006524562835693, val_loss = 0.7955430150032043\n",
      "epoch n°2142 : train_loss = 2.085550308227539, val_loss = 0.7994588017463684\n",
      "epoch n°2143 : train_loss = 2.0847437381744385, val_loss = 0.7939640879631042\n",
      "epoch n°2144 : train_loss = 2.0834696292877197, val_loss = 0.7955076694488525\n",
      "epoch n°2145 : train_loss = 2.08636212348938, val_loss = 0.7932680249214172\n",
      "epoch n°2146 : train_loss = 2.0848186016082764, val_loss = 0.796501100063324\n",
      "epoch n°2147 : train_loss = 2.0854649543762207, val_loss = 0.7957290410995483\n",
      "epoch n°2148 : train_loss = 2.083879232406616, val_loss = 0.8011038899421692\n",
      "epoch n°2149 : train_loss = 2.0916810035705566, val_loss = 0.7975564002990723\n",
      "epoch n°2150 : train_loss = 2.082120895385742, val_loss = 0.792329728603363\n",
      "epoch n°2151 : train_loss = 2.0919365882873535, val_loss = 0.7914286851882935\n",
      "epoch n°2152 : train_loss = 2.0900309085845947, val_loss = 0.7928786873817444\n",
      "epoch n°2153 : train_loss = 2.0877888202667236, val_loss = 0.7962682843208313\n",
      "epoch n°2154 : train_loss = 2.0793542861938477, val_loss = 0.8029985427856445\n",
      "epoch n°2155 : train_loss = 2.0896317958831787, val_loss = 0.7982780933380127\n",
      "epoch n°2156 : train_loss = 2.083425521850586, val_loss = 0.7946832776069641\n",
      "epoch n°2157 : train_loss = 2.0870680809020996, val_loss = 0.797332227230072\n",
      "epoch n°2158 : train_loss = 2.0859262943267822, val_loss = 0.7934062480926514\n",
      "epoch n°2159 : train_loss = 2.082134962081909, val_loss = 0.7965726852416992\n",
      "epoch n°2160 : train_loss = 2.0766189098358154, val_loss = 0.7973239421844482\n",
      "epoch n°2161 : train_loss = 2.0756423473358154, val_loss = 0.7962584495544434\n",
      "epoch n°2162 : train_loss = 2.081712245941162, val_loss = 0.7995986342430115\n",
      "epoch n°2163 : train_loss = 2.082477569580078, val_loss = 0.796887218952179\n",
      "epoch n°2164 : train_loss = 2.0811283588409424, val_loss = 0.7958770394325256\n",
      "epoch n°2165 : train_loss = 2.080928087234497, val_loss = 0.7966397404670715\n",
      "epoch n°2166 : train_loss = 2.0829944610595703, val_loss = 0.7938882112503052\n",
      "epoch n°2167 : train_loss = 2.0812265872955322, val_loss = 0.7990221977233887\n",
      "epoch n°2168 : train_loss = 2.085669994354248, val_loss = 0.7927753925323486\n",
      "epoch n°2169 : train_loss = 2.081698179244995, val_loss = 0.7932640314102173\n",
      "epoch n°2170 : train_loss = 2.087878704071045, val_loss = 0.7979269027709961\n",
      "epoch n°2171 : train_loss = 2.0810863971710205, val_loss = 0.7955467104911804\n",
      "epoch n°2172 : train_loss = 2.0891168117523193, val_loss = 0.7952314615249634\n",
      "epoch n°2173 : train_loss = 2.0709116458892822, val_loss = 0.7940008640289307\n",
      "epoch n°2174 : train_loss = 2.0840694904327393, val_loss = 0.7976474165916443\n",
      "epoch n°2175 : train_loss = 2.0832293033599854, val_loss = 0.7994239330291748\n",
      "epoch n°2176 : train_loss = 2.0809106826782227, val_loss = 0.8000098466873169\n",
      "epoch n°2177 : train_loss = 2.0819530487060547, val_loss = 0.8005240559577942\n",
      "epoch n°2178 : train_loss = 2.087949275970459, val_loss = 0.797024667263031\n",
      "epoch n°2179 : train_loss = 2.092128038406372, val_loss = 0.7917444109916687\n",
      "epoch n°2180 : train_loss = 2.0870730876922607, val_loss = 0.7945495247840881\n",
      "epoch n°2181 : train_loss = 2.087810754776001, val_loss = 0.7970532178878784\n",
      "epoch n°2182 : train_loss = 2.0733776092529297, val_loss = 0.7942283749580383\n",
      "epoch n°2183 : train_loss = 2.077819347381592, val_loss = 0.7979135513305664\n",
      "epoch n°2184 : train_loss = 2.0905911922454834, val_loss = 0.7909260988235474\n",
      "epoch n°2185 : train_loss = 2.0909626483917236, val_loss = 0.798511803150177\n",
      "epoch n°2186 : train_loss = 2.0731351375579834, val_loss = 0.794004499912262\n",
      "epoch n°2187 : train_loss = 2.0799384117126465, val_loss = 0.7954889535903931\n",
      "epoch n°2188 : train_loss = 2.0844485759735107, val_loss = 0.7916997671127319\n",
      "epoch n°2189 : train_loss = 2.0790276527404785, val_loss = 0.7915452122688293\n",
      "epoch n°2190 : train_loss = 2.086454391479492, val_loss = 0.7962053418159485\n",
      "epoch n°2191 : train_loss = 2.0977485179901123, val_loss = 0.7981323003768921\n",
      "epoch n°2192 : train_loss = 2.0684046745300293, val_loss = 0.7952608466148376\n",
      "epoch n°2193 : train_loss = 2.084742307662964, val_loss = 0.7984872460365295\n",
      "epoch n°2194 : train_loss = 2.0859901905059814, val_loss = 0.7969529032707214\n",
      "epoch n°2195 : train_loss = 2.087629795074463, val_loss = 0.7955875992774963\n",
      "epoch n°2196 : train_loss = 2.0846567153930664, val_loss = 0.7954280376434326\n",
      "epoch n°2197 : train_loss = 2.082406759262085, val_loss = 0.7981925010681152\n",
      "epoch n°2198 : train_loss = 2.0866827964782715, val_loss = 0.7982828617095947\n",
      "epoch n°2199 : train_loss = 2.0902514457702637, val_loss = 0.7974604368209839\n",
      "epoch n°2200 : train_loss = 2.0908429622650146, val_loss = 0.7971193790435791\n",
      "epoch n°2201 : train_loss = 2.0793206691741943, val_loss = 0.7983499765396118\n",
      "epoch n°2202 : train_loss = 2.0912203788757324, val_loss = 0.7963142991065979\n",
      "epoch n°2203 : train_loss = 2.081144332885742, val_loss = 0.7984006404876709\n",
      "epoch n°2204 : train_loss = 2.0728418827056885, val_loss = 0.7977588176727295\n",
      "epoch n°2205 : train_loss = 2.0866141319274902, val_loss = 0.7991612553596497\n",
      "epoch n°2206 : train_loss = 2.0881612300872803, val_loss = 0.7955707311630249\n",
      "epoch n°2207 : train_loss = 2.0858819484710693, val_loss = 0.7941006422042847\n",
      "epoch n°2208 : train_loss = 2.079314947128296, val_loss = 0.7948993444442749\n",
      "epoch n°2209 : train_loss = 2.075449228286743, val_loss = 0.797144889831543\n",
      "epoch n°2210 : train_loss = 2.0809457302093506, val_loss = 0.796194314956665\n",
      "epoch n°2211 : train_loss = 2.0841333866119385, val_loss = 0.7881145477294922\n",
      "epoch n°2212 : train_loss = 2.0812630653381348, val_loss = 0.7956637740135193\n",
      "epoch n°2213 : train_loss = 2.090893507003784, val_loss = 0.7955390810966492\n",
      "epoch n°2214 : train_loss = 2.0821423530578613, val_loss = 0.7995579242706299\n",
      "epoch n°2215 : train_loss = 2.0824058055877686, val_loss = 0.7953957319259644\n",
      "epoch n°2216 : train_loss = 2.0753109455108643, val_loss = 0.7951433062553406\n",
      "epoch n°2217 : train_loss = 2.072087287902832, val_loss = 0.7912546992301941\n",
      "epoch n°2218 : train_loss = 2.0845274925231934, val_loss = 0.7956120371818542\n",
      "epoch n°2219 : train_loss = 2.0853471755981445, val_loss = 0.7961782217025757\n",
      "epoch n°2220 : train_loss = 2.0839521884918213, val_loss = 0.7967706918716431\n",
      "epoch n°2221 : train_loss = 2.0846898555755615, val_loss = 0.7973640561103821\n",
      "epoch n°2222 : train_loss = 2.0859272480010986, val_loss = 0.7966102957725525\n",
      "epoch n°2223 : train_loss = 2.0871636867523193, val_loss = 0.7957209348678589\n",
      "epoch n°2224 : train_loss = 2.086484670639038, val_loss = 0.794881284236908\n",
      "epoch n°2225 : train_loss = 2.0812106132507324, val_loss = 0.7921105623245239\n",
      "epoch n°2226 : train_loss = 2.0847320556640625, val_loss = 0.7917233109474182\n",
      "epoch n°2227 : train_loss = 2.080673933029175, val_loss = 0.7937065958976746\n",
      "epoch n°2228 : train_loss = 2.0851452350616455, val_loss = 0.7971367835998535\n",
      "epoch n°2229 : train_loss = 2.0769667625427246, val_loss = 0.8004292845726013\n",
      "epoch n°2230 : train_loss = 2.0854766368865967, val_loss = 0.7942793965339661\n",
      "epoch n°2231 : train_loss = 2.078240394592285, val_loss = 0.7930447459220886\n",
      "epoch n°2232 : train_loss = 2.0802409648895264, val_loss = 0.792973518371582\n",
      "epoch n°2233 : train_loss = 2.0795857906341553, val_loss = 0.7956739068031311\n",
      "epoch n°2234 : train_loss = 2.0836856365203857, val_loss = 0.7914940118789673\n",
      "epoch n°2235 : train_loss = 2.080070734024048, val_loss = 0.7971129417419434\n",
      "epoch n°2236 : train_loss = 2.097501277923584, val_loss = 0.7953107953071594\n",
      "epoch n°2237 : train_loss = 2.0832390785217285, val_loss = 0.797201931476593\n",
      "epoch n°2238 : train_loss = 2.078890323638916, val_loss = 0.8008283972740173\n",
      "epoch n°2239 : train_loss = 2.084049940109253, val_loss = 0.7942605018615723\n",
      "epoch n°2240 : train_loss = 2.082156181335449, val_loss = 0.7928393483161926\n",
      "epoch n°2241 : train_loss = 2.0901050567626953, val_loss = 0.7968152165412903\n",
      "epoch n°2242 : train_loss = 2.07916522026062, val_loss = 0.7956156134605408\n",
      "epoch n°2243 : train_loss = 2.0799596309661865, val_loss = 0.7902655601501465\n",
      "epoch n°2244 : train_loss = 2.076491117477417, val_loss = 0.7958046793937683\n",
      "epoch n°2245 : train_loss = 2.079758882522583, val_loss = 0.8003987669944763\n",
      "epoch n°2246 : train_loss = 2.08111572265625, val_loss = 0.7985952496528625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°2247 : train_loss = 2.086789846420288, val_loss = 0.796997606754303\n",
      "epoch n°2248 : train_loss = 2.0809524059295654, val_loss = 0.7982658743858337\n",
      "epoch n°2249 : train_loss = 2.079645872116089, val_loss = 0.7894875407218933\n",
      "epoch n°2250 : train_loss = 2.072305917739868, val_loss = 0.7922650575637817\n",
      "epoch n°2251 : train_loss = 2.0824389457702637, val_loss = 0.7944534420967102\n",
      "epoch n°2252 : train_loss = 2.0830092430114746, val_loss = 0.7984733581542969\n",
      "epoch n°2253 : train_loss = 2.094104051589966, val_loss = 0.79765385389328\n",
      "epoch n°2254 : train_loss = 2.0842816829681396, val_loss = 0.7939919233322144\n",
      "epoch n°2255 : train_loss = 2.086811065673828, val_loss = 0.7954715490341187\n",
      "epoch n°2256 : train_loss = 2.0804712772369385, val_loss = 0.798409104347229\n",
      "epoch n°2257 : train_loss = 2.078476667404175, val_loss = 0.7907283902168274\n",
      "epoch n°2258 : train_loss = 2.0816640853881836, val_loss = 0.7903569936752319\n",
      "epoch n°2259 : train_loss = 2.079854726791382, val_loss = 0.7942262887954712\n",
      "epoch n°2260 : train_loss = 2.0802226066589355, val_loss = 0.7966707944869995\n",
      "epoch n°2261 : train_loss = 2.086249351501465, val_loss = 0.7962512373924255\n",
      "epoch n°2262 : train_loss = 2.071780204772949, val_loss = 0.7960329055786133\n",
      "epoch n°2263 : train_loss = 2.080202341079712, val_loss = 0.7975025177001953\n",
      "epoch n°2264 : train_loss = 2.069136381149292, val_loss = 0.7938515543937683\n",
      "epoch n°2265 : train_loss = 2.0825226306915283, val_loss = 0.7937401533126831\n",
      "epoch n°2266 : train_loss = 2.0885705947875977, val_loss = 0.7942538857460022\n",
      "epoch n°2267 : train_loss = 2.0931262969970703, val_loss = 0.7953331470489502\n",
      "epoch n°2268 : train_loss = 2.0795977115631104, val_loss = 0.7967559099197388\n",
      "epoch n°2269 : train_loss = 2.0817463397979736, val_loss = 0.7932784557342529\n",
      "epoch n°2270 : train_loss = 2.0802106857299805, val_loss = 0.7967118620872498\n",
      "epoch n°2271 : train_loss = 2.0797903537750244, val_loss = 0.8004679083824158\n",
      "epoch n°2272 : train_loss = 2.0744857788085938, val_loss = 0.7912814021110535\n",
      "epoch n°2273 : train_loss = 2.074169397354126, val_loss = 0.7946631908416748\n",
      "epoch n°2274 : train_loss = 2.084320306777954, val_loss = 0.7993161082267761\n",
      "epoch n°2275 : train_loss = 2.0813934803009033, val_loss = 0.7934510111808777\n",
      "epoch n°2276 : train_loss = 2.0775132179260254, val_loss = 0.7943302989006042\n",
      "epoch n°2277 : train_loss = 2.0744807720184326, val_loss = 0.7979059815406799\n",
      "epoch n°2278 : train_loss = 2.077627182006836, val_loss = 0.7947757244110107\n",
      "epoch n°2279 : train_loss = 2.0877935886383057, val_loss = 0.7975883483886719\n",
      "epoch n°2280 : train_loss = 2.0851800441741943, val_loss = 0.7915077209472656\n",
      "epoch n°2281 : train_loss = 2.078092098236084, val_loss = 0.7971141338348389\n",
      "epoch n°2282 : train_loss = 2.072021007537842, val_loss = 0.7946542501449585\n",
      "epoch n°2283 : train_loss = 2.0853753089904785, val_loss = 0.7953930497169495\n",
      "epoch n°2284 : train_loss = 2.088632345199585, val_loss = 0.7982938885688782\n",
      "epoch n°2285 : train_loss = 2.075937509536743, val_loss = 0.7990038394927979\n",
      "epoch n°2286 : train_loss = 2.073380947113037, val_loss = 0.7930954694747925\n",
      "epoch n°2287 : train_loss = 2.0868117809295654, val_loss = 0.7911779284477234\n",
      "epoch n°2288 : train_loss = 2.083273410797119, val_loss = 0.796952486038208\n",
      "epoch n°2289 : train_loss = 2.086446762084961, val_loss = 0.7943945527076721\n",
      "epoch n°2290 : train_loss = 2.0772769451141357, val_loss = 0.7980484366416931\n",
      "epoch n°2291 : train_loss = 2.07853102684021, val_loss = 0.7941507697105408\n",
      "epoch n°2292 : train_loss = 2.0735814571380615, val_loss = 0.7939842343330383\n",
      "epoch n°2293 : train_loss = 2.085930824279785, val_loss = 0.7959650754928589\n",
      "epoch n°2294 : train_loss = 2.078468084335327, val_loss = 0.7972615361213684\n",
      "epoch n°2295 : train_loss = 2.0843944549560547, val_loss = 0.796474814414978\n",
      "epoch n°2296 : train_loss = 2.071340322494507, val_loss = 0.793935239315033\n",
      "epoch n°2297 : train_loss = 2.0770068168640137, val_loss = 0.7973671555519104\n",
      "epoch n°2298 : train_loss = 2.075969934463501, val_loss = 0.7950215935707092\n",
      "epoch n°2299 : train_loss = 2.0797109603881836, val_loss = 0.8015861511230469\n",
      "epoch n°2300 : train_loss = 2.0847244262695312, val_loss = 0.7968010902404785\n",
      "epoch n°2301 : train_loss = 2.075813055038452, val_loss = 0.7981296181678772\n",
      "epoch n°2302 : train_loss = 2.0859079360961914, val_loss = 0.7956240773200989\n",
      "epoch n°2303 : train_loss = 2.080673933029175, val_loss = 0.796207070350647\n",
      "epoch n°2304 : train_loss = 2.078619956970215, val_loss = 0.7984929084777832\n",
      "epoch n°2305 : train_loss = 2.0749945640563965, val_loss = 0.8026922941207886\n",
      "epoch n°2306 : train_loss = 2.0884039402008057, val_loss = 0.7953632473945618\n",
      "epoch n°2307 : train_loss = 2.0728111267089844, val_loss = 0.7951556444168091\n",
      "epoch n°2308 : train_loss = 2.086117744445801, val_loss = 0.7940749526023865\n",
      "epoch n°2309 : train_loss = 2.077397108078003, val_loss = 0.7955667972564697\n",
      "epoch n°2310 : train_loss = 2.0894973278045654, val_loss = 0.7951472401618958\n",
      "epoch n°2311 : train_loss = 2.084876537322998, val_loss = 0.7944825291633606\n",
      "epoch n°2312 : train_loss = 2.0745785236358643, val_loss = 0.793775200843811\n",
      "epoch n°2313 : train_loss = 2.0764353275299072, val_loss = 0.7933400273323059\n",
      "epoch n°2314 : train_loss = 2.072370767593384, val_loss = 0.7981984615325928\n",
      "epoch n°2315 : train_loss = 2.082303047180176, val_loss = 0.7973636388778687\n",
      "epoch n°2316 : train_loss = 2.0780491828918457, val_loss = 0.7922174334526062\n",
      "epoch n°2317 : train_loss = 2.077249765396118, val_loss = 0.7960726022720337\n",
      "epoch n°2318 : train_loss = 2.0726253986358643, val_loss = 0.7935934066772461\n",
      "epoch n°2319 : train_loss = 2.0765349864959717, val_loss = 0.7932958006858826\n",
      "epoch n°2320 : train_loss = 2.0786571502685547, val_loss = 0.7966264486312866\n",
      "epoch n°2321 : train_loss = 2.0852084159851074, val_loss = 0.7976569533348083\n",
      "epoch n°2322 : train_loss = 2.075124740600586, val_loss = 0.7969197034835815\n",
      "epoch n°2323 : train_loss = 2.081003189086914, val_loss = 0.7996413111686707\n",
      "epoch n°2324 : train_loss = 2.08065128326416, val_loss = 0.801589846611023\n",
      "epoch n°2325 : train_loss = 2.074814558029175, val_loss = 0.7941396236419678\n",
      "epoch n°2326 : train_loss = 2.0749502182006836, val_loss = 0.7921938896179199\n",
      "epoch n°2327 : train_loss = 2.0766372680664062, val_loss = 0.7970741987228394\n",
      "epoch n°2328 : train_loss = 2.074645757675171, val_loss = 0.7949545383453369\n",
      "epoch n°2329 : train_loss = 2.0807738304138184, val_loss = 0.7981241345405579\n",
      "epoch n°2330 : train_loss = 2.075594186782837, val_loss = 0.794154942035675\n",
      "epoch n°2331 : train_loss = 2.0803747177124023, val_loss = 0.7954424619674683\n",
      "epoch n°2332 : train_loss = 2.075695276260376, val_loss = 0.7943738698959351\n",
      "epoch n°2333 : train_loss = 2.076392889022827, val_loss = 0.7998649477958679\n",
      "epoch n°2334 : train_loss = 2.0811853408813477, val_loss = 0.7986488342285156\n",
      "epoch n°2335 : train_loss = 2.077415943145752, val_loss = 0.7952654361724854\n",
      "epoch n°2336 : train_loss = 2.073887825012207, val_loss = 0.7941644191741943\n",
      "epoch n°2337 : train_loss = 2.091275215148926, val_loss = 0.7957170009613037\n",
      "epoch n°2338 : train_loss = 2.080813407897949, val_loss = 0.7939701080322266\n",
      "epoch n°2339 : train_loss = 2.0741682052612305, val_loss = 0.7932477593421936\n",
      "epoch n°2340 : train_loss = 2.0865986347198486, val_loss = 0.7986348867416382\n",
      "epoch n°2341 : train_loss = 2.0746653079986572, val_loss = 0.7929221987724304\n",
      "epoch n°2342 : train_loss = 2.0763683319091797, val_loss = 0.8000407218933105\n",
      "epoch n°2343 : train_loss = 2.09502911567688, val_loss = 0.7938811182975769\n",
      "epoch n°2344 : train_loss = 2.0775020122528076, val_loss = 0.797835648059845\n",
      "epoch n°2345 : train_loss = 2.0786728858947754, val_loss = 0.7943573594093323\n",
      "epoch n°2346 : train_loss = 2.0760905742645264, val_loss = 0.7977311611175537\n",
      "epoch n°2347 : train_loss = 2.081207513809204, val_loss = 0.7966615557670593\n",
      "epoch n°2348 : train_loss = 2.0844039916992188, val_loss = 0.7968815565109253\n",
      "epoch n°2349 : train_loss = 2.080868721008301, val_loss = 0.7958184480667114\n",
      "epoch n°2350 : train_loss = 2.078381061553955, val_loss = 0.7953590154647827\n",
      "epoch n°2351 : train_loss = 2.077500581741333, val_loss = 0.7955246567726135\n",
      "epoch n°2352 : train_loss = 2.079111099243164, val_loss = 0.7912115454673767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°2353 : train_loss = 2.07436466217041, val_loss = 0.7929233908653259\n",
      "epoch n°2354 : train_loss = 2.080721139907837, val_loss = 0.7948721647262573\n",
      "epoch n°2355 : train_loss = 2.082836389541626, val_loss = 0.7957271933555603\n",
      "epoch n°2356 : train_loss = 2.0823817253112793, val_loss = 0.7966898679733276\n",
      "epoch n°2357 : train_loss = 2.076502799987793, val_loss = 0.7994319200515747\n",
      "epoch n°2358 : train_loss = 2.0797653198242188, val_loss = 0.7907552719116211\n",
      "epoch n°2359 : train_loss = 2.0758159160614014, val_loss = 0.7983647584915161\n",
      "epoch n°2360 : train_loss = 2.0830225944519043, val_loss = 0.7997296452522278\n",
      "epoch n°2361 : train_loss = 2.069087505340576, val_loss = 0.7946821451187134\n",
      "epoch n°2362 : train_loss = 2.080655097961426, val_loss = 0.8000028133392334\n",
      "epoch n°2363 : train_loss = 2.0789341926574707, val_loss = 0.795431911945343\n",
      "epoch n°2364 : train_loss = 2.076141595840454, val_loss = 0.7931331992149353\n",
      "epoch n°2365 : train_loss = 2.0787405967712402, val_loss = 0.7955597043037415\n",
      "epoch n°2366 : train_loss = 2.074514865875244, val_loss = 0.7922801971435547\n",
      "epoch n°2367 : train_loss = 2.0870823860168457, val_loss = 0.7935900688171387\n",
      "epoch n°2368 : train_loss = 2.081468105316162, val_loss = 0.7932792901992798\n",
      "epoch n°2369 : train_loss = 2.0748744010925293, val_loss = 0.7955030202865601\n",
      "epoch n°2370 : train_loss = 2.07934832572937, val_loss = 0.7966471314430237\n",
      "epoch n°2371 : train_loss = 2.07598876953125, val_loss = 0.7973648905754089\n",
      "epoch n°2372 : train_loss = 2.0748291015625, val_loss = 0.7981895804405212\n",
      "epoch n°2373 : train_loss = 2.0818986892700195, val_loss = 0.7917335629463196\n",
      "epoch n°2374 : train_loss = 2.067981481552124, val_loss = 0.797858715057373\n",
      "epoch n°2375 : train_loss = 2.0768091678619385, val_loss = 0.7940361499786377\n",
      "epoch n°2376 : train_loss = 2.0849013328552246, val_loss = 0.7934589385986328\n",
      "epoch n°2377 : train_loss = 2.073753833770752, val_loss = 0.7920893430709839\n",
      "epoch n°2378 : train_loss = 2.08178448677063, val_loss = 0.7925271987915039\n",
      "epoch n°2379 : train_loss = 2.0797410011291504, val_loss = 0.7976899147033691\n",
      "epoch n°2380 : train_loss = 2.070639133453369, val_loss = 0.7983891367912292\n",
      "epoch n°2381 : train_loss = 2.078289031982422, val_loss = 0.7912381887435913\n",
      "epoch n°2382 : train_loss = 2.074826955795288, val_loss = 0.7993862628936768\n",
      "epoch n°2383 : train_loss = 2.0784552097320557, val_loss = 0.796812117099762\n",
      "epoch n°2384 : train_loss = 2.0769896507263184, val_loss = 0.793320894241333\n",
      "epoch n°2385 : train_loss = 2.0789990425109863, val_loss = 0.7930627465248108\n",
      "epoch n°2386 : train_loss = 2.0735721588134766, val_loss = 0.7968480587005615\n",
      "epoch n°2387 : train_loss = 2.071486234664917, val_loss = 0.7968699932098389\n",
      "epoch n°2388 : train_loss = 2.0795722007751465, val_loss = 0.7925510406494141\n",
      "epoch n°2389 : train_loss = 2.0720627307891846, val_loss = 0.794602632522583\n",
      "epoch n°2390 : train_loss = 2.06951904296875, val_loss = 0.7924901843070984\n",
      "epoch n°2391 : train_loss = 2.081338882446289, val_loss = 0.7985085844993591\n",
      "epoch n°2392 : train_loss = 2.0747852325439453, val_loss = 0.7955008149147034\n",
      "epoch n°2393 : train_loss = 2.07747483253479, val_loss = 0.7917712330818176\n",
      "epoch n°2394 : train_loss = 2.0664327144622803, val_loss = 0.7959994673728943\n",
      "epoch n°2395 : train_loss = 2.0755629539489746, val_loss = 0.7953909635543823\n",
      "epoch n°2396 : train_loss = 2.0724620819091797, val_loss = 0.7940437197685242\n",
      "epoch n°2397 : train_loss = 2.064887285232544, val_loss = 0.7915527820587158\n",
      "epoch n°2398 : train_loss = 2.0744524002075195, val_loss = 0.800983726978302\n",
      "epoch n°2399 : train_loss = 2.0718178749084473, val_loss = 0.7950562834739685\n",
      "epoch n°2400 : train_loss = 2.086414098739624, val_loss = 0.7958359718322754\n",
      "epoch n°2401 : train_loss = 2.0799059867858887, val_loss = 0.7937098741531372\n",
      "epoch n°2402 : train_loss = 2.073046922683716, val_loss = 0.7970685958862305\n",
      "epoch n°2403 : train_loss = 2.08439564704895, val_loss = 0.7974656224250793\n",
      "epoch n°2404 : train_loss = 2.0765302181243896, val_loss = 0.7960831522941589\n",
      "epoch n°2405 : train_loss = 2.077239990234375, val_loss = 0.7912328839302063\n",
      "epoch n°2406 : train_loss = 2.075392246246338, val_loss = 0.7934578061103821\n",
      "epoch n°2407 : train_loss = 2.0715577602386475, val_loss = 0.795781672000885\n",
      "epoch n°2408 : train_loss = 2.076822519302368, val_loss = 0.7985000014305115\n",
      "epoch n°2409 : train_loss = 2.0692083835601807, val_loss = 0.795734703540802\n",
      "epoch n°2410 : train_loss = 2.078611135482788, val_loss = 0.7934063673019409\n",
      "epoch n°2411 : train_loss = 2.067868709564209, val_loss = 0.7927648425102234\n",
      "epoch n°2412 : train_loss = 2.0751171112060547, val_loss = 0.7943207621574402\n",
      "epoch n°2413 : train_loss = 2.0825300216674805, val_loss = 0.7962210178375244\n",
      "epoch n°2414 : train_loss = 2.0746474266052246, val_loss = 0.7984410524368286\n",
      "epoch n°2415 : train_loss = 2.07212495803833, val_loss = 0.7992610931396484\n",
      "epoch n°2416 : train_loss = 2.073352813720703, val_loss = 0.7978892922401428\n",
      "epoch n°2417 : train_loss = 2.0727219581604004, val_loss = 0.7946997880935669\n",
      "epoch n°2418 : train_loss = 2.0756049156188965, val_loss = 0.7975701093673706\n",
      "epoch n°2419 : train_loss = 2.075258731842041, val_loss = 0.7977966070175171\n",
      "epoch n°2420 : train_loss = 2.072188138961792, val_loss = 0.7928751111030579\n",
      "epoch n°2421 : train_loss = 2.0806450843811035, val_loss = 0.7949028015136719\n",
      "epoch n°2422 : train_loss = 2.0725324153900146, val_loss = 0.794597327709198\n",
      "epoch n°2423 : train_loss = 2.082340717315674, val_loss = 0.7943679094314575\n",
      "epoch n°2424 : train_loss = 2.070432186126709, val_loss = 0.7919718623161316\n",
      "epoch n°2425 : train_loss = 2.0789477825164795, val_loss = 0.796574592590332\n",
      "epoch n°2426 : train_loss = 2.073946237564087, val_loss = 0.7958053946495056\n",
      "epoch n°2427 : train_loss = 2.075852155685425, val_loss = 0.7950792908668518\n",
      "epoch n°2428 : train_loss = 2.082080125808716, val_loss = 0.7984302639961243\n",
      "epoch n°2429 : train_loss = 2.0678465366363525, val_loss = 0.7937734723091125\n",
      "epoch n°2430 : train_loss = 2.0785505771636963, val_loss = 0.7924671769142151\n",
      "epoch n°2431 : train_loss = 2.0779998302459717, val_loss = 0.7979333400726318\n",
      "epoch n°2432 : train_loss = 2.077218532562256, val_loss = 0.7953246235847473\n",
      "epoch n°2433 : train_loss = 2.0764145851135254, val_loss = 0.7956897020339966\n",
      "epoch n°2434 : train_loss = 2.0802929401397705, val_loss = 0.7972722053527832\n",
      "epoch n°2435 : train_loss = 2.081416368484497, val_loss = 0.7963519096374512\n",
      "epoch n°2436 : train_loss = 2.0733230113983154, val_loss = 0.79593825340271\n",
      "epoch n°2437 : train_loss = 2.07106876373291, val_loss = 0.7954202890396118\n",
      "epoch n°2438 : train_loss = 2.0625462532043457, val_loss = 0.7936989068984985\n",
      "epoch n°2439 : train_loss = 2.0754129886627197, val_loss = 0.7969975471496582\n",
      "epoch n°2440 : train_loss = 2.070343494415283, val_loss = 0.7971809506416321\n",
      "epoch n°2441 : train_loss = 2.076914072036743, val_loss = 0.7967526316642761\n",
      "epoch n°2442 : train_loss = 2.0756990909576416, val_loss = 0.7943530678749084\n",
      "epoch n°2443 : train_loss = 2.0805118083953857, val_loss = 0.7937295436859131\n",
      "epoch n°2444 : train_loss = 2.080531597137451, val_loss = 0.7895359992980957\n",
      "epoch n°2445 : train_loss = 2.0747950077056885, val_loss = 0.7958065867424011\n",
      "epoch n°2446 : train_loss = 2.074125051498413, val_loss = 0.7951630353927612\n",
      "epoch n°2447 : train_loss = 2.072828769683838, val_loss = 0.7960901856422424\n",
      "epoch n°2448 : train_loss = 2.0730979442596436, val_loss = 0.7949947714805603\n",
      "epoch n°2449 : train_loss = 2.0754730701446533, val_loss = 0.7981618642807007\n",
      "epoch n°2450 : train_loss = 2.070915937423706, val_loss = 0.7968323826789856\n",
      "epoch n°2451 : train_loss = 2.0710628032684326, val_loss = 0.7962983250617981\n",
      "epoch n°2452 : train_loss = 2.065474271774292, val_loss = 0.7951444387435913\n",
      "epoch n°2453 : train_loss = 2.0770602226257324, val_loss = 0.7928726673126221\n",
      "epoch n°2454 : train_loss = 2.0679540634155273, val_loss = 0.7961304187774658\n",
      "epoch n°2455 : train_loss = 2.07800555229187, val_loss = 0.7930452227592468\n",
      "epoch n°2456 : train_loss = 2.075270891189575, val_loss = 0.7954300045967102\n",
      "epoch n°2457 : train_loss = 2.076913833618164, val_loss = 0.7980737090110779\n",
      "epoch n°2458 : train_loss = 2.0671987533569336, val_loss = 0.7940158247947693\n",
      "epoch n°2459 : train_loss = 2.076385259628296, val_loss = 0.7947037816047668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°2460 : train_loss = 2.0771753787994385, val_loss = 0.7974385619163513\n",
      "epoch n°2461 : train_loss = 2.068376064300537, val_loss = 0.7905205488204956\n",
      "epoch n°2462 : train_loss = 2.0702261924743652, val_loss = 0.7956539392471313\n",
      "epoch n°2463 : train_loss = 2.0686655044555664, val_loss = 0.7981555461883545\n",
      "epoch n°2464 : train_loss = 2.072016716003418, val_loss = 0.7933168411254883\n",
      "epoch n°2465 : train_loss = 2.076005220413208, val_loss = 0.7985706329345703\n",
      "epoch n°2466 : train_loss = 2.0703916549682617, val_loss = 0.7917314767837524\n",
      "epoch n°2467 : train_loss = 2.0780584812164307, val_loss = 0.7924384474754333\n",
      "epoch n°2468 : train_loss = 2.0728657245635986, val_loss = 0.7935881018638611\n",
      "epoch n°2469 : train_loss = 2.0756149291992188, val_loss = 0.7981774210929871\n",
      "epoch n°2470 : train_loss = 2.0790607929229736, val_loss = 0.7906035780906677\n",
      "epoch n°2471 : train_loss = 2.0674915313720703, val_loss = 0.7933405637741089\n",
      "epoch n°2472 : train_loss = 2.0763349533081055, val_loss = 0.7949090003967285\n",
      "epoch n°2473 : train_loss = 2.0627362728118896, val_loss = 0.7936904430389404\n",
      "epoch n°2474 : train_loss = 2.0662970542907715, val_loss = 0.7906147837638855\n",
      "epoch n°2475 : train_loss = 2.0726993083953857, val_loss = 0.7910510301589966\n",
      "epoch n°2476 : train_loss = 2.0750911235809326, val_loss = 0.7919752597808838\n",
      "epoch n°2477 : train_loss = 2.07901668548584, val_loss = 0.7905761003494263\n",
      "epoch n°2478 : train_loss = 2.0682332515716553, val_loss = 0.7954933643341064\n",
      "epoch n°2479 : train_loss = 2.073516368865967, val_loss = 0.7996017932891846\n",
      "epoch n°2480 : train_loss = 2.0772557258605957, val_loss = 0.7926767468452454\n",
      "epoch n°2481 : train_loss = 2.074619770050049, val_loss = 0.800422728061676\n",
      "epoch n°2482 : train_loss = 2.071991205215454, val_loss = 0.793394148349762\n",
      "epoch n°2483 : train_loss = 2.069237232208252, val_loss = 0.7965800762176514\n",
      "epoch n°2484 : train_loss = 2.066195249557495, val_loss = 0.7975620627403259\n",
      "epoch n°2485 : train_loss = 2.078900098800659, val_loss = 0.7917676568031311\n",
      "epoch n°2486 : train_loss = 2.0721395015716553, val_loss = 0.7953755259513855\n",
      "epoch n°2487 : train_loss = 2.068142890930176, val_loss = 0.7906139492988586\n",
      "epoch n°2488 : train_loss = 2.0757579803466797, val_loss = 0.7985629439353943\n",
      "epoch n°2489 : train_loss = 2.0768516063690186, val_loss = 0.7918379306793213\n",
      "epoch n°2490 : train_loss = 2.0709228515625, val_loss = 0.795072078704834\n",
      "epoch n°2491 : train_loss = 2.074570417404175, val_loss = 0.7957441806793213\n",
      "epoch n°2492 : train_loss = 2.073765754699707, val_loss = 0.8000888824462891\n",
      "epoch n°2493 : train_loss = 2.0693726539611816, val_loss = 0.794795572757721\n",
      "epoch n°2494 : train_loss = 2.0735602378845215, val_loss = 0.7956814765930176\n",
      "epoch n°2495 : train_loss = 2.0721137523651123, val_loss = 0.7935248017311096\n",
      "epoch n°2496 : train_loss = 2.0705819129943848, val_loss = 0.7968717813491821\n",
      "epoch n°2497 : train_loss = 2.072695016860962, val_loss = 0.791405439376831\n",
      "epoch n°2498 : train_loss = 2.066215991973877, val_loss = 0.7968605756759644\n",
      "epoch n°2499 : train_loss = 2.0779435634613037, val_loss = 0.7949302792549133\n",
      "epoch n°2500 : train_loss = 2.0826303958892822, val_loss = 0.7945833802223206\n",
      "epoch n°2501 : train_loss = 2.0796101093292236, val_loss = 0.7966699004173279\n",
      "epoch n°2502 : train_loss = 2.0752153396606445, val_loss = 0.7945549488067627\n",
      "epoch n°2503 : train_loss = 2.0761218070983887, val_loss = 0.7938224673271179\n",
      "epoch n°2504 : train_loss = 2.075127124786377, val_loss = 0.7968400716781616\n",
      "epoch n°2505 : train_loss = 2.0696139335632324, val_loss = 0.7946422696113586\n",
      "epoch n°2506 : train_loss = 2.0733489990234375, val_loss = 0.7954827547073364\n",
      "epoch n°2507 : train_loss = 2.074021577835083, val_loss = 0.7936232686042786\n",
      "epoch n°2508 : train_loss = 2.060635805130005, val_loss = 0.7902715802192688\n",
      "epoch n°2509 : train_loss = 2.077341079711914, val_loss = 0.7957170009613037\n",
      "epoch n°2510 : train_loss = 2.067779064178467, val_loss = 0.7945190072059631\n",
      "epoch n°2511 : train_loss = 2.077270030975342, val_loss = 0.792502760887146\n",
      "epoch n°2512 : train_loss = 2.0709779262542725, val_loss = 0.7960231900215149\n",
      "epoch n°2513 : train_loss = 2.0867085456848145, val_loss = 0.7962969541549683\n",
      "epoch n°2514 : train_loss = 2.0646464824676514, val_loss = 0.7984534502029419\n",
      "epoch n°2515 : train_loss = 2.06207537651062, val_loss = 0.7956771850585938\n",
      "epoch n°2516 : train_loss = 2.08215069770813, val_loss = 0.7978801727294922\n",
      "epoch n°2517 : train_loss = 2.0787155628204346, val_loss = 0.7956992983818054\n",
      "epoch n°2518 : train_loss = 2.076930284500122, val_loss = 0.7935121059417725\n",
      "epoch n°2519 : train_loss = 2.065523862838745, val_loss = 0.7959403395652771\n",
      "epoch n°2520 : train_loss = 2.069927930831909, val_loss = 0.7918150424957275\n",
      "epoch n°2521 : train_loss = 2.072309732437134, val_loss = 0.795480489730835\n",
      "epoch n°2522 : train_loss = 2.0757298469543457, val_loss = 0.7933221459388733\n",
      "epoch n°2523 : train_loss = 2.064173936843872, val_loss = 0.7956657409667969\n",
      "epoch n°2524 : train_loss = 2.0712525844573975, val_loss = 0.7961193919181824\n",
      "epoch n°2525 : train_loss = 2.076547861099243, val_loss = 0.7957857251167297\n",
      "epoch n°2526 : train_loss = 2.066349983215332, val_loss = 0.7930822372436523\n",
      "epoch n°2527 : train_loss = 2.0732619762420654, val_loss = 0.7965076565742493\n",
      "epoch n°2528 : train_loss = 2.070222854614258, val_loss = 0.7945336103439331\n",
      "epoch n°2529 : train_loss = 2.0676283836364746, val_loss = 0.7960686683654785\n",
      "epoch n°2530 : train_loss = 2.077988386154175, val_loss = 0.7957895398139954\n",
      "epoch n°2531 : train_loss = 2.0778212547302246, val_loss = 0.7919972538948059\n",
      "epoch n°2532 : train_loss = 2.069342851638794, val_loss = 0.7933862209320068\n",
      "epoch n°2533 : train_loss = 2.0627639293670654, val_loss = 0.7952864170074463\n",
      "epoch n°2534 : train_loss = 2.055516004562378, val_loss = 0.7945136427879333\n",
      "epoch n°2535 : train_loss = 2.0669610500335693, val_loss = 0.7941370010375977\n",
      "epoch n°2536 : train_loss = 2.072476863861084, val_loss = 0.7938616871833801\n",
      "epoch n°2537 : train_loss = 2.072162628173828, val_loss = 0.7971687912940979\n",
      "epoch n°2538 : train_loss = 2.056537628173828, val_loss = 0.7957470417022705\n",
      "epoch n°2539 : train_loss = 2.0677425861358643, val_loss = 0.7893447875976562\n",
      "epoch n°2540 : train_loss = 2.0739405155181885, val_loss = 0.7928095459938049\n",
      "epoch n°2541 : train_loss = 2.073986768722534, val_loss = 0.7956611514091492\n",
      "epoch n°2542 : train_loss = 2.0650229454040527, val_loss = 0.7928333282470703\n",
      "epoch n°2543 : train_loss = 2.067837715148926, val_loss = 0.7930592894554138\n",
      "epoch n°2544 : train_loss = 2.072600841522217, val_loss = 0.7974372506141663\n",
      "epoch n°2545 : train_loss = 2.0642645359039307, val_loss = 0.7900339961051941\n",
      "epoch n°2546 : train_loss = 2.071743965148926, val_loss = 0.7878211140632629\n",
      "epoch n°2547 : train_loss = 2.0736031532287598, val_loss = 0.7914679050445557\n",
      "epoch n°2548 : train_loss = 2.07207989692688, val_loss = 0.7977248430252075\n",
      "epoch n°2549 : train_loss = 2.0626626014709473, val_loss = 0.7961580157279968\n",
      "epoch n°2550 : train_loss = 2.066999673843384, val_loss = 0.7949120402336121\n",
      "epoch n°2551 : train_loss = 2.0747976303100586, val_loss = 0.7983630299568176\n",
      "epoch n°2552 : train_loss = 2.0727455615997314, val_loss = 0.7940677404403687\n",
      "epoch n°2553 : train_loss = 2.0745913982391357, val_loss = 0.8041991591453552\n",
      "epoch n°2554 : train_loss = 2.0740416049957275, val_loss = 0.7956171631813049\n",
      "epoch n°2555 : train_loss = 2.071716785430908, val_loss = 0.7985125780105591\n",
      "epoch n°2556 : train_loss = 2.068208694458008, val_loss = 0.7907739281654358\n",
      "epoch n°2557 : train_loss = 2.07857608795166, val_loss = 0.7939580678939819\n",
      "epoch n°2558 : train_loss = 2.0736117362976074, val_loss = 0.7927968502044678\n",
      "epoch n°2559 : train_loss = 2.0674402713775635, val_loss = 0.7911421060562134\n",
      "epoch n°2560 : train_loss = 2.061213493347168, val_loss = 0.7934168577194214\n",
      "epoch n°2561 : train_loss = 2.0704715251922607, val_loss = 0.7961546778678894\n",
      "epoch n°2562 : train_loss = 2.0655863285064697, val_loss = 0.7932080626487732\n",
      "epoch n°2563 : train_loss = 2.0744946002960205, val_loss = 0.7933704853057861\n",
      "epoch n°2564 : train_loss = 2.07779598236084, val_loss = 0.7918423414230347\n",
      "epoch n°2565 : train_loss = 2.063052177429199, val_loss = 0.7934448719024658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°2566 : train_loss = 2.062581777572632, val_loss = 0.7958925366401672\n",
      "epoch n°2567 : train_loss = 2.0672428607940674, val_loss = 0.7950834035873413\n",
      "epoch n°2568 : train_loss = 2.0619513988494873, val_loss = 0.8018878102302551\n",
      "epoch n°2569 : train_loss = 2.06235408782959, val_loss = 0.7915725708007812\n",
      "epoch n°2570 : train_loss = 2.0675909519195557, val_loss = 0.7968552112579346\n",
      "epoch n°2571 : train_loss = 2.0710771083831787, val_loss = 0.7924591302871704\n",
      "epoch n°2572 : train_loss = 2.0630412101745605, val_loss = 0.794274091720581\n",
      "epoch n°2573 : train_loss = 2.065228223800659, val_loss = 0.8001793622970581\n",
      "epoch n°2574 : train_loss = 2.0637123584747314, val_loss = 0.7958373427391052\n",
      "epoch n°2575 : train_loss = 2.0672237873077393, val_loss = 0.7990629076957703\n",
      "epoch n°2576 : train_loss = 2.066303014755249, val_loss = 0.7980601787567139\n",
      "epoch n°2577 : train_loss = 2.067595958709717, val_loss = 0.7987068295478821\n",
      "epoch n°2578 : train_loss = 2.0656466484069824, val_loss = 0.7991995811462402\n",
      "epoch n°2579 : train_loss = 2.0727365016937256, val_loss = 0.7883133888244629\n",
      "epoch n°2580 : train_loss = 2.0593302249908447, val_loss = 0.7949204444885254\n",
      "epoch n°2581 : train_loss = 2.0711309909820557, val_loss = 0.7932716608047485\n",
      "epoch n°2582 : train_loss = 2.067521333694458, val_loss = 0.7994311451911926\n",
      "epoch n°2583 : train_loss = 2.0793142318725586, val_loss = 0.7989097237586975\n",
      "epoch n°2584 : train_loss = 2.0589828491210938, val_loss = 0.7942928075790405\n",
      "epoch n°2585 : train_loss = 2.0702292919158936, val_loss = 0.7941436171531677\n",
      "epoch n°2586 : train_loss = 2.0662741661071777, val_loss = 0.7922727465629578\n",
      "epoch n°2587 : train_loss = 2.07165265083313, val_loss = 0.7946866154670715\n",
      "epoch n°2588 : train_loss = 2.06585431098938, val_loss = 0.7949528694152832\n",
      "epoch n°2589 : train_loss = 2.0707132816314697, val_loss = 0.7953113913536072\n",
      "epoch n°2590 : train_loss = 2.0767934322357178, val_loss = 0.7912693619728088\n",
      "epoch n°2591 : train_loss = 2.0685110092163086, val_loss = 0.789614200592041\n",
      "epoch n°2592 : train_loss = 2.072876453399658, val_loss = 0.7940589785575867\n",
      "epoch n°2593 : train_loss = 2.0786664485931396, val_loss = 0.7955416440963745\n",
      "epoch n°2594 : train_loss = 2.0682077407836914, val_loss = 0.7934612035751343\n",
      "epoch n°2595 : train_loss = 2.0686492919921875, val_loss = 0.7932373881340027\n",
      "epoch n°2596 : train_loss = 2.0638294219970703, val_loss = 0.7920255661010742\n",
      "epoch n°2597 : train_loss = 2.0771586894989014, val_loss = 0.7953469753265381\n",
      "epoch n°2598 : train_loss = 2.063354253768921, val_loss = 0.7965201139450073\n",
      "epoch n°2599 : train_loss = 2.069587230682373, val_loss = 0.794612467288971\n",
      "epoch n°2600 : train_loss = 2.0760676860809326, val_loss = 0.7925875186920166\n",
      "epoch n°2601 : train_loss = 2.07448410987854, val_loss = 0.7975175380706787\n",
      "epoch n°2602 : train_loss = 2.0717358589172363, val_loss = 0.7974472045898438\n",
      "epoch n°2603 : train_loss = 2.0684568881988525, val_loss = 0.7978623509407043\n",
      "epoch n°2604 : train_loss = 2.058285713195801, val_loss = 0.791800320148468\n",
      "epoch n°2605 : train_loss = 2.07206392288208, val_loss = 0.7962352633476257\n",
      "epoch n°2606 : train_loss = 2.068791627883911, val_loss = 0.7935148477554321\n",
      "epoch n°2607 : train_loss = 2.0735268592834473, val_loss = 0.7935965061187744\n",
      "epoch n°2608 : train_loss = 2.067554235458374, val_loss = 0.7938491702079773\n",
      "epoch n°2609 : train_loss = 2.073580741882324, val_loss = 0.7987203001976013\n",
      "epoch n°2610 : train_loss = 2.0616962909698486, val_loss = 0.7939358949661255\n",
      "epoch n°2611 : train_loss = 2.0642447471618652, val_loss = 0.7968023419380188\n",
      "epoch n°2612 : train_loss = 2.0653228759765625, val_loss = 0.7961790561676025\n",
      "epoch n°2613 : train_loss = 2.0687179565429688, val_loss = 0.8001986145973206\n",
      "epoch n°2614 : train_loss = 2.068342447280884, val_loss = 0.7956491708755493\n",
      "epoch n°2615 : train_loss = 2.0723233222961426, val_loss = 0.8003463745117188\n",
      "epoch n°2616 : train_loss = 2.058633327484131, val_loss = 0.798027515411377\n",
      "epoch n°2617 : train_loss = 2.054462432861328, val_loss = 0.7938171625137329\n",
      "epoch n°2618 : train_loss = 2.0699071884155273, val_loss = 0.7956166863441467\n",
      "epoch n°2619 : train_loss = 2.068380117416382, val_loss = 0.7926813960075378\n",
      "epoch n°2620 : train_loss = 2.076350450515747, val_loss = 0.7948583960533142\n",
      "epoch n°2621 : train_loss = 2.0623207092285156, val_loss = 0.7966415882110596\n",
      "epoch n°2622 : train_loss = 2.0650393962860107, val_loss = 0.793153703212738\n",
      "epoch n°2623 : train_loss = 2.061469554901123, val_loss = 0.7975717782974243\n",
      "epoch n°2624 : train_loss = 2.0590715408325195, val_loss = 0.801641583442688\n",
      "epoch n°2625 : train_loss = 2.069646120071411, val_loss = 0.7995805144309998\n",
      "epoch n°2626 : train_loss = 2.069845199584961, val_loss = 0.7978777885437012\n",
      "epoch n°2627 : train_loss = 2.0701801776885986, val_loss = 0.7937397956848145\n",
      "epoch n°2628 : train_loss = 2.0594589710235596, val_loss = 0.7954741716384888\n",
      "epoch n°2629 : train_loss = 2.064802646636963, val_loss = 0.7949013710021973\n",
      "epoch n°2630 : train_loss = 2.0672049522399902, val_loss = 0.7928406596183777\n",
      "epoch n°2631 : train_loss = 2.06585955619812, val_loss = 0.7993409037590027\n",
      "epoch n°2632 : train_loss = 2.069735288619995, val_loss = 0.7965067028999329\n",
      "epoch n°2633 : train_loss = 2.0714969635009766, val_loss = 0.7915460467338562\n",
      "epoch n°2634 : train_loss = 2.0662262439727783, val_loss = 0.7932748794555664\n",
      "epoch n°2635 : train_loss = 2.067688226699829, val_loss = 0.7905950546264648\n",
      "epoch n°2636 : train_loss = 2.0652201175689697, val_loss = 0.7953696250915527\n",
      "epoch n°2637 : train_loss = 2.0656416416168213, val_loss = 0.7957215309143066\n",
      "epoch n°2638 : train_loss = 2.0603203773498535, val_loss = 0.7955951690673828\n",
      "epoch n°2639 : train_loss = 2.0652377605438232, val_loss = 0.7939067482948303\n",
      "epoch n°2640 : train_loss = 2.0696823596954346, val_loss = 0.794331967830658\n",
      "epoch n°2641 : train_loss = 2.0605952739715576, val_loss = 0.7925287485122681\n",
      "epoch n°2642 : train_loss = 2.071470260620117, val_loss = 0.7963451147079468\n",
      "epoch n°2643 : train_loss = 2.068795919418335, val_loss = 0.7919399738311768\n",
      "epoch n°2644 : train_loss = 2.062487840652466, val_loss = 0.7959246635437012\n",
      "epoch n°2645 : train_loss = 2.074951648712158, val_loss = 0.7928428053855896\n",
      "epoch n°2646 : train_loss = 2.058847665786743, val_loss = 0.7938872575759888\n",
      "epoch n°2647 : train_loss = 2.0598325729370117, val_loss = 0.7942687273025513\n",
      "epoch n°2648 : train_loss = 2.0701677799224854, val_loss = 0.7931576371192932\n",
      "epoch n°2649 : train_loss = 2.0590147972106934, val_loss = 0.7977278828620911\n",
      "epoch n°2650 : train_loss = 2.0657215118408203, val_loss = 0.7944495677947998\n",
      "epoch n°2651 : train_loss = 2.060944080352783, val_loss = 0.7934445142745972\n",
      "epoch n°2652 : train_loss = 2.067265748977661, val_loss = 0.792166531085968\n",
      "epoch n°2653 : train_loss = 2.0643863677978516, val_loss = 0.7921700477600098\n",
      "epoch n°2654 : train_loss = 2.065674304962158, val_loss = 0.7944614291191101\n",
      "epoch n°2655 : train_loss = 2.067077875137329, val_loss = 0.7961218357086182\n",
      "epoch n°2656 : train_loss = 2.066272735595703, val_loss = 0.7913459539413452\n",
      "epoch n°2657 : train_loss = 2.0529251098632812, val_loss = 0.7968665361404419\n",
      "epoch n°2658 : train_loss = 2.063915491104126, val_loss = 0.7972751259803772\n",
      "epoch n°2659 : train_loss = 2.058302640914917, val_loss = 0.7997499704360962\n",
      "epoch n°2660 : train_loss = 2.055048704147339, val_loss = 0.7954393029212952\n",
      "epoch n°2661 : train_loss = 2.0491783618927, val_loss = 0.7900480628013611\n",
      "epoch n°2662 : train_loss = 2.062314748764038, val_loss = 0.7919267416000366\n",
      "epoch n°2663 : train_loss = 2.062044143676758, val_loss = 0.7962722182273865\n",
      "epoch n°2664 : train_loss = 2.06160831451416, val_loss = 0.7929974794387817\n",
      "epoch n°2665 : train_loss = 2.0574660301208496, val_loss = 0.7989291548728943\n",
      "epoch n°2666 : train_loss = 2.0680181980133057, val_loss = 0.7957879900932312\n",
      "epoch n°2667 : train_loss = 2.0613958835601807, val_loss = 0.7961893081665039\n",
      "epoch n°2668 : train_loss = 2.0607450008392334, val_loss = 0.7938457131385803\n",
      "epoch n°2669 : train_loss = 2.066239833831787, val_loss = 0.7919025421142578\n",
      "epoch n°2670 : train_loss = 2.0644099712371826, val_loss = 0.7963550090789795\n",
      "epoch n°2671 : train_loss = 2.0641396045684814, val_loss = 0.7906436920166016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°2672 : train_loss = 2.067476987838745, val_loss = 0.7987282276153564\n",
      "epoch n°2673 : train_loss = 2.0590145587921143, val_loss = 0.7916828989982605\n",
      "epoch n°2674 : train_loss = 2.058492660522461, val_loss = 0.7931827306747437\n",
      "epoch n°2675 : train_loss = 2.0639686584472656, val_loss = 0.7932569980621338\n",
      "epoch n°2676 : train_loss = 2.060399055480957, val_loss = 0.7952693700790405\n",
      "epoch n°2677 : train_loss = 2.0497164726257324, val_loss = 0.7937905788421631\n",
      "epoch n°2678 : train_loss = 2.0587716102600098, val_loss = 0.7951778173446655\n",
      "epoch n°2679 : train_loss = 2.0672085285186768, val_loss = 0.7937468886375427\n",
      "epoch n°2680 : train_loss = 2.069793462753296, val_loss = 0.7865792512893677\n",
      "epoch n°2681 : train_loss = 2.06154465675354, val_loss = 0.7893362641334534\n",
      "epoch n°2682 : train_loss = 2.063958168029785, val_loss = 0.7979415059089661\n",
      "epoch n°2683 : train_loss = 2.0671226978302, val_loss = 0.7968992590904236\n",
      "epoch n°2684 : train_loss = 2.0633697509765625, val_loss = 0.7904786467552185\n",
      "epoch n°2685 : train_loss = 2.060239315032959, val_loss = 0.7923539280891418\n",
      "epoch n°2686 : train_loss = 2.0637366771698, val_loss = 0.7950439453125\n",
      "epoch n°2687 : train_loss = 2.070767402648926, val_loss = 0.7965174317359924\n",
      "epoch n°2688 : train_loss = 2.060199022293091, val_loss = 0.7967772483825684\n",
      "epoch n°2689 : train_loss = 2.0647218227386475, val_loss = 0.7921722531318665\n",
      "epoch n°2690 : train_loss = 2.0615222454071045, val_loss = 0.7958952188491821\n",
      "epoch n°2691 : train_loss = 2.0592517852783203, val_loss = 0.7923828363418579\n",
      "epoch n°2692 : train_loss = 2.057831048965454, val_loss = 0.7964440584182739\n",
      "epoch n°2693 : train_loss = 2.060286045074463, val_loss = 0.79252028465271\n",
      "epoch n°2694 : train_loss = 2.060833692550659, val_loss = 0.7925747632980347\n",
      "epoch n°2695 : train_loss = 2.0659947395324707, val_loss = 0.7970483899116516\n",
      "epoch n°2696 : train_loss = 2.0602047443389893, val_loss = 0.7946254014968872\n",
      "epoch n°2697 : train_loss = 2.057645559310913, val_loss = 0.7952149510383606\n",
      "epoch n°2698 : train_loss = 2.0717880725860596, val_loss = 0.7951154112815857\n",
      "epoch n°2699 : train_loss = 2.0637433528900146, val_loss = 0.7892244458198547\n",
      "epoch n°2700 : train_loss = 2.0618345737457275, val_loss = 0.7892919182777405\n",
      "epoch n°2701 : train_loss = 2.0643246173858643, val_loss = 0.7946117520332336\n",
      "epoch n°2702 : train_loss = 2.053589344024658, val_loss = 0.7986019253730774\n",
      "epoch n°2703 : train_loss = 2.0548603534698486, val_loss = 0.7941280603408813\n",
      "epoch n°2704 : train_loss = 2.0653092861175537, val_loss = 0.7957948446273804\n",
      "epoch n°2705 : train_loss = 2.0644819736480713, val_loss = 0.7927531599998474\n",
      "epoch n°2706 : train_loss = 2.0634732246398926, val_loss = 0.797112762928009\n",
      "epoch n°2707 : train_loss = 2.0617480278015137, val_loss = 0.7930631637573242\n",
      "epoch n°2708 : train_loss = 2.0683236122131348, val_loss = 0.7938370704650879\n",
      "epoch n°2709 : train_loss = 2.051079750061035, val_loss = 0.79496830701828\n",
      "epoch n°2710 : train_loss = 2.0633318424224854, val_loss = 0.7939152717590332\n",
      "epoch n°2711 : train_loss = 2.062366247177124, val_loss = 0.7948245406150818\n",
      "epoch n°2712 : train_loss = 2.0624797344207764, val_loss = 0.7963151335716248\n",
      "epoch n°2713 : train_loss = 2.0554726123809814, val_loss = 0.7936174273490906\n",
      "epoch n°2714 : train_loss = 2.059507131576538, val_loss = 0.7947840690612793\n",
      "epoch n°2715 : train_loss = 2.0637781620025635, val_loss = 0.7965659499168396\n",
      "epoch n°2716 : train_loss = 2.057464361190796, val_loss = 0.7935777306556702\n",
      "epoch n°2717 : train_loss = 2.0579686164855957, val_loss = 0.7927667498588562\n",
      "epoch n°2718 : train_loss = 2.0581698417663574, val_loss = 0.7858638763427734\n",
      "epoch n°2719 : train_loss = 2.0556282997131348, val_loss = 0.7974013090133667\n",
      "epoch n°2720 : train_loss = 2.051851987838745, val_loss = 0.7975142002105713\n",
      "epoch n°2721 : train_loss = 2.065778970718384, val_loss = 0.793964684009552\n",
      "epoch n°2722 : train_loss = 2.070960521697998, val_loss = 0.7939854860305786\n",
      "epoch n°2723 : train_loss = 2.0607690811157227, val_loss = 0.7962473034858704\n",
      "epoch n°2724 : train_loss = 2.0663487911224365, val_loss = 0.7945556044578552\n",
      "epoch n°2725 : train_loss = 2.059905529022217, val_loss = 0.7939093112945557\n",
      "epoch n°2726 : train_loss = 2.0722224712371826, val_loss = 0.7938578724861145\n",
      "epoch n°2727 : train_loss = 2.062711477279663, val_loss = 0.7943560481071472\n",
      "epoch n°2728 : train_loss = 2.0571858882904053, val_loss = 0.7928754687309265\n",
      "epoch n°2729 : train_loss = 2.05344820022583, val_loss = 0.7936033010482788\n",
      "epoch n°2730 : train_loss = 2.0594680309295654, val_loss = 0.7966788411140442\n",
      "epoch n°2731 : train_loss = 2.0642664432525635, val_loss = 0.7962746024131775\n",
      "epoch n°2732 : train_loss = 2.0601446628570557, val_loss = 0.7944862842559814\n",
      "epoch n°2733 : train_loss = 2.058668851852417, val_loss = 0.7935258150100708\n",
      "epoch n°2734 : train_loss = 2.053475856781006, val_loss = 0.797691285610199\n",
      "epoch n°2735 : train_loss = 2.0670320987701416, val_loss = 0.7928742170333862\n",
      "epoch n°2736 : train_loss = 2.0616953372955322, val_loss = 0.7933673858642578\n",
      "epoch n°2737 : train_loss = 2.064039945602417, val_loss = 0.7921473383903503\n",
      "epoch n°2738 : train_loss = 2.0596091747283936, val_loss = 0.7933192253112793\n",
      "epoch n°2739 : train_loss = 2.0561981201171875, val_loss = 0.7963529825210571\n",
      "epoch n°2740 : train_loss = 2.0556674003601074, val_loss = 0.7941141724586487\n",
      "epoch n°2741 : train_loss = 2.054081678390503, val_loss = 0.7976027727127075\n",
      "epoch n°2742 : train_loss = 2.06661319732666, val_loss = 0.7946788668632507\n",
      "epoch n°2743 : train_loss = 2.0561506748199463, val_loss = 0.7937820553779602\n",
      "epoch n°2744 : train_loss = 2.0590598583221436, val_loss = 0.7909948229789734\n",
      "epoch n°2745 : train_loss = 2.056772470474243, val_loss = 0.795450747013092\n",
      "epoch n°2746 : train_loss = 2.0605814456939697, val_loss = 0.7929077744483948\n",
      "epoch n°2747 : train_loss = 2.0542871952056885, val_loss = 0.7980620861053467\n",
      "epoch n°2748 : train_loss = 2.060439109802246, val_loss = 0.7950196266174316\n",
      "epoch n°2749 : train_loss = 2.0584676265716553, val_loss = 0.7934096455574036\n",
      "epoch n°2750 : train_loss = 2.0598435401916504, val_loss = 0.7985443472862244\n",
      "epoch n°2751 : train_loss = 2.063377618789673, val_loss = 0.7920820116996765\n",
      "epoch n°2752 : train_loss = 2.053212881088257, val_loss = 0.7917662858963013\n",
      "epoch n°2753 : train_loss = 2.056591033935547, val_loss = 0.7996566295623779\n",
      "epoch n°2754 : train_loss = 2.0574426651000977, val_loss = 0.7954739332199097\n",
      "epoch n°2755 : train_loss = 2.059234857559204, val_loss = 0.7954863905906677\n",
      "epoch n°2756 : train_loss = 2.0697381496429443, val_loss = 0.7936476469039917\n",
      "epoch n°2757 : train_loss = 2.060194730758667, val_loss = 0.7942577600479126\n",
      "epoch n°2758 : train_loss = 2.070478916168213, val_loss = 0.7935187816619873\n",
      "epoch n°2759 : train_loss = 2.067697525024414, val_loss = 0.7953112125396729\n",
      "epoch n°2760 : train_loss = 2.065882444381714, val_loss = 0.7929869294166565\n",
      "epoch n°2761 : train_loss = 2.0595433712005615, val_loss = 0.7966063022613525\n",
      "epoch n°2762 : train_loss = 2.0622620582580566, val_loss = 0.7979762554168701\n",
      "epoch n°2763 : train_loss = 2.056447744369507, val_loss = 0.7950707674026489\n",
      "epoch n°2764 : train_loss = 2.0659596920013428, val_loss = 0.7962853908538818\n",
      "epoch n°2765 : train_loss = 2.0589759349823, val_loss = 0.7950619459152222\n",
      "epoch n°2766 : train_loss = 2.054356813430786, val_loss = 0.7934632897377014\n",
      "epoch n°2767 : train_loss = 2.0608644485473633, val_loss = 0.802057683467865\n",
      "epoch n°2768 : train_loss = 2.0642802715301514, val_loss = 0.793124258518219\n",
      "epoch n°2769 : train_loss = 2.063782215118408, val_loss = 0.7969582080841064\n",
      "epoch n°2770 : train_loss = 2.064195156097412, val_loss = 0.7920823693275452\n",
      "epoch n°2771 : train_loss = 2.062809944152832, val_loss = 0.7936012744903564\n",
      "epoch n°2772 : train_loss = 2.0604031085968018, val_loss = 0.7944956421852112\n",
      "epoch n°2773 : train_loss = 2.064059019088745, val_loss = 0.7917082905769348\n",
      "epoch n°2774 : train_loss = 2.0692832469940186, val_loss = 0.7977326512336731\n",
      "epoch n°2775 : train_loss = 2.061297655105591, val_loss = 0.7919238805770874\n",
      "epoch n°2776 : train_loss = 2.0643012523651123, val_loss = 0.7953721880912781\n",
      "epoch n°2777 : train_loss = 2.0610969066619873, val_loss = 0.7939029335975647\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°2778 : train_loss = 2.0581424236297607, val_loss = 0.791713297367096\n",
      "epoch n°2779 : train_loss = 2.0649468898773193, val_loss = 0.793591320514679\n",
      "epoch n°2780 : train_loss = 2.04803729057312, val_loss = 0.7946167588233948\n",
      "epoch n°2781 : train_loss = 2.0623667240142822, val_loss = 0.793396532535553\n",
      "epoch n°2782 : train_loss = 2.060593843460083, val_loss = 0.7937297224998474\n",
      "epoch n°2783 : train_loss = 2.061028003692627, val_loss = 0.7939335703849792\n",
      "epoch n°2784 : train_loss = 2.054239511489868, val_loss = 0.7976046800613403\n",
      "epoch n°2785 : train_loss = 2.0586798191070557, val_loss = 0.7903836369514465\n",
      "epoch n°2786 : train_loss = 2.0632996559143066, val_loss = 0.7923145890235901\n",
      "epoch n°2787 : train_loss = 2.0629591941833496, val_loss = 0.7924433350563049\n",
      "epoch n°2788 : train_loss = 2.0579333305358887, val_loss = 0.7932413816452026\n",
      "epoch n°2789 : train_loss = 2.0546865463256836, val_loss = 0.7989276051521301\n",
      "epoch n°2790 : train_loss = 2.0533363819122314, val_loss = 0.7992241978645325\n",
      "epoch n°2791 : train_loss = 2.0569746494293213, val_loss = 0.7911809682846069\n",
      "epoch n°2792 : train_loss = 2.051893472671509, val_loss = 0.7982956767082214\n",
      "epoch n°2793 : train_loss = 2.0631654262542725, val_loss = 0.7978973388671875\n",
      "epoch n°2794 : train_loss = 2.0591344833374023, val_loss = 0.7892988324165344\n",
      "epoch n°2795 : train_loss = 2.056906223297119, val_loss = 0.7963985800743103\n",
      "epoch n°2796 : train_loss = 2.0544795989990234, val_loss = 0.7983325719833374\n",
      "epoch n°2797 : train_loss = 2.058933734893799, val_loss = 0.7962036728858948\n",
      "epoch n°2798 : train_loss = 2.0550618171691895, val_loss = 0.7911902070045471\n",
      "epoch n°2799 : train_loss = 2.0546929836273193, val_loss = 0.7963922023773193\n",
      "epoch n°2800 : train_loss = 2.0601718425750732, val_loss = 0.7958956360816956\n",
      "epoch n°2801 : train_loss = 2.0722203254699707, val_loss = 0.7936334013938904\n",
      "epoch n°2802 : train_loss = 2.0672593116760254, val_loss = 0.7917220592498779\n",
      "epoch n°2803 : train_loss = 2.05139422416687, val_loss = 0.792595386505127\n",
      "epoch n°2804 : train_loss = 2.056000232696533, val_loss = 0.7936901450157166\n",
      "epoch n°2805 : train_loss = 2.0640206336975098, val_loss = 0.7931267619132996\n",
      "epoch n°2806 : train_loss = 2.058212995529175, val_loss = 0.7944007515907288\n",
      "epoch n°2807 : train_loss = 2.0570766925811768, val_loss = 0.7927480340003967\n",
      "epoch n°2808 : train_loss = 2.0567398071289062, val_loss = 0.7917108535766602\n",
      "epoch n°2809 : train_loss = 2.05967378616333, val_loss = 0.7945478558540344\n",
      "epoch n°2810 : train_loss = 2.059103488922119, val_loss = 0.7968318462371826\n",
      "epoch n°2811 : train_loss = 2.0562760829925537, val_loss = 0.7904819250106812\n",
      "epoch n°2812 : train_loss = 2.051011323928833, val_loss = 0.7925263047218323\n",
      "epoch n°2813 : train_loss = 2.0629329681396484, val_loss = 0.7987425327301025\n",
      "epoch n°2814 : train_loss = 2.059762954711914, val_loss = 0.7967857718467712\n",
      "epoch n°2815 : train_loss = 2.052602529525757, val_loss = 0.7915742993354797\n",
      "epoch n°2816 : train_loss = 2.0618886947631836, val_loss = 0.7948591709136963\n",
      "epoch n°2817 : train_loss = 2.0555965900421143, val_loss = 0.7939220070838928\n",
      "epoch n°2818 : train_loss = 2.0595970153808594, val_loss = 0.7945793271064758\n",
      "epoch n°2819 : train_loss = 2.067728281021118, val_loss = 0.7976589798927307\n",
      "epoch n°2820 : train_loss = 2.0522289276123047, val_loss = 0.7916882634162903\n",
      "epoch n°2821 : train_loss = 2.052403211593628, val_loss = 0.7900058031082153\n",
      "epoch n°2822 : train_loss = 2.062655448913574, val_loss = 0.7956087589263916\n",
      "epoch n°2823 : train_loss = 2.060065269470215, val_loss = 0.7905800342559814\n",
      "epoch n°2824 : train_loss = 2.054696559906006, val_loss = 0.7957415580749512\n",
      "epoch n°2825 : train_loss = 2.0457136631011963, val_loss = 0.79282146692276\n",
      "epoch n°2826 : train_loss = 2.0513157844543457, val_loss = 0.7939226627349854\n",
      "epoch n°2827 : train_loss = 2.063598394393921, val_loss = 0.7970476150512695\n",
      "epoch n°2828 : train_loss = 2.0560293197631836, val_loss = 0.7946614623069763\n",
      "epoch n°2829 : train_loss = 2.0577781200408936, val_loss = 0.7956696152687073\n",
      "epoch n°2830 : train_loss = 2.051058530807495, val_loss = 0.7943645715713501\n",
      "epoch n°2831 : train_loss = 2.0584726333618164, val_loss = 0.792169988155365\n",
      "epoch n°2832 : train_loss = 2.0652859210968018, val_loss = 0.7941437363624573\n",
      "epoch n°2833 : train_loss = 2.053039073944092, val_loss = 0.7944256663322449\n",
      "epoch n°2834 : train_loss = 2.0548508167266846, val_loss = 0.7973548769950867\n",
      "epoch n°2835 : train_loss = 2.0508182048797607, val_loss = 0.7947467565536499\n",
      "epoch n°2836 : train_loss = 2.061788320541382, val_loss = 0.7954505681991577\n",
      "epoch n°2837 : train_loss = 2.056351900100708, val_loss = 0.7970765829086304\n",
      "epoch n°2838 : train_loss = 2.049032688140869, val_loss = 0.7924017310142517\n",
      "epoch n°2839 : train_loss = 2.0566070079803467, val_loss = 0.796875\n",
      "epoch n°2840 : train_loss = 2.05972957611084, val_loss = 0.7934831976890564\n",
      "epoch n°2841 : train_loss = 2.047527551651001, val_loss = 0.7918537259101868\n",
      "epoch n°2842 : train_loss = 2.0605223178863525, val_loss = 0.7942196726799011\n",
      "epoch n°2843 : train_loss = 2.047790288925171, val_loss = 0.7938870787620544\n",
      "epoch n°2844 : train_loss = 2.0583786964416504, val_loss = 0.7955427765846252\n",
      "epoch n°2845 : train_loss = 2.051882028579712, val_loss = 0.7918764352798462\n",
      "epoch n°2846 : train_loss = 2.050647497177124, val_loss = 0.7941412925720215\n",
      "epoch n°2847 : train_loss = 2.0625221729278564, val_loss = 0.7983507513999939\n",
      "epoch n°2848 : train_loss = 2.061605453491211, val_loss = 0.79278564453125\n",
      "epoch n°2849 : train_loss = 2.055911064147949, val_loss = 0.7915503978729248\n",
      "epoch n°2850 : train_loss = 2.058196783065796, val_loss = 0.7913764119148254\n",
      "epoch n°2851 : train_loss = 2.0480124950408936, val_loss = 0.7951881289482117\n",
      "epoch n°2852 : train_loss = 2.0581228733062744, val_loss = 0.7964751720428467\n",
      "epoch n°2853 : train_loss = 2.05438494682312, val_loss = 0.793257474899292\n",
      "epoch n°2854 : train_loss = 2.048658847808838, val_loss = 0.793286919593811\n",
      "epoch n°2855 : train_loss = 2.055741786956787, val_loss = 0.7937473654747009\n",
      "epoch n°2856 : train_loss = 2.054769277572632, val_loss = 0.7952451705932617\n",
      "epoch n°2857 : train_loss = 2.051532030105591, val_loss = 0.7926974892616272\n",
      "epoch n°2858 : train_loss = 2.055302381515503, val_loss = 0.791962206363678\n",
      "epoch n°2859 : train_loss = 2.054438591003418, val_loss = 0.7935944199562073\n",
      "epoch n°2860 : train_loss = 2.0497982501983643, val_loss = 0.7942765951156616\n",
      "epoch n°2861 : train_loss = 2.0619752407073975, val_loss = 0.793490469455719\n",
      "epoch n°2862 : train_loss = 2.0621864795684814, val_loss = 0.7946956753730774\n",
      "epoch n°2863 : train_loss = 2.054091453552246, val_loss = 0.7968074679374695\n",
      "epoch n°2864 : train_loss = 2.0538389682769775, val_loss = 0.7950157523155212\n",
      "epoch n°2865 : train_loss = 2.0688538551330566, val_loss = 0.7911312580108643\n",
      "epoch n°2866 : train_loss = 2.056391954421997, val_loss = 0.7926129698753357\n",
      "epoch n°2867 : train_loss = 2.047302722930908, val_loss = 0.7946069836616516\n",
      "epoch n°2868 : train_loss = 2.048124074935913, val_loss = 0.7884770631790161\n",
      "epoch n°2869 : train_loss = 2.0471694469451904, val_loss = 0.7916273474693298\n",
      "epoch n°2870 : train_loss = 2.055753707885742, val_loss = 0.7915116548538208\n",
      "epoch n°2871 : train_loss = 2.0539662837982178, val_loss = 0.7938886284828186\n",
      "epoch n°2872 : train_loss = 2.0447604656219482, val_loss = 0.7918443083763123\n",
      "epoch n°2873 : train_loss = 2.050102710723877, val_loss = 0.7907959818840027\n",
      "epoch n°2874 : train_loss = 2.0553767681121826, val_loss = 0.7939555048942566\n",
      "epoch n°2875 : train_loss = 2.059680700302124, val_loss = 0.7941427230834961\n",
      "epoch n°2876 : train_loss = 2.0669314861297607, val_loss = 0.795472264289856\n",
      "epoch n°2877 : train_loss = 2.0595920085906982, val_loss = 0.7936882972717285\n",
      "epoch n°2878 : train_loss = 2.045919418334961, val_loss = 0.7880313396453857\n",
      "epoch n°2879 : train_loss = 2.0501954555511475, val_loss = 0.7922205328941345\n",
      "epoch n°2880 : train_loss = 2.0533483028411865, val_loss = 0.7948276400566101\n",
      "epoch n°2881 : train_loss = 2.0571680068969727, val_loss = 0.788266658782959\n",
      "epoch n°2882 : train_loss = 2.0558395385742188, val_loss = 0.7875294089317322\n",
      "epoch n°2883 : train_loss = 2.0677716732025146, val_loss = 0.7951489686965942\n",
      "epoch n°2884 : train_loss = 2.047638416290283, val_loss = 0.7904075384140015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°2885 : train_loss = 2.0531113147735596, val_loss = 0.7931883931159973\n",
      "epoch n°2886 : train_loss = 2.0517892837524414, val_loss = 0.7921643853187561\n",
      "epoch n°2887 : train_loss = 2.0501046180725098, val_loss = 0.7912037968635559\n",
      "epoch n°2888 : train_loss = 2.0550155639648438, val_loss = 0.7982395887374878\n",
      "epoch n°2889 : train_loss = 2.0504813194274902, val_loss = 0.7962189316749573\n",
      "epoch n°2890 : train_loss = 2.056983470916748, val_loss = 0.789268970489502\n",
      "epoch n°2891 : train_loss = 2.047243356704712, val_loss = 0.7963753342628479\n",
      "epoch n°2892 : train_loss = 2.052450180053711, val_loss = 0.7955403327941895\n",
      "epoch n°2893 : train_loss = 2.0532009601593018, val_loss = 0.7952909469604492\n",
      "epoch n°2894 : train_loss = 2.0516459941864014, val_loss = 0.792922854423523\n",
      "epoch n°2895 : train_loss = 2.0499703884124756, val_loss = 0.7972187995910645\n",
      "epoch n°2896 : train_loss = 2.0557448863983154, val_loss = 0.7958849668502808\n",
      "epoch n°2897 : train_loss = 2.059962034225464, val_loss = 0.7938396334648132\n",
      "epoch n°2898 : train_loss = 2.0492515563964844, val_loss = 0.7901029586791992\n",
      "epoch n°2899 : train_loss = 2.0505573749542236, val_loss = 0.793427050113678\n",
      "epoch n°2900 : train_loss = 2.0522525310516357, val_loss = 0.7935357689857483\n",
      "epoch n°2901 : train_loss = 2.049267530441284, val_loss = 0.7952852845191956\n",
      "epoch n°2902 : train_loss = 2.049962043762207, val_loss = 0.7934854626655579\n",
      "epoch n°2903 : train_loss = 2.0453293323516846, val_loss = 0.7929229736328125\n",
      "epoch n°2904 : train_loss = 2.056119918823242, val_loss = 0.7989063262939453\n",
      "epoch n°2905 : train_loss = 2.054976463317871, val_loss = 0.7943471074104309\n",
      "epoch n°2906 : train_loss = 2.0490102767944336, val_loss = 0.7923900485038757\n",
      "epoch n°2907 : train_loss = 2.0557074546813965, val_loss = 0.7916207909584045\n",
      "epoch n°2908 : train_loss = 2.04927396774292, val_loss = 0.7930678725242615\n",
      "epoch n°2909 : train_loss = 2.048818588256836, val_loss = 0.7950899600982666\n",
      "epoch n°2910 : train_loss = 2.051663875579834, val_loss = 0.7904448509216309\n",
      "epoch n°2911 : train_loss = 2.0598161220550537, val_loss = 0.7947049736976624\n",
      "epoch n°2912 : train_loss = 2.050030469894409, val_loss = 0.7919865846633911\n",
      "epoch n°2913 : train_loss = 2.047760009765625, val_loss = 0.7974004149436951\n",
      "epoch n°2914 : train_loss = 2.0444540977478027, val_loss = 0.7920097708702087\n",
      "epoch n°2915 : train_loss = 2.0577523708343506, val_loss = 0.7959378957748413\n",
      "epoch n°2916 : train_loss = 2.0558836460113525, val_loss = 0.7903282642364502\n",
      "epoch n°2917 : train_loss = 2.049448251724243, val_loss = 0.7982184886932373\n",
      "epoch n°2918 : train_loss = 2.045694589614868, val_loss = 0.7907055616378784\n",
      "epoch n°2919 : train_loss = 2.049938917160034, val_loss = 0.794590175151825\n",
      "epoch n°2920 : train_loss = 2.0477957725524902, val_loss = 0.8012079000473022\n",
      "epoch n°2921 : train_loss = 2.0494556427001953, val_loss = 0.7884091734886169\n",
      "epoch n°2922 : train_loss = 2.054159164428711, val_loss = 0.7935270071029663\n",
      "epoch n°2923 : train_loss = 2.048950433731079, val_loss = 0.7936528921127319\n",
      "epoch n°2924 : train_loss = 2.0567450523376465, val_loss = 0.7940723896026611\n",
      "epoch n°2925 : train_loss = 2.050489902496338, val_loss = 0.795185923576355\n",
      "epoch n°2926 : train_loss = 2.048020839691162, val_loss = 0.7930142879486084\n",
      "epoch n°2927 : train_loss = 2.0591514110565186, val_loss = 0.7918903827667236\n",
      "epoch n°2928 : train_loss = 2.0595669746398926, val_loss = 0.7941920757293701\n",
      "epoch n°2929 : train_loss = 2.050619125366211, val_loss = 0.7913998365402222\n",
      "epoch n°2930 : train_loss = 2.0489234924316406, val_loss = 0.7996159195899963\n",
      "epoch n°2931 : train_loss = 2.0481395721435547, val_loss = 0.7904205918312073\n",
      "epoch n°2932 : train_loss = 2.0535082817077637, val_loss = 0.7940478920936584\n",
      "epoch n°2933 : train_loss = 2.0427377223968506, val_loss = 0.7944504022598267\n",
      "epoch n°2934 : train_loss = 2.0501837730407715, val_loss = 0.7938010692596436\n",
      "epoch n°2935 : train_loss = 2.050205945968628, val_loss = 0.792563259601593\n",
      "epoch n°2936 : train_loss = 2.052628755569458, val_loss = 0.7926027774810791\n",
      "epoch n°2937 : train_loss = 2.0529067516326904, val_loss = 0.7929590940475464\n",
      "epoch n°2938 : train_loss = 2.0503928661346436, val_loss = 0.7990952134132385\n",
      "epoch n°2939 : train_loss = 2.056495189666748, val_loss = 0.793300449848175\n",
      "epoch n°2940 : train_loss = 2.0452325344085693, val_loss = 0.7950026392936707\n",
      "epoch n°2941 : train_loss = 2.0477030277252197, val_loss = 0.7981288433074951\n",
      "epoch n°2942 : train_loss = 2.0548055171966553, val_loss = 0.7966422438621521\n",
      "epoch n°2943 : train_loss = 2.0525763034820557, val_loss = 0.7939519286155701\n",
      "epoch n°2944 : train_loss = 2.064385414123535, val_loss = 0.7939857840538025\n",
      "epoch n°2945 : train_loss = 2.0490052700042725, val_loss = 0.7941047549247742\n",
      "epoch n°2946 : train_loss = 2.0529956817626953, val_loss = 0.7944005727767944\n",
      "epoch n°2947 : train_loss = 2.0514426231384277, val_loss = 0.7936387658119202\n",
      "epoch n°2948 : train_loss = 2.051536798477173, val_loss = 0.7980862855911255\n",
      "epoch n°2949 : train_loss = 2.0551135540008545, val_loss = 0.7918537855148315\n",
      "epoch n°2950 : train_loss = 2.044506072998047, val_loss = 0.7959924936294556\n",
      "epoch n°2951 : train_loss = 2.048264265060425, val_loss = 0.7926918268203735\n",
      "epoch n°2952 : train_loss = 2.0501773357391357, val_loss = 0.7945299744606018\n",
      "epoch n°2953 : train_loss = 2.055068254470825, val_loss = 0.7939566969871521\n",
      "epoch n°2954 : train_loss = 2.0587615966796875, val_loss = 0.7937237024307251\n",
      "epoch n°2955 : train_loss = 2.049847364425659, val_loss = 0.7913991212844849\n",
      "epoch n°2956 : train_loss = 2.0526413917541504, val_loss = 0.793460488319397\n",
      "epoch n°2957 : train_loss = 2.0491080284118652, val_loss = 0.7932353019714355\n",
      "epoch n°2958 : train_loss = 2.037182092666626, val_loss = 0.7961820960044861\n",
      "epoch n°2959 : train_loss = 2.0540308952331543, val_loss = 0.791226863861084\n",
      "epoch n°2960 : train_loss = 2.0450356006622314, val_loss = 0.7927430272102356\n",
      "epoch n°2961 : train_loss = 2.050591468811035, val_loss = 0.7943702936172485\n",
      "epoch n°2962 : train_loss = 2.046856641769409, val_loss = 0.7948372960090637\n",
      "epoch n°2963 : train_loss = 2.0584867000579834, val_loss = 0.7958141565322876\n",
      "epoch n°2964 : train_loss = 2.0521183013916016, val_loss = 0.7942705750465393\n",
      "epoch n°2965 : train_loss = 2.0509018898010254, val_loss = 0.7903536558151245\n",
      "epoch n°2966 : train_loss = 2.0475704669952393, val_loss = 0.7959091663360596\n",
      "epoch n°2967 : train_loss = 2.056382656097412, val_loss = 0.7933878302574158\n",
      "epoch n°2968 : train_loss = 2.04856276512146, val_loss = 0.7914640307426453\n",
      "epoch n°2969 : train_loss = 2.047565221786499, val_loss = 0.7936236262321472\n",
      "epoch n°2970 : train_loss = 2.049377679824829, val_loss = 0.7982091307640076\n",
      "epoch n°2971 : train_loss = 2.0451231002807617, val_loss = 0.7958216667175293\n",
      "epoch n°2972 : train_loss = 2.051966905593872, val_loss = 0.7928473949432373\n",
      "epoch n°2973 : train_loss = 2.05572247505188, val_loss = 0.7944514751434326\n",
      "epoch n°2974 : train_loss = 2.0419840812683105, val_loss = 0.7952049374580383\n",
      "epoch n°2975 : train_loss = 2.052500009536743, val_loss = 0.7897897958755493\n",
      "epoch n°2976 : train_loss = 2.038856267929077, val_loss = 0.7927992343902588\n",
      "epoch n°2977 : train_loss = 2.0522985458374023, val_loss = 0.7971182465553284\n",
      "epoch n°2978 : train_loss = 2.0577139854431152, val_loss = 0.7962560653686523\n",
      "epoch n°2979 : train_loss = 2.051673412322998, val_loss = 0.7903255224227905\n",
      "epoch n°2980 : train_loss = 2.055124044418335, val_loss = 0.7947182059288025\n",
      "epoch n°2981 : train_loss = 2.0547306537628174, val_loss = 0.7925074100494385\n",
      "epoch n°2982 : train_loss = 2.053899049758911, val_loss = 0.7965279221534729\n",
      "epoch n°2983 : train_loss = 2.0464065074920654, val_loss = 0.7940757274627686\n",
      "epoch n°2984 : train_loss = 2.0453457832336426, val_loss = 0.7961599230766296\n",
      "epoch n°2985 : train_loss = 2.045254707336426, val_loss = 0.7936225533485413\n",
      "epoch n°2986 : train_loss = 2.051845073699951, val_loss = 0.7966025471687317\n",
      "epoch n°2987 : train_loss = 2.0532827377319336, val_loss = 0.7921621203422546\n",
      "epoch n°2988 : train_loss = 2.0457441806793213, val_loss = 0.7919138669967651\n",
      "epoch n°2989 : train_loss = 2.048691987991333, val_loss = 0.7899133563041687\n",
      "epoch n°2990 : train_loss = 2.0517568588256836, val_loss = 0.7932081818580627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°2991 : train_loss = 2.05172061920166, val_loss = 0.7945701479911804\n",
      "epoch n°2992 : train_loss = 2.043924570083618, val_loss = 0.7928577065467834\n",
      "epoch n°2993 : train_loss = 2.053943634033203, val_loss = 0.7941602468490601\n",
      "epoch n°2994 : train_loss = 2.045875072479248, val_loss = 0.7928969264030457\n",
      "epoch n°2995 : train_loss = 2.050640106201172, val_loss = 0.7907989025115967\n",
      "epoch n°2996 : train_loss = 2.0459203720092773, val_loss = 0.7951367497444153\n",
      "epoch n°2997 : train_loss = 2.0508739948272705, val_loss = 0.7983592748641968\n",
      "epoch n°2998 : train_loss = 2.0526583194732666, val_loss = 0.7959936261177063\n",
      "epoch n°2999 : train_loss = 2.0432205200195312, val_loss = 0.7963268756866455\n",
      "epoch n°3000 : train_loss = 2.0467076301574707, val_loss = 0.7963128089904785\n",
      "epoch n°3001 : train_loss = 2.042295217514038, val_loss = 0.7955003976821899\n",
      "epoch n°3002 : train_loss = 2.050311326980591, val_loss = 0.7908007502555847\n",
      "epoch n°3003 : train_loss = 2.0436320304870605, val_loss = 0.7918140292167664\n",
      "epoch n°3004 : train_loss = 2.0465707778930664, val_loss = 0.7953295707702637\n",
      "epoch n°3005 : train_loss = 2.048675298690796, val_loss = 0.7915149927139282\n",
      "epoch n°3006 : train_loss = 2.0470056533813477, val_loss = 0.7886357307434082\n",
      "epoch n°3007 : train_loss = 2.052151918411255, val_loss = 0.7943978309631348\n",
      "epoch n°3008 : train_loss = 2.040977716445923, val_loss = 0.7925565242767334\n",
      "epoch n°3009 : train_loss = 2.053880214691162, val_loss = 0.7904502749443054\n",
      "epoch n°3010 : train_loss = 2.044189214706421, val_loss = 0.7957602739334106\n",
      "epoch n°3011 : train_loss = 2.052151918411255, val_loss = 0.7936268448829651\n",
      "epoch n°3012 : train_loss = 2.049398899078369, val_loss = 0.7907889485359192\n",
      "epoch n°3013 : train_loss = 2.048922300338745, val_loss = 0.7941128611564636\n",
      "epoch n°3014 : train_loss = 2.043431282043457, val_loss = 0.7938331365585327\n",
      "epoch n°3015 : train_loss = 2.0502915382385254, val_loss = 0.7915695905685425\n",
      "epoch n°3016 : train_loss = 2.0380868911743164, val_loss = 0.7914600968360901\n",
      "epoch n°3017 : train_loss = 2.043606758117676, val_loss = 0.7950258255004883\n",
      "epoch n°3018 : train_loss = 2.0409622192382812, val_loss = 0.7967286705970764\n",
      "epoch n°3019 : train_loss = 2.054522752761841, val_loss = 0.7936010956764221\n",
      "epoch n°3020 : train_loss = 2.0569252967834473, val_loss = 0.7905522584915161\n",
      "epoch n°3021 : train_loss = 2.048372745513916, val_loss = 0.792510449886322\n",
      "epoch n°3022 : train_loss = 2.0513832569122314, val_loss = 0.7927762269973755\n",
      "epoch n°3023 : train_loss = 2.040487051010132, val_loss = 0.7946516871452332\n",
      "epoch n°3024 : train_loss = 2.041170120239258, val_loss = 0.7922883033752441\n",
      "epoch n°3025 : train_loss = 2.033585786819458, val_loss = 0.7869130969047546\n",
      "epoch n°3026 : train_loss = 2.0533812046051025, val_loss = 0.7936404347419739\n",
      "epoch n°3027 : train_loss = 2.043181896209717, val_loss = 0.7962398529052734\n",
      "epoch n°3028 : train_loss = 2.04514741897583, val_loss = 0.792253315448761\n",
      "epoch n°3029 : train_loss = 2.0496573448181152, val_loss = 0.7980645895004272\n",
      "epoch n°3030 : train_loss = 2.0456583499908447, val_loss = 0.7943143844604492\n",
      "epoch n°3031 : train_loss = 2.0482468605041504, val_loss = 0.792168915271759\n",
      "epoch n°3032 : train_loss = 2.0430469512939453, val_loss = 0.7911498546600342\n",
      "epoch n°3033 : train_loss = 2.0529119968414307, val_loss = 0.7963789105415344\n",
      "epoch n°3034 : train_loss = 2.032778024673462, val_loss = 0.7926753163337708\n",
      "epoch n°3035 : train_loss = 2.0403900146484375, val_loss = 0.7947912216186523\n",
      "epoch n°3036 : train_loss = 2.0390517711639404, val_loss = 0.7904748320579529\n",
      "epoch n°3037 : train_loss = 2.0456573963165283, val_loss = 0.7955055832862854\n",
      "epoch n°3038 : train_loss = 2.046847343444824, val_loss = 0.7953436970710754\n",
      "epoch n°3039 : train_loss = 2.045658826828003, val_loss = 0.7953560948371887\n",
      "epoch n°3040 : train_loss = 2.040085554122925, val_loss = 0.7934941649436951\n",
      "epoch n°3041 : train_loss = 2.0441317558288574, val_loss = 0.7921547293663025\n",
      "epoch n°3042 : train_loss = 2.050548553466797, val_loss = 0.7923932671546936\n",
      "epoch n°3043 : train_loss = 2.0402705669403076, val_loss = 0.7966957092285156\n",
      "epoch n°3044 : train_loss = 2.0477945804595947, val_loss = 0.7892327904701233\n",
      "epoch n°3045 : train_loss = 2.0486576557159424, val_loss = 0.7906811833381653\n",
      "epoch n°3046 : train_loss = 2.0440943241119385, val_loss = 0.7956884503364563\n",
      "epoch n°3047 : train_loss = 2.0382511615753174, val_loss = 0.7938092350959778\n",
      "epoch n°3048 : train_loss = 2.0477514266967773, val_loss = 0.7884315252304077\n",
      "epoch n°3049 : train_loss = 2.0424768924713135, val_loss = 0.7910924553871155\n",
      "epoch n°3050 : train_loss = 2.0425193309783936, val_loss = 0.7909929752349854\n",
      "epoch n°3051 : train_loss = 2.0398764610290527, val_loss = 0.79453045129776\n",
      "epoch n°3052 : train_loss = 2.0404977798461914, val_loss = 0.7885958552360535\n",
      "epoch n°3053 : train_loss = 2.041269540786743, val_loss = 0.7954912781715393\n",
      "epoch n°3054 : train_loss = 2.0371105670928955, val_loss = 0.7959516048431396\n",
      "epoch n°3055 : train_loss = 2.0497195720672607, val_loss = 0.7940755486488342\n",
      "epoch n°3056 : train_loss = 2.041299343109131, val_loss = 0.7903485298156738\n",
      "epoch n°3057 : train_loss = 2.05186128616333, val_loss = 0.7881790399551392\n",
      "epoch n°3058 : train_loss = 2.047175407409668, val_loss = 0.793128252029419\n",
      "epoch n°3059 : train_loss = 2.041534900665283, val_loss = 0.7916716933250427\n",
      "epoch n°3060 : train_loss = 2.0519375801086426, val_loss = 0.7923821210861206\n",
      "epoch n°3061 : train_loss = 2.0398452281951904, val_loss = 0.7934971451759338\n",
      "epoch n°3062 : train_loss = 2.047027111053467, val_loss = 0.7962508797645569\n",
      "epoch n°3063 : train_loss = 2.050722599029541, val_loss = 0.7944153547286987\n",
      "epoch n°3064 : train_loss = 2.0473504066467285, val_loss = 0.7938051223754883\n",
      "epoch n°3065 : train_loss = 2.037083387374878, val_loss = 0.7944983839988708\n",
      "epoch n°3066 : train_loss = 2.041898012161255, val_loss = 0.7920628786087036\n",
      "epoch n°3067 : train_loss = 2.0448198318481445, val_loss = 0.7961955070495605\n",
      "epoch n°3068 : train_loss = 2.039707899093628, val_loss = 0.7950801253318787\n",
      "epoch n°3069 : train_loss = 2.0450119972229004, val_loss = 0.7938991785049438\n",
      "epoch n°3070 : train_loss = 2.0448079109191895, val_loss = 0.7918047308921814\n",
      "epoch n°3071 : train_loss = 2.0317835807800293, val_loss = 0.7921192646026611\n",
      "epoch n°3072 : train_loss = 2.0474982261657715, val_loss = 0.7916826605796814\n",
      "epoch n°3073 : train_loss = 2.0475523471832275, val_loss = 0.790932297706604\n",
      "epoch n°3074 : train_loss = 2.0513124465942383, val_loss = 0.7931106090545654\n",
      "epoch n°3075 : train_loss = 2.0473930835723877, val_loss = 0.7874400615692139\n",
      "epoch n°3076 : train_loss = 2.0417184829711914, val_loss = 0.7908322215080261\n",
      "epoch n°3077 : train_loss = 2.044187307357788, val_loss = 0.7953510880470276\n",
      "epoch n°3078 : train_loss = 2.045649528503418, val_loss = 0.7949569225311279\n",
      "epoch n°3079 : train_loss = 2.0497236251831055, val_loss = 0.7960264086723328\n",
      "epoch n°3080 : train_loss = 2.049586534500122, val_loss = 0.7943878769874573\n",
      "epoch n°3081 : train_loss = 2.0455667972564697, val_loss = 0.7958291172981262\n",
      "epoch n°3082 : train_loss = 2.0462701320648193, val_loss = 0.7921179533004761\n",
      "epoch n°3083 : train_loss = 2.041494607925415, val_loss = 0.7944316864013672\n",
      "epoch n°3084 : train_loss = 2.04862642288208, val_loss = 0.7908821105957031\n",
      "epoch n°3085 : train_loss = 2.0479190349578857, val_loss = 0.7910536527633667\n",
      "epoch n°3086 : train_loss = 2.0428714752197266, val_loss = 0.7942917346954346\n",
      "epoch n°3087 : train_loss = 2.037712812423706, val_loss = 0.792082667350769\n",
      "epoch n°3088 : train_loss = 2.045761823654175, val_loss = 0.7927093505859375\n",
      "epoch n°3089 : train_loss = 2.050954818725586, val_loss = 0.7894670963287354\n",
      "epoch n°3090 : train_loss = 2.04813814163208, val_loss = 0.7992537617683411\n",
      "epoch n°3091 : train_loss = 2.0305016040802, val_loss = 0.7938408851623535\n",
      "epoch n°3092 : train_loss = 2.0495338439941406, val_loss = 0.7927578091621399\n",
      "epoch n°3093 : train_loss = 2.039909601211548, val_loss = 0.7915433049201965\n",
      "epoch n°3094 : train_loss = 2.040874719619751, val_loss = 0.7966423034667969\n",
      "epoch n°3095 : train_loss = 2.0445101261138916, val_loss = 0.7876975536346436\n",
      "epoch n°3096 : train_loss = 2.0443854331970215, val_loss = 0.7953123450279236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°3097 : train_loss = 2.0345020294189453, val_loss = 0.7993793487548828\n",
      "epoch n°3098 : train_loss = 2.0439462661743164, val_loss = 0.7901510000228882\n",
      "epoch n°3099 : train_loss = 2.0488240718841553, val_loss = 0.793315589427948\n",
      "epoch n°3100 : train_loss = 2.0315444469451904, val_loss = 0.7952379584312439\n",
      "epoch n°3101 : train_loss = 2.0407252311706543, val_loss = 0.7889896631240845\n",
      "epoch n°3102 : train_loss = 2.047902822494507, val_loss = 0.7946640849113464\n",
      "epoch n°3103 : train_loss = 2.0317208766937256, val_loss = 0.7902134656906128\n",
      "epoch n°3104 : train_loss = 2.043222665786743, val_loss = 0.7913590669631958\n",
      "epoch n°3105 : train_loss = 2.041168689727783, val_loss = 0.7890458703041077\n",
      "epoch n°3106 : train_loss = 2.041179895401001, val_loss = 0.7925271391868591\n",
      "epoch n°3107 : train_loss = 2.036102533340454, val_loss = 0.7925128936767578\n",
      "epoch n°3108 : train_loss = 2.0402493476867676, val_loss = 0.7934216856956482\n",
      "epoch n°3109 : train_loss = 2.0456793308258057, val_loss = 0.7921856641769409\n",
      "epoch n°3110 : train_loss = 2.038655996322632, val_loss = 0.7938785552978516\n",
      "epoch n°3111 : train_loss = 2.040356397628784, val_loss = 0.797760009765625\n",
      "epoch n°3112 : train_loss = 2.0394062995910645, val_loss = 0.7987081408500671\n",
      "epoch n°3113 : train_loss = 2.0465714931488037, val_loss = 0.7911971211433411\n",
      "epoch n°3114 : train_loss = 2.0447938442230225, val_loss = 0.7969587445259094\n",
      "epoch n°3115 : train_loss = 2.04203724861145, val_loss = 0.7892820239067078\n",
      "epoch n°3116 : train_loss = 2.040922164916992, val_loss = 0.7946232557296753\n",
      "epoch n°3117 : train_loss = 2.04040265083313, val_loss = 0.7947621941566467\n",
      "epoch n°3118 : train_loss = 2.0418100357055664, val_loss = 0.7870703935623169\n",
      "epoch n°3119 : train_loss = 2.0348446369171143, val_loss = 0.7938902378082275\n",
      "epoch n°3120 : train_loss = 2.044088363647461, val_loss = 0.7925571203231812\n",
      "epoch n°3121 : train_loss = 2.0334436893463135, val_loss = 0.7930641770362854\n",
      "epoch n°3122 : train_loss = 2.039510488510132, val_loss = 0.7983765602111816\n",
      "epoch n°3123 : train_loss = 2.0473837852478027, val_loss = 0.7947596311569214\n",
      "epoch n°3124 : train_loss = 2.0461056232452393, val_loss = 0.7922480702400208\n",
      "epoch n°3125 : train_loss = 2.0467987060546875, val_loss = 0.7907461524009705\n",
      "epoch n°3126 : train_loss = 2.0459799766540527, val_loss = 0.7932127714157104\n",
      "epoch n°3127 : train_loss = 2.039330005645752, val_loss = 0.7927224636077881\n",
      "epoch n°3128 : train_loss = 2.042185068130493, val_loss = 0.7934086322784424\n",
      "epoch n°3129 : train_loss = 2.047416925430298, val_loss = 0.7905850410461426\n",
      "epoch n°3130 : train_loss = 2.0363783836364746, val_loss = 0.7932310700416565\n",
      "epoch n°3131 : train_loss = 2.0401957035064697, val_loss = 0.7925821542739868\n",
      "epoch n°3132 : train_loss = 2.0365772247314453, val_loss = 0.7885798811912537\n",
      "epoch n°3133 : train_loss = 2.0389928817749023, val_loss = 0.7909828424453735\n",
      "epoch n°3134 : train_loss = 2.0435376167297363, val_loss = 0.7932494282722473\n",
      "epoch n°3135 : train_loss = 2.0431511402130127, val_loss = 0.7927795052528381\n",
      "epoch n°3136 : train_loss = 2.0406932830810547, val_loss = 0.794956624507904\n",
      "epoch n°3137 : train_loss = 2.046311140060425, val_loss = 0.7928764224052429\n",
      "epoch n°3138 : train_loss = 2.035515069961548, val_loss = 0.7926223874092102\n",
      "epoch n°3139 : train_loss = 2.0393452644348145, val_loss = 0.7937049269676208\n",
      "epoch n°3140 : train_loss = 2.04286789894104, val_loss = 0.7947090268135071\n",
      "epoch n°3141 : train_loss = 2.0539331436157227, val_loss = 0.7934420704841614\n",
      "epoch n°3142 : train_loss = 2.036625862121582, val_loss = 0.7954019904136658\n",
      "epoch n°3143 : train_loss = 2.04032301902771, val_loss = 0.7942789793014526\n",
      "epoch n°3144 : train_loss = 2.0467946529388428, val_loss = 0.7949019074440002\n",
      "epoch n°3145 : train_loss = 2.04030704498291, val_loss = 0.7940331101417542\n",
      "epoch n°3146 : train_loss = 2.0367348194122314, val_loss = 0.7916455864906311\n",
      "epoch n°3147 : train_loss = 2.0402493476867676, val_loss = 0.7911515831947327\n",
      "epoch n°3148 : train_loss = 2.0402114391326904, val_loss = 0.7947760820388794\n",
      "epoch n°3149 : train_loss = 2.042325496673584, val_loss = 0.7940358519554138\n",
      "epoch n°3150 : train_loss = 2.0390889644622803, val_loss = 0.7950094938278198\n",
      "epoch n°3151 : train_loss = 2.0371522903442383, val_loss = 0.7927893400192261\n",
      "epoch n°3152 : train_loss = 2.0383105278015137, val_loss = 0.7917736768722534\n",
      "epoch n°3153 : train_loss = 2.0335586071014404, val_loss = 0.7933782339096069\n",
      "epoch n°3154 : train_loss = 2.0363457202911377, val_loss = 0.7899731397628784\n",
      "epoch n°3155 : train_loss = 2.0380237102508545, val_loss = 0.7928950190544128\n",
      "epoch n°3156 : train_loss = 2.0439040660858154, val_loss = 0.795258641242981\n",
      "epoch n°3157 : train_loss = 2.0349280834198, val_loss = 0.786849856376648\n",
      "epoch n°3158 : train_loss = 2.0467965602874756, val_loss = 0.7920388579368591\n",
      "epoch n°3159 : train_loss = 2.045910596847534, val_loss = 0.7922190427780151\n",
      "epoch n°3160 : train_loss = 2.0388805866241455, val_loss = 0.7948597073554993\n",
      "epoch n°3161 : train_loss = 2.036127805709839, val_loss = 0.7918466925621033\n",
      "epoch n°3162 : train_loss = 2.035492181777954, val_loss = 0.7940047383308411\n",
      "epoch n°3163 : train_loss = 2.050879716873169, val_loss = 0.7926803827285767\n",
      "epoch n°3164 : train_loss = 2.0383927822113037, val_loss = 0.7948257923126221\n",
      "epoch n°3165 : train_loss = 2.038822889328003, val_loss = 0.7939980030059814\n",
      "epoch n°3166 : train_loss = 2.0439906120300293, val_loss = 0.7897434830665588\n",
      "epoch n°3167 : train_loss = 2.04923152923584, val_loss = 0.7872884273529053\n",
      "epoch n°3168 : train_loss = 2.0381391048431396, val_loss = 0.7976417541503906\n",
      "epoch n°3169 : train_loss = 2.0309207439422607, val_loss = 0.7893252968788147\n",
      "epoch n°3170 : train_loss = 2.0388951301574707, val_loss = 0.7934237122535706\n",
      "epoch n°3171 : train_loss = 2.0446596145629883, val_loss = 0.7963684797286987\n",
      "epoch n°3172 : train_loss = 2.040133476257324, val_loss = 0.7937104105949402\n",
      "epoch n°3173 : train_loss = 2.0409624576568604, val_loss = 0.7907779216766357\n",
      "epoch n°3174 : train_loss = 2.051011562347412, val_loss = 0.7939746379852295\n",
      "epoch n°3175 : train_loss = 2.0390450954437256, val_loss = 0.788063645362854\n",
      "epoch n°3176 : train_loss = 2.042412519454956, val_loss = 0.796791672706604\n",
      "epoch n°3177 : train_loss = 2.0425238609313965, val_loss = 0.7908763885498047\n",
      "epoch n°3178 : train_loss = 2.042470693588257, val_loss = 0.7901704907417297\n",
      "epoch n°3179 : train_loss = 2.0366272926330566, val_loss = 0.7950693368911743\n",
      "epoch n°3180 : train_loss = 2.04028058052063, val_loss = 0.793371319770813\n",
      "epoch n°3181 : train_loss = 2.0405054092407227, val_loss = 0.7911460399627686\n",
      "epoch n°3182 : train_loss = 2.037341833114624, val_loss = 0.7917208671569824\n",
      "epoch n°3183 : train_loss = 2.0322916507720947, val_loss = 0.7907204627990723\n",
      "epoch n°3184 : train_loss = 2.037449359893799, val_loss = 0.790381908416748\n",
      "epoch n°3185 : train_loss = 2.0321788787841797, val_loss = 0.7907629609107971\n",
      "epoch n°3186 : train_loss = 2.037959337234497, val_loss = 0.7880325317382812\n",
      "epoch n°3187 : train_loss = 2.036437749862671, val_loss = 0.7947058081626892\n",
      "epoch n°3188 : train_loss = 2.0393147468566895, val_loss = 0.7939974665641785\n",
      "epoch n°3189 : train_loss = 2.038710594177246, val_loss = 0.7899887561798096\n",
      "epoch n°3190 : train_loss = 2.039794683456421, val_loss = 0.7947713136672974\n",
      "epoch n°3191 : train_loss = 2.0446386337280273, val_loss = 0.7937038540840149\n",
      "epoch n°3192 : train_loss = 2.0449934005737305, val_loss = 0.7905723452568054\n",
      "epoch n°3193 : train_loss = 2.034881114959717, val_loss = 0.7965390086174011\n",
      "epoch n°3194 : train_loss = 2.042847156524658, val_loss = 0.7891228795051575\n",
      "epoch n°3195 : train_loss = 2.0345168113708496, val_loss = 0.7967541813850403\n",
      "epoch n°3196 : train_loss = 2.039024829864502, val_loss = 0.7875294089317322\n",
      "epoch n°3197 : train_loss = 2.0329577922821045, val_loss = 0.789868950843811\n",
      "epoch n°3198 : train_loss = 2.028687000274658, val_loss = 0.7918059229850769\n",
      "epoch n°3199 : train_loss = 2.041860342025757, val_loss = 0.7942001223564148\n",
      "epoch n°3200 : train_loss = 2.0346243381500244, val_loss = 0.7893170714378357\n",
      "epoch n°3201 : train_loss = 2.028498649597168, val_loss = 0.7927476763725281\n",
      "epoch n°3202 : train_loss = 2.035832405090332, val_loss = 0.7910366058349609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°3203 : train_loss = 2.040743589401245, val_loss = 0.7905868887901306\n",
      "epoch n°3204 : train_loss = 2.0396103858947754, val_loss = 0.7936487197875977\n",
      "epoch n°3205 : train_loss = 2.041027784347534, val_loss = 0.7947460412979126\n",
      "epoch n°3206 : train_loss = 2.0379350185394287, val_loss = 0.7907794713973999\n",
      "epoch n°3207 : train_loss = 2.0359487533569336, val_loss = 0.7941707372665405\n",
      "epoch n°3208 : train_loss = 2.0349786281585693, val_loss = 0.7915663123130798\n",
      "epoch n°3209 : train_loss = 2.0326948165893555, val_loss = 0.7959595322608948\n",
      "epoch n°3210 : train_loss = 2.0390782356262207, val_loss = 0.7923293113708496\n",
      "epoch n°3211 : train_loss = 2.0352039337158203, val_loss = 0.7918460369110107\n",
      "epoch n°3212 : train_loss = 2.0284183025360107, val_loss = 0.7911098599433899\n",
      "epoch n°3213 : train_loss = 2.04606294631958, val_loss = 0.795337975025177\n",
      "epoch n°3214 : train_loss = 2.0379767417907715, val_loss = 0.7929864525794983\n",
      "epoch n°3215 : train_loss = 2.035945177078247, val_loss = 0.7881152629852295\n",
      "epoch n°3216 : train_loss = 2.030089855194092, val_loss = 0.7946090698242188\n",
      "epoch n°3217 : train_loss = 2.029430389404297, val_loss = 0.7922757267951965\n",
      "epoch n°3218 : train_loss = 2.0309600830078125, val_loss = 0.791212797164917\n",
      "epoch n°3219 : train_loss = 2.0385611057281494, val_loss = 0.7930546402931213\n",
      "epoch n°3220 : train_loss = 2.041438102722168, val_loss = 0.79445481300354\n",
      "epoch n°3221 : train_loss = 2.0395846366882324, val_loss = 0.7937702536582947\n",
      "epoch n°3222 : train_loss = 2.041109323501587, val_loss = 0.7933762669563293\n",
      "epoch n°3223 : train_loss = 2.035288095474243, val_loss = 0.793095052242279\n",
      "epoch n°3224 : train_loss = 2.0394091606140137, val_loss = 0.795326292514801\n",
      "epoch n°3225 : train_loss = 2.0389552116394043, val_loss = 0.8001031279563904\n",
      "epoch n°3226 : train_loss = 2.037938356399536, val_loss = 0.7908878922462463\n",
      "epoch n°3227 : train_loss = 2.0266525745391846, val_loss = 0.7890140414237976\n",
      "epoch n°3228 : train_loss = 2.0380401611328125, val_loss = 0.793706476688385\n",
      "epoch n°3229 : train_loss = 2.0407474040985107, val_loss = 0.7909700870513916\n",
      "epoch n°3230 : train_loss = 2.037656545639038, val_loss = 0.7982705235481262\n",
      "epoch n°3231 : train_loss = 2.0380043983459473, val_loss = 0.7924632430076599\n",
      "epoch n°3232 : train_loss = 2.0382394790649414, val_loss = 0.7915027737617493\n",
      "epoch n°3233 : train_loss = 2.0355772972106934, val_loss = 0.7918752431869507\n",
      "epoch n°3234 : train_loss = 2.037034511566162, val_loss = 0.7910601496696472\n",
      "epoch n°3235 : train_loss = 2.026606321334839, val_loss = 0.7941949367523193\n",
      "epoch n°3236 : train_loss = 2.0366499423980713, val_loss = 0.7944501042366028\n",
      "epoch n°3237 : train_loss = 2.034714698791504, val_loss = 0.786512553691864\n",
      "epoch n°3238 : train_loss = 2.031336545944214, val_loss = 0.7908424139022827\n",
      "epoch n°3239 : train_loss = 2.0382707118988037, val_loss = 0.78986656665802\n",
      "epoch n°3240 : train_loss = 2.0409929752349854, val_loss = 0.7942238450050354\n",
      "epoch n°3241 : train_loss = 2.0362675189971924, val_loss = 0.7929539680480957\n",
      "epoch n°3242 : train_loss = 2.030825614929199, val_loss = 0.7940722703933716\n",
      "epoch n°3243 : train_loss = 2.0342111587524414, val_loss = 0.7907252907752991\n",
      "epoch n°3244 : train_loss = 2.0281975269317627, val_loss = 0.7954318523406982\n",
      "epoch n°3245 : train_loss = 2.034226179122925, val_loss = 0.7890932559967041\n",
      "epoch n°3246 : train_loss = 2.0431690216064453, val_loss = 0.7927506566047668\n",
      "epoch n°3247 : train_loss = 2.042382001876831, val_loss = 0.7979289889335632\n",
      "epoch n°3248 : train_loss = 2.0364365577697754, val_loss = 0.7954962849617004\n",
      "epoch n°3249 : train_loss = 2.0450055599212646, val_loss = 0.7873673439025879\n",
      "epoch n°3250 : train_loss = 2.042092800140381, val_loss = 0.795515239238739\n",
      "epoch n°3251 : train_loss = 2.0412356853485107, val_loss = 0.7957834005355835\n",
      "epoch n°3252 : train_loss = 2.0422070026397705, val_loss = 0.7923529148101807\n",
      "epoch n°3253 : train_loss = 2.033468246459961, val_loss = 0.7931590676307678\n",
      "epoch n°3254 : train_loss = 2.022763967514038, val_loss = 0.7929598093032837\n",
      "epoch n°3255 : train_loss = 2.037562608718872, val_loss = 0.7935961484909058\n",
      "epoch n°3256 : train_loss = 2.036130905151367, val_loss = 0.7956252694129944\n",
      "epoch n°3257 : train_loss = 2.0326220989227295, val_loss = 0.7931841015815735\n",
      "epoch n°3258 : train_loss = 2.036196708679199, val_loss = 0.7953261733055115\n",
      "epoch n°3259 : train_loss = 2.035656213760376, val_loss = 0.7939359545707703\n",
      "epoch n°3260 : train_loss = 2.0492146015167236, val_loss = 0.7929622530937195\n",
      "epoch n°3261 : train_loss = 2.0342929363250732, val_loss = 0.7928928136825562\n",
      "epoch n°3262 : train_loss = 2.038431406021118, val_loss = 0.7895199060440063\n",
      "epoch n°3263 : train_loss = 2.0268759727478027, val_loss = 0.7933862805366516\n",
      "epoch n°3264 : train_loss = 2.04318904876709, val_loss = 0.7944962978363037\n",
      "epoch n°3265 : train_loss = 2.02384090423584, val_loss = 0.7961445450782776\n",
      "epoch n°3266 : train_loss = 2.0312700271606445, val_loss = 0.7907942533493042\n",
      "epoch n°3267 : train_loss = 2.0342636108398438, val_loss = 0.7927924394607544\n",
      "epoch n°3268 : train_loss = 2.0320327281951904, val_loss = 0.7888312935829163\n",
      "epoch n°3269 : train_loss = 2.0406594276428223, val_loss = 0.7944481372833252\n",
      "epoch n°3270 : train_loss = 2.034609794616699, val_loss = 0.793929934501648\n",
      "epoch n°3271 : train_loss = 2.0436770915985107, val_loss = 0.7908409833908081\n",
      "epoch n°3272 : train_loss = 2.0319747924804688, val_loss = 0.7885052561759949\n",
      "epoch n°3273 : train_loss = 2.0250205993652344, val_loss = 0.7924943566322327\n",
      "epoch n°3274 : train_loss = 2.024841070175171, val_loss = 0.7905235290527344\n",
      "epoch n°3275 : train_loss = 2.038398265838623, val_loss = 0.791840672492981\n",
      "epoch n°3276 : train_loss = 2.032184600830078, val_loss = 0.7925710082054138\n",
      "epoch n°3277 : train_loss = 2.033254384994507, val_loss = 0.7903942465782166\n",
      "epoch n°3278 : train_loss = 2.034885883331299, val_loss = 0.7955936193466187\n",
      "epoch n°3279 : train_loss = 2.0354502201080322, val_loss = 0.7889273762702942\n",
      "epoch n°3280 : train_loss = 2.0365443229675293, val_loss = 0.7924649715423584\n",
      "epoch n°3281 : train_loss = 2.0326876640319824, val_loss = 0.7956176996231079\n",
      "epoch n°3282 : train_loss = 2.0413105487823486, val_loss = 0.7961711883544922\n",
      "epoch n°3283 : train_loss = 2.0318593978881836, val_loss = 0.7946975231170654\n",
      "epoch n°3284 : train_loss = 2.0395264625549316, val_loss = 0.7925909161567688\n",
      "epoch n°3285 : train_loss = 2.038943290710449, val_loss = 0.7893669605255127\n",
      "epoch n°3286 : train_loss = 2.043255567550659, val_loss = 0.7873505353927612\n",
      "epoch n°3287 : train_loss = 2.027442455291748, val_loss = 0.7965502738952637\n",
      "epoch n°3288 : train_loss = 2.050200939178467, val_loss = 0.7938221096992493\n",
      "epoch n°3289 : train_loss = 2.0343687534332275, val_loss = 0.789201557636261\n",
      "epoch n°3290 : train_loss = 2.0298540592193604, val_loss = 0.7921493649482727\n",
      "epoch n°3291 : train_loss = 2.040618419647217, val_loss = 0.7922937273979187\n",
      "epoch n°3292 : train_loss = 2.0313773155212402, val_loss = 0.7946619987487793\n",
      "epoch n°3293 : train_loss = 2.0308611392974854, val_loss = 0.7973540425300598\n",
      "epoch n°3294 : train_loss = 2.0328381061553955, val_loss = 0.7915101647377014\n",
      "epoch n°3295 : train_loss = 2.0301642417907715, val_loss = 0.791397213935852\n",
      "epoch n°3296 : train_loss = 2.0378057956695557, val_loss = 0.7912258505821228\n",
      "epoch n°3297 : train_loss = 2.03609037399292, val_loss = 0.7926450371742249\n",
      "epoch n°3298 : train_loss = 2.0364110469818115, val_loss = 0.790140688419342\n",
      "epoch n°3299 : train_loss = 2.0280673503875732, val_loss = 0.7912741899490356\n",
      "epoch n°3300 : train_loss = 2.0261409282684326, val_loss = 0.7919699549674988\n",
      "epoch n°3301 : train_loss = 2.033391237258911, val_loss = 0.7965865731239319\n",
      "epoch n°3302 : train_loss = 2.04536509513855, val_loss = 0.7918262481689453\n",
      "epoch n°3303 : train_loss = 2.0234198570251465, val_loss = 0.7894768714904785\n",
      "epoch n°3304 : train_loss = 2.0262820720672607, val_loss = 0.7942590713500977\n",
      "epoch n°3305 : train_loss = 2.0349409580230713, val_loss = 0.7937794923782349\n",
      "epoch n°3306 : train_loss = 2.0351309776306152, val_loss = 0.7917146682739258\n",
      "epoch n°3307 : train_loss = 2.0254664421081543, val_loss = 0.7889100313186646\n",
      "epoch n°3308 : train_loss = 2.0405359268188477, val_loss = 0.7931267619132996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°3309 : train_loss = 2.0315921306610107, val_loss = 0.7918734550476074\n",
      "epoch n°3310 : train_loss = 2.03531813621521, val_loss = 0.7940924763679504\n",
      "epoch n°3311 : train_loss = 2.039156913757324, val_loss = 0.7935526967048645\n",
      "epoch n°3312 : train_loss = 2.023803234100342, val_loss = 0.7956115007400513\n",
      "epoch n°3313 : train_loss = 2.0278797149658203, val_loss = 0.7961307168006897\n",
      "epoch n°3314 : train_loss = 2.029573678970337, val_loss = 0.7951270937919617\n",
      "epoch n°3315 : train_loss = 2.040356397628784, val_loss = 0.7905092239379883\n",
      "epoch n°3316 : train_loss = 2.028373956680298, val_loss = 0.7959811687469482\n",
      "epoch n°3317 : train_loss = 2.0353100299835205, val_loss = 0.7897055149078369\n",
      "epoch n°3318 : train_loss = 2.033750295639038, val_loss = 0.7919362783432007\n",
      "epoch n°3319 : train_loss = 2.0294511318206787, val_loss = 0.7924994826316833\n",
      "epoch n°3320 : train_loss = 2.0310966968536377, val_loss = 0.7897738814353943\n",
      "epoch n°3321 : train_loss = 2.0377535820007324, val_loss = 0.7863073348999023\n",
      "epoch n°3322 : train_loss = 2.035755157470703, val_loss = 0.7950248122215271\n",
      "epoch n°3323 : train_loss = 2.037527322769165, val_loss = 0.7902328372001648\n",
      "epoch n°3324 : train_loss = 2.019439935684204, val_loss = 0.794333815574646\n",
      "epoch n°3325 : train_loss = 2.030423402786255, val_loss = 0.7908325791358948\n",
      "epoch n°3326 : train_loss = 2.0377063751220703, val_loss = 0.7948141098022461\n",
      "epoch n°3327 : train_loss = 2.026733875274658, val_loss = 0.7912670373916626\n",
      "epoch n°3328 : train_loss = 2.037200689315796, val_loss = 0.792977511882782\n",
      "epoch n°3329 : train_loss = 2.02951717376709, val_loss = 0.7959652543067932\n",
      "epoch n°3330 : train_loss = 2.037172555923462, val_loss = 0.7914506793022156\n",
      "epoch n°3331 : train_loss = 2.033597946166992, val_loss = 0.7968170642852783\n",
      "epoch n°3332 : train_loss = 2.019768714904785, val_loss = 0.7913067936897278\n",
      "epoch n°3333 : train_loss = 2.0327792167663574, val_loss = 0.7895658016204834\n",
      "epoch n°3334 : train_loss = 2.0249428749084473, val_loss = 0.7945576906204224\n",
      "epoch n°3335 : train_loss = 2.0248005390167236, val_loss = 0.7883517742156982\n",
      "epoch n°3336 : train_loss = 2.040231704711914, val_loss = 0.7937746644020081\n",
      "epoch n°3337 : train_loss = 2.032735586166382, val_loss = 0.796583354473114\n",
      "epoch n°3338 : train_loss = 2.0310792922973633, val_loss = 0.7911664843559265\n",
      "epoch n°3339 : train_loss = 2.031099557876587, val_loss = 0.7951611280441284\n",
      "epoch n°3340 : train_loss = 2.0267605781555176, val_loss = 0.7934854030609131\n",
      "epoch n°3341 : train_loss = 2.020220994949341, val_loss = 0.7927221059799194\n",
      "epoch n°3342 : train_loss = 2.0378458499908447, val_loss = 0.7910730242729187\n",
      "epoch n°3343 : train_loss = 2.034072160720825, val_loss = 0.7947630286216736\n",
      "epoch n°3344 : train_loss = 2.0350658893585205, val_loss = 0.7921514511108398\n",
      "epoch n°3345 : train_loss = 2.0310349464416504, val_loss = 0.7933043241500854\n",
      "epoch n°3346 : train_loss = 2.023021697998047, val_loss = 0.7928592562675476\n",
      "epoch n°3347 : train_loss = 2.0340418815612793, val_loss = 0.7941095232963562\n",
      "epoch n°3348 : train_loss = 2.031726121902466, val_loss = 0.792489230632782\n",
      "epoch n°3349 : train_loss = 2.0285606384277344, val_loss = 0.7901560664176941\n",
      "epoch n°3350 : train_loss = 2.0316662788391113, val_loss = 0.7969186305999756\n",
      "epoch n°3351 : train_loss = 2.0328922271728516, val_loss = 0.790256917476654\n",
      "epoch n°3352 : train_loss = 2.020296812057495, val_loss = 0.794583797454834\n",
      "epoch n°3353 : train_loss = 2.0357420444488525, val_loss = 0.7929857969284058\n",
      "epoch n°3354 : train_loss = 2.0350513458251953, val_loss = 0.7914391756057739\n",
      "epoch n°3355 : train_loss = 2.0233592987060547, val_loss = 0.7898350954055786\n",
      "epoch n°3356 : train_loss = 2.032071828842163, val_loss = 0.7928113341331482\n",
      "epoch n°3357 : train_loss = 2.0331966876983643, val_loss = 0.7923272252082825\n",
      "epoch n°3358 : train_loss = 2.0345213413238525, val_loss = 0.7918652296066284\n",
      "epoch n°3359 : train_loss = 2.027751922607422, val_loss = 0.7929627895355225\n",
      "epoch n°3360 : train_loss = 2.027195692062378, val_loss = 0.7908942699432373\n",
      "epoch n°3361 : train_loss = 2.025362014770508, val_loss = 0.7888163924217224\n",
      "epoch n°3362 : train_loss = 2.0170061588287354, val_loss = 0.7920166850090027\n",
      "epoch n°3363 : train_loss = 2.027691602706909, val_loss = 0.7897741198539734\n",
      "epoch n°3364 : train_loss = 2.028639078140259, val_loss = 0.790947675704956\n",
      "epoch n°3365 : train_loss = 2.028057813644409, val_loss = 0.7931024432182312\n",
      "epoch n°3366 : train_loss = 2.0306286811828613, val_loss = 0.7976973056793213\n",
      "epoch n°3367 : train_loss = 2.0316269397735596, val_loss = 0.7922396063804626\n",
      "epoch n°3368 : train_loss = 2.023209571838379, val_loss = 0.7965911626815796\n",
      "epoch n°3369 : train_loss = 2.02663516998291, val_loss = 0.7976532578468323\n",
      "epoch n°3370 : train_loss = 2.0342719554901123, val_loss = 0.7910170555114746\n",
      "epoch n°3371 : train_loss = 2.031209945678711, val_loss = 0.7926985025405884\n",
      "epoch n°3372 : train_loss = 2.028174877166748, val_loss = 0.7930265069007874\n",
      "epoch n°3373 : train_loss = 2.033872604370117, val_loss = 0.7957488298416138\n",
      "epoch n°3374 : train_loss = 2.029752492904663, val_loss = 0.7915441989898682\n",
      "epoch n°3375 : train_loss = 2.0333023071289062, val_loss = 0.7914835214614868\n",
      "epoch n°3376 : train_loss = 2.030130624771118, val_loss = 0.7885591983795166\n",
      "epoch n°3377 : train_loss = 2.038208484649658, val_loss = 0.7909843921661377\n",
      "epoch n°3378 : train_loss = 2.0324549674987793, val_loss = 0.7916093468666077\n",
      "epoch n°3379 : train_loss = 2.0231082439422607, val_loss = 0.7862206101417542\n",
      "epoch n°3380 : train_loss = 2.0333642959594727, val_loss = 0.7923109531402588\n",
      "epoch n°3381 : train_loss = 2.0246617794036865, val_loss = 0.7928292155265808\n",
      "epoch n°3382 : train_loss = 2.03818416595459, val_loss = 0.7878783345222473\n",
      "epoch n°3383 : train_loss = 2.034633159637451, val_loss = 0.7946430444717407\n",
      "epoch n°3384 : train_loss = 2.0190680027008057, val_loss = 0.7906070947647095\n",
      "epoch n°3385 : train_loss = 2.02695369720459, val_loss = 0.7937464118003845\n",
      "epoch n°3386 : train_loss = 2.032236337661743, val_loss = 0.7926538586616516\n",
      "epoch n°3387 : train_loss = 2.0167407989501953, val_loss = 0.7910969257354736\n",
      "epoch n°3388 : train_loss = 2.033640146255493, val_loss = 0.7890405058860779\n",
      "epoch n°3389 : train_loss = 2.0332248210906982, val_loss = 0.7943885326385498\n",
      "epoch n°3390 : train_loss = 2.0283327102661133, val_loss = 0.7911427021026611\n",
      "epoch n°3391 : train_loss = 2.0273797512054443, val_loss = 0.7962067127227783\n",
      "epoch n°3392 : train_loss = 2.031855583190918, val_loss = 0.7929213047027588\n",
      "epoch n°3393 : train_loss = 2.0266268253326416, val_loss = 0.795116126537323\n",
      "epoch n°3394 : train_loss = 2.021437644958496, val_loss = 0.7897866368293762\n",
      "epoch n°3395 : train_loss = 2.027259349822998, val_loss = 0.791100025177002\n",
      "epoch n°3396 : train_loss = 2.024291515350342, val_loss = 0.7963846325874329\n",
      "epoch n°3397 : train_loss = 2.029393196105957, val_loss = 0.7911337614059448\n",
      "epoch n°3398 : train_loss = 2.0341639518737793, val_loss = 0.7940356135368347\n",
      "epoch n°3399 : train_loss = 2.0374433994293213, val_loss = 0.7902345657348633\n",
      "epoch n°3400 : train_loss = 2.03047513961792, val_loss = 0.7916435599327087\n",
      "epoch n°3401 : train_loss = 2.021963596343994, val_loss = 0.790931761264801\n",
      "epoch n°3402 : train_loss = 2.029038667678833, val_loss = 0.7898141741752625\n",
      "epoch n°3403 : train_loss = 2.0262386798858643, val_loss = 0.7910404205322266\n",
      "epoch n°3404 : train_loss = 2.027906656265259, val_loss = 0.790813148021698\n",
      "epoch n°3405 : train_loss = 2.02751088142395, val_loss = 0.7892677187919617\n",
      "epoch n°3406 : train_loss = 2.02158260345459, val_loss = 0.7934490442276001\n",
      "epoch n°3407 : train_loss = 2.029754161834717, val_loss = 0.792487621307373\n",
      "epoch n°3408 : train_loss = 2.0309789180755615, val_loss = 0.7922161221504211\n",
      "epoch n°3409 : train_loss = 2.0259294509887695, val_loss = 0.7949743270874023\n",
      "epoch n°3410 : train_loss = 2.0246846675872803, val_loss = 0.7937963604927063\n",
      "epoch n°3411 : train_loss = 2.0313327312469482, val_loss = 0.7962870001792908\n",
      "epoch n°3412 : train_loss = 2.0192272663116455, val_loss = 0.7909093499183655\n",
      "epoch n°3413 : train_loss = 2.0301241874694824, val_loss = 0.7932347059249878\n",
      "epoch n°3414 : train_loss = 2.0278854370117188, val_loss = 0.7892665266990662\n",
      "epoch n°3415 : train_loss = 2.033799409866333, val_loss = 0.7908555865287781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°3416 : train_loss = 2.038238048553467, val_loss = 0.7966295480728149\n",
      "epoch n°3417 : train_loss = 2.0394041538238525, val_loss = 0.7889423966407776\n",
      "epoch n°3418 : train_loss = 2.026616334915161, val_loss = 0.7876806855201721\n",
      "epoch n°3419 : train_loss = 2.03572940826416, val_loss = 0.790361762046814\n",
      "epoch n°3420 : train_loss = 2.029482841491699, val_loss = 0.7954167127609253\n",
      "epoch n°3421 : train_loss = 2.0228984355926514, val_loss = 0.7934736013412476\n",
      "epoch n°3422 : train_loss = 2.0330634117126465, val_loss = 0.7929393649101257\n",
      "epoch n°3423 : train_loss = 2.030689239501953, val_loss = 0.7963622212409973\n",
      "epoch n°3424 : train_loss = 2.031421661376953, val_loss = 0.7935289740562439\n",
      "epoch n°3425 : train_loss = 2.0354578495025635, val_loss = 0.7934752702713013\n",
      "epoch n°3426 : train_loss = 2.0306906700134277, val_loss = 0.7941861748695374\n",
      "epoch n°3427 : train_loss = 2.0269434452056885, val_loss = 0.7930223345756531\n",
      "epoch n°3428 : train_loss = 2.0278053283691406, val_loss = 0.7961651682853699\n",
      "epoch n°3429 : train_loss = 2.0241565704345703, val_loss = 0.7914056777954102\n",
      "epoch n°3430 : train_loss = 2.019310474395752, val_loss = 0.7948912978172302\n",
      "epoch n°3431 : train_loss = 2.031118869781494, val_loss = 0.7921837568283081\n",
      "epoch n°3432 : train_loss = 2.0311412811279297, val_loss = 0.7918463945388794\n",
      "epoch n°3433 : train_loss = 2.032238006591797, val_loss = 0.7890301942825317\n",
      "epoch n°3434 : train_loss = 2.0263116359710693, val_loss = 0.7888603806495667\n",
      "epoch n°3435 : train_loss = 2.0361125469207764, val_loss = 0.7892455458641052\n",
      "epoch n°3436 : train_loss = 2.0317249298095703, val_loss = 0.7945771217346191\n",
      "epoch n°3437 : train_loss = 2.0230448246002197, val_loss = 0.7960638403892517\n",
      "epoch n°3438 : train_loss = 2.028740882873535, val_loss = 0.7906925082206726\n",
      "epoch n°3439 : train_loss = 2.031919240951538, val_loss = 0.7955524921417236\n",
      "epoch n°3440 : train_loss = 2.025906562805176, val_loss = 0.7882659435272217\n",
      "epoch n°3441 : train_loss = 2.0282912254333496, val_loss = 0.7927422523498535\n",
      "epoch n°3442 : train_loss = 2.0327916145324707, val_loss = 0.7926852703094482\n",
      "epoch n°3443 : train_loss = 2.0344154834747314, val_loss = 0.791999876499176\n",
      "epoch n°3444 : train_loss = 2.033806800842285, val_loss = 0.7962505221366882\n",
      "epoch n°3445 : train_loss = 2.02584171295166, val_loss = 0.7950763702392578\n",
      "epoch n°3446 : train_loss = 2.0255398750305176, val_loss = 0.7926579713821411\n",
      "epoch n°3447 : train_loss = 2.0247786045074463, val_loss = 0.7953757047653198\n",
      "epoch n°3448 : train_loss = 2.0270299911499023, val_loss = 0.7904294729232788\n",
      "epoch n°3449 : train_loss = 2.036115884780884, val_loss = 0.7921887636184692\n",
      "epoch n°3450 : train_loss = 2.0312654972076416, val_loss = 0.791222095489502\n",
      "epoch n°3451 : train_loss = 2.028242826461792, val_loss = 0.7963050603866577\n",
      "epoch n°3452 : train_loss = 2.0263450145721436, val_loss = 0.7878690958023071\n",
      "epoch n°3453 : train_loss = 2.018594741821289, val_loss = 0.7893261313438416\n",
      "epoch n°3454 : train_loss = 2.029486656188965, val_loss = 0.7949574589729309\n",
      "epoch n°3455 : train_loss = 2.0245776176452637, val_loss = 0.7960973978042603\n",
      "epoch n°3456 : train_loss = 2.0274553298950195, val_loss = 0.8003415465354919\n",
      "epoch n°3457 : train_loss = 2.016700267791748, val_loss = 0.7920780181884766\n",
      "epoch n°3458 : train_loss = 2.024561882019043, val_loss = 0.7936262488365173\n",
      "epoch n°3459 : train_loss = 2.0229079723358154, val_loss = 0.7919726967811584\n",
      "epoch n°3460 : train_loss = 2.0197064876556396, val_loss = 0.7919996976852417\n",
      "epoch n°3461 : train_loss = 2.031583070755005, val_loss = 0.7959949374198914\n",
      "epoch n°3462 : train_loss = 2.029749631881714, val_loss = 0.7856802940368652\n",
      "epoch n°3463 : train_loss = 2.023440361022949, val_loss = 0.7914797067642212\n",
      "epoch n°3464 : train_loss = 2.0246334075927734, val_loss = 0.7922587394714355\n",
      "epoch n°3465 : train_loss = 2.0294086933135986, val_loss = 0.7928023338317871\n",
      "epoch n°3466 : train_loss = 2.0360300540924072, val_loss = 0.791212797164917\n",
      "epoch n°3467 : train_loss = 2.02371883392334, val_loss = 0.7912508845329285\n",
      "epoch n°3468 : train_loss = 2.019200325012207, val_loss = 0.7941994071006775\n",
      "epoch n°3469 : train_loss = 2.025214672088623, val_loss = 0.79347163438797\n",
      "epoch n°3470 : train_loss = 2.018862724304199, val_loss = 0.7973353266716003\n",
      "epoch n°3471 : train_loss = 2.0354244709014893, val_loss = 0.7963313460350037\n",
      "epoch n°3472 : train_loss = 2.022944450378418, val_loss = 0.7898088097572327\n",
      "epoch n°3473 : train_loss = 2.028148651123047, val_loss = 0.7905058264732361\n",
      "epoch n°3474 : train_loss = 2.028151273727417, val_loss = 0.789548933506012\n",
      "epoch n°3475 : train_loss = 2.0313711166381836, val_loss = 0.7966802716255188\n",
      "epoch n°3476 : train_loss = 2.0255651473999023, val_loss = 0.7952730655670166\n",
      "epoch n°3477 : train_loss = 2.02380633354187, val_loss = 0.7910841703414917\n",
      "epoch n°3478 : train_loss = 2.025773525238037, val_loss = 0.7880311608314514\n",
      "epoch n°3479 : train_loss = 2.0228867530822754, val_loss = 0.7941392660140991\n",
      "epoch n°3480 : train_loss = 2.0288991928100586, val_loss = 0.7934003472328186\n",
      "epoch n°3481 : train_loss = 2.0162723064422607, val_loss = 0.792350172996521\n",
      "epoch n°3482 : train_loss = 2.025188446044922, val_loss = 0.7945246696472168\n",
      "epoch n°3483 : train_loss = 2.0248918533325195, val_loss = 0.7927680015563965\n",
      "epoch n°3484 : train_loss = 2.0275425910949707, val_loss = 0.78797847032547\n",
      "epoch n°3485 : train_loss = 2.0236918926239014, val_loss = 0.7911001443862915\n",
      "epoch n°3486 : train_loss = 2.0243234634399414, val_loss = 0.7926703095436096\n",
      "epoch n°3487 : train_loss = 2.0252110958099365, val_loss = 0.7860540151596069\n",
      "epoch n°3488 : train_loss = 2.024043321609497, val_loss = 0.7926549315452576\n",
      "epoch n°3489 : train_loss = 2.0311172008514404, val_loss = 0.7889593243598938\n",
      "epoch n°3490 : train_loss = 2.0284814834594727, val_loss = 0.787928581237793\n",
      "epoch n°3491 : train_loss = 2.0234720706939697, val_loss = 0.7939103245735168\n",
      "epoch n°3492 : train_loss = 2.0275866985321045, val_loss = 0.7938409447669983\n",
      "epoch n°3493 : train_loss = 2.021078586578369, val_loss = 0.7957622408866882\n",
      "epoch n°3494 : train_loss = 2.0330569744110107, val_loss = 0.793632447719574\n",
      "epoch n°3495 : train_loss = 2.0196824073791504, val_loss = 0.7883421182632446\n",
      "epoch n°3496 : train_loss = 2.012118101119995, val_loss = 0.7946212291717529\n",
      "epoch n°3497 : train_loss = 2.0237200260162354, val_loss = 0.7935134172439575\n",
      "epoch n°3498 : train_loss = 2.0308265686035156, val_loss = 0.792047917842865\n",
      "epoch n°3499 : train_loss = 2.03171968460083, val_loss = 0.7882509827613831\n",
      "epoch n°3500 : train_loss = 2.0247738361358643, val_loss = 0.7897934913635254\n",
      "epoch n°3501 : train_loss = 2.0257740020751953, val_loss = 0.7932682037353516\n",
      "epoch n°3502 : train_loss = 2.012321949005127, val_loss = 0.7887417674064636\n",
      "epoch n°3503 : train_loss = 2.0322937965393066, val_loss = 0.7908353209495544\n",
      "epoch n°3504 : train_loss = 2.0148727893829346, val_loss = 0.7930512428283691\n",
      "epoch n°3505 : train_loss = 2.039724349975586, val_loss = 0.7959301471710205\n",
      "epoch n°3506 : train_loss = 2.035944938659668, val_loss = 0.7892340421676636\n",
      "epoch n°3507 : train_loss = 2.0277955532073975, val_loss = 0.7936994433403015\n",
      "epoch n°3508 : train_loss = 2.025291919708252, val_loss = 0.7904552817344666\n",
      "epoch n°3509 : train_loss = 2.0264360904693604, val_loss = 0.7922013401985168\n",
      "epoch n°3510 : train_loss = 2.0240869522094727, val_loss = 0.7884842753410339\n",
      "epoch n°3511 : train_loss = 2.021294593811035, val_loss = 0.7900454998016357\n",
      "epoch n°3512 : train_loss = 2.014770746231079, val_loss = 0.7898365259170532\n",
      "epoch n°3513 : train_loss = 2.0217716693878174, val_loss = 0.7876961827278137\n",
      "epoch n°3514 : train_loss = 2.0313026905059814, val_loss = 0.7936071157455444\n",
      "epoch n°3515 : train_loss = 2.026966094970703, val_loss = 0.7901972532272339\n",
      "epoch n°3516 : train_loss = 2.0230438709259033, val_loss = 0.7948137521743774\n",
      "epoch n°3517 : train_loss = 2.030482292175293, val_loss = 0.7944008708000183\n",
      "epoch n°3518 : train_loss = 2.0253567695617676, val_loss = 0.7914087772369385\n",
      "epoch n°3519 : train_loss = 2.033203363418579, val_loss = 0.7912487387657166\n",
      "epoch n°3520 : train_loss = 2.0217859745025635, val_loss = 0.7931626439094543\n",
      "epoch n°3521 : train_loss = 2.030414342880249, val_loss = 0.788394033908844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°3522 : train_loss = 2.027547597885132, val_loss = 0.7878039479255676\n",
      "epoch n°3523 : train_loss = 2.0225868225097656, val_loss = 0.7954515814781189\n",
      "epoch n°3524 : train_loss = 2.0279226303100586, val_loss = 0.7919180393218994\n",
      "epoch n°3525 : train_loss = 2.026055335998535, val_loss = 0.7923033833503723\n",
      "epoch n°3526 : train_loss = 2.025651454925537, val_loss = 0.7926830649375916\n",
      "epoch n°3527 : train_loss = 2.022967576980591, val_loss = 0.7974276542663574\n",
      "epoch n°3528 : train_loss = 2.031094551086426, val_loss = 0.7953699231147766\n",
      "epoch n°3529 : train_loss = 2.021524667739868, val_loss = 0.7890104055404663\n",
      "epoch n°3530 : train_loss = 2.0145344734191895, val_loss = 0.7921067476272583\n",
      "epoch n°3531 : train_loss = 2.0221331119537354, val_loss = 0.7927387952804565\n",
      "epoch n°3532 : train_loss = 2.0270001888275146, val_loss = 0.7934428453445435\n",
      "epoch n°3533 : train_loss = 2.0271999835968018, val_loss = 0.7969607710838318\n",
      "epoch n°3534 : train_loss = 2.0211281776428223, val_loss = 0.7894147038459778\n",
      "epoch n°3535 : train_loss = 2.017881155014038, val_loss = 0.7907009124755859\n",
      "epoch n°3536 : train_loss = 2.026338815689087, val_loss = 0.7977501153945923\n",
      "epoch n°3537 : train_loss = 2.0169153213500977, val_loss = 0.7927850484848022\n",
      "epoch n°3538 : train_loss = 2.015669584274292, val_loss = 0.7931168675422668\n",
      "epoch n°3539 : train_loss = 2.0263495445251465, val_loss = 0.7939627766609192\n",
      "epoch n°3540 : train_loss = 2.0266058444976807, val_loss = 0.7920302748680115\n",
      "epoch n°3541 : train_loss = 2.022407293319702, val_loss = 0.7915778160095215\n",
      "epoch n°3542 : train_loss = 2.0213205814361572, val_loss = 0.7888473272323608\n",
      "epoch n°3543 : train_loss = 2.0205211639404297, val_loss = 0.7920916676521301\n",
      "epoch n°3544 : train_loss = 2.0171661376953125, val_loss = 0.7932975888252258\n",
      "epoch n°3545 : train_loss = 2.0208494663238525, val_loss = 0.790074348449707\n",
      "epoch n°3546 : train_loss = 2.015717029571533, val_loss = 0.7862196564674377\n",
      "epoch n°3547 : train_loss = 2.027554750442505, val_loss = 0.787654459476471\n",
      "epoch n°3548 : train_loss = 2.0240137577056885, val_loss = 0.7976894378662109\n",
      "epoch n°3549 : train_loss = 2.0298850536346436, val_loss = 0.7920805811882019\n",
      "epoch n°3550 : train_loss = 2.0218617916107178, val_loss = 0.7931065559387207\n",
      "epoch n°3551 : train_loss = 2.021984100341797, val_loss = 0.7941485643386841\n",
      "epoch n°3552 : train_loss = 2.020949602127075, val_loss = 0.7887343764305115\n",
      "epoch n°3553 : train_loss = 2.0193934440612793, val_loss = 0.7921371459960938\n",
      "epoch n°3554 : train_loss = 2.014566421508789, val_loss = 0.7900757789611816\n",
      "epoch n°3555 : train_loss = 2.0256800651550293, val_loss = 0.7918528318405151\n",
      "epoch n°3556 : train_loss = 2.0248591899871826, val_loss = 0.7900745868682861\n",
      "epoch n°3557 : train_loss = 2.014376401901245, val_loss = 0.7986143231391907\n",
      "epoch n°3558 : train_loss = 2.0226762294769287, val_loss = 0.7934517860412598\n",
      "epoch n°3559 : train_loss = 2.022521495819092, val_loss = 0.7910867929458618\n",
      "epoch n°3560 : train_loss = 2.0246827602386475, val_loss = 0.7917194962501526\n",
      "epoch n°3561 : train_loss = 2.0206336975097656, val_loss = 0.7904184460639954\n",
      "epoch n°3562 : train_loss = 2.020547389984131, val_loss = 0.7906204462051392\n",
      "epoch n°3563 : train_loss = 2.018265962600708, val_loss = 0.7936408519744873\n",
      "epoch n°3564 : train_loss = 2.0261294841766357, val_loss = 0.7991175651550293\n",
      "epoch n°3565 : train_loss = 2.022490978240967, val_loss = 0.7914771437644958\n",
      "epoch n°3566 : train_loss = 2.0144975185394287, val_loss = 0.7919750809669495\n",
      "epoch n°3567 : train_loss = 2.0290725231170654, val_loss = 0.7880210280418396\n",
      "epoch n°3568 : train_loss = 2.024524688720703, val_loss = 0.7916448712348938\n",
      "epoch n°3569 : train_loss = 2.0256876945495605, val_loss = 0.7933214902877808\n",
      "epoch n°3570 : train_loss = 2.033297538757324, val_loss = 0.7928319573402405\n",
      "epoch n°3571 : train_loss = 2.0249786376953125, val_loss = 0.788026750087738\n",
      "epoch n°3572 : train_loss = 2.0248851776123047, val_loss = 0.7923212051391602\n",
      "epoch n°3573 : train_loss = 2.017838954925537, val_loss = 0.7913750410079956\n",
      "epoch n°3574 : train_loss = 2.0278587341308594, val_loss = 0.7913548946380615\n",
      "epoch n°3575 : train_loss = 2.025233268737793, val_loss = 0.7924792170524597\n",
      "epoch n°3576 : train_loss = 2.0269615650177, val_loss = 0.7892696261405945\n",
      "epoch n°3577 : train_loss = 2.013422966003418, val_loss = 0.7875714302062988\n",
      "epoch n°3578 : train_loss = 2.019392490386963, val_loss = 0.7904469966888428\n",
      "epoch n°3579 : train_loss = 2.017524242401123, val_loss = 0.7901058197021484\n",
      "epoch n°3580 : train_loss = 2.0171115398406982, val_loss = 0.7881191968917847\n",
      "epoch n°3581 : train_loss = 2.017425775527954, val_loss = 0.7937933206558228\n",
      "epoch n°3582 : train_loss = 2.02949595451355, val_loss = 0.7913910746574402\n",
      "epoch n°3583 : train_loss = 2.0283257961273193, val_loss = 0.7892522811889648\n",
      "epoch n°3584 : train_loss = 2.024796962738037, val_loss = 0.7920077443122864\n",
      "epoch n°3585 : train_loss = 2.019021511077881, val_loss = 0.7922157645225525\n",
      "epoch n°3586 : train_loss = 2.0213277339935303, val_loss = 0.7906661629676819\n",
      "epoch n°3587 : train_loss = 2.0174050331115723, val_loss = 0.7907555103302002\n",
      "epoch n°3588 : train_loss = 2.0216104984283447, val_loss = 0.7932596206665039\n",
      "epoch n°3589 : train_loss = 2.0185000896453857, val_loss = 0.7956076860427856\n",
      "epoch n°3590 : train_loss = 2.027508020401001, val_loss = 0.7929903864860535\n",
      "epoch n°3591 : train_loss = 2.024651288986206, val_loss = 0.7941702604293823\n",
      "epoch n°3592 : train_loss = 2.0155115127563477, val_loss = 0.7900657653808594\n",
      "epoch n°3593 : train_loss = 2.028871774673462, val_loss = 0.7920997142791748\n",
      "epoch n°3594 : train_loss = 2.0223233699798584, val_loss = 0.7946100831031799\n",
      "epoch n°3595 : train_loss = 2.0239198207855225, val_loss = 0.7903221249580383\n",
      "epoch n°3596 : train_loss = 2.0275590419769287, val_loss = 0.7942460775375366\n",
      "epoch n°3597 : train_loss = 2.0165507793426514, val_loss = 0.7933225035667419\n",
      "epoch n°3598 : train_loss = 2.0195751190185547, val_loss = 0.7947900295257568\n",
      "epoch n°3599 : train_loss = 2.0226058959960938, val_loss = 0.7953330278396606\n",
      "epoch n°3600 : train_loss = 2.017923593521118, val_loss = 0.7916397452354431\n",
      "epoch n°3601 : train_loss = 2.0207860469818115, val_loss = 0.7920355796813965\n",
      "epoch n°3602 : train_loss = 2.0251471996307373, val_loss = 0.7940250039100647\n",
      "epoch n°3603 : train_loss = 2.022608757019043, val_loss = 0.7926856279373169\n",
      "epoch n°3604 : train_loss = 2.029207468032837, val_loss = 0.7944663763046265\n",
      "epoch n°3605 : train_loss = 2.0234436988830566, val_loss = 0.7889710664749146\n",
      "epoch n°3606 : train_loss = 2.022312641143799, val_loss = 0.7916519641876221\n",
      "epoch n°3607 : train_loss = 2.027238607406616, val_loss = 0.7899425029754639\n",
      "epoch n°3608 : train_loss = 2.0152666568756104, val_loss = 0.7917153835296631\n",
      "epoch n°3609 : train_loss = 2.0294694900512695, val_loss = 0.795781672000885\n",
      "epoch n°3610 : train_loss = 2.0221126079559326, val_loss = 0.7888060808181763\n",
      "epoch n°3611 : train_loss = 2.025526762008667, val_loss = 0.7961204051971436\n",
      "epoch n°3612 : train_loss = 2.0154342651367188, val_loss = 0.7884399890899658\n",
      "epoch n°3613 : train_loss = 2.0215792655944824, val_loss = 0.7902839183807373\n",
      "epoch n°3614 : train_loss = 2.019578456878662, val_loss = 0.7919288873672485\n",
      "epoch n°3615 : train_loss = 2.0215165615081787, val_loss = 0.7947628498077393\n",
      "epoch n°3616 : train_loss = 2.023092031478882, val_loss = 0.7899361848831177\n",
      "epoch n°3617 : train_loss = 2.020400285720825, val_loss = 0.7915366291999817\n",
      "epoch n°3618 : train_loss = 2.0202178955078125, val_loss = 0.7892192602157593\n",
      "epoch n°3619 : train_loss = 2.025862216949463, val_loss = 0.7905627489089966\n",
      "epoch n°3620 : train_loss = 2.0155467987060547, val_loss = 0.7922387719154358\n",
      "epoch n°3621 : train_loss = 2.0261924266815186, val_loss = 0.7892856597900391\n",
      "epoch n°3622 : train_loss = 2.0238053798675537, val_loss = 0.7903385758399963\n",
      "epoch n°3623 : train_loss = 2.018157720565796, val_loss = 0.7877702713012695\n",
      "epoch n°3624 : train_loss = 2.018044948577881, val_loss = 0.7934367656707764\n",
      "epoch n°3625 : train_loss = 2.024458408355713, val_loss = 0.7926703691482544\n",
      "epoch n°3626 : train_loss = 2.0286943912506104, val_loss = 0.7932642698287964\n",
      "epoch n°3627 : train_loss = 2.024906873703003, val_loss = 0.7925381660461426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°3628 : train_loss = 2.0283212661743164, val_loss = 0.7917956709861755\n",
      "epoch n°3629 : train_loss = 2.0234804153442383, val_loss = 0.7929254770278931\n",
      "epoch n°3630 : train_loss = 2.021559953689575, val_loss = 0.7876308560371399\n",
      "epoch n°3631 : train_loss = 2.022686719894409, val_loss = 0.7926648855209351\n",
      "epoch n°3632 : train_loss = 2.01955246925354, val_loss = 0.7910313010215759\n",
      "epoch n°3633 : train_loss = 2.0253379344940186, val_loss = 0.7902359366416931\n",
      "epoch n°3634 : train_loss = 2.020163059234619, val_loss = 0.7906777262687683\n",
      "epoch n°3635 : train_loss = 2.014739513397217, val_loss = 0.79071444272995\n",
      "epoch n°3636 : train_loss = 2.0266919136047363, val_loss = 0.7917569279670715\n",
      "epoch n°3637 : train_loss = 2.032547950744629, val_loss = 0.7937561869621277\n",
      "epoch n°3638 : train_loss = 2.0209336280822754, val_loss = 0.7971866726875305\n",
      "epoch n°3639 : train_loss = 2.0195672512054443, val_loss = 0.7934920191764832\n",
      "epoch n°3640 : train_loss = 2.021026134490967, val_loss = 0.7945191264152527\n",
      "epoch n°3641 : train_loss = 2.0309858322143555, val_loss = 0.794721782207489\n",
      "epoch n°3642 : train_loss = 2.0271427631378174, val_loss = 0.7916246652603149\n",
      "epoch n°3643 : train_loss = 2.0168371200561523, val_loss = 0.789056122303009\n",
      "epoch n°3644 : train_loss = 2.0185742378234863, val_loss = 0.7897791266441345\n",
      "epoch n°3645 : train_loss = 2.026533842086792, val_loss = 0.7953748106956482\n",
      "epoch n°3646 : train_loss = 2.019840955734253, val_loss = 0.791455864906311\n",
      "epoch n°3647 : train_loss = 2.019005298614502, val_loss = 0.7899513244628906\n",
      "epoch n°3648 : train_loss = 2.030472755432129, val_loss = 0.7884430289268494\n",
      "epoch n°3649 : train_loss = 2.019388437271118, val_loss = 0.7939335107803345\n",
      "epoch n°3650 : train_loss = 2.0229454040527344, val_loss = 0.7949529886245728\n",
      "epoch n°3651 : train_loss = 2.0156090259552, val_loss = 0.7951049208641052\n",
      "epoch n°3652 : train_loss = 2.023853302001953, val_loss = 0.7902710437774658\n",
      "epoch n°3653 : train_loss = 2.0268640518188477, val_loss = 0.7886360287666321\n",
      "epoch n°3654 : train_loss = 2.0134503841400146, val_loss = 0.7910876274108887\n",
      "epoch n°3655 : train_loss = 2.025019645690918, val_loss = 0.794001579284668\n",
      "epoch n°3656 : train_loss = 2.0328316688537598, val_loss = 0.7905690670013428\n",
      "epoch n°3657 : train_loss = 2.0290989875793457, val_loss = 0.7932394742965698\n",
      "epoch n°3658 : train_loss = 2.0211379528045654, val_loss = 0.7892440557479858\n",
      "epoch n°3659 : train_loss = 2.022273063659668, val_loss = 0.7911829948425293\n",
      "epoch n°3660 : train_loss = 2.023650884628296, val_loss = 0.7920847535133362\n",
      "epoch n°3661 : train_loss = 2.0217480659484863, val_loss = 0.7973155379295349\n",
      "epoch n°3662 : train_loss = 2.0197365283966064, val_loss = 0.7893555164337158\n",
      "epoch n°3663 : train_loss = 2.0311338901519775, val_loss = 0.791545033454895\n",
      "epoch n°3664 : train_loss = 2.0162711143493652, val_loss = 0.7934682965278625\n",
      "epoch n°3665 : train_loss = 2.021509885787964, val_loss = 0.7938704490661621\n",
      "epoch n°3666 : train_loss = 2.0210845470428467, val_loss = 0.7884966135025024\n",
      "epoch n°3667 : train_loss = 2.022101879119873, val_loss = 0.7887423038482666\n",
      "epoch n°3668 : train_loss = 2.0221312046051025, val_loss = 0.7880098819732666\n",
      "epoch n°3669 : train_loss = 2.0200746059417725, val_loss = 0.7907763123512268\n",
      "epoch n°3670 : train_loss = 2.028223991394043, val_loss = 0.7865930199623108\n",
      "epoch n°3671 : train_loss = 2.0099802017211914, val_loss = 0.792219877243042\n",
      "epoch n°3672 : train_loss = 2.01751446723938, val_loss = 0.7889813184738159\n",
      "epoch n°3673 : train_loss = 2.014799118041992, val_loss = 0.7925969362258911\n",
      "epoch n°3674 : train_loss = 2.0148541927337646, val_loss = 0.793506920337677\n",
      "epoch n°3675 : train_loss = 2.0220766067504883, val_loss = 0.7951679825782776\n",
      "epoch n°3676 : train_loss = 2.025780200958252, val_loss = 0.7886740565299988\n",
      "epoch n°3677 : train_loss = 2.0326478481292725, val_loss = 0.789638102054596\n",
      "epoch n°3678 : train_loss = 2.0193140506744385, val_loss = 0.7950316667556763\n",
      "epoch n°3679 : train_loss = 2.0225701332092285, val_loss = 0.7950155735015869\n",
      "epoch n°3680 : train_loss = 2.029665231704712, val_loss = 0.791137158870697\n",
      "epoch n°3681 : train_loss = 2.009852647781372, val_loss = 0.7872319221496582\n",
      "epoch n°3682 : train_loss = 2.0186409950256348, val_loss = 0.7927518486976624\n",
      "epoch n°3683 : train_loss = 2.0242016315460205, val_loss = 0.7918123006820679\n",
      "epoch n°3684 : train_loss = 2.0276150703430176, val_loss = 0.7905659675598145\n",
      "epoch n°3685 : train_loss = 2.021286725997925, val_loss = 0.7921679615974426\n",
      "epoch n°3686 : train_loss = 2.018035411834717, val_loss = 0.7923322916030884\n",
      "epoch n°3687 : train_loss = 2.018247127532959, val_loss = 0.79121333360672\n",
      "epoch n°3688 : train_loss = 2.0211024284362793, val_loss = 0.7930098176002502\n",
      "epoch n°3689 : train_loss = 2.0147175788879395, val_loss = 0.7900697588920593\n",
      "epoch n°3690 : train_loss = 2.0221307277679443, val_loss = 0.7949243187904358\n",
      "epoch n°3691 : train_loss = 2.0286049842834473, val_loss = 0.7945507764816284\n",
      "epoch n°3692 : train_loss = 2.01835560798645, val_loss = 0.7894970774650574\n",
      "epoch n°3693 : train_loss = 2.0214085578918457, val_loss = 0.7933276295661926\n",
      "epoch n°3694 : train_loss = 2.0226848125457764, val_loss = 0.7892203330993652\n",
      "epoch n°3695 : train_loss = 2.013007164001465, val_loss = 0.789478063583374\n",
      "epoch n°3696 : train_loss = 2.0269358158111572, val_loss = 0.792850136756897\n",
      "epoch n°3697 : train_loss = 2.017831563949585, val_loss = 0.7913492918014526\n",
      "epoch n°3698 : train_loss = 2.018794298171997, val_loss = 0.7893203496932983\n",
      "epoch n°3699 : train_loss = 2.0276434421539307, val_loss = 0.7888028025627136\n",
      "epoch n°3700 : train_loss = 2.022209405899048, val_loss = 0.7927258610725403\n",
      "epoch n°3701 : train_loss = 2.0305652618408203, val_loss = 0.7922683358192444\n",
      "epoch n°3702 : train_loss = 2.0283169746398926, val_loss = 0.7940767407417297\n",
      "epoch n°3703 : train_loss = 2.017854928970337, val_loss = 0.7890117764472961\n",
      "epoch n°3704 : train_loss = 2.0183393955230713, val_loss = 0.7899956703186035\n",
      "epoch n°3705 : train_loss = 2.007927894592285, val_loss = 0.7949144840240479\n",
      "epoch n°3706 : train_loss = 2.0205609798431396, val_loss = 0.7929890751838684\n",
      "epoch n°3707 : train_loss = 2.019345283508301, val_loss = 0.7946817278862\n",
      "epoch n°3708 : train_loss = 2.018742799758911, val_loss = 0.7936360239982605\n",
      "epoch n°3709 : train_loss = 2.0180716514587402, val_loss = 0.7944591641426086\n",
      "epoch n°3710 : train_loss = 2.022442102432251, val_loss = 0.7921498417854309\n",
      "epoch n°3711 : train_loss = 2.0203497409820557, val_loss = 0.7914730310440063\n",
      "epoch n°3712 : train_loss = 2.024357557296753, val_loss = 0.787916362285614\n",
      "epoch n°3713 : train_loss = 2.022592067718506, val_loss = 0.7907828688621521\n",
      "epoch n°3714 : train_loss = 2.022535562515259, val_loss = 0.7926621437072754\n",
      "epoch n°3715 : train_loss = 2.0230467319488525, val_loss = 0.7915816903114319\n",
      "epoch n°3716 : train_loss = 2.0150129795074463, val_loss = 0.7933220267295837\n",
      "epoch n°3717 : train_loss = 2.0222721099853516, val_loss = 0.7928877472877502\n",
      "epoch n°3718 : train_loss = 2.0230774879455566, val_loss = 0.7921212315559387\n",
      "epoch n°3719 : train_loss = 2.006002426147461, val_loss = 0.7934564352035522\n",
      "epoch n°3720 : train_loss = 2.0218634605407715, val_loss = 0.7893458008766174\n",
      "epoch n°3721 : train_loss = 2.018494129180908, val_loss = 0.7911404371261597\n",
      "epoch n°3722 : train_loss = 2.0256683826446533, val_loss = 0.7881482243537903\n",
      "epoch n°3723 : train_loss = 2.022916078567505, val_loss = 0.7930223941802979\n",
      "epoch n°3724 : train_loss = 2.0211164951324463, val_loss = 0.789767861366272\n",
      "epoch n°3725 : train_loss = 2.014329433441162, val_loss = 0.7911129593849182\n",
      "epoch n°3726 : train_loss = 2.0332295894622803, val_loss = 0.7942582368850708\n",
      "epoch n°3727 : train_loss = 2.0160975456237793, val_loss = 0.7919193506240845\n",
      "epoch n°3728 : train_loss = 2.0209925174713135, val_loss = 0.7917990684509277\n",
      "epoch n°3729 : train_loss = 2.0100667476654053, val_loss = 0.7869572639465332\n",
      "epoch n°3730 : train_loss = 2.023740530014038, val_loss = 0.7942520380020142\n",
      "epoch n°3731 : train_loss = 2.0168356895446777, val_loss = 0.7943968176841736\n",
      "epoch n°3732 : train_loss = 2.0226504802703857, val_loss = 0.7893117666244507\n",
      "epoch n°3733 : train_loss = 2.016143560409546, val_loss = 0.7890346646308899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°3734 : train_loss = 2.0273241996765137, val_loss = 0.7920435070991516\n",
      "epoch n°3735 : train_loss = 2.018195152282715, val_loss = 0.7911106944084167\n",
      "epoch n°3736 : train_loss = 2.0211620330810547, val_loss = 0.7954918146133423\n",
      "epoch n°3737 : train_loss = 2.018415927886963, val_loss = 0.7935808300971985\n",
      "epoch n°3738 : train_loss = 2.021836519241333, val_loss = 0.7934287190437317\n",
      "epoch n°3739 : train_loss = 2.0203118324279785, val_loss = 0.789320707321167\n",
      "epoch n°3740 : train_loss = 2.0218145847320557, val_loss = 0.7926338911056519\n",
      "epoch n°3741 : train_loss = 2.031282424926758, val_loss = 0.7874051928520203\n",
      "epoch n°3742 : train_loss = 2.0161454677581787, val_loss = 0.7923540472984314\n",
      "epoch n°3743 : train_loss = 2.0135722160339355, val_loss = 0.7898024916648865\n",
      "epoch n°3744 : train_loss = 2.0183613300323486, val_loss = 0.7894567847251892\n",
      "epoch n°3745 : train_loss = 2.012097120285034, val_loss = 0.7903531789779663\n",
      "epoch n°3746 : train_loss = 2.0236709117889404, val_loss = 0.7937659621238708\n",
      "epoch n°3747 : train_loss = 2.017303228378296, val_loss = 0.795772910118103\n",
      "epoch n°3748 : train_loss = 2.0107998847961426, val_loss = 0.7919769287109375\n",
      "epoch n°3749 : train_loss = 2.021878480911255, val_loss = 0.7952491044998169\n",
      "epoch n°3750 : train_loss = 2.0162010192871094, val_loss = 0.7931499481201172\n",
      "epoch n°3751 : train_loss = 2.0274975299835205, val_loss = 0.7922525405883789\n",
      "epoch n°3752 : train_loss = 2.0217339992523193, val_loss = 0.7918566465377808\n",
      "epoch n°3753 : train_loss = 2.0149295330047607, val_loss = 0.7899788022041321\n",
      "epoch n°3754 : train_loss = 2.01635479927063, val_loss = 0.7920218706130981\n",
      "epoch n°3755 : train_loss = 2.007601499557495, val_loss = 0.7945516705513\n",
      "epoch n°3756 : train_loss = 2.0106728076934814, val_loss = 0.7899602055549622\n",
      "epoch n°3757 : train_loss = 2.021493911743164, val_loss = 0.7948362827301025\n",
      "epoch n°3758 : train_loss = 2.0143113136291504, val_loss = 0.7882913947105408\n",
      "epoch n°3759 : train_loss = 2.0148494243621826, val_loss = 0.7900229692459106\n",
      "epoch n°3760 : train_loss = 2.0163395404815674, val_loss = 0.7964081764221191\n",
      "epoch n°3761 : train_loss = 2.0203769207000732, val_loss = 0.7933518290519714\n",
      "epoch n°3762 : train_loss = 2.0153305530548096, val_loss = 0.7915957570075989\n",
      "epoch n°3763 : train_loss = 2.0217740535736084, val_loss = 0.7911241054534912\n",
      "epoch n°3764 : train_loss = 2.0144433975219727, val_loss = 0.7868167757987976\n",
      "epoch n°3765 : train_loss = 2.0229549407958984, val_loss = 0.7907615900039673\n",
      "epoch n°3766 : train_loss = 2.0216190814971924, val_loss = 0.7945014238357544\n",
      "epoch n°3767 : train_loss = 2.028639316558838, val_loss = 0.7884345650672913\n",
      "epoch n°3768 : train_loss = 2.015882730484009, val_loss = 0.792227566242218\n",
      "epoch n°3769 : train_loss = 2.010127067565918, val_loss = 0.7916110157966614\n",
      "epoch n°3770 : train_loss = 2.0181963443756104, val_loss = 0.789447009563446\n",
      "epoch n°3771 : train_loss = 2.0128116607666016, val_loss = 0.7883365154266357\n",
      "epoch n°3772 : train_loss = 2.0167901515960693, val_loss = 0.7887111902236938\n",
      "epoch n°3773 : train_loss = 2.0170235633850098, val_loss = 0.7901002168655396\n",
      "epoch n°3774 : train_loss = 2.0193159580230713, val_loss = 0.7895634174346924\n",
      "epoch n°3775 : train_loss = 2.009059190750122, val_loss = 0.79542475938797\n",
      "epoch n°3776 : train_loss = 2.011326551437378, val_loss = 0.7908145189285278\n",
      "epoch n°3777 : train_loss = 2.011711597442627, val_loss = 0.793868362903595\n",
      "epoch n°3778 : train_loss = 2.015651226043701, val_loss = 0.7849504947662354\n",
      "epoch n°3779 : train_loss = 2.0186963081359863, val_loss = 0.7954918742179871\n",
      "epoch n°3780 : train_loss = 2.0173802375793457, val_loss = 0.7894217371940613\n",
      "epoch n°3781 : train_loss = 2.0194740295410156, val_loss = 0.7926459312438965\n",
      "epoch n°3782 : train_loss = 2.0316455364227295, val_loss = 0.7906453609466553\n",
      "epoch n°3783 : train_loss = 2.0150182247161865, val_loss = 0.7943909764289856\n",
      "epoch n°3784 : train_loss = 2.018230676651001, val_loss = 0.7951209545135498\n",
      "epoch n°3785 : train_loss = 2.020779609680176, val_loss = 0.7942488193511963\n",
      "epoch n°3786 : train_loss = 2.016604423522949, val_loss = 0.7895692586898804\n",
      "epoch n°3787 : train_loss = 2.0151774883270264, val_loss = 0.7926256656646729\n",
      "epoch n°3788 : train_loss = 2.023669958114624, val_loss = 0.7958396077156067\n",
      "epoch n°3789 : train_loss = 2.0220446586608887, val_loss = 0.7915250658988953\n",
      "epoch n°3790 : train_loss = 2.0171236991882324, val_loss = 0.7903201580047607\n",
      "epoch n°3791 : train_loss = 2.0259649753570557, val_loss = 0.7886720299720764\n",
      "epoch n°3792 : train_loss = 2.0238070487976074, val_loss = 0.7913133502006531\n",
      "epoch n°3793 : train_loss = 2.0180530548095703, val_loss = 0.792210578918457\n",
      "epoch n°3794 : train_loss = 2.020533323287964, val_loss = 0.7957754135131836\n",
      "epoch n°3795 : train_loss = 2.009279727935791, val_loss = 0.7948295474052429\n",
      "epoch n°3796 : train_loss = 2.0194108486175537, val_loss = 0.7891900539398193\n",
      "epoch n°3797 : train_loss = 2.0171892642974854, val_loss = 0.79172682762146\n",
      "epoch n°3798 : train_loss = 2.017148733139038, val_loss = 0.7926225662231445\n",
      "epoch n°3799 : train_loss = 2.019383430480957, val_loss = 0.7975525856018066\n",
      "epoch n°3800 : train_loss = 2.0254292488098145, val_loss = 0.7903155088424683\n",
      "epoch n°3801 : train_loss = 2.010178804397583, val_loss = 0.7921248078346252\n",
      "epoch n°3802 : train_loss = 2.01786470413208, val_loss = 0.792901873588562\n",
      "epoch n°3803 : train_loss = 2.016658067703247, val_loss = 0.7940813302993774\n",
      "epoch n°3804 : train_loss = 2.0145087242126465, val_loss = 0.7897911071777344\n",
      "epoch n°3805 : train_loss = 2.0230910778045654, val_loss = 0.7928994297981262\n",
      "epoch n°3806 : train_loss = 2.0232977867126465, val_loss = 0.7949616312980652\n",
      "epoch n°3807 : train_loss = 2.012273073196411, val_loss = 0.7872417569160461\n",
      "epoch n°3808 : train_loss = 2.0176334381103516, val_loss = 0.7925378680229187\n",
      "epoch n°3809 : train_loss = 2.0208356380462646, val_loss = 0.7922029495239258\n",
      "epoch n°3810 : train_loss = 2.0196914672851562, val_loss = 0.7886032462120056\n",
      "epoch n°3811 : train_loss = 2.01811146736145, val_loss = 0.7950373291969299\n",
      "epoch n°3812 : train_loss = 2.019411087036133, val_loss = 0.792048990726471\n",
      "epoch n°3813 : train_loss = 2.0188708305358887, val_loss = 0.7899375557899475\n",
      "epoch n°3814 : train_loss = 2.018350601196289, val_loss = 0.7920060157775879\n",
      "epoch n°3815 : train_loss = 2.0221810340881348, val_loss = 0.7915838956832886\n",
      "epoch n°3816 : train_loss = 2.0183794498443604, val_loss = 0.7900013327598572\n",
      "epoch n°3817 : train_loss = 2.0122148990631104, val_loss = 0.7911077737808228\n",
      "epoch n°3818 : train_loss = 2.0267627239227295, val_loss = 0.7925309538841248\n",
      "epoch n°3819 : train_loss = 2.0208864212036133, val_loss = 0.7926284074783325\n",
      "epoch n°3820 : train_loss = 2.0175342559814453, val_loss = 0.7906457781791687\n",
      "epoch n°3821 : train_loss = 2.00907826423645, val_loss = 0.7908040881156921\n",
      "epoch n°3822 : train_loss = 2.023740530014038, val_loss = 0.7930346131324768\n",
      "epoch n°3823 : train_loss = 2.0111911296844482, val_loss = 0.7936626076698303\n",
      "epoch n°3824 : train_loss = 2.0142955780029297, val_loss = 0.7911454439163208\n",
      "epoch n°3825 : train_loss = 2.0069127082824707, val_loss = 0.794945478439331\n",
      "epoch n°3826 : train_loss = 2.0288760662078857, val_loss = 0.7912641763687134\n",
      "epoch n°3827 : train_loss = 2.0165905952453613, val_loss = 0.7887117266654968\n",
      "epoch n°3828 : train_loss = 2.0192649364471436, val_loss = 0.7936084866523743\n",
      "epoch n°3829 : train_loss = 2.017518997192383, val_loss = 0.793163001537323\n",
      "epoch n°3830 : train_loss = 2.007622241973877, val_loss = 0.7935258150100708\n",
      "epoch n°3831 : train_loss = 2.0159265995025635, val_loss = 0.7931535243988037\n",
      "epoch n°3832 : train_loss = 2.017561912536621, val_loss = 0.7910548448562622\n",
      "epoch n°3833 : train_loss = 2.019979476928711, val_loss = 0.7893162369728088\n",
      "epoch n°3834 : train_loss = 2.0192220211029053, val_loss = 0.789328396320343\n",
      "epoch n°3835 : train_loss = 2.016728401184082, val_loss = 0.7901907563209534\n",
      "epoch n°3836 : train_loss = 2.0177814960479736, val_loss = 0.7895619869232178\n",
      "epoch n°3837 : train_loss = 2.016618490219116, val_loss = 0.7948942184448242\n",
      "epoch n°3838 : train_loss = 2.0097219944000244, val_loss = 0.7932963967323303\n",
      "epoch n°3839 : train_loss = 2.0228164196014404, val_loss = 0.7913755178451538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°3840 : train_loss = 2.010676383972168, val_loss = 0.7931050062179565\n",
      "epoch n°3841 : train_loss = 2.0222537517547607, val_loss = 0.7891705632209778\n",
      "epoch n°3842 : train_loss = 2.0159261226654053, val_loss = 0.7910085916519165\n",
      "epoch n°3843 : train_loss = 2.010918140411377, val_loss = 0.7940701842308044\n",
      "epoch n°3844 : train_loss = 2.0136916637420654, val_loss = 0.7944579124450684\n",
      "epoch n°3845 : train_loss = 2.019195079803467, val_loss = 0.7940580248832703\n",
      "epoch n°3846 : train_loss = 2.0223958492279053, val_loss = 0.7875478863716125\n",
      "epoch n°3847 : train_loss = 2.0131211280822754, val_loss = 0.7871554493904114\n",
      "epoch n°3848 : train_loss = 2.0134165287017822, val_loss = 0.7908666133880615\n",
      "epoch n°3849 : train_loss = 2.020833969116211, val_loss = 0.7946516871452332\n",
      "epoch n°3850 : train_loss = 2.013592481613159, val_loss = 0.7923764586448669\n",
      "epoch n°3851 : train_loss = 2.0166964530944824, val_loss = 0.7944880723953247\n",
      "epoch n°3852 : train_loss = 2.011226177215576, val_loss = 0.7922990918159485\n",
      "epoch n°3853 : train_loss = 2.0185563564300537, val_loss = 0.7892552018165588\n",
      "epoch n°3854 : train_loss = 2.0190272331237793, val_loss = 0.7881283164024353\n",
      "epoch n°3855 : train_loss = 2.0136029720306396, val_loss = 0.7867957353591919\n",
      "epoch n°3856 : train_loss = 2.018831491470337, val_loss = 0.7875769138336182\n",
      "epoch n°3857 : train_loss = 2.0158748626708984, val_loss = 0.7938930988311768\n",
      "epoch n°3858 : train_loss = 2.0290932655334473, val_loss = 0.7883440256118774\n",
      "epoch n°3859 : train_loss = 2.0168817043304443, val_loss = 0.7886559963226318\n",
      "epoch n°3860 : train_loss = 2.0147345066070557, val_loss = 0.7908397316932678\n",
      "epoch n°3861 : train_loss = 2.019592046737671, val_loss = 0.7892763614654541\n",
      "epoch n°3862 : train_loss = 2.020350933074951, val_loss = 0.7941665649414062\n",
      "epoch n°3863 : train_loss = 2.015219211578369, val_loss = 0.7948405742645264\n",
      "epoch n°3864 : train_loss = 2.012115716934204, val_loss = 0.7907629013061523\n",
      "epoch n°3865 : train_loss = 2.018493175506592, val_loss = 0.7929218411445618\n",
      "epoch n°3866 : train_loss = 2.0174107551574707, val_loss = 0.789548397064209\n",
      "epoch n°3867 : train_loss = 2.020348072052002, val_loss = 0.7885735034942627\n",
      "epoch n°3868 : train_loss = 2.0223121643066406, val_loss = 0.7906309366226196\n",
      "epoch n°3869 : train_loss = 2.015328884124756, val_loss = 0.7860429883003235\n",
      "epoch n°3870 : train_loss = 2.0143988132476807, val_loss = 0.793379008769989\n",
      "epoch n°3871 : train_loss = 2.0182416439056396, val_loss = 0.7923800945281982\n",
      "epoch n°3872 : train_loss = 2.023136854171753, val_loss = 0.7907174229621887\n",
      "epoch n°3873 : train_loss = 2.021249532699585, val_loss = 0.7938750982284546\n",
      "epoch n°3874 : train_loss = 2.0215330123901367, val_loss = 0.7934938669204712\n",
      "epoch n°3875 : train_loss = 2.0133743286132812, val_loss = 0.7860792279243469\n",
      "epoch n°3876 : train_loss = 2.016903877258301, val_loss = 0.7903808355331421\n",
      "epoch n°3877 : train_loss = 2.0226759910583496, val_loss = 0.7911742329597473\n",
      "epoch n°3878 : train_loss = 2.0165646076202393, val_loss = 0.7913509607315063\n",
      "epoch n°3879 : train_loss = 2.0193207263946533, val_loss = 0.7918554544448853\n",
      "epoch n°3880 : train_loss = 2.0190353393554688, val_loss = 0.7895262241363525\n",
      "epoch n°3881 : train_loss = 2.0196266174316406, val_loss = 0.7889963388442993\n",
      "epoch n°3882 : train_loss = 2.023008108139038, val_loss = 0.7899634838104248\n",
      "epoch n°3883 : train_loss = 2.0160164833068848, val_loss = 0.7924078702926636\n",
      "epoch n°3884 : train_loss = 2.0199358463287354, val_loss = 0.7913739681243896\n",
      "epoch n°3885 : train_loss = 2.010157346725464, val_loss = 0.7893022298812866\n",
      "epoch n°3886 : train_loss = 2.0155029296875, val_loss = 0.7895241975784302\n",
      "epoch n°3887 : train_loss = 2.017580986022949, val_loss = 0.7932617664337158\n",
      "epoch n°3888 : train_loss = 2.020045280456543, val_loss = 0.788587749004364\n",
      "epoch n°3889 : train_loss = 2.018693447113037, val_loss = 0.788813054561615\n",
      "epoch n°3890 : train_loss = 2.008408546447754, val_loss = 0.7903957962989807\n",
      "epoch n°3891 : train_loss = 2.0144617557525635, val_loss = 0.7935904264450073\n",
      "epoch n°3892 : train_loss = 2.0197455883026123, val_loss = 0.7958184480667114\n",
      "epoch n°3893 : train_loss = 2.0174686908721924, val_loss = 0.7899870872497559\n",
      "epoch n°3894 : train_loss = 2.0213022232055664, val_loss = 0.790271520614624\n",
      "epoch n°3895 : train_loss = 2.018826723098755, val_loss = 0.7961743474006653\n",
      "epoch n°3896 : train_loss = 2.020014762878418, val_loss = 0.7956363558769226\n",
      "epoch n°3897 : train_loss = 2.018383741378784, val_loss = 0.7884732484817505\n",
      "epoch n°3898 : train_loss = 2.013625383377075, val_loss = 0.7895762324333191\n",
      "epoch n°3899 : train_loss = 2.01811146736145, val_loss = 0.7911407351493835\n",
      "epoch n°3900 : train_loss = 2.020369052886963, val_loss = 0.7907440662384033\n",
      "epoch n°3901 : train_loss = 2.0179572105407715, val_loss = 0.7907158136367798\n",
      "epoch n°3902 : train_loss = 2.014251470565796, val_loss = 0.786773145198822\n",
      "epoch n°3903 : train_loss = 2.011317491531372, val_loss = 0.7935572862625122\n",
      "epoch n°3904 : train_loss = 2.0168039798736572, val_loss = 0.792216420173645\n",
      "epoch n°3905 : train_loss = 2.013716220855713, val_loss = 0.7902696132659912\n",
      "epoch n°3906 : train_loss = 2.0119547843933105, val_loss = 0.7893330454826355\n",
      "epoch n°3907 : train_loss = 2.016629934310913, val_loss = 0.7918441295623779\n",
      "epoch n°3908 : train_loss = 2.0177483558654785, val_loss = 0.7905772924423218\n",
      "epoch n°3909 : train_loss = 2.024221897125244, val_loss = 0.7914972901344299\n",
      "epoch n°3910 : train_loss = 2.0260839462280273, val_loss = 0.7919042706489563\n",
      "epoch n°3911 : train_loss = 2.008852243423462, val_loss = 0.7938544154167175\n",
      "epoch n°3912 : train_loss = 2.0098648071289062, val_loss = 0.7925187945365906\n",
      "epoch n°3913 : train_loss = 2.0158233642578125, val_loss = 0.7868936061859131\n",
      "epoch n°3914 : train_loss = 2.028974771499634, val_loss = 0.7930269837379456\n",
      "epoch n°3915 : train_loss = 2.0224852561950684, val_loss = 0.7917713522911072\n",
      "epoch n°3916 : train_loss = 2.016967535018921, val_loss = 0.7886881232261658\n",
      "epoch n°3917 : train_loss = 2.0201735496520996, val_loss = 0.7907423377037048\n",
      "epoch n°3918 : train_loss = 2.020829439163208, val_loss = 0.7957340478897095\n",
      "epoch n°3919 : train_loss = 2.018475294113159, val_loss = 0.7919233441352844\n",
      "epoch n°3920 : train_loss = 2.015933036804199, val_loss = 0.7914544939994812\n",
      "epoch n°3921 : train_loss = 2.0173521041870117, val_loss = 0.79123455286026\n",
      "epoch n°3922 : train_loss = 2.0203516483306885, val_loss = 0.7903782725334167\n",
      "epoch n°3923 : train_loss = 2.0162715911865234, val_loss = 0.7917287945747375\n",
      "epoch n°3924 : train_loss = 2.0050511360168457, val_loss = 0.7909348607063293\n",
      "epoch n°3925 : train_loss = 2.014026403427124, val_loss = 0.7930138111114502\n",
      "epoch n°3926 : train_loss = 2.0145223140716553, val_loss = 0.7877547740936279\n",
      "epoch n°3927 : train_loss = 2.0180442333221436, val_loss = 0.7935485243797302\n",
      "epoch n°3928 : train_loss = 2.016502857208252, val_loss = 0.7913790345191956\n",
      "epoch n°3929 : train_loss = 2.0084421634674072, val_loss = 0.7873517870903015\n",
      "epoch n°3930 : train_loss = 2.0127580165863037, val_loss = 0.7931733131408691\n",
      "epoch n°3931 : train_loss = 2.0132195949554443, val_loss = 0.789739191532135\n",
      "epoch n°3932 : train_loss = 2.0217418670654297, val_loss = 0.7879374623298645\n",
      "epoch n°3933 : train_loss = 2.018265724182129, val_loss = 0.7941222786903381\n",
      "epoch n°3934 : train_loss = 2.0189764499664307, val_loss = 0.7900247573852539\n",
      "epoch n°3935 : train_loss = 2.00382399559021, val_loss = 0.7936944365501404\n",
      "epoch n°3936 : train_loss = 2.0204620361328125, val_loss = 0.7926633358001709\n",
      "epoch n°3937 : train_loss = 2.0104739665985107, val_loss = 0.7911989092826843\n",
      "epoch n°3938 : train_loss = 2.0195229053497314, val_loss = 0.7915677428245544\n",
      "epoch n°3939 : train_loss = 2.009018659591675, val_loss = 0.7949985265731812\n",
      "epoch n°3940 : train_loss = 2.0150539875030518, val_loss = 0.7920805811882019\n",
      "epoch n°3941 : train_loss = 2.01586651802063, val_loss = 0.7901486158370972\n",
      "epoch n°3942 : train_loss = 2.023695707321167, val_loss = 0.7878947257995605\n",
      "epoch n°3943 : train_loss = 2.01816463470459, val_loss = 0.7945571541786194\n",
      "epoch n°3944 : train_loss = 2.0191080570220947, val_loss = 0.7929772138595581\n",
      "epoch n°3945 : train_loss = 2.0176541805267334, val_loss = 0.7902868390083313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°3946 : train_loss = 2.013347625732422, val_loss = 0.7893847823143005\n",
      "epoch n°3947 : train_loss = 2.01733660697937, val_loss = 0.7888001799583435\n",
      "epoch n°3948 : train_loss = 2.0163538455963135, val_loss = 0.7920605540275574\n",
      "epoch n°3949 : train_loss = 2.024801731109619, val_loss = 0.7905817627906799\n",
      "epoch n°3950 : train_loss = 2.0124475955963135, val_loss = 0.7922951579093933\n",
      "epoch n°3951 : train_loss = 2.017301321029663, val_loss = 0.793402910232544\n",
      "epoch n°3952 : train_loss = 2.0085339546203613, val_loss = 0.7931086421012878\n",
      "epoch n°3953 : train_loss = 2.015597105026245, val_loss = 0.7918294668197632\n",
      "epoch n°3954 : train_loss = 2.00862717628479, val_loss = 0.7896990180015564\n",
      "epoch n°3955 : train_loss = 2.0166966915130615, val_loss = 0.7919116616249084\n",
      "epoch n°3956 : train_loss = 2.0203912258148193, val_loss = 0.788445234298706\n",
      "epoch n°3957 : train_loss = 2.019946813583374, val_loss = 0.7934084534645081\n",
      "epoch n°3958 : train_loss = 2.0260207653045654, val_loss = 0.7958279252052307\n",
      "epoch n°3959 : train_loss = 2.017840623855591, val_loss = 0.7930983304977417\n",
      "epoch n°3960 : train_loss = 2.005152940750122, val_loss = 0.7961829900741577\n",
      "epoch n°3961 : train_loss = 2.016725778579712, val_loss = 0.7947508096694946\n",
      "epoch n°3962 : train_loss = 2.020488739013672, val_loss = 0.7905149459838867\n",
      "epoch n°3963 : train_loss = 2.0208420753479004, val_loss = 0.7931979894638062\n",
      "epoch n°3964 : train_loss = 2.022695779800415, val_loss = 0.7941795587539673\n",
      "epoch n°3965 : train_loss = 2.027024269104004, val_loss = 0.7903109192848206\n",
      "epoch n°3966 : train_loss = 2.0230329036712646, val_loss = 0.7897858023643494\n",
      "epoch n°3967 : train_loss = 2.0120136737823486, val_loss = 0.7868091464042664\n",
      "epoch n°3968 : train_loss = 2.018850326538086, val_loss = 0.789253830909729\n",
      "epoch n°3969 : train_loss = 2.027414321899414, val_loss = 0.7892403602600098\n",
      "epoch n°3970 : train_loss = 2.0184905529022217, val_loss = 0.7938811182975769\n",
      "epoch n°3971 : train_loss = 2.0160086154937744, val_loss = 0.7915438413619995\n",
      "epoch n°3972 : train_loss = 2.0218446254730225, val_loss = 0.7930110692977905\n",
      "epoch n°3973 : train_loss = 2.014897108078003, val_loss = 0.7959305047988892\n",
      "epoch n°3974 : train_loss = 2.014975070953369, val_loss = 0.7953235507011414\n",
      "epoch n°3975 : train_loss = 2.0164201259613037, val_loss = 0.7897598743438721\n",
      "epoch n°3976 : train_loss = 2.0197017192840576, val_loss = 0.7897554039955139\n",
      "epoch n°3977 : train_loss = 2.0142619609832764, val_loss = 0.7904994487762451\n",
      "epoch n°3978 : train_loss = 2.0156168937683105, val_loss = 0.7914111018180847\n",
      "epoch n°3979 : train_loss = 2.0191080570220947, val_loss = 0.7901918292045593\n",
      "epoch n°3980 : train_loss = 2.0195693969726562, val_loss = 0.7926753759384155\n",
      "epoch n°3981 : train_loss = 2.0229132175445557, val_loss = 0.7926750183105469\n",
      "epoch n°3982 : train_loss = 2.0096468925476074, val_loss = 0.7866488695144653\n",
      "epoch n°3983 : train_loss = 2.013740301132202, val_loss = 0.7904300689697266\n",
      "epoch n°3984 : train_loss = 2.01179575920105, val_loss = 0.7911340594291687\n",
      "epoch n°3985 : train_loss = 2.021592617034912, val_loss = 0.7916744947433472\n",
      "epoch n°3986 : train_loss = 2.0160160064697266, val_loss = 0.7923535704612732\n",
      "epoch n°3987 : train_loss = 2.015606641769409, val_loss = 0.791626513004303\n",
      "epoch n°3988 : train_loss = 2.0136501789093018, val_loss = 0.7894222140312195\n",
      "epoch n°3989 : train_loss = 2.0175833702087402, val_loss = 0.795129656791687\n",
      "epoch n°3990 : train_loss = 2.0146727561950684, val_loss = 0.7882885336875916\n",
      "epoch n°3991 : train_loss = 2.0129010677337646, val_loss = 0.7878497242927551\n",
      "epoch n°3992 : train_loss = 2.0165019035339355, val_loss = 0.7920382022857666\n",
      "epoch n°3993 : train_loss = 2.015948534011841, val_loss = 0.7929508686065674\n",
      "epoch n°3994 : train_loss = 2.0118370056152344, val_loss = 0.7928414344787598\n",
      "epoch n°3995 : train_loss = 2.017000198364258, val_loss = 0.792436420917511\n",
      "epoch n°3996 : train_loss = 2.0155365467071533, val_loss = 0.7926036715507507\n",
      "epoch n°3997 : train_loss = 2.012700319290161, val_loss = 0.79485023021698\n",
      "epoch n°3998 : train_loss = 2.021960973739624, val_loss = 0.7903201580047607\n",
      "epoch n°3999 : train_loss = 2.0232362747192383, val_loss = 0.7925498485565186\n",
      "epoch n°4000 : train_loss = 2.01885724067688, val_loss = 0.7914455533027649\n",
      "epoch n°4001 : train_loss = 2.018749952316284, val_loss = 0.7947572469711304\n",
      "epoch n°4002 : train_loss = 2.010050058364868, val_loss = 0.7910718321800232\n",
      "epoch n°4003 : train_loss = 2.0146842002868652, val_loss = 0.7899617552757263\n",
      "epoch n°4004 : train_loss = 2.0213115215301514, val_loss = 0.7899816036224365\n",
      "epoch n°4005 : train_loss = 2.0156564712524414, val_loss = 0.7924240231513977\n",
      "epoch n°4006 : train_loss = 2.0184082984924316, val_loss = 0.7956854104995728\n",
      "epoch n°4007 : train_loss = 2.011788845062256, val_loss = 0.7922480702400208\n",
      "epoch n°4008 : train_loss = 2.0199339389801025, val_loss = 0.7919059991836548\n",
      "epoch n°4009 : train_loss = 2.014591693878174, val_loss = 0.7891915440559387\n",
      "epoch n°4010 : train_loss = 2.024899482727051, val_loss = 0.7919864654541016\n",
      "epoch n°4011 : train_loss = 2.0145199298858643, val_loss = 0.789426326751709\n",
      "epoch n°4012 : train_loss = 2.0250260829925537, val_loss = 0.7923750281333923\n",
      "epoch n°4013 : train_loss = 2.0215749740600586, val_loss = 0.7885949611663818\n",
      "epoch n°4014 : train_loss = 2.0188677310943604, val_loss = 0.7933271527290344\n",
      "epoch n°4015 : train_loss = 2.023533344268799, val_loss = 0.7905809283256531\n",
      "epoch n°4016 : train_loss = 2.0226917266845703, val_loss = 0.7948706746101379\n",
      "epoch n°4017 : train_loss = 2.0120575428009033, val_loss = 0.7899583578109741\n",
      "epoch n°4018 : train_loss = 2.009260654449463, val_loss = 0.7908320426940918\n",
      "epoch n°4019 : train_loss = 2.0147955417633057, val_loss = 0.7913182973861694\n",
      "epoch n°4020 : train_loss = 2.017982006072998, val_loss = 0.7892650961875916\n",
      "epoch n°4021 : train_loss = 2.016845941543579, val_loss = 0.7912843227386475\n",
      "epoch n°4022 : train_loss = 2.01863956451416, val_loss = 0.7952380180358887\n",
      "epoch n°4023 : train_loss = 2.0202832221984863, val_loss = 0.7932857275009155\n",
      "epoch n°4024 : train_loss = 2.015916347503662, val_loss = 0.7877018451690674\n",
      "epoch n°4025 : train_loss = 2.0176515579223633, val_loss = 0.7915540933609009\n",
      "epoch n°4026 : train_loss = 2.0198745727539062, val_loss = 0.791076123714447\n",
      "epoch n°4027 : train_loss = 2.0242550373077393, val_loss = 0.7956359386444092\n",
      "epoch n°4028 : train_loss = 2.016592502593994, val_loss = 0.7904147505760193\n",
      "epoch n°4029 : train_loss = 2.020665407180786, val_loss = 0.7928526997566223\n",
      "epoch n°4030 : train_loss = 2.021625518798828, val_loss = 0.7922345995903015\n",
      "epoch n°4031 : train_loss = 2.016127109527588, val_loss = 0.7911815047264099\n",
      "epoch n°4032 : train_loss = 2.018897771835327, val_loss = 0.7889474630355835\n",
      "epoch n°4033 : train_loss = 2.0141043663024902, val_loss = 0.7916495203971863\n",
      "epoch n°4034 : train_loss = 2.0126214027404785, val_loss = 0.7906546592712402\n",
      "epoch n°4035 : train_loss = 2.024404525756836, val_loss = 0.7931120991706848\n",
      "epoch n°4036 : train_loss = 2.0126900672912598, val_loss = 0.7961137294769287\n",
      "epoch n°4037 : train_loss = 2.0136125087738037, val_loss = 0.7910929918289185\n",
      "epoch n°4038 : train_loss = 2.017317295074463, val_loss = 0.7872804403305054\n",
      "epoch n°4039 : train_loss = 2.0208096504211426, val_loss = 0.7902510762214661\n",
      "epoch n°4040 : train_loss = 2.0204436779022217, val_loss = 0.7937383055686951\n",
      "epoch n°4041 : train_loss = 2.017434597015381, val_loss = 0.7905383110046387\n",
      "epoch n°4042 : train_loss = 2.018688440322876, val_loss = 0.7936036586761475\n",
      "epoch n°4043 : train_loss = 2.015505790710449, val_loss = 0.787811815738678\n",
      "epoch n°4044 : train_loss = 2.0178513526916504, val_loss = 0.7896642684936523\n",
      "epoch n°4045 : train_loss = 2.011990785598755, val_loss = 0.7924405336380005\n",
      "epoch n°4046 : train_loss = 2.0192532539367676, val_loss = 0.7931421399116516\n",
      "epoch n°4047 : train_loss = 2.0213608741760254, val_loss = 0.7888308167457581\n",
      "epoch n°4048 : train_loss = 2.0105388164520264, val_loss = 0.7902355790138245\n",
      "epoch n°4049 : train_loss = 2.0104005336761475, val_loss = 0.7941585779190063\n",
      "epoch n°4050 : train_loss = 2.020110845565796, val_loss = 0.7896560430526733\n",
      "epoch n°4051 : train_loss = 2.0243067741394043, val_loss = 0.7903772592544556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°4052 : train_loss = 2.0109946727752686, val_loss = 0.794083297252655\n",
      "epoch n°4053 : train_loss = 2.020913600921631, val_loss = 0.7917900085449219\n",
      "epoch n°4054 : train_loss = 2.0215468406677246, val_loss = 0.7890529036521912\n",
      "epoch n°4055 : train_loss = 2.016075372695923, val_loss = 0.7916417717933655\n",
      "epoch n°4056 : train_loss = 2.0180487632751465, val_loss = 0.786319375038147\n",
      "epoch n°4057 : train_loss = 2.0174591541290283, val_loss = 0.7884753942489624\n",
      "epoch n°4058 : train_loss = 2.0090818405151367, val_loss = 0.791824221611023\n",
      "epoch n°4059 : train_loss = 2.023369312286377, val_loss = 0.7881719470024109\n",
      "epoch n°4060 : train_loss = 2.0196290016174316, val_loss = 0.795339047908783\n",
      "epoch n°4061 : train_loss = 2.0143849849700928, val_loss = 0.7959772348403931\n",
      "epoch n°4062 : train_loss = 2.013880729675293, val_loss = 0.7898209095001221\n",
      "epoch n°4063 : train_loss = 2.01646089553833, val_loss = 0.7899242043495178\n",
      "epoch n°4064 : train_loss = 2.015986204147339, val_loss = 0.7895721197128296\n",
      "epoch n°4065 : train_loss = 2.0174384117126465, val_loss = 0.7928385138511658\n",
      "epoch n°4066 : train_loss = 2.0129778385162354, val_loss = 0.7911509275436401\n",
      "epoch n°4067 : train_loss = 2.0163521766662598, val_loss = 0.7928970456123352\n",
      "epoch n°4068 : train_loss = 2.0125515460968018, val_loss = 0.7971274852752686\n",
      "epoch n°4069 : train_loss = 2.0190563201904297, val_loss = 0.7912304997444153\n",
      "epoch n°4070 : train_loss = 2.007439136505127, val_loss = 0.7882609963417053\n",
      "epoch n°4071 : train_loss = 2.013413429260254, val_loss = 0.7898300886154175\n",
      "epoch n°4072 : train_loss = 2.022803544998169, val_loss = 0.7936392426490784\n",
      "epoch n°4073 : train_loss = 2.014721632003784, val_loss = 0.7888196110725403\n",
      "epoch n°4074 : train_loss = 2.016803741455078, val_loss = 0.7964600920677185\n",
      "epoch n°4075 : train_loss = 2.0133752822875977, val_loss = 0.792386531829834\n",
      "epoch n°4076 : train_loss = 2.015341281890869, val_loss = 0.7887675166130066\n",
      "epoch n°4077 : train_loss = 2.0116841793060303, val_loss = 0.7959645390510559\n",
      "epoch n°4078 : train_loss = 2.017788887023926, val_loss = 0.7926416397094727\n",
      "epoch n°4079 : train_loss = 2.0212252140045166, val_loss = 0.7941451072692871\n",
      "59349.54586791992\n"
     ]
    }
   ],
   "source": [
    "params = get_params(32,5,8,32,4,0.1)\n",
    "model = AttNet(*params,clf_dims=[1024,256,64])\n",
    "model = model.to(device)\n",
    "optim = torch.optim.AdamW(model.parameters(),lr = 0.0003)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optim,16,2)\n",
    "state = State(model,optim,scheduler)\n",
    "\n",
    "fname = \"models/stateATT_5L_fixed.pth\" \n",
    "start = time.time()\n",
    "Train,Eval,_ = main(train_dataloader, val_dataloader,fname=fname,epochs=4080,state=state,use_mut=False)\n",
    "stop = time.time()\n",
    "print(stop-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "03f15a5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f487be875b0>]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(len(Train)),Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e964674b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f487aef4fd0>]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(len(Eval)),Eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "cd67de39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVALUATING ON TRAIN DATA : \n",
      "score_train = 0.7220045924186707\n",
      "\n",
      "EVALUATING ON TEST DATA : \n",
      "score_test = 0.8083394169807434\n",
      "\n",
      "EVALUATING ON VAL DATA : \n",
      "score_val = 0.7904196381568909\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fname = \"models/stateATT_5L_fixed.pth\" \n",
    "SCORES = eval_model(fname,train_dataloader,test_dataloader,val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c591f2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVALUATING ON TRAIN DATA : \n",
      "score_train = 0.7225131392478943\n",
      "\n",
      "EVALUATING ON TEST DATA : \n",
      "score_test = 0.8086221218109131\n",
      "\n",
      "EVALUATING ON VAL DATA : \n",
      "score_val = 0.7914513945579529\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fname = \"models/stateATT_5L_fixed_best.pth\" \n",
    "SCORES = eval_model(fname,train_dataloader,test_dataloader,val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "202a3717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°0 : train_loss = 2.806739330291748, val_loss = 0.8816468119621277\n",
      "epoch n°1 : train_loss = 2.5022969245910645, val_loss = 0.8408346176147461\n",
      "epoch n°2 : train_loss = 2.4001095294952393, val_loss = 0.8274690508842468\n",
      "epoch n°3 : train_loss = 2.371164083480835, val_loss = 0.8199614882469177\n",
      "epoch n°4 : train_loss = 2.3547325134277344, val_loss = 0.8223732709884644\n",
      "epoch n°5 : train_loss = 2.3445284366607666, val_loss = 0.814386248588562\n",
      "epoch n°6 : train_loss = 2.3266186714172363, val_loss = 0.8143227100372314\n",
      "epoch n°7 : train_loss = 2.3193273544311523, val_loss = 0.8111643195152283\n",
      "epoch n°8 : train_loss = 2.3149149417877197, val_loss = 0.8108239769935608\n",
      "epoch n°9 : train_loss = 2.310821056365967, val_loss = 0.8116379976272583\n",
      "epoch n°10 : train_loss = 2.301464319229126, val_loss = 0.8089765906333923\n",
      "epoch n°11 : train_loss = 2.296995162963867, val_loss = 0.8098387122154236\n",
      "epoch n°12 : train_loss = 2.29388165473938, val_loss = 0.8102185726165771\n",
      "epoch n°13 : train_loss = 2.2967560291290283, val_loss = 0.805435836315155\n",
      "epoch n°14 : train_loss = 2.2859251499176025, val_loss = 0.8064224720001221\n",
      "epoch n°15 : train_loss = 2.2953333854675293, val_loss = 0.8090124130249023\n",
      "epoch n°16 : train_loss = 2.309340476989746, val_loss = 0.8110967874526978\n",
      "epoch n°17 : train_loss = 2.3164873123168945, val_loss = 0.8106274604797363\n",
      "epoch n°18 : train_loss = 2.302405834197998, val_loss = 0.8161101341247559\n",
      "epoch n°19 : train_loss = 2.3005247116088867, val_loss = 0.8132044076919556\n",
      "epoch n°20 : train_loss = 2.2978713512420654, val_loss = 0.8108406662940979\n",
      "epoch n°21 : train_loss = 2.290569305419922, val_loss = 0.8117629289627075\n",
      "epoch n°22 : train_loss = 2.2895498275756836, val_loss = 0.8116846084594727\n",
      "epoch n°23 : train_loss = 2.282022714614868, val_loss = 0.8130444884300232\n",
      "epoch n°24 : train_loss = 2.28092885017395, val_loss = 0.8060027956962585\n",
      "epoch n°25 : train_loss = 2.288708448410034, val_loss = 0.8082621693611145\n",
      "epoch n°26 : train_loss = 2.279571056365967, val_loss = 0.8077074885368347\n",
      "epoch n°27 : train_loss = 2.2722864151000977, val_loss = 0.8103476166725159\n",
      "epoch n°28 : train_loss = 2.27001690864563, val_loss = 0.8039889335632324\n",
      "epoch n°29 : train_loss = 2.263267755508423, val_loss = 0.8063480257987976\n",
      "epoch n°30 : train_loss = 2.266547441482544, val_loss = 0.8060895204544067\n",
      "epoch n°31 : train_loss = 2.26162052154541, val_loss = 0.8058273196220398\n",
      "epoch n°32 : train_loss = 2.2535622119903564, val_loss = 0.8040451407432556\n",
      "epoch n°33 : train_loss = 2.25966739654541, val_loss = 0.8027687072753906\n",
      "epoch n°34 : train_loss = 2.257957935333252, val_loss = 0.8009738922119141\n",
      "epoch n°35 : train_loss = 2.267587423324585, val_loss = 0.799848735332489\n",
      "epoch n°36 : train_loss = 2.2511982917785645, val_loss = 0.8001196980476379\n",
      "epoch n°37 : train_loss = 2.2376747131347656, val_loss = 0.7988447546958923\n",
      "epoch n°38 : train_loss = 2.2482409477233887, val_loss = 0.801429271697998\n",
      "epoch n°39 : train_loss = 2.2475099563598633, val_loss = 0.7993205189704895\n",
      "epoch n°40 : train_loss = 2.244555711746216, val_loss = 0.8014500737190247\n",
      "epoch n°41 : train_loss = 2.2370355129241943, val_loss = 0.7990197539329529\n",
      "epoch n°42 : train_loss = 2.2380971908569336, val_loss = 0.8021202683448792\n",
      "epoch n°43 : train_loss = 2.2433013916015625, val_loss = 0.7999677062034607\n",
      "epoch n°44 : train_loss = 2.2466301918029785, val_loss = 0.8012043833732605\n",
      "epoch n°45 : train_loss = 2.235495090484619, val_loss = 0.8027148246765137\n",
      "epoch n°46 : train_loss = 2.231182098388672, val_loss = 0.7988641858100891\n",
      "epoch n°47 : train_loss = 2.242131233215332, val_loss = 0.8000139594078064\n",
      "epoch n°48 : train_loss = 2.2526111602783203, val_loss = 0.8056958913803101\n",
      "epoch n°49 : train_loss = 2.260141611099243, val_loss = 0.803939163684845\n",
      "epoch n°50 : train_loss = 2.2536838054656982, val_loss = 0.8024344444274902\n",
      "epoch n°51 : train_loss = 2.2524735927581787, val_loss = 0.8049712777137756\n",
      "epoch n°52 : train_loss = 2.262460947036743, val_loss = 0.8053415417671204\n",
      "epoch n°53 : train_loss = 2.259042263031006, val_loss = 0.8010870814323425\n",
      "epoch n°54 : train_loss = 2.2539851665496826, val_loss = 0.8042339086532593\n",
      "epoch n°55 : train_loss = 2.252593517303467, val_loss = 0.8081788420677185\n",
      "epoch n°56 : train_loss = 2.2531864643096924, val_loss = 0.8008739352226257\n",
      "epoch n°57 : train_loss = 2.2490084171295166, val_loss = 0.7989192008972168\n",
      "epoch n°58 : train_loss = 2.2615952491760254, val_loss = 0.8022386431694031\n",
      "epoch n°59 : train_loss = 2.2485408782958984, val_loss = 0.8071870803833008\n",
      "epoch n°60 : train_loss = 2.2458062171936035, val_loss = 0.8053848147392273\n",
      "epoch n°61 : train_loss = 2.252031087875366, val_loss = 0.7961844205856323\n",
      "epoch n°62 : train_loss = 2.245689630508423, val_loss = 0.8037923574447632\n",
      "epoch n°63 : train_loss = 2.239169120788574, val_loss = 0.7987158298492432\n",
      "epoch n°64 : train_loss = 2.245366096496582, val_loss = 0.8032339215278625\n",
      "epoch n°65 : train_loss = 2.2325634956359863, val_loss = 0.8045654892921448\n",
      "epoch n°66 : train_loss = 2.2421772480010986, val_loss = 0.8025678396224976\n",
      "epoch n°67 : train_loss = 2.2378549575805664, val_loss = 0.802807629108429\n",
      "epoch n°68 : train_loss = 2.228991985321045, val_loss = 0.802351713180542\n",
      "epoch n°69 : train_loss = 2.238520622253418, val_loss = 0.8007401823997498\n",
      "epoch n°70 : train_loss = 2.23175048828125, val_loss = 0.8045475482940674\n",
      "epoch n°71 : train_loss = 2.232893705368042, val_loss = 0.7980582118034363\n",
      "epoch n°72 : train_loss = 2.2260680198669434, val_loss = 0.8039425611495972\n",
      "epoch n°73 : train_loss = 2.235323190689087, val_loss = 0.80191570520401\n",
      "epoch n°74 : train_loss = 2.2262675762176514, val_loss = 0.8031728863716125\n",
      "epoch n°75 : train_loss = 2.227384328842163, val_loss = 0.8014916777610779\n",
      "epoch n°76 : train_loss = 2.226193428039551, val_loss = 0.7995495200157166\n",
      "epoch n°77 : train_loss = 2.229172945022583, val_loss = 0.8014589548110962\n",
      "epoch n°78 : train_loss = 2.2138521671295166, val_loss = 0.7999424934387207\n",
      "epoch n°79 : train_loss = 2.222878932952881, val_loss = 0.803793728351593\n",
      "epoch n°80 : train_loss = 2.217203140258789, val_loss = 0.80050128698349\n",
      "epoch n°81 : train_loss = 2.2171072959899902, val_loss = 0.7956456542015076\n",
      "epoch n°82 : train_loss = 2.2194154262542725, val_loss = 0.7994266152381897\n",
      "epoch n°83 : train_loss = 2.2136151790618896, val_loss = 0.7950342893600464\n",
      "epoch n°84 : train_loss = 2.2166543006896973, val_loss = 0.7984305620193481\n",
      "epoch n°85 : train_loss = 2.219318389892578, val_loss = 0.8012250661849976\n",
      "epoch n°86 : train_loss = 2.207176923751831, val_loss = 0.8027216196060181\n",
      "epoch n°87 : train_loss = 2.209710121154785, val_loss = 0.8007632493972778\n",
      "epoch n°88 : train_loss = 2.212228536605835, val_loss = 0.7957795262336731\n",
      "epoch n°89 : train_loss = 2.213711977005005, val_loss = 0.8016245365142822\n",
      "epoch n°90 : train_loss = 2.2065658569335938, val_loss = 0.7970542907714844\n",
      "epoch n°91 : train_loss = 2.2127201557159424, val_loss = 0.7953558564186096\n",
      "epoch n°92 : train_loss = 2.206688165664673, val_loss = 0.7999531030654907\n",
      "epoch n°93 : train_loss = 2.2064037322998047, val_loss = 0.7957053184509277\n",
      "epoch n°94 : train_loss = 2.205169916152954, val_loss = 0.800521731376648\n",
      "epoch n°95 : train_loss = 2.2144458293914795, val_loss = 0.796281635761261\n",
      "epoch n°96 : train_loss = 2.205901622772217, val_loss = 0.7949543595314026\n",
      "epoch n°97 : train_loss = 2.215822458267212, val_loss = 0.7949098944664001\n",
      "epoch n°98 : train_loss = 2.1985647678375244, val_loss = 0.7930628061294556\n",
      "epoch n°99 : train_loss = 2.2082395553588867, val_loss = 0.7978696823120117\n",
      "epoch n°100 : train_loss = 2.205003261566162, val_loss = 0.7985218167304993\n",
      "epoch n°101 : train_loss = 2.207904815673828, val_loss = 0.7986506223678589\n",
      "epoch n°102 : train_loss = 2.2082176208496094, val_loss = 0.7999827265739441\n",
      "epoch n°103 : train_loss = 2.2093167304992676, val_loss = 0.7980191111564636\n",
      "epoch n°104 : train_loss = 2.2022593021392822, val_loss = 0.7954495549201965\n",
      "epoch n°105 : train_loss = 2.200822591781616, val_loss = 0.7964975237846375\n",
      "epoch n°106 : train_loss = 2.214529275894165, val_loss = 0.7968853116035461\n",
      "epoch n°107 : train_loss = 2.2132723331451416, val_loss = 0.7941597104072571\n",
      "epoch n°108 : train_loss = 2.2011570930480957, val_loss = 0.7923489212989807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°109 : train_loss = 2.207512378692627, val_loss = 0.7980828285217285\n",
      "epoch n°110 : train_loss = 2.212315320968628, val_loss = 0.7977216839790344\n",
      "epoch n°111 : train_loss = 2.2042930126190186, val_loss = 0.794154942035675\n",
      "epoch n°112 : train_loss = 2.2243716716766357, val_loss = 0.8006142973899841\n",
      "epoch n°113 : train_loss = 2.226938009262085, val_loss = 0.7943142652511597\n",
      "epoch n°114 : train_loss = 2.2291510105133057, val_loss = 0.8015153408050537\n",
      "epoch n°115 : train_loss = 2.2294113636016846, val_loss = 0.800089418888092\n",
      "epoch n°116 : train_loss = 2.2232460975646973, val_loss = 0.8044569492340088\n",
      "epoch n°117 : train_loss = 2.2224931716918945, val_loss = 0.7947297096252441\n",
      "epoch n°118 : train_loss = 2.22031831741333, val_loss = 0.8011676669120789\n",
      "epoch n°119 : train_loss = 2.2267165184020996, val_loss = 0.8028435111045837\n",
      "epoch n°120 : train_loss = 2.223907947540283, val_loss = 0.7994950413703918\n",
      "epoch n°121 : train_loss = 2.2238309383392334, val_loss = 0.8016420006752014\n",
      "epoch n°122 : train_loss = 2.224093437194824, val_loss = 0.8042957782745361\n",
      "epoch n°123 : train_loss = 2.2143173217773438, val_loss = 0.7978265285491943\n",
      "epoch n°124 : train_loss = 2.2231523990631104, val_loss = 0.7988324165344238\n",
      "epoch n°125 : train_loss = 2.210452079772949, val_loss = 0.8046928644180298\n",
      "epoch n°126 : train_loss = 2.2169501781463623, val_loss = 0.8031883239746094\n",
      "epoch n°127 : train_loss = 2.216248035430908, val_loss = 0.8004186153411865\n",
      "epoch n°128 : train_loss = 2.2181363105773926, val_loss = 0.7981374859809875\n",
      "epoch n°129 : train_loss = 2.223675012588501, val_loss = 0.8017264008522034\n",
      "epoch n°130 : train_loss = 2.216383695602417, val_loss = 0.7959277629852295\n",
      "epoch n°131 : train_loss = 2.215860605239868, val_loss = 0.7992105484008789\n",
      "epoch n°132 : train_loss = 2.2148215770721436, val_loss = 0.7999242544174194\n",
      "epoch n°133 : train_loss = 2.2172327041625977, val_loss = 0.80280601978302\n",
      "epoch n°134 : train_loss = 2.2230894565582275, val_loss = 0.8013044595718384\n",
      "epoch n°135 : train_loss = 2.214473009109497, val_loss = 0.8019971251487732\n",
      "epoch n°136 : train_loss = 2.2148940563201904, val_loss = 0.8002763986587524\n",
      "epoch n°137 : train_loss = 2.207003116607666, val_loss = 0.7995079755783081\n",
      "epoch n°138 : train_loss = 2.213603973388672, val_loss = 0.8001773953437805\n",
      "epoch n°139 : train_loss = 2.212095022201538, val_loss = 0.7996422052383423\n",
      "epoch n°140 : train_loss = 2.2062487602233887, val_loss = 0.7990651726722717\n",
      "epoch n°141 : train_loss = 2.209390640258789, val_loss = 0.8002956509590149\n",
      "epoch n°142 : train_loss = 2.2162282466888428, val_loss = 0.797681987285614\n",
      "epoch n°143 : train_loss = 2.2070908546447754, val_loss = 0.8050724864006042\n",
      "epoch n°144 : train_loss = 2.2069003582000732, val_loss = 0.8014103770256042\n",
      "epoch n°145 : train_loss = 2.2104737758636475, val_loss = 0.8012831211090088\n",
      "epoch n°146 : train_loss = 2.205023765563965, val_loss = 0.7999285459518433\n",
      "epoch n°147 : train_loss = 2.199308395385742, val_loss = 0.7984020709991455\n",
      "epoch n°148 : train_loss = 2.204430341720581, val_loss = 0.7985907793045044\n",
      "epoch n°149 : train_loss = 2.2036097049713135, val_loss = 0.7969791889190674\n",
      "epoch n°150 : train_loss = 2.2043917179107666, val_loss = 0.7984726428985596\n",
      "epoch n°151 : train_loss = 2.2217962741851807, val_loss = 0.7956442832946777\n",
      "epoch n°152 : train_loss = 2.209439992904663, val_loss = 0.7972537875175476\n",
      "epoch n°153 : train_loss = 2.205181837081909, val_loss = 0.7982804775238037\n",
      "epoch n°154 : train_loss = 2.200284242630005, val_loss = 0.8031766414642334\n",
      "epoch n°155 : train_loss = 2.2033822536468506, val_loss = 0.8014253377914429\n",
      "epoch n°156 : train_loss = 2.2041049003601074, val_loss = 0.7995134592056274\n",
      "epoch n°157 : train_loss = 2.19901442527771, val_loss = 0.7959646582603455\n",
      "epoch n°158 : train_loss = 2.2085750102996826, val_loss = 0.8018324971199036\n",
      "epoch n°159 : train_loss = 2.207691192626953, val_loss = 0.7978200316429138\n",
      "epoch n°160 : train_loss = 2.206522226333618, val_loss = 0.7977774143218994\n",
      "epoch n°161 : train_loss = 2.206171989440918, val_loss = 0.7993862628936768\n",
      "epoch n°162 : train_loss = 2.197216033935547, val_loss = 0.793646514415741\n",
      "epoch n°163 : train_loss = 2.194845199584961, val_loss = 0.7995062470436096\n",
      "epoch n°164 : train_loss = 2.1986746788024902, val_loss = 0.7977157235145569\n",
      "epoch n°165 : train_loss = 2.196749687194824, val_loss = 0.798276424407959\n",
      "epoch n°166 : train_loss = 2.200709342956543, val_loss = 0.7988085150718689\n",
      "epoch n°167 : train_loss = 2.1916184425354004, val_loss = 0.7951549291610718\n",
      "epoch n°168 : train_loss = 2.1977148056030273, val_loss = 0.7983208894729614\n",
      "epoch n°169 : train_loss = 2.197110176086426, val_loss = 0.8009712100028992\n",
      "epoch n°170 : train_loss = 2.1890757083892822, val_loss = 0.7963054180145264\n",
      "epoch n°171 : train_loss = 2.190542697906494, val_loss = 0.7979334592819214\n",
      "epoch n°172 : train_loss = 2.19958758354187, val_loss = 0.7980970740318298\n",
      "epoch n°173 : train_loss = 2.196775436401367, val_loss = 0.8008857369422913\n",
      "epoch n°174 : train_loss = 2.191401481628418, val_loss = 0.7971891760826111\n",
      "epoch n°175 : train_loss = 2.191462755203247, val_loss = 0.794661819934845\n",
      "epoch n°176 : train_loss = 2.1869757175445557, val_loss = 0.7928625345230103\n",
      "epoch n°177 : train_loss = 2.1817421913146973, val_loss = 0.7990739345550537\n",
      "epoch n°178 : train_loss = 2.1793763637542725, val_loss = 0.7965982556343079\n",
      "epoch n°179 : train_loss = 2.194162607192993, val_loss = 0.8026484847068787\n",
      "epoch n°180 : train_loss = 2.186851978302002, val_loss = 0.7998248338699341\n",
      "epoch n°181 : train_loss = 2.1911792755126953, val_loss = 0.7964850068092346\n",
      "epoch n°182 : train_loss = 2.1919565200805664, val_loss = 0.7998294830322266\n",
      "epoch n°183 : train_loss = 2.187081813812256, val_loss = 0.7937717437744141\n",
      "epoch n°184 : train_loss = 2.1844613552093506, val_loss = 0.7961486577987671\n",
      "epoch n°185 : train_loss = 2.1832408905029297, val_loss = 0.797819972038269\n",
      "epoch n°186 : train_loss = 2.1834137439727783, val_loss = 0.7922165393829346\n",
      "epoch n°187 : train_loss = 2.186833381652832, val_loss = 0.8024629950523376\n",
      "epoch n°188 : train_loss = 2.1870663166046143, val_loss = 0.7958979606628418\n",
      "epoch n°189 : train_loss = 2.1745517253875732, val_loss = 0.7971161007881165\n",
      "epoch n°190 : train_loss = 2.178179979324341, val_loss = 0.7971224784851074\n",
      "epoch n°191 : train_loss = 2.1786768436431885, val_loss = 0.7963566184043884\n",
      "epoch n°192 : train_loss = 2.184307813644409, val_loss = 0.7987540364265442\n",
      "epoch n°193 : train_loss = 2.1853976249694824, val_loss = 0.7997081875801086\n",
      "epoch n°194 : train_loss = 2.17972469329834, val_loss = 0.7991958260536194\n",
      "epoch n°195 : train_loss = 2.17862606048584, val_loss = 0.7969428896903992\n",
      "epoch n°196 : train_loss = 2.1795599460601807, val_loss = 0.795179009437561\n",
      "epoch n°197 : train_loss = 2.1774837970733643, val_loss = 0.7961301803588867\n",
      "epoch n°198 : train_loss = 2.1741929054260254, val_loss = 0.7930888533592224\n",
      "epoch n°199 : train_loss = 2.174271821975708, val_loss = 0.7964346408843994\n",
      "epoch n°200 : train_loss = 2.171427011489868, val_loss = 0.8003905415534973\n",
      "epoch n°201 : train_loss = 2.1706671714782715, val_loss = 0.7939177751541138\n",
      "epoch n°202 : train_loss = 2.1711080074310303, val_loss = 0.7926803827285767\n",
      "epoch n°203 : train_loss = 2.170741558074951, val_loss = 0.7962080836296082\n",
      "epoch n°204 : train_loss = 2.173534631729126, val_loss = 0.7932392954826355\n",
      "epoch n°205 : train_loss = 2.174827814102173, val_loss = 0.7913574576377869\n",
      "epoch n°206 : train_loss = 2.1834254264831543, val_loss = 0.7958469390869141\n",
      "epoch n°207 : train_loss = 2.178542375564575, val_loss = 0.7947565317153931\n",
      "epoch n°208 : train_loss = 2.1762163639068604, val_loss = 0.796038806438446\n",
      "epoch n°209 : train_loss = 2.1789708137512207, val_loss = 0.7902093529701233\n",
      "epoch n°210 : train_loss = 2.1740899085998535, val_loss = 0.7939615249633789\n",
      "epoch n°211 : train_loss = 2.167659282684326, val_loss = 0.7964234352111816\n",
      "epoch n°212 : train_loss = 2.1703243255615234, val_loss = 0.7890565395355225\n",
      "epoch n°213 : train_loss = 2.1703569889068604, val_loss = 0.7986683249473572\n",
      "epoch n°214 : train_loss = 2.1578547954559326, val_loss = 0.7964997887611389\n",
      "epoch n°215 : train_loss = 2.172685384750366, val_loss = 0.7916075587272644\n",
      "epoch n°216 : train_loss = 2.173827886581421, val_loss = 0.7968466281890869\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°217 : train_loss = 2.1665589809417725, val_loss = 0.7959944009780884\n",
      "epoch n°218 : train_loss = 2.1718428134918213, val_loss = 0.7935855984687805\n",
      "epoch n°219 : train_loss = 2.1632673740386963, val_loss = 0.7944694757461548\n",
      "epoch n°220 : train_loss = 2.1655938625335693, val_loss = 0.7926751375198364\n",
      "epoch n°221 : train_loss = 2.1671135425567627, val_loss = 0.7972661852836609\n",
      "epoch n°222 : train_loss = 2.167555570602417, val_loss = 0.7933489680290222\n",
      "epoch n°223 : train_loss = 2.163851261138916, val_loss = 0.7939926981925964\n",
      "epoch n°224 : train_loss = 2.1767630577087402, val_loss = 0.7945605516433716\n",
      "epoch n°225 : train_loss = 2.169572353363037, val_loss = 0.792656660079956\n",
      "epoch n°226 : train_loss = 2.1701529026031494, val_loss = 0.7969812750816345\n",
      "epoch n°227 : train_loss = 2.167621612548828, val_loss = 0.7936090230941772\n",
      "epoch n°228 : train_loss = 2.1636319160461426, val_loss = 0.7923827767372131\n",
      "epoch n°229 : train_loss = 2.17431378364563, val_loss = 0.7979716658592224\n",
      "epoch n°230 : train_loss = 2.1695761680603027, val_loss = 0.7915235757827759\n",
      "epoch n°231 : train_loss = 2.1637675762176514, val_loss = 0.79618901014328\n",
      "epoch n°232 : train_loss = 2.1636016368865967, val_loss = 0.7941688895225525\n",
      "epoch n°233 : train_loss = 2.1644177436828613, val_loss = 0.7968704104423523\n",
      "epoch n°234 : train_loss = 2.1687822341918945, val_loss = 0.79523104429245\n",
      "epoch n°235 : train_loss = 2.167473793029785, val_loss = 0.79511559009552\n",
      "epoch n°236 : train_loss = 2.1616265773773193, val_loss = 0.789273202419281\n",
      "epoch n°237 : train_loss = 2.163356065750122, val_loss = 0.7965716123580933\n",
      "epoch n°238 : train_loss = 2.161818742752075, val_loss = 0.7904845476150513\n",
      "epoch n°239 : train_loss = 2.169616222381592, val_loss = 0.794082760810852\n",
      "epoch n°240 : train_loss = 2.178920030593872, val_loss = 0.8001838326454163\n",
      "epoch n°241 : train_loss = 2.182961940765381, val_loss = 0.795301079750061\n",
      "epoch n°242 : train_loss = 2.1919093132019043, val_loss = 0.8023572564125061\n",
      "epoch n°243 : train_loss = 2.188401460647583, val_loss = 0.8005847930908203\n",
      "epoch n°244 : train_loss = 2.199719190597534, val_loss = 0.7992991209030151\n",
      "epoch n°245 : train_loss = 2.1982085704803467, val_loss = 0.8002597689628601\n",
      "epoch n°246 : train_loss = 2.188822031021118, val_loss = 0.7976589202880859\n",
      "epoch n°247 : train_loss = 2.19201397895813, val_loss = 0.7960765957832336\n",
      "epoch n°248 : train_loss = 2.1901473999023438, val_loss = 0.7995034456253052\n",
      "epoch n°249 : train_loss = 2.1908726692199707, val_loss = 0.800301194190979\n",
      "epoch n°250 : train_loss = 2.191338539123535, val_loss = 0.7974756956100464\n",
      "epoch n°251 : train_loss = 2.1899807453155518, val_loss = 0.7973864078521729\n",
      "epoch n°252 : train_loss = 2.1831486225128174, val_loss = 0.7978946566581726\n",
      "epoch n°253 : train_loss = 2.1826910972595215, val_loss = 0.7991746068000793\n",
      "epoch n°254 : train_loss = 2.1839029788970947, val_loss = 0.7955470085144043\n",
      "epoch n°255 : train_loss = 2.1937193870544434, val_loss = 0.8029643297195435\n",
      "epoch n°256 : train_loss = 2.186565637588501, val_loss = 0.8006428480148315\n",
      "epoch n°257 : train_loss = 2.1906487941741943, val_loss = 0.7968378663063049\n",
      "epoch n°258 : train_loss = 2.185295581817627, val_loss = 0.7991694808006287\n",
      "epoch n°259 : train_loss = 2.1986589431762695, val_loss = 0.7972665429115295\n",
      "epoch n°260 : train_loss = 2.1849045753479004, val_loss = 0.7983778119087219\n",
      "epoch n°261 : train_loss = 2.176370859146118, val_loss = 0.7958688139915466\n",
      "epoch n°262 : train_loss = 2.1955552101135254, val_loss = 0.798486590385437\n",
      "epoch n°263 : train_loss = 2.1843724250793457, val_loss = 0.7988461852073669\n",
      "epoch n°264 : train_loss = 2.1870362758636475, val_loss = 0.797164797782898\n",
      "epoch n°265 : train_loss = 2.1932694911956787, val_loss = 0.7991145253181458\n",
      "epoch n°266 : train_loss = 2.192262887954712, val_loss = 0.7977042198181152\n",
      "epoch n°267 : train_loss = 2.1857986450195312, val_loss = 0.7980539202690125\n",
      "epoch n°268 : train_loss = 2.17270565032959, val_loss = 0.800849199295044\n",
      "epoch n°269 : train_loss = 2.1896772384643555, val_loss = 0.7982079982757568\n",
      "epoch n°270 : train_loss = 2.189476490020752, val_loss = 0.7992693185806274\n",
      "epoch n°271 : train_loss = 2.1919987201690674, val_loss = 0.8002713918685913\n",
      "epoch n°272 : train_loss = 2.190903425216675, val_loss = 0.7980250716209412\n",
      "epoch n°273 : train_loss = 2.1889679431915283, val_loss = 0.798125684261322\n",
      "epoch n°274 : train_loss = 2.188530445098877, val_loss = 0.8000274896621704\n",
      "epoch n°275 : train_loss = 2.1790194511413574, val_loss = 0.8013352751731873\n",
      "epoch n°276 : train_loss = 2.1884536743164062, val_loss = 0.7986370325088501\n",
      "epoch n°277 : train_loss = 2.180250883102417, val_loss = 0.7974637150764465\n",
      "epoch n°278 : train_loss = 2.1866507530212402, val_loss = 0.7994160056114197\n",
      "epoch n°279 : train_loss = 2.1823983192443848, val_loss = 0.8026946187019348\n",
      "epoch n°280 : train_loss = 2.1932756900787354, val_loss = 0.7988602519035339\n",
      "epoch n°281 : train_loss = 2.1823689937591553, val_loss = 0.7946023344993591\n",
      "epoch n°282 : train_loss = 2.1835005283355713, val_loss = 0.7951334714889526\n",
      "epoch n°283 : train_loss = 2.1773502826690674, val_loss = 0.7971836924552917\n",
      "epoch n°284 : train_loss = 2.1829214096069336, val_loss = 0.7990643382072449\n",
      "epoch n°285 : train_loss = 2.17758846282959, val_loss = 0.7959681749343872\n",
      "epoch n°286 : train_loss = 2.179649591445923, val_loss = 0.7985861301422119\n",
      "epoch n°287 : train_loss = 2.183666229248047, val_loss = 0.7984563112258911\n",
      "epoch n°288 : train_loss = 2.1757547855377197, val_loss = 0.8007123470306396\n",
      "epoch n°289 : train_loss = 2.18041729927063, val_loss = 0.7963823676109314\n",
      "epoch n°290 : train_loss = 2.176708698272705, val_loss = 0.8004794716835022\n",
      "epoch n°291 : train_loss = 2.1790926456451416, val_loss = 0.7926837205886841\n",
      "epoch n°292 : train_loss = 2.185777187347412, val_loss = 0.7979451417922974\n",
      "epoch n°293 : train_loss = 2.1768670082092285, val_loss = 0.7972024083137512\n",
      "epoch n°294 : train_loss = 2.1882483959198, val_loss = 0.7971177101135254\n",
      "epoch n°295 : train_loss = 2.1811556816101074, val_loss = 0.7957738637924194\n",
      "epoch n°296 : train_loss = 2.175300121307373, val_loss = 0.7985420823097229\n",
      "epoch n°297 : train_loss = 2.1788527965545654, val_loss = 0.7981794476509094\n",
      "epoch n°298 : train_loss = 2.172112226486206, val_loss = 0.7985512614250183\n",
      "epoch n°299 : train_loss = 2.1729321479797363, val_loss = 0.7996688485145569\n",
      "epoch n°300 : train_loss = 2.169245719909668, val_loss = 0.7973112463951111\n",
      "epoch n°301 : train_loss = 2.174880027770996, val_loss = 0.7969547510147095\n",
      "epoch n°302 : train_loss = 2.1722071170806885, val_loss = 0.800803542137146\n",
      "epoch n°303 : train_loss = 2.170659303665161, val_loss = 0.7959370017051697\n",
      "epoch n°304 : train_loss = 2.1699695587158203, val_loss = 0.7969790101051331\n",
      "epoch n°305 : train_loss = 2.1740050315856934, val_loss = 0.7929368019104004\n",
      "epoch n°306 : train_loss = 2.182865619659424, val_loss = 0.7970630526542664\n",
      "epoch n°307 : train_loss = 2.1638519763946533, val_loss = 0.7965005040168762\n",
      "epoch n°308 : train_loss = 2.1762306690216064, val_loss = 0.7978983521461487\n",
      "epoch n°309 : train_loss = 2.170405387878418, val_loss = 0.7999621033668518\n",
      "epoch n°310 : train_loss = 2.172140598297119, val_loss = 0.7970984578132629\n",
      "epoch n°311 : train_loss = 2.173462390899658, val_loss = 0.7934424877166748\n",
      "epoch n°312 : train_loss = 2.1686363220214844, val_loss = 0.7924919128417969\n",
      "epoch n°313 : train_loss = 2.169062376022339, val_loss = 0.7989518642425537\n",
      "epoch n°314 : train_loss = 2.169717788696289, val_loss = 0.8000351190567017\n",
      "epoch n°315 : train_loss = 2.170417070388794, val_loss = 0.7998045682907104\n",
      "epoch n°316 : train_loss = 2.162273406982422, val_loss = 0.7946836352348328\n",
      "epoch n°317 : train_loss = 2.171769618988037, val_loss = 0.7952765226364136\n",
      "epoch n°318 : train_loss = 2.171905755996704, val_loss = 0.7950225472450256\n",
      "epoch n°319 : train_loss = 2.1655139923095703, val_loss = 0.7980414032936096\n",
      "epoch n°320 : train_loss = 2.1723203659057617, val_loss = 0.799323320388794\n",
      "epoch n°321 : train_loss = 2.1635944843292236, val_loss = 0.7947202324867249\n",
      "epoch n°322 : train_loss = 2.16937518119812, val_loss = 0.7985450029373169\n",
      "epoch n°323 : train_loss = 2.1650140285491943, val_loss = 0.7938377857208252\n",
      "epoch n°324 : train_loss = 2.1612446308135986, val_loss = 0.8008077144622803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°325 : train_loss = 2.170300245285034, val_loss = 0.7992147207260132\n",
      "epoch n°326 : train_loss = 2.1665139198303223, val_loss = 0.7993298172950745\n",
      "epoch n°327 : train_loss = 2.1702558994293213, val_loss = 0.7952573895454407\n",
      "epoch n°328 : train_loss = 2.171250343322754, val_loss = 0.799369752407074\n",
      "epoch n°329 : train_loss = 2.162463903427124, val_loss = 0.7972077131271362\n",
      "epoch n°330 : train_loss = 2.169067144393921, val_loss = 0.7933105826377869\n",
      "epoch n°331 : train_loss = 2.177208185195923, val_loss = 0.7969515323638916\n",
      "epoch n°332 : train_loss = 2.1665377616882324, val_loss = 0.8031787276268005\n",
      "epoch n°333 : train_loss = 2.1663808822631836, val_loss = 0.797497570514679\n",
      "epoch n°334 : train_loss = 2.159637689590454, val_loss = 0.7976476550102234\n",
      "epoch n°335 : train_loss = 2.163597583770752, val_loss = 0.7935846447944641\n",
      "epoch n°336 : train_loss = 2.161052703857422, val_loss = 0.7980049848556519\n",
      "epoch n°337 : train_loss = 2.156229019165039, val_loss = 0.7917993664741516\n",
      "epoch n°338 : train_loss = 2.162137269973755, val_loss = 0.7990669012069702\n",
      "epoch n°339 : train_loss = 2.1618573665618896, val_loss = 0.7990416288375854\n",
      "epoch n°340 : train_loss = 2.1530020236968994, val_loss = 0.7951321005821228\n",
      "epoch n°341 : train_loss = 2.1624836921691895, val_loss = 0.7991276979446411\n",
      "epoch n°342 : train_loss = 2.1570534706115723, val_loss = 0.7996168732643127\n",
      "epoch n°343 : train_loss = 2.159196138381958, val_loss = 0.8023796081542969\n",
      "epoch n°344 : train_loss = 2.155689001083374, val_loss = 0.7961637377738953\n",
      "epoch n°345 : train_loss = 2.1645188331604004, val_loss = 0.7957015037536621\n",
      "epoch n°346 : train_loss = 2.1661128997802734, val_loss = 0.7990639805793762\n",
      "epoch n°347 : train_loss = 2.157496690750122, val_loss = 0.791967511177063\n",
      "epoch n°348 : train_loss = 2.1535465717315674, val_loss = 0.7938235402107239\n",
      "epoch n°349 : train_loss = 2.1618642807006836, val_loss = 0.7951539158821106\n",
      "epoch n°350 : train_loss = 2.1598451137542725, val_loss = 0.7943875193595886\n",
      "epoch n°351 : train_loss = 2.1539547443389893, val_loss = 0.7940773963928223\n",
      "epoch n°352 : train_loss = 2.151367664337158, val_loss = 0.7973487377166748\n",
      "epoch n°353 : train_loss = 2.152841806411743, val_loss = 0.7920799851417542\n",
      "epoch n°354 : train_loss = 2.159147262573242, val_loss = 0.7929183840751648\n",
      "epoch n°355 : train_loss = 2.152259349822998, val_loss = 0.7895147204399109\n",
      "epoch n°356 : train_loss = 2.1556835174560547, val_loss = 0.7953226566314697\n",
      "epoch n°357 : train_loss = 2.1570022106170654, val_loss = 0.7965928912162781\n",
      "epoch n°358 : train_loss = 2.157289743423462, val_loss = 0.7936703562736511\n",
      "epoch n°359 : train_loss = 2.1533093452453613, val_loss = 0.794432520866394\n",
      "epoch n°360 : train_loss = 2.1533150672912598, val_loss = 0.7933437824249268\n",
      "epoch n°361 : train_loss = 2.15092134475708, val_loss = 0.7929960489273071\n",
      "epoch n°362 : train_loss = 2.1558942794799805, val_loss = 0.798413872718811\n",
      "epoch n°363 : train_loss = 2.1517930030822754, val_loss = 0.7934932112693787\n",
      "epoch n°364 : train_loss = 2.1452040672302246, val_loss = 0.7888681292533875\n",
      "epoch n°365 : train_loss = 2.1457738876342773, val_loss = 0.798515260219574\n",
      "epoch n°366 : train_loss = 2.1497931480407715, val_loss = 0.7966020107269287\n",
      "epoch n°367 : train_loss = 2.1579976081848145, val_loss = 0.7916902899742126\n",
      "epoch n°368 : train_loss = 2.147108793258667, val_loss = 0.7974569797515869\n",
      "epoch n°369 : train_loss = 2.1466197967529297, val_loss = 0.7928565144538879\n",
      "epoch n°370 : train_loss = 2.1471691131591797, val_loss = 0.7914597988128662\n",
      "epoch n°371 : train_loss = 2.14483380317688, val_loss = 0.7944571375846863\n",
      "epoch n°372 : train_loss = 2.144658327102661, val_loss = 0.7934340834617615\n",
      "epoch n°373 : train_loss = 2.153280735015869, val_loss = 0.7958829998970032\n",
      "epoch n°374 : train_loss = 2.144157648086548, val_loss = 0.7954344153404236\n",
      "epoch n°375 : train_loss = 2.1543092727661133, val_loss = 0.7910367250442505\n",
      "epoch n°376 : train_loss = 2.1417384147644043, val_loss = 0.7981376647949219\n",
      "epoch n°377 : train_loss = 2.1496236324310303, val_loss = 0.7927336096763611\n",
      "epoch n°378 : train_loss = 2.1543142795562744, val_loss = 0.7994213104248047\n",
      "epoch n°379 : train_loss = 2.1416995525360107, val_loss = 0.7960114479064941\n",
      "epoch n°380 : train_loss = 2.147458553314209, val_loss = 0.7964121699333191\n",
      "epoch n°381 : train_loss = 2.1413216590881348, val_loss = 0.790753960609436\n",
      "epoch n°382 : train_loss = 2.13798189163208, val_loss = 0.7964380383491516\n",
      "epoch n°383 : train_loss = 2.142251491546631, val_loss = 0.7974480986595154\n",
      "epoch n°384 : train_loss = 2.144768476486206, val_loss = 0.7956611514091492\n",
      "epoch n°385 : train_loss = 2.1398329734802246, val_loss = 0.7989935278892517\n",
      "epoch n°386 : train_loss = 2.141617774963379, val_loss = 0.794245719909668\n",
      "epoch n°387 : train_loss = 2.141745090484619, val_loss = 0.7943663001060486\n",
      "epoch n°388 : train_loss = 2.141789674758911, val_loss = 0.796807587146759\n",
      "epoch n°389 : train_loss = 2.1357460021972656, val_loss = 0.8012319207191467\n",
      "epoch n°390 : train_loss = 2.150679588317871, val_loss = 0.7967752814292908\n",
      "epoch n°391 : train_loss = 2.1366493701934814, val_loss = 0.7931344509124756\n",
      "epoch n°392 : train_loss = 2.1427183151245117, val_loss = 0.7882135510444641\n",
      "epoch n°393 : train_loss = 2.1409285068511963, val_loss = 0.7952278256416321\n",
      "epoch n°394 : train_loss = 2.1381609439849854, val_loss = 0.7937057614326477\n",
      "epoch n°395 : train_loss = 2.1442532539367676, val_loss = 0.7935625910758972\n",
      "epoch n°396 : train_loss = 2.138273239135742, val_loss = 0.7958517670631409\n",
      "epoch n°397 : train_loss = 2.147569417953491, val_loss = 0.7961955666542053\n",
      "epoch n°398 : train_loss = 2.1359801292419434, val_loss = 0.7942496538162231\n",
      "epoch n°399 : train_loss = 2.144226551055908, val_loss = 0.7971063256263733\n",
      "epoch n°400 : train_loss = 2.143991470336914, val_loss = 0.7941169738769531\n",
      "epoch n°401 : train_loss = 2.140761613845825, val_loss = 0.797290563583374\n",
      "epoch n°402 : train_loss = 2.1453816890716553, val_loss = 0.8008880019187927\n",
      "epoch n°403 : train_loss = 2.13535737991333, val_loss = 0.796371340751648\n",
      "epoch n°404 : train_loss = 2.138181209564209, val_loss = 0.7893418669700623\n",
      "epoch n°405 : train_loss = 2.140778064727783, val_loss = 0.7956781387329102\n",
      "epoch n°406 : train_loss = 2.1403372287750244, val_loss = 0.7914789915084839\n",
      "epoch n°407 : train_loss = 2.135777711868286, val_loss = 0.7943861484527588\n",
      "epoch n°408 : train_loss = 2.1416993141174316, val_loss = 0.7936019897460938\n",
      "epoch n°409 : train_loss = 2.1286842823028564, val_loss = 0.7900562882423401\n",
      "epoch n°410 : train_loss = 2.1415774822235107, val_loss = 0.7979438304901123\n",
      "epoch n°411 : train_loss = 2.136613368988037, val_loss = 0.7964430451393127\n",
      "epoch n°412 : train_loss = 2.13590145111084, val_loss = 0.796169102191925\n",
      "epoch n°413 : train_loss = 2.1364188194274902, val_loss = 0.7945265769958496\n",
      "epoch n°414 : train_loss = 2.135488986968994, val_loss = 0.791000485420227\n",
      "epoch n°415 : train_loss = 2.1348345279693604, val_loss = 0.7935147881507874\n",
      "epoch n°416 : train_loss = 2.1296448707580566, val_loss = 0.7982922196388245\n",
      "epoch n°417 : train_loss = 2.1332483291625977, val_loss = 0.7969898581504822\n",
      "epoch n°418 : train_loss = 2.1333253383636475, val_loss = 0.798697829246521\n",
      "epoch n°419 : train_loss = 2.1415657997131348, val_loss = 0.7920710444450378\n",
      "epoch n°420 : train_loss = 2.137681245803833, val_loss = 0.7946012616157532\n",
      "epoch n°421 : train_loss = 2.1315627098083496, val_loss = 0.7981785535812378\n",
      "epoch n°422 : train_loss = 2.12955379486084, val_loss = 0.794175922870636\n",
      "epoch n°423 : train_loss = 2.1326260566711426, val_loss = 0.7943115234375\n",
      "epoch n°424 : train_loss = 2.1273717880249023, val_loss = 0.7946444749832153\n",
      "epoch n°425 : train_loss = 2.138984441757202, val_loss = 0.7919256091117859\n",
      "epoch n°426 : train_loss = 2.140552282333374, val_loss = 0.7948614954948425\n",
      "epoch n°427 : train_loss = 2.1395745277404785, val_loss = 0.7909420728683472\n",
      "epoch n°428 : train_loss = 2.1322858333587646, val_loss = 0.7951288223266602\n",
      "epoch n°429 : train_loss = 2.1329262256622314, val_loss = 0.7949409484863281\n",
      "epoch n°430 : train_loss = 2.129746913909912, val_loss = 0.7950710654258728\n",
      "epoch n°431 : train_loss = 2.130148410797119, val_loss = 0.7995744943618774\n",
      "epoch n°432 : train_loss = 2.130064010620117, val_loss = 0.7939407825469971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°433 : train_loss = 2.126255750656128, val_loss = 0.7952192425727844\n",
      "epoch n°434 : train_loss = 2.124504566192627, val_loss = 0.7943929433822632\n",
      "epoch n°435 : train_loss = 2.1243550777435303, val_loss = 0.792349636554718\n",
      "epoch n°436 : train_loss = 2.1276321411132812, val_loss = 0.7917258143424988\n",
      "epoch n°437 : train_loss = 2.1233880519866943, val_loss = 0.794529139995575\n",
      "epoch n°438 : train_loss = 2.125499725341797, val_loss = 0.7959420084953308\n",
      "epoch n°439 : train_loss = 2.1214230060577393, val_loss = 0.7915503978729248\n",
      "epoch n°440 : train_loss = 2.1342520713806152, val_loss = 0.7933728694915771\n",
      "epoch n°441 : train_loss = 2.1298272609710693, val_loss = 0.7931636571884155\n",
      "epoch n°442 : train_loss = 2.124436140060425, val_loss = 0.7894834280014038\n",
      "epoch n°443 : train_loss = 2.1343398094177246, val_loss = 0.7945133447647095\n",
      "epoch n°444 : train_loss = 2.1312007904052734, val_loss = 0.7940004467964172\n",
      "epoch n°445 : train_loss = 2.1263930797576904, val_loss = 0.7940899729728699\n",
      "epoch n°446 : train_loss = 2.1234843730926514, val_loss = 0.7958653569221497\n",
      "epoch n°447 : train_loss = 2.129639148712158, val_loss = 0.7910643219947815\n",
      "epoch n°448 : train_loss = 2.1297948360443115, val_loss = 0.7901709675788879\n",
      "epoch n°449 : train_loss = 2.1440107822418213, val_loss = 0.7943340539932251\n",
      "epoch n°450 : train_loss = 2.1292285919189453, val_loss = 0.7932010889053345\n",
      "epoch n°451 : train_loss = 2.125281810760498, val_loss = 0.793724000453949\n",
      "epoch n°452 : train_loss = 2.1337924003601074, val_loss = 0.7941321134567261\n",
      "epoch n°453 : train_loss = 2.1295244693756104, val_loss = 0.7970316410064697\n",
      "epoch n°454 : train_loss = 2.1220715045928955, val_loss = 0.7943956851959229\n",
      "epoch n°455 : train_loss = 2.131892442703247, val_loss = 0.7937493324279785\n",
      "epoch n°456 : train_loss = 2.134958028793335, val_loss = 0.794714629650116\n",
      "epoch n°457 : train_loss = 2.121687412261963, val_loss = 0.7963653802871704\n",
      "epoch n°458 : train_loss = 2.126405954360962, val_loss = 0.7925227284431458\n",
      "epoch n°459 : train_loss = 2.1276893615722656, val_loss = 0.7933632731437683\n",
      "epoch n°460 : train_loss = 2.125204086303711, val_loss = 0.7936791777610779\n",
      "epoch n°461 : train_loss = 2.1322033405303955, val_loss = 0.7925609946250916\n",
      "epoch n°462 : train_loss = 2.12734055519104, val_loss = 0.7947525382041931\n",
      "epoch n°463 : train_loss = 2.1298818588256836, val_loss = 0.7897287011146545\n",
      "epoch n°464 : train_loss = 2.134860038757324, val_loss = 0.7955080270767212\n",
      "epoch n°465 : train_loss = 2.1299331188201904, val_loss = 0.793720006942749\n",
      "epoch n°466 : train_loss = 2.1182312965393066, val_loss = 0.7970836162567139\n",
      "epoch n°467 : train_loss = 2.1274361610412598, val_loss = 0.790055513381958\n",
      "epoch n°468 : train_loss = 2.1249144077301025, val_loss = 0.7966516017913818\n",
      "epoch n°469 : train_loss = 2.1292614936828613, val_loss = 0.7951439023017883\n",
      "epoch n°470 : train_loss = 2.128342866897583, val_loss = 0.7935023307800293\n",
      "epoch n°471 : train_loss = 2.114952564239502, val_loss = 0.7908906936645508\n",
      "epoch n°472 : train_loss = 2.1204724311828613, val_loss = 0.794675886631012\n",
      "epoch n°473 : train_loss = 2.1318345069885254, val_loss = 0.7939481735229492\n",
      "epoch n°474 : train_loss = 2.1284701824188232, val_loss = 0.7918412089347839\n",
      "epoch n°475 : train_loss = 2.130882978439331, val_loss = 0.7951183319091797\n",
      "epoch n°476 : train_loss = 2.1231024265289307, val_loss = 0.7948099374771118\n",
      "epoch n°477 : train_loss = 2.1174240112304688, val_loss = 0.7937425374984741\n",
      "epoch n°478 : train_loss = 2.1245059967041016, val_loss = 0.7913005948066711\n",
      "epoch n°479 : train_loss = 2.12221622467041, val_loss = 0.794248104095459\n",
      "epoch n°480 : train_loss = 2.128779649734497, val_loss = 0.793244481086731\n",
      "epoch n°481 : train_loss = 2.1211941242218018, val_loss = 0.7888429760932922\n",
      "epoch n°482 : train_loss = 2.1233534812927246, val_loss = 0.7921814918518066\n",
      "epoch n°483 : train_loss = 2.1220147609710693, val_loss = 0.7918292880058289\n",
      "epoch n°484 : train_loss = 2.1281583309173584, val_loss = 0.7954990267753601\n",
      "epoch n°485 : train_loss = 2.1199018955230713, val_loss = 0.7952672243118286\n",
      "epoch n°486 : train_loss = 2.1395201683044434, val_loss = 0.7939987182617188\n",
      "epoch n°487 : train_loss = 2.1224958896636963, val_loss = 0.7950117588043213\n",
      "epoch n°488 : train_loss = 2.1309475898742676, val_loss = 0.7910613417625427\n",
      "epoch n°489 : train_loss = 2.132528066635132, val_loss = 0.7932829856872559\n",
      "epoch n°490 : train_loss = 2.1305930614471436, val_loss = 0.7925919890403748\n",
      "epoch n°491 : train_loss = 2.1213905811309814, val_loss = 0.7958711385726929\n",
      "epoch n°492 : train_loss = 2.1216681003570557, val_loss = 0.7956389784812927\n",
      "epoch n°493 : train_loss = 2.1197032928466797, val_loss = 0.7928794026374817\n",
      "epoch n°494 : train_loss = 2.1294198036193848, val_loss = 0.7930917739868164\n",
      "epoch n°495 : train_loss = 2.1205432415008545, val_loss = 0.791933000087738\n",
      "epoch n°496 : train_loss = 2.1415228843688965, val_loss = 0.7966979146003723\n",
      "epoch n°497 : train_loss = 2.150956630706787, val_loss = 0.7973671555519104\n",
      "epoch n°498 : train_loss = 2.1546220779418945, val_loss = 0.7974764704704285\n",
      "epoch n°499 : train_loss = 2.157716989517212, val_loss = 0.7977139353752136\n",
      "epoch n°500 : train_loss = 2.156074047088623, val_loss = 0.8009571433067322\n",
      "epoch n°501 : train_loss = 2.152040719985962, val_loss = 0.800347089767456\n",
      "epoch n°502 : train_loss = 2.1452112197875977, val_loss = 0.7978213429450989\n",
      "epoch n°503 : train_loss = 2.1511456966400146, val_loss = 0.7976399064064026\n",
      "epoch n°504 : train_loss = 2.154207944869995, val_loss = 0.7964736819267273\n",
      "epoch n°505 : train_loss = 2.153834342956543, val_loss = 0.79481440782547\n",
      "epoch n°506 : train_loss = 2.153683662414551, val_loss = 0.7962886691093445\n",
      "epoch n°507 : train_loss = 2.1555795669555664, val_loss = 0.7968804836273193\n",
      "epoch n°508 : train_loss = 2.1601316928863525, val_loss = 0.794702410697937\n",
      "epoch n°509 : train_loss = 2.1594362258911133, val_loss = 0.7965473532676697\n",
      "epoch n°510 : train_loss = 2.1589536666870117, val_loss = 0.7975192070007324\n",
      "epoch n°511 : train_loss = 2.159433603286743, val_loss = 0.7976414561271667\n",
      "epoch n°512 : train_loss = 2.1510229110717773, val_loss = 0.7940330505371094\n",
      "epoch n°513 : train_loss = 2.1405699253082275, val_loss = 0.7928447723388672\n",
      "epoch n°514 : train_loss = 2.142651319503784, val_loss = 0.7994201183319092\n",
      "epoch n°515 : train_loss = 2.1562695503234863, val_loss = 0.7976561784744263\n",
      "epoch n°516 : train_loss = 2.155904531478882, val_loss = 0.7951118350028992\n",
      "epoch n°517 : train_loss = 2.1512646675109863, val_loss = 0.7978619933128357\n",
      "epoch n°518 : train_loss = 2.1432225704193115, val_loss = 0.7935287952423096\n",
      "epoch n°519 : train_loss = 2.1587300300598145, val_loss = 0.8030651211738586\n",
      "epoch n°520 : train_loss = 2.1511504650115967, val_loss = 0.795364499092102\n",
      "epoch n°521 : train_loss = 2.1604883670806885, val_loss = 0.7990486025810242\n",
      "epoch n°522 : train_loss = 2.1559977531433105, val_loss = 0.8012996912002563\n",
      "epoch n°523 : train_loss = 2.1549627780914307, val_loss = 0.800115168094635\n",
      "epoch n°524 : train_loss = 2.159022331237793, val_loss = 0.7958428859710693\n",
      "epoch n°525 : train_loss = 2.148298978805542, val_loss = 0.7930347919464111\n",
      "epoch n°526 : train_loss = 2.146042585372925, val_loss = 0.7953605055809021\n",
      "epoch n°527 : train_loss = 2.1522929668426514, val_loss = 0.7984499931335449\n",
      "epoch n°528 : train_loss = 2.1497178077697754, val_loss = 0.7965071797370911\n",
      "epoch n°529 : train_loss = 2.1458868980407715, val_loss = 0.7951023578643799\n",
      "epoch n°530 : train_loss = 2.155056953430176, val_loss = 0.7986255288124084\n",
      "epoch n°531 : train_loss = 2.145090341567993, val_loss = 0.7997426986694336\n",
      "epoch n°532 : train_loss = 2.149474620819092, val_loss = 0.7975441813468933\n",
      "epoch n°533 : train_loss = 2.1544883251190186, val_loss = 0.796545147895813\n",
      "epoch n°534 : train_loss = 2.1427323818206787, val_loss = 0.798516035079956\n",
      "epoch n°535 : train_loss = 2.151782274246216, val_loss = 0.8015953302383423\n",
      "epoch n°536 : train_loss = 2.1589930057525635, val_loss = 0.8009448647499084\n",
      "epoch n°537 : train_loss = 2.1507279872894287, val_loss = 0.7989905476570129\n",
      "epoch n°538 : train_loss = 2.1518301963806152, val_loss = 0.7974592447280884\n",
      "epoch n°539 : train_loss = 2.1490566730499268, val_loss = 0.7961015701293945\n",
      "epoch n°540 : train_loss = 2.1459155082702637, val_loss = 0.8007628917694092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°541 : train_loss = 2.143472909927368, val_loss = 0.794990599155426\n",
      "epoch n°542 : train_loss = 2.148756504058838, val_loss = 0.7979754209518433\n",
      "epoch n°543 : train_loss = 2.1481375694274902, val_loss = 0.7945008873939514\n",
      "epoch n°544 : train_loss = 2.145817518234253, val_loss = 0.7992925643920898\n",
      "epoch n°545 : train_loss = 2.1608331203460693, val_loss = 0.7967986464500427\n",
      "epoch n°546 : train_loss = 2.138352632522583, val_loss = 0.7960898280143738\n",
      "epoch n°547 : train_loss = 2.152390241622925, val_loss = 0.795279860496521\n",
      "epoch n°548 : train_loss = 2.150275707244873, val_loss = 0.7910460829734802\n",
      "epoch n°549 : train_loss = 2.1484315395355225, val_loss = 0.7969066500663757\n",
      "epoch n°550 : train_loss = 2.153146982192993, val_loss = 0.7954768538475037\n",
      "epoch n°551 : train_loss = 2.1528890132904053, val_loss = 0.7960150241851807\n",
      "epoch n°552 : train_loss = 2.147212028503418, val_loss = 0.7978477478027344\n",
      "epoch n°553 : train_loss = 2.135885000228882, val_loss = 0.7980668544769287\n",
      "epoch n°554 : train_loss = 2.1526362895965576, val_loss = 0.7994580268859863\n",
      "epoch n°555 : train_loss = 2.1459157466888428, val_loss = 0.7988108992576599\n",
      "epoch n°556 : train_loss = 2.1458563804626465, val_loss = 0.7939103841781616\n",
      "epoch n°557 : train_loss = 2.1462414264678955, val_loss = 0.7966521978378296\n",
      "epoch n°558 : train_loss = 2.1547842025756836, val_loss = 0.7984131574630737\n",
      "epoch n°559 : train_loss = 2.1531426906585693, val_loss = 0.7950005531311035\n",
      "epoch n°560 : train_loss = 2.149745225906372, val_loss = 0.795728862285614\n",
      "epoch n°561 : train_loss = 2.146150827407837, val_loss = 0.7959619760513306\n",
      "epoch n°562 : train_loss = 2.1510889530181885, val_loss = 0.7981593012809753\n",
      "epoch n°563 : train_loss = 2.154935598373413, val_loss = 0.7970240712165833\n",
      "epoch n°564 : train_loss = 2.148388385772705, val_loss = 0.7942276000976562\n",
      "epoch n°565 : train_loss = 2.1446752548217773, val_loss = 0.7951030731201172\n",
      "epoch n°566 : train_loss = 2.1515274047851562, val_loss = 0.797155499458313\n",
      "epoch n°567 : train_loss = 2.1402339935302734, val_loss = 0.7947736978530884\n",
      "epoch n°568 : train_loss = 2.15332293510437, val_loss = 0.7981706261634827\n",
      "epoch n°569 : train_loss = 2.1446280479431152, val_loss = 0.7977892756462097\n",
      "epoch n°570 : train_loss = 2.1558053493499756, val_loss = 0.7943629622459412\n",
      "epoch n°571 : train_loss = 2.140990734100342, val_loss = 0.7989203929901123\n",
      "epoch n°572 : train_loss = 2.1521425247192383, val_loss = 0.7951548099517822\n",
      "epoch n°573 : train_loss = 2.141547918319702, val_loss = 0.7986683249473572\n",
      "epoch n°574 : train_loss = 2.143409252166748, val_loss = 0.794586181640625\n",
      "epoch n°575 : train_loss = 2.142396926879883, val_loss = 0.796901285648346\n",
      "epoch n°576 : train_loss = 2.1419453620910645, val_loss = 0.7964769601821899\n",
      "epoch n°577 : train_loss = 2.140183448791504, val_loss = 0.7969973683357239\n",
      "epoch n°578 : train_loss = 2.149019956588745, val_loss = 0.7953293919563293\n",
      "epoch n°579 : train_loss = 2.141305685043335, val_loss = 0.796492338180542\n",
      "epoch n°580 : train_loss = 2.1413564682006836, val_loss = 0.7997472286224365\n",
      "epoch n°581 : train_loss = 2.1466259956359863, val_loss = 0.7918503284454346\n",
      "epoch n°582 : train_loss = 2.1338274478912354, val_loss = 0.7994943261146545\n",
      "epoch n°583 : train_loss = 2.1436398029327393, val_loss = 0.795997142791748\n",
      "epoch n°584 : train_loss = 2.137389898300171, val_loss = 0.7900540828704834\n",
      "epoch n°585 : train_loss = 2.135789155960083, val_loss = 0.7953815460205078\n",
      "epoch n°586 : train_loss = 2.138852834701538, val_loss = 0.7965156435966492\n",
      "epoch n°587 : train_loss = 2.1347246170043945, val_loss = 0.7990519404411316\n",
      "epoch n°588 : train_loss = 2.1472692489624023, val_loss = 0.7943212985992432\n",
      "epoch n°589 : train_loss = 2.14643931388855, val_loss = 0.792670488357544\n",
      "epoch n°590 : train_loss = 2.1451010704040527, val_loss = 0.7938491702079773\n",
      "epoch n°591 : train_loss = 2.1477978229522705, val_loss = 0.7971057891845703\n",
      "epoch n°592 : train_loss = 2.143458127975464, val_loss = 0.7955296635627747\n",
      "epoch n°593 : train_loss = 2.142329692840576, val_loss = 0.7974193096160889\n",
      "epoch n°594 : train_loss = 2.1365675926208496, val_loss = 0.7940757274627686\n",
      "epoch n°595 : train_loss = 2.137239694595337, val_loss = 0.7929159998893738\n",
      "epoch n°596 : train_loss = 2.143549919128418, val_loss = 0.7953398823738098\n",
      "epoch n°597 : train_loss = 2.137216567993164, val_loss = 0.8001726269721985\n",
      "epoch n°598 : train_loss = 2.1407971382141113, val_loss = 0.7942649126052856\n",
      "epoch n°599 : train_loss = 2.1444268226623535, val_loss = 0.7984402179718018\n",
      "epoch n°600 : train_loss = 2.1432554721832275, val_loss = 0.7971343398094177\n",
      "epoch n°601 : train_loss = 2.1414971351623535, val_loss = 0.796541154384613\n",
      "epoch n°602 : train_loss = 2.1408262252807617, val_loss = 0.7945074439048767\n",
      "epoch n°603 : train_loss = 2.1370840072631836, val_loss = 0.7973985075950623\n",
      "epoch n°604 : train_loss = 2.131143093109131, val_loss = 0.7950499057769775\n",
      "epoch n°605 : train_loss = 2.1374869346618652, val_loss = 0.795195996761322\n",
      "epoch n°606 : train_loss = 2.1372218132019043, val_loss = 0.7970591187477112\n",
      "epoch n°607 : train_loss = 2.135979652404785, val_loss = 0.7980905175209045\n",
      "epoch n°608 : train_loss = 2.142490863800049, val_loss = 0.7963466644287109\n",
      "epoch n°609 : train_loss = 2.134413242340088, val_loss = 0.7923840284347534\n",
      "epoch n°610 : train_loss = 2.1261582374572754, val_loss = 0.7988439202308655\n",
      "epoch n°611 : train_loss = 2.138495445251465, val_loss = 0.7937980890274048\n",
      "epoch n°612 : train_loss = 2.133582353591919, val_loss = 0.7943010330200195\n",
      "epoch n°613 : train_loss = 2.1411683559417725, val_loss = 0.7994096279144287\n",
      "epoch n°614 : train_loss = 2.1409308910369873, val_loss = 0.792985737323761\n",
      "epoch n°615 : train_loss = 2.130776882171631, val_loss = 0.7965956330299377\n",
      "epoch n°616 : train_loss = 2.133551597595215, val_loss = 0.797980785369873\n",
      "epoch n°617 : train_loss = 2.1379354000091553, val_loss = 0.7996429800987244\n",
      "epoch n°618 : train_loss = 2.136526107788086, val_loss = 0.8008811473846436\n",
      "epoch n°619 : train_loss = 2.1381592750549316, val_loss = 0.7917062640190125\n",
      "epoch n°620 : train_loss = 2.131962299346924, val_loss = 0.7990577220916748\n",
      "epoch n°621 : train_loss = 2.129298686981201, val_loss = 0.7938600182533264\n",
      "epoch n°622 : train_loss = 2.1370656490325928, val_loss = 0.7969958782196045\n",
      "epoch n°623 : train_loss = 2.1397287845611572, val_loss = 0.8009548187255859\n",
      "epoch n°624 : train_loss = 2.1424612998962402, val_loss = 0.7950818538665771\n",
      "epoch n°625 : train_loss = 2.1289608478546143, val_loss = 0.7958462238311768\n",
      "epoch n°626 : train_loss = 2.135694980621338, val_loss = 0.7982913255691528\n",
      "epoch n°627 : train_loss = 2.135350465774536, val_loss = 0.7952503561973572\n",
      "epoch n°628 : train_loss = 2.1277859210968018, val_loss = 0.7965636849403381\n",
      "epoch n°629 : train_loss = 2.130295753479004, val_loss = 0.7990822196006775\n",
      "epoch n°630 : train_loss = 2.1332969665527344, val_loss = 0.7974478602409363\n",
      "epoch n°631 : train_loss = 2.1337358951568604, val_loss = 0.8022974729537964\n",
      "epoch n°632 : train_loss = 2.1357455253601074, val_loss = 0.7987357974052429\n",
      "epoch n°633 : train_loss = 2.1369669437408447, val_loss = 0.7918816208839417\n",
      "epoch n°634 : train_loss = 2.136413812637329, val_loss = 0.7969421744346619\n",
      "epoch n°635 : train_loss = 2.1353673934936523, val_loss = 0.7942273020744324\n",
      "epoch n°636 : train_loss = 2.135401725769043, val_loss = 0.7932040691375732\n",
      "epoch n°637 : train_loss = 2.1357359886169434, val_loss = 0.7974991202354431\n",
      "epoch n°638 : train_loss = 2.1310195922851562, val_loss = 0.7977562546730042\n",
      "epoch n°639 : train_loss = 2.138033866882324, val_loss = 0.7933357357978821\n",
      "epoch n°640 : train_loss = 2.1292340755462646, val_loss = 0.7939314842224121\n",
      "epoch n°641 : train_loss = 2.1351161003112793, val_loss = 0.7916970252990723\n",
      "epoch n°642 : train_loss = 2.135230541229248, val_loss = 0.7967588305473328\n",
      "epoch n°643 : train_loss = 2.1260135173797607, val_loss = 0.800159215927124\n",
      "epoch n°644 : train_loss = 2.133049249649048, val_loss = 0.7949087619781494\n",
      "epoch n°645 : train_loss = 2.1432442665100098, val_loss = 0.7977139949798584\n",
      "epoch n°646 : train_loss = 2.1304800510406494, val_loss = 0.7999644875526428\n",
      "epoch n°647 : train_loss = 2.1315455436706543, val_loss = 0.7990828156471252\n",
      "epoch n°648 : train_loss = 2.131276845932007, val_loss = 0.7962793707847595\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°649 : train_loss = 2.1365599632263184, val_loss = 0.7980204820632935\n",
      "epoch n°650 : train_loss = 2.13140606880188, val_loss = 0.7942866086959839\n",
      "epoch n°651 : train_loss = 2.130439519882202, val_loss = 0.7953019142150879\n",
      "epoch n°652 : train_loss = 2.1333091259002686, val_loss = 0.7940741777420044\n",
      "epoch n°653 : train_loss = 2.133861780166626, val_loss = 0.7980040907859802\n",
      "epoch n°654 : train_loss = 2.1287572383880615, val_loss = 0.7916649580001831\n",
      "epoch n°655 : train_loss = 2.125403642654419, val_loss = 0.7979270815849304\n",
      "epoch n°656 : train_loss = 2.1286165714263916, val_loss = 0.7909977436065674\n",
      "epoch n°657 : train_loss = 2.1347336769104004, val_loss = 0.7932138442993164\n",
      "epoch n°658 : train_loss = 2.117732048034668, val_loss = 0.7945458292961121\n",
      "epoch n°659 : train_loss = 2.1316208839416504, val_loss = 0.7913652658462524\n",
      "epoch n°660 : train_loss = 2.1274917125701904, val_loss = 0.7964085340499878\n",
      "epoch n°661 : train_loss = 2.1285507678985596, val_loss = 0.7984780073165894\n",
      "epoch n°662 : train_loss = 2.126156806945801, val_loss = 0.7985807657241821\n",
      "epoch n°663 : train_loss = 2.129117727279663, val_loss = 0.7945506572723389\n",
      "epoch n°664 : train_loss = 2.125279188156128, val_loss = 0.7961886525154114\n",
      "epoch n°665 : train_loss = 2.122659921646118, val_loss = 0.7967368364334106\n",
      "epoch n°666 : train_loss = 2.126455307006836, val_loss = 0.7962381839752197\n",
      "epoch n°667 : train_loss = 2.1218955516815186, val_loss = 0.7951750755310059\n",
      "epoch n°668 : train_loss = 2.120313882827759, val_loss = 0.7957393527030945\n",
      "epoch n°669 : train_loss = 2.1222848892211914, val_loss = 0.7975513339042664\n",
      "epoch n°670 : train_loss = 2.124502182006836, val_loss = 0.7878957986831665\n",
      "epoch n°671 : train_loss = 2.1269803047180176, val_loss = 0.7954588532447815\n",
      "epoch n°672 : train_loss = 2.1262319087982178, val_loss = 0.7960735559463501\n",
      "epoch n°673 : train_loss = 2.1266493797302246, val_loss = 0.7973860502243042\n",
      "epoch n°674 : train_loss = 2.110942840576172, val_loss = 0.7926449179649353\n",
      "epoch n°675 : train_loss = 2.1172034740448, val_loss = 0.7952591180801392\n",
      "epoch n°676 : train_loss = 2.119206428527832, val_loss = 0.7915709614753723\n",
      "epoch n°677 : train_loss = 2.1197962760925293, val_loss = 0.7965733408927917\n",
      "epoch n°678 : train_loss = 2.125699043273926, val_loss = 0.7933491468429565\n",
      "epoch n°679 : train_loss = 2.1186084747314453, val_loss = 0.7903440594673157\n",
      "epoch n°680 : train_loss = 2.119076728820801, val_loss = 0.7975563406944275\n",
      "epoch n°681 : train_loss = 2.120321273803711, val_loss = 0.7956746816635132\n",
      "epoch n°682 : train_loss = 2.107794761657715, val_loss = 0.7974660992622375\n",
      "epoch n°683 : train_loss = 2.1120314598083496, val_loss = 0.79234379529953\n",
      "epoch n°684 : train_loss = 2.122222423553467, val_loss = 0.7963512539863586\n",
      "epoch n°685 : train_loss = 2.118640661239624, val_loss = 0.7978509664535522\n",
      "epoch n°686 : train_loss = 2.113504648208618, val_loss = 0.7978055477142334\n",
      "epoch n°687 : train_loss = 2.117577075958252, val_loss = 0.7929095029830933\n",
      "epoch n°688 : train_loss = 2.116122245788574, val_loss = 0.7986019253730774\n",
      "epoch n°689 : train_loss = 2.1163902282714844, val_loss = 0.7941544055938721\n",
      "epoch n°690 : train_loss = 2.1194605827331543, val_loss = 0.7927714586257935\n",
      "epoch n°691 : train_loss = 2.1184945106506348, val_loss = 0.7891852259635925\n",
      "epoch n°692 : train_loss = 2.1232218742370605, val_loss = 0.7952940464019775\n",
      "epoch n°693 : train_loss = 2.11683988571167, val_loss = 0.7960695028305054\n",
      "epoch n°694 : train_loss = 2.1206891536712646, val_loss = 0.7929537892341614\n",
      "epoch n°695 : train_loss = 2.1167056560516357, val_loss = 0.7944139838218689\n",
      "epoch n°696 : train_loss = 2.125805616378784, val_loss = 0.7988353371620178\n",
      "epoch n°697 : train_loss = 2.115607738494873, val_loss = 0.7926977276802063\n",
      "epoch n°698 : train_loss = 2.121403455734253, val_loss = 0.7932857275009155\n",
      "epoch n°699 : train_loss = 2.122387409210205, val_loss = 0.7957429885864258\n",
      "epoch n°700 : train_loss = 2.1141271591186523, val_loss = 0.7983040809631348\n",
      "epoch n°701 : train_loss = 2.121462821960449, val_loss = 0.7961056232452393\n",
      "epoch n°702 : train_loss = 2.11747670173645, val_loss = 0.7921797633171082\n",
      "epoch n°703 : train_loss = 2.117708921432495, val_loss = 0.7957929968833923\n",
      "epoch n°704 : train_loss = 2.116936445236206, val_loss = 0.7921749949455261\n",
      "epoch n°705 : train_loss = 2.1166248321533203, val_loss = 0.7985691428184509\n",
      "epoch n°706 : train_loss = 2.1267454624176025, val_loss = 0.7946652173995972\n",
      "epoch n°707 : train_loss = 2.1196274757385254, val_loss = 0.7927708625793457\n",
      "epoch n°708 : train_loss = 2.1129884719848633, val_loss = 0.7917688488960266\n",
      "epoch n°709 : train_loss = 2.1244211196899414, val_loss = 0.7938743829727173\n",
      "epoch n°710 : train_loss = 2.1137242317199707, val_loss = 0.7937577366828918\n",
      "epoch n°711 : train_loss = 2.1197826862335205, val_loss = 0.7921420335769653\n",
      "epoch n°712 : train_loss = 2.1202478408813477, val_loss = 0.7934176921844482\n",
      "epoch n°713 : train_loss = 2.1236412525177, val_loss = 0.7980021834373474\n",
      "epoch n°714 : train_loss = 2.116525888442993, val_loss = 0.7965357303619385\n",
      "epoch n°715 : train_loss = 2.1213085651397705, val_loss = 0.7900675535202026\n",
      "epoch n°716 : train_loss = 2.1149935722351074, val_loss = 0.7926851511001587\n",
      "epoch n°717 : train_loss = 2.1098666191101074, val_loss = 0.7975632548332214\n",
      "epoch n°718 : train_loss = 2.1161439418792725, val_loss = 0.7942200899124146\n",
      "epoch n°719 : train_loss = 2.116286277770996, val_loss = 0.789622962474823\n",
      "epoch n°720 : train_loss = 2.103595495223999, val_loss = 0.7960035800933838\n",
      "epoch n°721 : train_loss = 2.112079620361328, val_loss = 0.7929846048355103\n",
      "epoch n°722 : train_loss = 2.1200602054595947, val_loss = 0.7967481017112732\n",
      "epoch n°723 : train_loss = 2.11606502532959, val_loss = 0.7953701615333557\n",
      "epoch n°724 : train_loss = 2.117218255996704, val_loss = 0.7946016788482666\n",
      "epoch n°725 : train_loss = 2.115286350250244, val_loss = 0.7964114546775818\n",
      "epoch n°726 : train_loss = 2.112701892852783, val_loss = 0.7981898784637451\n",
      "epoch n°727 : train_loss = 2.1160786151885986, val_loss = 0.7983551025390625\n",
      "epoch n°728 : train_loss = 2.1117985248565674, val_loss = 0.7977420091629028\n",
      "epoch n°729 : train_loss = 2.1181061267852783, val_loss = 0.793638288974762\n",
      "epoch n°730 : train_loss = 2.1151225566864014, val_loss = 0.7941996455192566\n",
      "epoch n°731 : train_loss = 2.116917848587036, val_loss = 0.7934919595718384\n",
      "epoch n°732 : train_loss = 2.116842269897461, val_loss = 0.7979826331138611\n",
      "epoch n°733 : train_loss = 2.118840217590332, val_loss = 0.7909759283065796\n",
      "epoch n°734 : train_loss = 2.111461639404297, val_loss = 0.7933661341667175\n",
      "epoch n°735 : train_loss = 2.1126163005828857, val_loss = 0.7923092246055603\n",
      "epoch n°736 : train_loss = 2.107403516769409, val_loss = 0.7942062020301819\n",
      "epoch n°737 : train_loss = 2.108896493911743, val_loss = 0.7930392622947693\n",
      "epoch n°738 : train_loss = 2.115121841430664, val_loss = 0.7971010804176331\n",
      "epoch n°739 : train_loss = 2.1128005981445312, val_loss = 0.7938934564590454\n",
      "epoch n°740 : train_loss = 2.100538969039917, val_loss = 0.7948605418205261\n",
      "epoch n°741 : train_loss = 2.1022701263427734, val_loss = 0.7997583746910095\n",
      "epoch n°742 : train_loss = 2.111165761947632, val_loss = 0.7957842350006104\n",
      "epoch n°743 : train_loss = 2.11655855178833, val_loss = 0.7980325222015381\n",
      "epoch n°744 : train_loss = 2.108689546585083, val_loss = 0.794180154800415\n",
      "epoch n°745 : train_loss = 2.1071512699127197, val_loss = 0.7919555306434631\n",
      "epoch n°746 : train_loss = 2.1141486167907715, val_loss = 0.7944958209991455\n",
      "epoch n°747 : train_loss = 2.1087803840637207, val_loss = 0.7955731153488159\n",
      "epoch n°748 : train_loss = 2.1098926067352295, val_loss = 0.7935659289360046\n",
      "epoch n°749 : train_loss = 2.1132564544677734, val_loss = 0.79896080493927\n",
      "epoch n°750 : train_loss = 2.1187024116516113, val_loss = 0.7965388298034668\n",
      "epoch n°751 : train_loss = 2.1046576499938965, val_loss = 0.7926508188247681\n",
      "epoch n°752 : train_loss = 2.1048190593719482, val_loss = 0.7943254113197327\n",
      "epoch n°753 : train_loss = 2.108511447906494, val_loss = 0.7925668954849243\n",
      "epoch n°754 : train_loss = 2.107593297958374, val_loss = 0.7949090003967285\n",
      "epoch n°755 : train_loss = 2.1094846725463867, val_loss = 0.7937691807746887\n",
      "epoch n°756 : train_loss = 2.102634906768799, val_loss = 0.7966912984848022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°757 : train_loss = 2.0992233753204346, val_loss = 0.8000769019126892\n",
      "epoch n°758 : train_loss = 2.099357843399048, val_loss = 0.7932307124137878\n",
      "epoch n°759 : train_loss = 2.100553035736084, val_loss = 0.7962704300880432\n",
      "epoch n°760 : train_loss = 2.1014814376831055, val_loss = 0.7944208383560181\n",
      "epoch n°761 : train_loss = 2.1050827503204346, val_loss = 0.7921178936958313\n",
      "epoch n°762 : train_loss = 2.105966567993164, val_loss = 0.7938555479049683\n",
      "epoch n°763 : train_loss = 2.1047463417053223, val_loss = 0.7954151630401611\n",
      "epoch n°764 : train_loss = 2.1025426387786865, val_loss = 0.791235089302063\n",
      "epoch n°765 : train_loss = 2.111398220062256, val_loss = 0.7937304973602295\n",
      "epoch n°766 : train_loss = 2.10072922706604, val_loss = 0.7945005893707275\n",
      "epoch n°767 : train_loss = 2.113544225692749, val_loss = 0.7928482294082642\n",
      "epoch n°768 : train_loss = 2.115508794784546, val_loss = 0.7935711741447449\n",
      "epoch n°769 : train_loss = 2.094050884246826, val_loss = 0.7983036637306213\n",
      "epoch n°770 : train_loss = 2.1049389839172363, val_loss = 0.7908056378364563\n",
      "epoch n°771 : train_loss = 2.107591390609741, val_loss = 0.7937557697296143\n",
      "epoch n°772 : train_loss = 2.1054859161376953, val_loss = 0.7949875593185425\n",
      "epoch n°773 : train_loss = 2.1029574871063232, val_loss = 0.7923976182937622\n",
      "epoch n°774 : train_loss = 2.1048476696014404, val_loss = 0.7965642213821411\n",
      "epoch n°775 : train_loss = 2.1035969257354736, val_loss = 0.7956869602203369\n",
      "epoch n°776 : train_loss = 2.099107027053833, val_loss = 0.7985712885856628\n",
      "epoch n°777 : train_loss = 2.1134209632873535, val_loss = 0.7947728037834167\n",
      "epoch n°778 : train_loss = 2.1059839725494385, val_loss = 0.7976316213607788\n",
      "epoch n°779 : train_loss = 2.105900764465332, val_loss = 0.7920161485671997\n",
      "epoch n°780 : train_loss = 2.1019394397735596, val_loss = 0.7970060110092163\n",
      "epoch n°781 : train_loss = 2.0978245735168457, val_loss = 0.798015832901001\n",
      "epoch n°782 : train_loss = 2.109550952911377, val_loss = 0.7904480695724487\n",
      "epoch n°783 : train_loss = 2.106900215148926, val_loss = 0.7913908362388611\n",
      "epoch n°784 : train_loss = 2.0993120670318604, val_loss = 0.7897700071334839\n",
      "epoch n°785 : train_loss = 2.106914520263672, val_loss = 0.7962933778762817\n",
      "epoch n°786 : train_loss = 2.1015498638153076, val_loss = 0.7911705374717712\n",
      "epoch n°787 : train_loss = 2.1026718616485596, val_loss = 0.793426513671875\n",
      "epoch n°788 : train_loss = 2.099416971206665, val_loss = 0.7959729433059692\n",
      "epoch n°789 : train_loss = 2.096545457839966, val_loss = 0.7916491627693176\n",
      "epoch n°790 : train_loss = 2.1014420986175537, val_loss = 0.7947977781295776\n",
      "epoch n°791 : train_loss = 2.0971407890319824, val_loss = 0.7951962351799011\n",
      "epoch n°792 : train_loss = 2.100916624069214, val_loss = 0.7948084473609924\n",
      "epoch n°793 : train_loss = 2.100898504257202, val_loss = 0.7925629019737244\n",
      "epoch n°794 : train_loss = 2.1018407344818115, val_loss = 0.7921546697616577\n",
      "epoch n°795 : train_loss = 2.0920536518096924, val_loss = 0.795966625213623\n",
      "epoch n°796 : train_loss = 2.106907606124878, val_loss = 0.7962108850479126\n",
      "epoch n°797 : train_loss = 2.101031541824341, val_loss = 0.7965377569198608\n",
      "epoch n°798 : train_loss = 2.0984437465667725, val_loss = 0.7935526371002197\n",
      "epoch n°799 : train_loss = 2.1000876426696777, val_loss = 0.7884013056755066\n",
      "epoch n°800 : train_loss = 2.099280595779419, val_loss = 0.7957199811935425\n",
      "epoch n°801 : train_loss = 2.0963170528411865, val_loss = 0.7923731207847595\n",
      "epoch n°802 : train_loss = 2.099548101425171, val_loss = 0.79246586561203\n",
      "epoch n°803 : train_loss = 2.099271774291992, val_loss = 0.7945018410682678\n",
      "epoch n°804 : train_loss = 2.09899640083313, val_loss = 0.7904167771339417\n",
      "epoch n°805 : train_loss = 2.101506471633911, val_loss = 0.7948316335678101\n",
      "epoch n°806 : train_loss = 2.0934345722198486, val_loss = 0.7917687892913818\n",
      "epoch n°807 : train_loss = 2.09460186958313, val_loss = 0.793651819229126\n",
      "epoch n°808 : train_loss = 2.0989599227905273, val_loss = 0.796604573726654\n",
      "epoch n°809 : train_loss = 2.0986058712005615, val_loss = 0.7869062423706055\n",
      "epoch n°810 : train_loss = 2.1002864837646484, val_loss = 0.7891185879707336\n",
      "epoch n°811 : train_loss = 2.0990793704986572, val_loss = 0.7934623956680298\n",
      "epoch n°812 : train_loss = 2.09440016746521, val_loss = 0.7921339273452759\n",
      "epoch n°813 : train_loss = 2.103452444076538, val_loss = 0.7937465310096741\n",
      "epoch n°814 : train_loss = 2.092822313308716, val_loss = 0.7960681915283203\n",
      "epoch n°815 : train_loss = 2.0965654850006104, val_loss = 0.7990545034408569\n",
      "epoch n°816 : train_loss = 2.0934789180755615, val_loss = 0.7945178151130676\n",
      "epoch n°817 : train_loss = 2.097994089126587, val_loss = 0.7912730574607849\n",
      "epoch n°818 : train_loss = 2.097860336303711, val_loss = 0.7965149283409119\n",
      "epoch n°819 : train_loss = 2.1023600101470947, val_loss = 0.7942082285881042\n",
      "epoch n°820 : train_loss = 2.1004810333251953, val_loss = 0.7972436547279358\n",
      "epoch n°821 : train_loss = 2.0943427085876465, val_loss = 0.7948330640792847\n",
      "epoch n°822 : train_loss = 2.0937235355377197, val_loss = 0.7944952249526978\n",
      "epoch n°823 : train_loss = 2.0929887294769287, val_loss = 0.7928531169891357\n",
      "epoch n°824 : train_loss = 2.096562385559082, val_loss = 0.7910120487213135\n",
      "epoch n°825 : train_loss = 2.103379249572754, val_loss = 0.7893258333206177\n",
      "epoch n°826 : train_loss = 2.096950054168701, val_loss = 0.7929772138595581\n",
      "epoch n°827 : train_loss = 2.093416929244995, val_loss = 0.795600950717926\n",
      "epoch n°828 : train_loss = 2.0959277153015137, val_loss = 0.7938975691795349\n",
      "epoch n°829 : train_loss = 2.105282783508301, val_loss = 0.7967042922973633\n",
      "epoch n°830 : train_loss = 2.0888233184814453, val_loss = 0.7906782627105713\n",
      "epoch n°831 : train_loss = 2.0977187156677246, val_loss = 0.7952519059181213\n",
      "epoch n°832 : train_loss = 2.1030325889587402, val_loss = 0.7909845113754272\n",
      "epoch n°833 : train_loss = 2.0890417098999023, val_loss = 0.791733980178833\n",
      "epoch n°834 : train_loss = 2.0907845497131348, val_loss = 0.7951355576515198\n",
      "epoch n°835 : train_loss = 2.094644069671631, val_loss = 0.7938479781150818\n",
      "epoch n°836 : train_loss = 2.0901336669921875, val_loss = 0.7947903871536255\n",
      "epoch n°837 : train_loss = 2.094517707824707, val_loss = 0.7951454520225525\n",
      "epoch n°838 : train_loss = 2.0977938175201416, val_loss = 0.7939199805259705\n",
      "epoch n°839 : train_loss = 2.090423107147217, val_loss = 0.7906191349029541\n",
      "epoch n°840 : train_loss = 2.0959253311157227, val_loss = 0.7903686761856079\n",
      "epoch n°841 : train_loss = 2.0895328521728516, val_loss = 0.7945886254310608\n",
      "epoch n°842 : train_loss = 2.093057870864868, val_loss = 0.7919372320175171\n",
      "epoch n°843 : train_loss = 2.0935938358306885, val_loss = 0.7938410639762878\n",
      "epoch n°844 : train_loss = 2.097661018371582, val_loss = 0.7915756702423096\n",
      "epoch n°845 : train_loss = 2.0868165493011475, val_loss = 0.7908257246017456\n",
      "epoch n°846 : train_loss = 2.0966153144836426, val_loss = 0.7919639348983765\n",
      "epoch n°847 : train_loss = 2.0943782329559326, val_loss = 0.7978449463844299\n",
      "epoch n°848 : train_loss = 2.0892248153686523, val_loss = 0.7946808934211731\n",
      "epoch n°849 : train_loss = 2.099701404571533, val_loss = 0.7943518757820129\n",
      "epoch n°850 : train_loss = 2.0914723873138428, val_loss = 0.7962639927864075\n",
      "epoch n°851 : train_loss = 2.0892410278320312, val_loss = 0.7954667806625366\n",
      "epoch n°852 : train_loss = 2.0805537700653076, val_loss = 0.7942558526992798\n",
      "epoch n°853 : train_loss = 2.0926923751831055, val_loss = 0.789065957069397\n",
      "epoch n°854 : train_loss = 2.085716724395752, val_loss = 0.796205461025238\n",
      "epoch n°855 : train_loss = 2.087787628173828, val_loss = 0.7923914194107056\n",
      "epoch n°856 : train_loss = 2.0957753658294678, val_loss = 0.7936801314353943\n",
      "epoch n°857 : train_loss = 2.085735321044922, val_loss = 0.7935859560966492\n",
      "epoch n°858 : train_loss = 2.0915257930755615, val_loss = 0.7906701564788818\n",
      "epoch n°859 : train_loss = 2.098881721496582, val_loss = 0.7981352210044861\n",
      "epoch n°860 : train_loss = 2.0879173278808594, val_loss = 0.7919518351554871\n",
      "epoch n°861 : train_loss = 2.0907464027404785, val_loss = 0.7928243279457092\n",
      "epoch n°862 : train_loss = 2.0952489376068115, val_loss = 0.7905248403549194\n",
      "epoch n°863 : train_loss = 2.0889570713043213, val_loss = 0.7911415696144104\n",
      "epoch n°864 : train_loss = 2.094449996948242, val_loss = 0.7936080098152161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°865 : train_loss = 2.0857269763946533, val_loss = 0.7921951413154602\n",
      "epoch n°866 : train_loss = 2.0852160453796387, val_loss = 0.7959306836128235\n",
      "epoch n°867 : train_loss = 2.088175058364868, val_loss = 0.7957115173339844\n",
      "epoch n°868 : train_loss = 2.0881471633911133, val_loss = 0.787458598613739\n",
      "epoch n°869 : train_loss = 2.084498405456543, val_loss = 0.7901675701141357\n",
      "epoch n°870 : train_loss = 2.087707042694092, val_loss = 0.7939946055412292\n",
      "epoch n°871 : train_loss = 2.088046073913574, val_loss = 0.7913609147071838\n",
      "epoch n°872 : train_loss = 2.087049722671509, val_loss = 0.7888826727867126\n",
      "epoch n°873 : train_loss = 2.0899100303649902, val_loss = 0.7943175435066223\n",
      "epoch n°874 : train_loss = 2.0961880683898926, val_loss = 0.7988506555557251\n",
      "epoch n°875 : train_loss = 2.0943667888641357, val_loss = 0.7928240299224854\n",
      "epoch n°876 : train_loss = 2.0890684127807617, val_loss = 0.794592022895813\n",
      "epoch n°877 : train_loss = 2.0822246074676514, val_loss = 0.7964931130409241\n",
      "epoch n°878 : train_loss = 2.0856730937957764, val_loss = 0.7957804203033447\n",
      "epoch n°879 : train_loss = 2.0846071243286133, val_loss = 0.7930998802185059\n",
      "epoch n°880 : train_loss = 2.082777738571167, val_loss = 0.7907556891441345\n",
      "epoch n°881 : train_loss = 2.0937979221343994, val_loss = 0.7935698628425598\n",
      "epoch n°882 : train_loss = 2.0917861461639404, val_loss = 0.794853925704956\n",
      "epoch n°883 : train_loss = 2.085817575454712, val_loss = 0.7890037298202515\n",
      "epoch n°884 : train_loss = 2.093219518661499, val_loss = 0.7986010313034058\n",
      "epoch n°885 : train_loss = 2.0896241664886475, val_loss = 0.7933943271636963\n",
      "epoch n°886 : train_loss = 2.0848748683929443, val_loss = 0.7926540374755859\n",
      "epoch n°887 : train_loss = 2.093425750732422, val_loss = 0.7931963801383972\n",
      "epoch n°888 : train_loss = 2.087636947631836, val_loss = 0.7928801774978638\n",
      "epoch n°889 : train_loss = 2.0809834003448486, val_loss = 0.7925791144371033\n",
      "epoch n°890 : train_loss = 2.089252233505249, val_loss = 0.791563093662262\n",
      "epoch n°891 : train_loss = 2.0910096168518066, val_loss = 0.7950561046600342\n",
      "epoch n°892 : train_loss = 2.088074207305908, val_loss = 0.7936287522315979\n",
      "epoch n°893 : train_loss = 2.089818000793457, val_loss = 0.7955403327941895\n",
      "epoch n°894 : train_loss = 2.0877082347869873, val_loss = 0.7928416728973389\n",
      "epoch n°895 : train_loss = 2.0917251110076904, val_loss = 0.7906914949417114\n",
      "epoch n°896 : train_loss = 2.0865609645843506, val_loss = 0.7886289954185486\n",
      "epoch n°897 : train_loss = 2.090803623199463, val_loss = 0.7971175312995911\n",
      "epoch n°898 : train_loss = 2.1026229858398438, val_loss = 0.7937394380569458\n",
      "epoch n°899 : train_loss = 2.08260440826416, val_loss = 0.7926258444786072\n",
      "epoch n°900 : train_loss = 2.082562208175659, val_loss = 0.7934268116950989\n",
      "epoch n°901 : train_loss = 2.089508056640625, val_loss = 0.7952345609664917\n",
      "epoch n°902 : train_loss = 2.086745500564575, val_loss = 0.7930335402488708\n",
      "epoch n°903 : train_loss = 2.085179090499878, val_loss = 0.7892522811889648\n",
      "epoch n°904 : train_loss = 2.0804173946380615, val_loss = 0.7937492728233337\n",
      "epoch n°905 : train_loss = 2.0855674743652344, val_loss = 0.7955064177513123\n",
      "epoch n°906 : train_loss = 2.0903875827789307, val_loss = 0.7955378890037537\n",
      "epoch n°907 : train_loss = 2.082822799682617, val_loss = 0.79429692029953\n",
      "epoch n°908 : train_loss = 2.09203839302063, val_loss = 0.7969313263893127\n",
      "epoch n°909 : train_loss = 2.0905520915985107, val_loss = 0.7909823060035706\n",
      "epoch n°910 : train_loss = 2.0838844776153564, val_loss = 0.7925316691398621\n",
      "epoch n°911 : train_loss = 2.0926177501678467, val_loss = 0.7952011823654175\n",
      "epoch n°912 : train_loss = 2.0844595432281494, val_loss = 0.7951240539550781\n",
      "epoch n°913 : train_loss = 2.081707239151001, val_loss = 0.7893983125686646\n",
      "epoch n°914 : train_loss = 2.079150915145874, val_loss = 0.792989194393158\n",
      "epoch n°915 : train_loss = 2.0744316577911377, val_loss = 0.7929204106330872\n",
      "epoch n°916 : train_loss = 2.082231044769287, val_loss = 0.7936373949050903\n",
      "epoch n°917 : train_loss = 2.0865066051483154, val_loss = 0.7930582761764526\n",
      "epoch n°918 : train_loss = 2.0838780403137207, val_loss = 0.7925797700881958\n",
      "epoch n°919 : train_loss = 2.0906126499176025, val_loss = 0.7929574251174927\n",
      "epoch n°920 : train_loss = 2.0894715785980225, val_loss = 0.794151782989502\n",
      "epoch n°921 : train_loss = 2.0912952423095703, val_loss = 0.7989864349365234\n",
      "epoch n°922 : train_loss = 2.0795235633850098, val_loss = 0.7909603118896484\n",
      "epoch n°923 : train_loss = 2.0824062824249268, val_loss = 0.7860053181648254\n",
      "epoch n°924 : train_loss = 2.081368923187256, val_loss = 0.795410692691803\n",
      "epoch n°925 : train_loss = 2.0909082889556885, val_loss = 0.7921799421310425\n",
      "epoch n°926 : train_loss = 2.085073947906494, val_loss = 0.7939791083335876\n",
      "epoch n°927 : train_loss = 2.073911428451538, val_loss = 0.794166088104248\n",
      "epoch n°928 : train_loss = 2.088707208633423, val_loss = 0.7902758717536926\n",
      "epoch n°929 : train_loss = 2.077273368835449, val_loss = 0.7900609970092773\n",
      "epoch n°930 : train_loss = 2.0873610973358154, val_loss = 0.7931895852088928\n",
      "epoch n°931 : train_loss = 2.083632469177246, val_loss = 0.7950223088264465\n",
      "epoch n°932 : train_loss = 2.08347225189209, val_loss = 0.7920410633087158\n",
      "epoch n°933 : train_loss = 2.085195302963257, val_loss = 0.7904661297798157\n",
      "epoch n°934 : train_loss = 2.091984510421753, val_loss = 0.7960573434829712\n",
      "epoch n°935 : train_loss = 2.0883920192718506, val_loss = 0.7890991568565369\n",
      "epoch n°936 : train_loss = 2.084611654281616, val_loss = 0.7903516888618469\n",
      "epoch n°937 : train_loss = 2.07681941986084, val_loss = 0.7923111319541931\n",
      "epoch n°938 : train_loss = 2.0727901458740234, val_loss = 0.792773962020874\n",
      "epoch n°939 : train_loss = 2.0835893154144287, val_loss = 0.7931057810783386\n",
      "epoch n°940 : train_loss = 2.078831195831299, val_loss = 0.7931255102157593\n",
      "epoch n°941 : train_loss = 2.0876574516296387, val_loss = 0.7956779599189758\n",
      "epoch n°942 : train_loss = 2.0915491580963135, val_loss = 0.7923662662506104\n",
      "epoch n°943 : train_loss = 2.0821945667266846, val_loss = 0.7920843958854675\n",
      "epoch n°944 : train_loss = 2.0878663063049316, val_loss = 0.7912824153900146\n",
      "epoch n°945 : train_loss = 2.0910890102386475, val_loss = 0.7998859286308289\n",
      "epoch n°946 : train_loss = 2.0882925987243652, val_loss = 0.7929881811141968\n",
      "epoch n°947 : train_loss = 2.083972692489624, val_loss = 0.7933725118637085\n",
      "epoch n°948 : train_loss = 2.0731968879699707, val_loss = 0.7970522046089172\n",
      "epoch n°949 : train_loss = 2.073681116104126, val_loss = 0.7982692122459412\n",
      "epoch n°950 : train_loss = 2.0857653617858887, val_loss = 0.7916282415390015\n",
      "epoch n°951 : train_loss = 2.0853431224823, val_loss = 0.7923487424850464\n",
      "epoch n°952 : train_loss = 2.080862045288086, val_loss = 0.792424201965332\n",
      "epoch n°953 : train_loss = 2.0839343070983887, val_loss = 0.7915350198745728\n",
      "epoch n°954 : train_loss = 2.0778000354766846, val_loss = 0.7926583290100098\n",
      "epoch n°955 : train_loss = 2.0807840824127197, val_loss = 0.7950800061225891\n",
      "epoch n°956 : train_loss = 2.0792593955993652, val_loss = 0.7939609885215759\n",
      "epoch n°957 : train_loss = 2.0838170051574707, val_loss = 0.7909892797470093\n",
      "epoch n°958 : train_loss = 2.085158109664917, val_loss = 0.7940763831138611\n",
      "epoch n°959 : train_loss = 2.0891637802124023, val_loss = 0.7913286685943604\n",
      "epoch n°960 : train_loss = 2.0782008171081543, val_loss = 0.7930834293365479\n",
      "epoch n°961 : train_loss = 2.085507392883301, val_loss = 0.7919774651527405\n",
      "epoch n°962 : train_loss = 2.090161085128784, val_loss = 0.7929421067237854\n",
      "epoch n°963 : train_loss = 2.083662509918213, val_loss = 0.7921887040138245\n",
      "epoch n°964 : train_loss = 2.089294672012329, val_loss = 0.7933886647224426\n",
      "epoch n°965 : train_loss = 2.077497959136963, val_loss = 0.7910385131835938\n",
      "epoch n°966 : train_loss = 2.0789921283721924, val_loss = 0.7989761233329773\n",
      "epoch n°967 : train_loss = 2.0833868980407715, val_loss = 0.7913703918457031\n",
      "epoch n°968 : train_loss = 2.0871033668518066, val_loss = 0.7936884760856628\n",
      "epoch n°969 : train_loss = 2.0838568210601807, val_loss = 0.7889456152915955\n",
      "epoch n°970 : train_loss = 2.088155746459961, val_loss = 0.7893279194831848\n",
      "epoch n°971 : train_loss = 2.0761759281158447, val_loss = 0.7949594855308533\n",
      "epoch n°972 : train_loss = 2.0771918296813965, val_loss = 0.7973562479019165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°973 : train_loss = 2.087625741958618, val_loss = 0.7923905849456787\n",
      "epoch n°974 : train_loss = 2.0830795764923096, val_loss = 0.7890609502792358\n",
      "epoch n°975 : train_loss = 2.0800702571868896, val_loss = 0.7991507053375244\n",
      "epoch n°976 : train_loss = 2.0892956256866455, val_loss = 0.7905445098876953\n",
      "epoch n°977 : train_loss = 2.081784963607788, val_loss = 0.7919243574142456\n",
      "epoch n°978 : train_loss = 2.0868911743164062, val_loss = 0.7914376258850098\n",
      "epoch n°979 : train_loss = 2.089404821395874, val_loss = 0.7941518425941467\n",
      "epoch n°980 : train_loss = 2.0824899673461914, val_loss = 0.7976041436195374\n",
      "epoch n°981 : train_loss = 2.078298568725586, val_loss = 0.7936816811561584\n",
      "epoch n°982 : train_loss = 2.0823965072631836, val_loss = 0.7918061017990112\n",
      "epoch n°983 : train_loss = 2.0838375091552734, val_loss = 0.788535475730896\n",
      "epoch n°984 : train_loss = 2.0886270999908447, val_loss = 0.7897277474403381\n",
      "epoch n°985 : train_loss = 2.0866270065307617, val_loss = 0.7917271852493286\n",
      "epoch n°986 : train_loss = 2.0863168239593506, val_loss = 0.7936123013496399\n",
      "epoch n°987 : train_loss = 2.075495481491089, val_loss = 0.7953510284423828\n",
      "epoch n°988 : train_loss = 2.0799169540405273, val_loss = 0.7923449873924255\n",
      "epoch n°989 : train_loss = 2.0802221298217773, val_loss = 0.7929352521896362\n",
      "epoch n°990 : train_loss = 2.0814144611358643, val_loss = 0.793428361415863\n",
      "epoch n°991 : train_loss = 2.0838708877563477, val_loss = 0.7923577427864075\n",
      "epoch n°992 : train_loss = 2.0779335498809814, val_loss = 0.792887806892395\n",
      "epoch n°993 : train_loss = 2.0831234455108643, val_loss = 0.7925273776054382\n",
      "epoch n°994 : train_loss = 2.0911083221435547, val_loss = 0.793420135974884\n",
      "epoch n°995 : train_loss = 2.07969331741333, val_loss = 0.7921457886695862\n",
      "epoch n°996 : train_loss = 2.0839288234710693, val_loss = 0.7929290533065796\n",
      "epoch n°997 : train_loss = 2.0910804271698, val_loss = 0.792086660861969\n",
      "epoch n°998 : train_loss = 2.08628249168396, val_loss = 0.7912302613258362\n",
      "epoch n°999 : train_loss = 2.0867531299591064, val_loss = 0.7924883365631104\n",
      "epoch n°1000 : train_loss = 2.084542751312256, val_loss = 0.791114091873169\n",
      "epoch n°1001 : train_loss = 2.0732712745666504, val_loss = 0.7939857840538025\n",
      "epoch n°1002 : train_loss = 2.0864148139953613, val_loss = 0.7900905609130859\n",
      "epoch n°1003 : train_loss = 2.074345350265503, val_loss = 0.7934364676475525\n",
      "epoch n°1004 : train_loss = 2.090424060821533, val_loss = 0.7926424741744995\n",
      "epoch n°1005 : train_loss = 2.084845781326294, val_loss = 0.7950007915496826\n",
      "epoch n°1006 : train_loss = 2.09189510345459, val_loss = 0.7930368185043335\n",
      "epoch n°1007 : train_loss = 2.0778000354766846, val_loss = 0.7947130799293518\n",
      "epoch n°1008 : train_loss = 2.099468946456909, val_loss = 0.7993550896644592\n",
      "epoch n°1009 : train_loss = 2.116765022277832, val_loss = 0.7970377802848816\n",
      "epoch n°1010 : train_loss = 2.1123385429382324, val_loss = 0.7976572513580322\n",
      "epoch n°1011 : train_loss = 2.1064260005950928, val_loss = 0.7952649593353271\n",
      "epoch n°1012 : train_loss = 2.1097912788391113, val_loss = 0.7935511469841003\n",
      "epoch n°1013 : train_loss = 2.106475591659546, val_loss = 0.7937977910041809\n",
      "epoch n°1014 : train_loss = 2.1123435497283936, val_loss = 0.7976738810539246\n",
      "epoch n°1015 : train_loss = 2.1065196990966797, val_loss = 0.794028103351593\n",
      "epoch n°1016 : train_loss = 2.106135606765747, val_loss = 0.7981613874435425\n",
      "epoch n°1017 : train_loss = 2.106786012649536, val_loss = 0.7969755530357361\n",
      "epoch n°1018 : train_loss = 2.115079879760742, val_loss = 0.7946537137031555\n",
      "epoch n°1019 : train_loss = 2.116544008255005, val_loss = 0.7975544333457947\n",
      "epoch n°1020 : train_loss = 2.1080052852630615, val_loss = 0.791292667388916\n",
      "epoch n°1021 : train_loss = 2.118253231048584, val_loss = 0.7967971563339233\n",
      "epoch n°1022 : train_loss = 2.112534761428833, val_loss = 0.7946953773498535\n",
      "epoch n°1023 : train_loss = 2.112826347351074, val_loss = 0.7977172136306763\n",
      "epoch n°1024 : train_loss = 2.1157546043395996, val_loss = 0.7978298664093018\n",
      "epoch n°1025 : train_loss = 2.118820905685425, val_loss = 0.794319212436676\n",
      "epoch n°1026 : train_loss = 2.1160390377044678, val_loss = 0.7937857508659363\n",
      "epoch n°1027 : train_loss = 2.1125190258026123, val_loss = 0.7951943278312683\n",
      "epoch n°1028 : train_loss = 2.11570143699646, val_loss = 0.797794759273529\n",
      "epoch n°1029 : train_loss = 2.113574504852295, val_loss = 0.7938477993011475\n",
      "epoch n°1030 : train_loss = 2.109598159790039, val_loss = 0.7999085783958435\n",
      "epoch n°1031 : train_loss = 2.1230664253234863, val_loss = 0.7941644191741943\n",
      "epoch n°1032 : train_loss = 2.12251877784729, val_loss = 0.7960325479507446\n",
      "epoch n°1033 : train_loss = 2.113044023513794, val_loss = 0.7949464917182922\n",
      "epoch n°1034 : train_loss = 2.1216390132904053, val_loss = 0.8009012341499329\n",
      "epoch n°1035 : train_loss = 2.1069114208221436, val_loss = 0.7928724884986877\n",
      "epoch n°1036 : train_loss = 2.116180896759033, val_loss = 0.7932442426681519\n",
      "epoch n°1037 : train_loss = 2.121562957763672, val_loss = 0.7956166863441467\n",
      "epoch n°1038 : train_loss = 2.119460344314575, val_loss = 0.796290934085846\n",
      "epoch n°1039 : train_loss = 2.109311103820801, val_loss = 0.7974230051040649\n",
      "epoch n°1040 : train_loss = 2.1099987030029297, val_loss = 0.7937796711921692\n",
      "epoch n°1041 : train_loss = 2.1070902347564697, val_loss = 0.7960245609283447\n",
      "epoch n°1042 : train_loss = 2.1170313358306885, val_loss = 0.7921619415283203\n",
      "epoch n°1043 : train_loss = 2.1207382678985596, val_loss = 0.7956274747848511\n",
      "epoch n°1044 : train_loss = 2.1203253269195557, val_loss = 0.7928798794746399\n",
      "epoch n°1045 : train_loss = 2.118954658508301, val_loss = 0.799235463142395\n",
      "epoch n°1046 : train_loss = 2.114891529083252, val_loss = 0.7968549132347107\n",
      "epoch n°1047 : train_loss = 2.115833044052124, val_loss = 0.7991138100624084\n",
      "epoch n°1048 : train_loss = 2.109461784362793, val_loss = 0.7952306270599365\n",
      "epoch n°1049 : train_loss = 2.1157286167144775, val_loss = 0.7958714962005615\n",
      "epoch n°1050 : train_loss = 2.1152503490448, val_loss = 0.7893410921096802\n",
      "epoch n°1051 : train_loss = 2.099576234817505, val_loss = 0.7970048189163208\n",
      "epoch n°1052 : train_loss = 2.1189863681793213, val_loss = 0.7934015393257141\n",
      "epoch n°1053 : train_loss = 2.114076614379883, val_loss = 0.7955272793769836\n",
      "epoch n°1054 : train_loss = 2.1196627616882324, val_loss = 0.8001812100410461\n",
      "epoch n°1055 : train_loss = 2.1226441860198975, val_loss = 0.8010880947113037\n",
      "epoch n°1056 : train_loss = 2.1233627796173096, val_loss = 0.7987726330757141\n",
      "epoch n°1057 : train_loss = 2.1204073429107666, val_loss = 0.7988805770874023\n",
      "epoch n°1058 : train_loss = 2.1181557178497314, val_loss = 0.7974700331687927\n",
      "epoch n°1059 : train_loss = 2.1059317588806152, val_loss = 0.7960851788520813\n",
      "epoch n°1060 : train_loss = 2.1152613162994385, val_loss = 0.7932212352752686\n",
      "epoch n°1061 : train_loss = 2.113908529281616, val_loss = 0.7989596128463745\n",
      "epoch n°1062 : train_loss = 2.1156907081604004, val_loss = 0.7964242696762085\n",
      "epoch n°1063 : train_loss = 2.106964111328125, val_loss = 0.7951323986053467\n",
      "epoch n°1064 : train_loss = 2.1237637996673584, val_loss = 0.7952821254730225\n",
      "epoch n°1065 : train_loss = 2.1124043464660645, val_loss = 0.7996441125869751\n",
      "epoch n°1066 : train_loss = 2.1188600063323975, val_loss = 0.7965236306190491\n",
      "epoch n°1067 : train_loss = 2.1077358722686768, val_loss = 0.7949846386909485\n",
      "epoch n°1068 : train_loss = 2.1146020889282227, val_loss = 0.7984216213226318\n",
      "epoch n°1069 : train_loss = 2.1103057861328125, val_loss = 0.7981887459754944\n",
      "epoch n°1070 : train_loss = 2.1191320419311523, val_loss = 0.7895259261131287\n",
      "epoch n°1071 : train_loss = 2.115248441696167, val_loss = 0.7958205342292786\n",
      "epoch n°1072 : train_loss = 2.114410877227783, val_loss = 0.792136013507843\n",
      "epoch n°1073 : train_loss = 2.1213150024414062, val_loss = 0.7944294810295105\n",
      "epoch n°1074 : train_loss = 2.1045901775360107, val_loss = 0.7987701892852783\n",
      "epoch n°1075 : train_loss = 2.113445520401001, val_loss = 0.7929156422615051\n",
      "epoch n°1076 : train_loss = 2.11118221282959, val_loss = 0.7929590940475464\n",
      "epoch n°1077 : train_loss = 2.1127994060516357, val_loss = 0.7958505749702454\n",
      "epoch n°1078 : train_loss = 2.11495041847229, val_loss = 0.7983161211013794\n",
      "epoch n°1079 : train_loss = 2.1167097091674805, val_loss = 0.7973597645759583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°1080 : train_loss = 2.1104772090911865, val_loss = 0.7965884804725647\n",
      "epoch n°1081 : train_loss = 2.1107892990112305, val_loss = 0.7940019965171814\n",
      "epoch n°1082 : train_loss = 2.117974042892456, val_loss = 0.7967818379402161\n",
      "epoch n°1083 : train_loss = 2.1215715408325195, val_loss = 0.7988618612289429\n",
      "epoch n°1084 : train_loss = 2.1095328330993652, val_loss = 0.7989643812179565\n",
      "epoch n°1085 : train_loss = 2.1154208183288574, val_loss = 0.7994586229324341\n",
      "epoch n°1086 : train_loss = 2.111900806427002, val_loss = 0.7984288930892944\n",
      "epoch n°1087 : train_loss = 2.11476993560791, val_loss = 0.7978559136390686\n",
      "epoch n°1088 : train_loss = 2.1061012744903564, val_loss = 0.7969882488250732\n",
      "epoch n°1089 : train_loss = 2.1151845455169678, val_loss = 0.793915331363678\n",
      "epoch n°1090 : train_loss = 2.106168746948242, val_loss = 0.7958977818489075\n",
      "epoch n°1091 : train_loss = 2.111713409423828, val_loss = 0.7946356534957886\n",
      "epoch n°1092 : train_loss = 2.1152963638305664, val_loss = 0.7970262169837952\n",
      "epoch n°1093 : train_loss = 2.1045680046081543, val_loss = 0.7978084683418274\n",
      "epoch n°1094 : train_loss = 2.1135313510894775, val_loss = 0.79432213306427\n",
      "epoch n°1095 : train_loss = 2.116657257080078, val_loss = 0.7960907220840454\n",
      "epoch n°1096 : train_loss = 2.1183300018310547, val_loss = 0.79539555311203\n",
      "epoch n°1097 : train_loss = 2.1117584705352783, val_loss = 0.7995536923408508\n",
      "epoch n°1098 : train_loss = 2.11623477935791, val_loss = 0.7929450273513794\n",
      "epoch n°1099 : train_loss = 2.1166725158691406, val_loss = 0.7993396520614624\n",
      "epoch n°1100 : train_loss = 2.115907907485962, val_loss = 0.7958352565765381\n",
      "epoch n°1101 : train_loss = 2.105363130569458, val_loss = 0.8015490174293518\n",
      "epoch n°1102 : train_loss = 2.115180492401123, val_loss = 0.7985462546348572\n",
      "epoch n°1103 : train_loss = 2.110945463180542, val_loss = 0.7984082102775574\n",
      "epoch n°1104 : train_loss = 2.1047303676605225, val_loss = 0.7963007092475891\n",
      "epoch n°1105 : train_loss = 2.1142327785491943, val_loss = 0.7982624769210815\n",
      "epoch n°1106 : train_loss = 2.1116816997528076, val_loss = 0.7958792448043823\n",
      "epoch n°1107 : train_loss = 2.1099295616149902, val_loss = 0.7987727522850037\n",
      "epoch n°1108 : train_loss = 2.1076719760894775, val_loss = 0.8009135723114014\n",
      "epoch n°1109 : train_loss = 2.109835624694824, val_loss = 0.7955024838447571\n",
      "epoch n°1110 : train_loss = 2.1088569164276123, val_loss = 0.7991968393325806\n",
      "epoch n°1111 : train_loss = 2.1140944957733154, val_loss = 0.797136664390564\n",
      "epoch n°1112 : train_loss = 2.111969232559204, val_loss = 0.7960073351860046\n",
      "epoch n°1113 : train_loss = 2.106673002243042, val_loss = 0.7987927198410034\n",
      "epoch n°1114 : train_loss = 2.114489793777466, val_loss = 0.7964115738868713\n",
      "epoch n°1115 : train_loss = 2.1036670207977295, val_loss = 0.7983680367469788\n",
      "epoch n°1116 : train_loss = 2.1103668212890625, val_loss = 0.7929205894470215\n",
      "epoch n°1117 : train_loss = 2.1088128089904785, val_loss = 0.7982990145683289\n",
      "epoch n°1118 : train_loss = 2.1163482666015625, val_loss = 0.7911300659179688\n",
      "epoch n°1119 : train_loss = 2.1171727180480957, val_loss = 0.7938051223754883\n",
      "epoch n°1120 : train_loss = 2.1120762825012207, val_loss = 0.7966126799583435\n",
      "epoch n°1121 : train_loss = 2.1047520637512207, val_loss = 0.7990185618400574\n",
      "epoch n°1122 : train_loss = 2.1117327213287354, val_loss = 0.7964011430740356\n",
      "epoch n°1123 : train_loss = 2.114222288131714, val_loss = 0.7987420558929443\n",
      "epoch n°1124 : train_loss = 2.110597610473633, val_loss = 0.7986648678779602\n",
      "epoch n°1125 : train_loss = 2.1114070415496826, val_loss = 0.7952625155448914\n",
      "epoch n°1126 : train_loss = 2.1134533882141113, val_loss = 0.7977247834205627\n",
      "epoch n°1127 : train_loss = 2.1092965602874756, val_loss = 0.7973413467407227\n",
      "epoch n°1128 : train_loss = 2.109342575073242, val_loss = 0.7927231788635254\n",
      "epoch n°1129 : train_loss = 2.1031203269958496, val_loss = 0.7992963194847107\n",
      "epoch n°1130 : train_loss = 2.1106269359588623, val_loss = 0.7962718605995178\n",
      "epoch n°1131 : train_loss = 2.103159189224243, val_loss = 0.7950108647346497\n",
      "epoch n°1132 : train_loss = 2.106840133666992, val_loss = 0.7945988774299622\n",
      "epoch n°1133 : train_loss = 2.1055476665496826, val_loss = 0.792629599571228\n",
      "epoch n°1134 : train_loss = 2.113334894180298, val_loss = 0.7963259816169739\n",
      "epoch n°1135 : train_loss = 2.115377902984619, val_loss = 0.7957894206047058\n",
      "epoch n°1136 : train_loss = 2.1073219776153564, val_loss = 0.794411838054657\n",
      "epoch n°1137 : train_loss = 2.107510805130005, val_loss = 0.7934529185295105\n",
      "epoch n°1138 : train_loss = 2.1075379848480225, val_loss = 0.7967185974121094\n",
      "epoch n°1139 : train_loss = 2.104050874710083, val_loss = 0.7928714752197266\n",
      "epoch n°1140 : train_loss = 2.1113054752349854, val_loss = 0.7975698113441467\n",
      "epoch n°1141 : train_loss = 2.1058738231658936, val_loss = 0.7942662835121155\n",
      "epoch n°1142 : train_loss = 2.103619337081909, val_loss = 0.7967237830162048\n",
      "epoch n°1143 : train_loss = 2.1137588024139404, val_loss = 0.7945403456687927\n",
      "epoch n°1144 : train_loss = 2.114192008972168, val_loss = 0.7942305207252502\n",
      "epoch n°1145 : train_loss = 2.114210605621338, val_loss = 0.7960162162780762\n",
      "epoch n°1146 : train_loss = 2.1045403480529785, val_loss = 0.7952938079833984\n",
      "epoch n°1147 : train_loss = 2.115661859512329, val_loss = 0.794219434261322\n",
      "epoch n°1148 : train_loss = 2.1064672470092773, val_loss = 0.7935968637466431\n",
      "epoch n°1149 : train_loss = 2.107034921646118, val_loss = 0.7942855358123779\n",
      "epoch n°1150 : train_loss = 2.110738754272461, val_loss = 0.7951013445854187\n",
      "epoch n°1151 : train_loss = 2.1099393367767334, val_loss = 0.7968663573265076\n",
      "epoch n°1152 : train_loss = 2.1176388263702393, val_loss = 0.7987083196640015\n",
      "epoch n°1153 : train_loss = 2.103224039077759, val_loss = 0.8001853227615356\n",
      "epoch n°1154 : train_loss = 2.110427141189575, val_loss = 0.8020492792129517\n",
      "epoch n°1155 : train_loss = 2.106966733932495, val_loss = 0.798544704914093\n",
      "epoch n°1156 : train_loss = 2.104518175125122, val_loss = 0.8009746074676514\n",
      "epoch n°1157 : train_loss = 2.1056480407714844, val_loss = 0.797968864440918\n",
      "epoch n°1158 : train_loss = 2.1070878505706787, val_loss = 0.7991223931312561\n",
      "epoch n°1159 : train_loss = 2.105065107345581, val_loss = 0.7931650280952454\n",
      "epoch n°1160 : train_loss = 2.113248109817505, val_loss = 0.7949820160865784\n",
      "epoch n°1161 : train_loss = 2.1074090003967285, val_loss = 0.7949822545051575\n",
      "epoch n°1162 : train_loss = 2.099348545074463, val_loss = 0.7968519926071167\n",
      "epoch n°1163 : train_loss = 2.1116340160369873, val_loss = 0.7978382706642151\n",
      "epoch n°1164 : train_loss = 2.110553741455078, val_loss = 0.7928516864776611\n",
      "epoch n°1165 : train_loss = 2.097999334335327, val_loss = 0.7925305962562561\n",
      "epoch n°1166 : train_loss = 2.099658727645874, val_loss = 0.7948692440986633\n",
      "epoch n°1167 : train_loss = 2.1109302043914795, val_loss = 0.7969893217086792\n",
      "epoch n°1168 : train_loss = 2.1107020378112793, val_loss = 0.7961850166320801\n",
      "epoch n°1169 : train_loss = 2.1061062812805176, val_loss = 0.7973169684410095\n",
      "epoch n°1170 : train_loss = 2.1121888160705566, val_loss = 0.799377977848053\n",
      "epoch n°1171 : train_loss = 2.1057372093200684, val_loss = 0.798611044883728\n",
      "epoch n°1172 : train_loss = 2.113264560699463, val_loss = 0.7965808510780334\n",
      "epoch n°1173 : train_loss = 2.1183862686157227, val_loss = 0.7986306548118591\n",
      "epoch n°1174 : train_loss = 2.1142165660858154, val_loss = 0.7989664673805237\n",
      "epoch n°1175 : train_loss = 2.1054861545562744, val_loss = 0.7924537658691406\n",
      "epoch n°1176 : train_loss = 2.1111366748809814, val_loss = 0.7977120876312256\n",
      "epoch n°1177 : train_loss = 2.1101558208465576, val_loss = 0.7945476770401001\n",
      "epoch n°1178 : train_loss = 2.1077160835266113, val_loss = 0.795864999294281\n",
      "epoch n°1179 : train_loss = 2.1133148670196533, val_loss = 0.7958771586418152\n",
      "epoch n°1180 : train_loss = 2.1079578399658203, val_loss = 0.7947869300842285\n",
      "epoch n°1181 : train_loss = 2.1111886501312256, val_loss = 0.8008267879486084\n",
      "epoch n°1182 : train_loss = 2.1039979457855225, val_loss = 0.7976723313331604\n",
      "epoch n°1183 : train_loss = 2.1048097610473633, val_loss = 0.795208215713501\n",
      "epoch n°1184 : train_loss = 2.1035091876983643, val_loss = 0.7952240109443665\n",
      "epoch n°1185 : train_loss = 2.105992317199707, val_loss = 0.7945356369018555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°1186 : train_loss = 2.1086513996124268, val_loss = 0.8022571802139282\n",
      "epoch n°1187 : train_loss = 2.0960116386413574, val_loss = 0.7985963821411133\n",
      "epoch n°1188 : train_loss = 2.1148111820220947, val_loss = 0.7974452972412109\n",
      "epoch n°1189 : train_loss = 2.119025707244873, val_loss = 0.7942862510681152\n",
      "epoch n°1190 : train_loss = 2.113572597503662, val_loss = 0.7978433966636658\n",
      "epoch n°1191 : train_loss = 2.1043710708618164, val_loss = 0.7906767129898071\n",
      "epoch n°1192 : train_loss = 2.1071488857269287, val_loss = 0.7972725629806519\n",
      "epoch n°1193 : train_loss = 2.105257749557495, val_loss = 0.7953662276268005\n",
      "epoch n°1194 : train_loss = 2.1063015460968018, val_loss = 0.7912688255310059\n",
      "epoch n°1195 : train_loss = 2.1030433177948, val_loss = 0.7983973622322083\n",
      "epoch n°1196 : train_loss = 2.104412317276001, val_loss = 0.7987870573997498\n",
      "epoch n°1197 : train_loss = 2.1157138347625732, val_loss = 0.7957521080970764\n",
      "epoch n°1198 : train_loss = 2.097208261489868, val_loss = 0.798672080039978\n",
      "epoch n°1199 : train_loss = 2.1145660877227783, val_loss = 0.7919661402702332\n",
      "epoch n°1200 : train_loss = 2.103888511657715, val_loss = 0.795757532119751\n",
      "epoch n°1201 : train_loss = 2.1046369075775146, val_loss = 0.7935213446617126\n",
      "epoch n°1202 : train_loss = 2.1048171520233154, val_loss = 0.7988381385803223\n",
      "epoch n°1203 : train_loss = 2.1086838245391846, val_loss = 0.7942907214164734\n",
      "epoch n°1204 : train_loss = 2.106851577758789, val_loss = 0.7940598726272583\n",
      "epoch n°1205 : train_loss = 2.1043286323547363, val_loss = 0.7956345081329346\n",
      "epoch n°1206 : train_loss = 2.097578763961792, val_loss = 0.8020167946815491\n",
      "epoch n°1207 : train_loss = 2.114004611968994, val_loss = 0.7974698543548584\n",
      "epoch n°1208 : train_loss = 2.102649688720703, val_loss = 0.7927553057670593\n",
      "epoch n°1209 : train_loss = 2.1033287048339844, val_loss = 0.7945179343223572\n",
      "epoch n°1210 : train_loss = 2.1042540073394775, val_loss = 0.7957156300544739\n",
      "epoch n°1211 : train_loss = 2.1005101203918457, val_loss = 0.7966814637184143\n",
      "epoch n°1212 : train_loss = 2.108823299407959, val_loss = 0.7977760434150696\n",
      "epoch n°1213 : train_loss = 2.11438250541687, val_loss = 0.7944979667663574\n",
      "epoch n°1214 : train_loss = 2.097137689590454, val_loss = 0.7950192093849182\n",
      "epoch n°1215 : train_loss = 2.100001335144043, val_loss = 0.7972534894943237\n",
      "epoch n°1216 : train_loss = 2.103339672088623, val_loss = 0.7945170402526855\n",
      "epoch n°1217 : train_loss = 2.097642660140991, val_loss = 0.7974377870559692\n",
      "epoch n°1218 : train_loss = 2.1019251346588135, val_loss = 0.7958028316497803\n",
      "epoch n°1219 : train_loss = 2.104522228240967, val_loss = 0.7928754091262817\n",
      "epoch n°1220 : train_loss = 2.099841356277466, val_loss = 0.7970078587532043\n",
      "epoch n°1221 : train_loss = 2.0999581813812256, val_loss = 0.7982184886932373\n",
      "epoch n°1222 : train_loss = 2.108353614807129, val_loss = 0.7971923351287842\n",
      "epoch n°1223 : train_loss = 2.092514753341675, val_loss = 0.7992061376571655\n",
      "epoch n°1224 : train_loss = 2.1010689735412598, val_loss = 0.7959407567977905\n",
      "epoch n°1225 : train_loss = 2.106405019760132, val_loss = 0.797477662563324\n",
      "epoch n°1226 : train_loss = 2.106900930404663, val_loss = 0.7955325841903687\n",
      "epoch n°1227 : train_loss = 2.097911834716797, val_loss = 0.7975776195526123\n",
      "epoch n°1228 : train_loss = 2.103076219558716, val_loss = 0.7921836972236633\n",
      "epoch n°1229 : train_loss = 2.100367307662964, val_loss = 0.7956773042678833\n",
      "epoch n°1230 : train_loss = 2.1047561168670654, val_loss = 0.7918222546577454\n",
      "epoch n°1231 : train_loss = 2.105952501296997, val_loss = 0.7948496341705322\n",
      "epoch n°1232 : train_loss = 2.094395399093628, val_loss = 0.7960014343261719\n",
      "epoch n°1233 : train_loss = 2.096737861633301, val_loss = 0.7932577133178711\n",
      "epoch n°1234 : train_loss = 2.091369152069092, val_loss = 0.7973253130912781\n",
      "epoch n°1235 : train_loss = 2.100130796432495, val_loss = 0.7982114553451538\n",
      "epoch n°1236 : train_loss = 2.102426528930664, val_loss = 0.7948474884033203\n",
      "epoch n°1237 : train_loss = 2.1070454120635986, val_loss = 0.795238196849823\n",
      "epoch n°1238 : train_loss = 2.1067614555358887, val_loss = 0.7970068454742432\n",
      "epoch n°1239 : train_loss = 2.106985569000244, val_loss = 0.7950500845909119\n",
      "epoch n°1240 : train_loss = 2.099782705307007, val_loss = 0.7922238111495972\n",
      "epoch n°1241 : train_loss = 2.104081392288208, val_loss = 0.7970383167266846\n",
      "epoch n°1242 : train_loss = 2.100187301635742, val_loss = 0.7948988080024719\n",
      "epoch n°1243 : train_loss = 2.095828056335449, val_loss = 0.796640157699585\n",
      "epoch n°1244 : train_loss = 2.1035773754119873, val_loss = 0.7964925169944763\n",
      "epoch n°1245 : train_loss = 2.095759630203247, val_loss = 0.7940819263458252\n",
      "epoch n°1246 : train_loss = 2.100451707839966, val_loss = 0.7945259809494019\n",
      "epoch n°1247 : train_loss = 2.1050004959106445, val_loss = 0.7963686585426331\n",
      "epoch n°1248 : train_loss = 2.0997354984283447, val_loss = 0.7952526211738586\n",
      "epoch n°1249 : train_loss = 2.1033172607421875, val_loss = 0.7961295247077942\n",
      "epoch n°1250 : train_loss = 2.1037683486938477, val_loss = 0.7941389083862305\n",
      "epoch n°1251 : train_loss = 2.1009998321533203, val_loss = 0.796011745929718\n",
      "epoch n°1252 : train_loss = 2.092698097229004, val_loss = 0.7911199331283569\n",
      "epoch n°1253 : train_loss = 2.0964279174804688, val_loss = 0.7932913899421692\n",
      "epoch n°1254 : train_loss = 2.101987361907959, val_loss = 0.7966868281364441\n",
      "epoch n°1255 : train_loss = 2.096618890762329, val_loss = 0.7931622862815857\n",
      "epoch n°1256 : train_loss = 2.101806879043579, val_loss = 0.7984333038330078\n",
      "epoch n°1257 : train_loss = 2.095674753189087, val_loss = 0.7969551086425781\n",
      "epoch n°1258 : train_loss = 2.0977861881256104, val_loss = 0.7964135408401489\n",
      "epoch n°1259 : train_loss = 2.092637300491333, val_loss = 0.7958184480667114\n",
      "epoch n°1260 : train_loss = 2.095384359359741, val_loss = 0.7985528111457825\n",
      "epoch n°1261 : train_loss = 2.0933854579925537, val_loss = 0.7923052310943604\n",
      "epoch n°1262 : train_loss = 2.1015408039093018, val_loss = 0.7961812615394592\n",
      "epoch n°1263 : train_loss = 2.0999274253845215, val_loss = 0.7951518893241882\n",
      "epoch n°1264 : train_loss = 2.0995969772338867, val_loss = 0.800810694694519\n",
      "epoch n°1265 : train_loss = 2.0966594219207764, val_loss = 0.7970969080924988\n",
      "epoch n°1266 : train_loss = 2.102874517440796, val_loss = 0.7987282872200012\n",
      "epoch n°1267 : train_loss = 2.093266725540161, val_loss = 0.7956822514533997\n",
      "epoch n°1268 : train_loss = 2.1098668575286865, val_loss = 0.795479953289032\n",
      "epoch n°1269 : train_loss = 2.098137855529785, val_loss = 0.7997345924377441\n",
      "epoch n°1270 : train_loss = 2.0924556255340576, val_loss = 0.7945960164070129\n",
      "epoch n°1271 : train_loss = 2.096306800842285, val_loss = 0.7958528399467468\n",
      "epoch n°1272 : train_loss = 2.10703182220459, val_loss = 0.7972306609153748\n",
      "epoch n°1273 : train_loss = 2.101654052734375, val_loss = 0.7921677231788635\n",
      "epoch n°1274 : train_loss = 2.096482515335083, val_loss = 0.7923286557197571\n",
      "epoch n°1275 : train_loss = 2.0946314334869385, val_loss = 0.7949725985527039\n",
      "epoch n°1276 : train_loss = 2.1044273376464844, val_loss = 0.7959294319152832\n",
      "epoch n°1277 : train_loss = 2.100721836090088, val_loss = 0.7939756512641907\n",
      "epoch n°1278 : train_loss = 2.0953221321105957, val_loss = 0.7963175773620605\n",
      "epoch n°1279 : train_loss = 2.0938000679016113, val_loss = 0.7921545505523682\n",
      "epoch n°1280 : train_loss = 2.1046133041381836, val_loss = 0.7946304082870483\n",
      "epoch n°1281 : train_loss = 2.0929346084594727, val_loss = 0.79911208152771\n",
      "epoch n°1282 : train_loss = 2.1046807765960693, val_loss = 0.7941939830780029\n",
      "epoch n°1283 : train_loss = 2.0933804512023926, val_loss = 0.7985366582870483\n",
      "epoch n°1284 : train_loss = 2.094231367111206, val_loss = 0.7980910539627075\n",
      "epoch n°1285 : train_loss = 2.10223388671875, val_loss = 0.7981659770011902\n",
      "epoch n°1286 : train_loss = 2.0981459617614746, val_loss = 0.7954623103141785\n",
      "epoch n°1287 : train_loss = 2.100360631942749, val_loss = 0.7920805811882019\n",
      "epoch n°1288 : train_loss = 2.0981972217559814, val_loss = 0.7918713092803955\n",
      "epoch n°1289 : train_loss = 2.0993576049804688, val_loss = 0.7950705289840698\n",
      "epoch n°1290 : train_loss = 2.0943918228149414, val_loss = 0.797410249710083\n",
      "epoch n°1291 : train_loss = 2.1071760654449463, val_loss = 0.7969593405723572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°1292 : train_loss = 2.094172477722168, val_loss = 0.7985141277313232\n",
      "epoch n°1293 : train_loss = 2.0933516025543213, val_loss = 0.7977502346038818\n",
      "epoch n°1294 : train_loss = 2.1007018089294434, val_loss = 0.794395387172699\n",
      "epoch n°1295 : train_loss = 2.0929956436157227, val_loss = 0.7975473999977112\n",
      "epoch n°1296 : train_loss = 2.0942013263702393, val_loss = 0.7967666983604431\n",
      "epoch n°1297 : train_loss = 2.096698760986328, val_loss = 0.7946879267692566\n",
      "epoch n°1298 : train_loss = 2.100573778152466, val_loss = 0.7943485975265503\n",
      "epoch n°1299 : train_loss = 2.093378782272339, val_loss = 0.8001096844673157\n",
      "epoch n°1300 : train_loss = 2.0911552906036377, val_loss = 0.7964851260185242\n",
      "epoch n°1301 : train_loss = 2.091792106628418, val_loss = 0.7971223592758179\n",
      "epoch n°1302 : train_loss = 2.088502883911133, val_loss = 0.7977346181869507\n",
      "epoch n°1303 : train_loss = 2.090897560119629, val_loss = 0.7967677116394043\n",
      "epoch n°1304 : train_loss = 2.1004791259765625, val_loss = 0.7954930663108826\n",
      "epoch n°1305 : train_loss = 2.092146873474121, val_loss = 0.795723021030426\n",
      "epoch n°1306 : train_loss = 2.0959343910217285, val_loss = 0.7947783470153809\n",
      "epoch n°1307 : train_loss = 2.089707612991333, val_loss = 0.7981762886047363\n",
      "epoch n°1308 : train_loss = 2.095492124557495, val_loss = 0.791739821434021\n",
      "epoch n°1309 : train_loss = 2.0940101146698, val_loss = 0.800630509853363\n",
      "epoch n°1310 : train_loss = 2.089937686920166, val_loss = 0.7916454076766968\n",
      "epoch n°1311 : train_loss = 2.0992679595947266, val_loss = 0.7910380959510803\n",
      "epoch n°1312 : train_loss = 2.096982479095459, val_loss = 0.7955110669136047\n",
      "epoch n°1313 : train_loss = 2.095033884048462, val_loss = 0.7970557808876038\n",
      "epoch n°1314 : train_loss = 2.0922000408172607, val_loss = 0.7976256012916565\n",
      "epoch n°1315 : train_loss = 2.0957775115966797, val_loss = 0.7970172762870789\n",
      "epoch n°1316 : train_loss = 2.0916850566864014, val_loss = 0.7978683114051819\n",
      "epoch n°1317 : train_loss = 2.095846176147461, val_loss = 0.7962831854820251\n",
      "epoch n°1318 : train_loss = 2.0947747230529785, val_loss = 0.7971738576889038\n",
      "epoch n°1319 : train_loss = 2.0940840244293213, val_loss = 0.7990496754646301\n",
      "epoch n°1320 : train_loss = 2.0944180488586426, val_loss = 0.7954033613204956\n",
      "epoch n°1321 : train_loss = 2.087109327316284, val_loss = 0.8014745116233826\n",
      "epoch n°1322 : train_loss = 2.0940983295440674, val_loss = 0.7943257689476013\n",
      "epoch n°1323 : train_loss = 2.077738046646118, val_loss = 0.7945112586021423\n",
      "epoch n°1324 : train_loss = 2.0864105224609375, val_loss = 0.7939890027046204\n",
      "epoch n°1325 : train_loss = 2.093392848968506, val_loss = 0.7985445261001587\n",
      "epoch n°1326 : train_loss = 2.0944321155548096, val_loss = 0.7974570393562317\n",
      "epoch n°1327 : train_loss = 2.090287685394287, val_loss = 0.7925727367401123\n",
      "epoch n°1328 : train_loss = 2.0896456241607666, val_loss = 0.7953919768333435\n",
      "epoch n°1329 : train_loss = 2.088873863220215, val_loss = 0.7969540357589722\n",
      "epoch n°1330 : train_loss = 2.0857977867126465, val_loss = 0.7940111756324768\n",
      "epoch n°1331 : train_loss = 2.083024740219116, val_loss = 0.7943553328514099\n",
      "epoch n°1332 : train_loss = 2.099745273590088, val_loss = 0.7968984246253967\n",
      "epoch n°1333 : train_loss = 2.0846877098083496, val_loss = 0.7978244423866272\n",
      "epoch n°1334 : train_loss = 2.0872445106506348, val_loss = 0.7943693995475769\n",
      "epoch n°1335 : train_loss = 2.0872364044189453, val_loss = 0.7949361801147461\n",
      "epoch n°1336 : train_loss = 2.0960748195648193, val_loss = 0.7936816811561584\n",
      "epoch n°1337 : train_loss = 2.096510648727417, val_loss = 0.7922387719154358\n",
      "epoch n°1338 : train_loss = 2.08577823638916, val_loss = 0.7962384819984436\n",
      "epoch n°1339 : train_loss = 2.093071937561035, val_loss = 0.7998857498168945\n",
      "epoch n°1340 : train_loss = 2.086601734161377, val_loss = 0.7989611625671387\n",
      "epoch n°1341 : train_loss = 2.088791847229004, val_loss = 0.7918627262115479\n",
      "epoch n°1342 : train_loss = 2.097566843032837, val_loss = 0.7897926568984985\n",
      "epoch n°1343 : train_loss = 2.0901851654052734, val_loss = 0.7979311943054199\n",
      "epoch n°1344 : train_loss = 2.0932023525238037, val_loss = 0.794878363609314\n",
      "epoch n°1345 : train_loss = 2.0878374576568604, val_loss = 0.7935589551925659\n",
      "epoch n°1346 : train_loss = 2.0946197509765625, val_loss = 0.7952584624290466\n",
      "epoch n°1347 : train_loss = 2.081958532333374, val_loss = 0.7942965626716614\n",
      "epoch n°1348 : train_loss = 2.0900180339813232, val_loss = 0.7976793646812439\n",
      "epoch n°1349 : train_loss = 2.0863406658172607, val_loss = 0.7923851609230042\n",
      "epoch n°1350 : train_loss = 2.0876822471618652, val_loss = 0.7944862842559814\n",
      "epoch n°1351 : train_loss = 2.0931828022003174, val_loss = 0.7996513247489929\n",
      "epoch n°1352 : train_loss = 2.0864381790161133, val_loss = 0.7954531311988831\n",
      "epoch n°1353 : train_loss = 2.0866658687591553, val_loss = 0.7952015399932861\n",
      "epoch n°1354 : train_loss = 2.091874599456787, val_loss = 0.7960654497146606\n",
      "epoch n°1355 : train_loss = 2.080791711807251, val_loss = 0.7914779782295227\n",
      "epoch n°1356 : train_loss = 2.088155508041382, val_loss = 0.7967462539672852\n",
      "epoch n°1357 : train_loss = 2.0830204486846924, val_loss = 0.7978012561798096\n",
      "epoch n°1358 : train_loss = 2.092643976211548, val_loss = 0.7970972061157227\n",
      "epoch n°1359 : train_loss = 2.087951183319092, val_loss = 0.7939062118530273\n",
      "epoch n°1360 : train_loss = 2.085102081298828, val_loss = 0.7959165573120117\n",
      "epoch n°1361 : train_loss = 2.08479380607605, val_loss = 0.8008384704589844\n",
      "epoch n°1362 : train_loss = 2.0860230922698975, val_loss = 0.7939605712890625\n",
      "epoch n°1363 : train_loss = 2.084660291671753, val_loss = 0.7946494817733765\n",
      "epoch n°1364 : train_loss = 2.093214273452759, val_loss = 0.7913232445716858\n",
      "epoch n°1365 : train_loss = 2.091085433959961, val_loss = 0.7927088141441345\n",
      "epoch n°1366 : train_loss = 2.0901541709899902, val_loss = 0.7969149947166443\n",
      "epoch n°1367 : train_loss = 2.0817816257476807, val_loss = 0.7949024438858032\n",
      "epoch n°1368 : train_loss = 2.0970239639282227, val_loss = 0.7967249751091003\n",
      "epoch n°1369 : train_loss = 2.0881216526031494, val_loss = 0.7980977892875671\n",
      "epoch n°1370 : train_loss = 2.0915205478668213, val_loss = 0.7972455620765686\n",
      "epoch n°1371 : train_loss = 2.097555160522461, val_loss = 0.7947874069213867\n",
      "epoch n°1372 : train_loss = 2.0959768295288086, val_loss = 0.7967967391014099\n",
      "epoch n°1373 : train_loss = 2.0872573852539062, val_loss = 0.7956660985946655\n",
      "epoch n°1374 : train_loss = 2.0916976928710938, val_loss = 0.7974915504455566\n",
      "epoch n°1375 : train_loss = 2.078897714614868, val_loss = 0.7923293113708496\n",
      "epoch n°1376 : train_loss = 2.086150884628296, val_loss = 0.7963988780975342\n",
      "epoch n°1377 : train_loss = 2.0913450717926025, val_loss = 0.7944890260696411\n",
      "epoch n°1378 : train_loss = 2.088733434677124, val_loss = 0.7922633290290833\n",
      "epoch n°1379 : train_loss = 2.083906650543213, val_loss = 0.7930828332901001\n",
      "epoch n°1380 : train_loss = 2.0897860527038574, val_loss = 0.7916983962059021\n",
      "epoch n°1381 : train_loss = 2.0948808193206787, val_loss = 0.7948199510574341\n",
      "epoch n°1382 : train_loss = 2.0826523303985596, val_loss = 0.7961852550506592\n",
      "epoch n°1383 : train_loss = 2.087739944458008, val_loss = 0.7937034368515015\n",
      "epoch n°1384 : train_loss = 2.087237596511841, val_loss = 0.7929708361625671\n",
      "epoch n°1385 : train_loss = 2.092221260070801, val_loss = 0.7929016947746277\n",
      "epoch n°1386 : train_loss = 2.0853850841522217, val_loss = 0.7968249917030334\n",
      "epoch n°1387 : train_loss = 2.087005376815796, val_loss = 0.8008860945701599\n",
      "epoch n°1388 : train_loss = 2.0961122512817383, val_loss = 0.7929790616035461\n",
      "epoch n°1389 : train_loss = 2.0769612789154053, val_loss = 0.7923511862754822\n",
      "epoch n°1390 : train_loss = 2.0922086238861084, val_loss = 0.7932365536689758\n",
      "epoch n°1391 : train_loss = 2.0957753658294678, val_loss = 0.7983741760253906\n",
      "epoch n°1392 : train_loss = 2.0791282653808594, val_loss = 0.7936131358146667\n",
      "epoch n°1393 : train_loss = 2.071361541748047, val_loss = 0.7936719059944153\n",
      "epoch n°1394 : train_loss = 2.0870072841644287, val_loss = 0.7977681159973145\n",
      "epoch n°1395 : train_loss = 2.089846611022949, val_loss = 0.7940076589584351\n",
      "epoch n°1396 : train_loss = 2.085770845413208, val_loss = 0.7968930006027222\n",
      "epoch n°1397 : train_loss = 2.09153413772583, val_loss = 0.799148678779602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°1398 : train_loss = 2.0802416801452637, val_loss = 0.7974389791488647\n",
      "epoch n°1399 : train_loss = 2.0815093517303467, val_loss = 0.7923377156257629\n",
      "epoch n°1400 : train_loss = 2.0791757106781006, val_loss = 0.7998242378234863\n",
      "epoch n°1401 : train_loss = 2.0903265476226807, val_loss = 0.793652355670929\n",
      "epoch n°1402 : train_loss = 2.0875887870788574, val_loss = 0.7955126166343689\n",
      "epoch n°1403 : train_loss = 2.077693462371826, val_loss = 0.7986419200897217\n",
      "epoch n°1404 : train_loss = 2.0858426094055176, val_loss = 0.7979470491409302\n",
      "epoch n°1405 : train_loss = 2.085702896118164, val_loss = 0.7944110631942749\n",
      "epoch n°1406 : train_loss = 2.081789493560791, val_loss = 0.7964059114456177\n",
      "epoch n°1407 : train_loss = 2.0814781188964844, val_loss = 0.79310542345047\n",
      "epoch n°1408 : train_loss = 2.0844178199768066, val_loss = 0.790240466594696\n",
      "epoch n°1409 : train_loss = 2.082747220993042, val_loss = 0.7974585294723511\n",
      "epoch n°1410 : train_loss = 2.085602283477783, val_loss = 0.7936521768569946\n",
      "epoch n°1411 : train_loss = 2.0882315635681152, val_loss = 0.7920400500297546\n",
      "epoch n°1412 : train_loss = 2.082359790802002, val_loss = 0.7939059138298035\n",
      "epoch n°1413 : train_loss = 2.0872175693511963, val_loss = 0.7925524115562439\n",
      "epoch n°1414 : train_loss = 2.0852761268615723, val_loss = 0.7955353260040283\n",
      "epoch n°1415 : train_loss = 2.08469295501709, val_loss = 0.7918546199798584\n",
      "epoch n°1416 : train_loss = 2.081104278564453, val_loss = 0.7962349057197571\n",
      "epoch n°1417 : train_loss = 2.0739645957946777, val_loss = 0.8009928464889526\n",
      "epoch n°1418 : train_loss = 2.085869789123535, val_loss = 0.7976583242416382\n",
      "epoch n°1419 : train_loss = 2.0810725688934326, val_loss = 0.791904091835022\n",
      "epoch n°1420 : train_loss = 2.0874202251434326, val_loss = 0.7965188026428223\n",
      "epoch n°1421 : train_loss = 2.08526349067688, val_loss = 0.7950897812843323\n",
      "epoch n°1422 : train_loss = 2.085017204284668, val_loss = 0.7892831563949585\n",
      "epoch n°1423 : train_loss = 2.0895955562591553, val_loss = 0.7904130220413208\n",
      "epoch n°1424 : train_loss = 2.0825886726379395, val_loss = 0.7943503260612488\n",
      "epoch n°1425 : train_loss = 2.080765962600708, val_loss = 0.7961125373840332\n",
      "epoch n°1426 : train_loss = 2.0879549980163574, val_loss = 0.7930589914321899\n",
      "epoch n°1427 : train_loss = 2.0782525539398193, val_loss = 0.7950382232666016\n",
      "epoch n°1428 : train_loss = 2.0794687271118164, val_loss = 0.7925940155982971\n",
      "epoch n°1429 : train_loss = 2.078684091567993, val_loss = 0.7924550175666809\n",
      "epoch n°1430 : train_loss = 2.093748092651367, val_loss = 0.7982141375541687\n",
      "epoch n°1431 : train_loss = 2.07232403755188, val_loss = 0.7980867624282837\n",
      "epoch n°1432 : train_loss = 2.070669651031494, val_loss = 0.7935041785240173\n",
      "epoch n°1433 : train_loss = 2.0797882080078125, val_loss = 0.7909817099571228\n",
      "epoch n°1434 : train_loss = 2.079791307449341, val_loss = 0.8005458116531372\n",
      "epoch n°1435 : train_loss = 2.0804617404937744, val_loss = 0.7978090047836304\n",
      "epoch n°1436 : train_loss = 2.0794625282287598, val_loss = 0.7933920621871948\n",
      "epoch n°1437 : train_loss = 2.0869085788726807, val_loss = 0.7928358316421509\n",
      "epoch n°1438 : train_loss = 2.0846197605133057, val_loss = 0.7900004386901855\n",
      "epoch n°1439 : train_loss = 2.0857040882110596, val_loss = 0.7961603403091431\n",
      "epoch n°1440 : train_loss = 2.080174684524536, val_loss = 0.790607750415802\n",
      "epoch n°1441 : train_loss = 2.070748805999756, val_loss = 0.7962706089019775\n",
      "epoch n°1442 : train_loss = 2.080420970916748, val_loss = 0.7947505116462708\n",
      "epoch n°1443 : train_loss = 2.0849432945251465, val_loss = 0.791622519493103\n",
      "epoch n°1444 : train_loss = 2.083939790725708, val_loss = 0.7937260866165161\n",
      "epoch n°1445 : train_loss = 2.082725763320923, val_loss = 0.7942125201225281\n",
      "epoch n°1446 : train_loss = 2.0823605060577393, val_loss = 0.7938104271888733\n",
      "epoch n°1447 : train_loss = 2.0776114463806152, val_loss = 0.796935498714447\n",
      "epoch n°1448 : train_loss = 2.075843334197998, val_loss = 0.7898150086402893\n",
      "epoch n°1449 : train_loss = 2.0882601737976074, val_loss = 0.796166718006134\n",
      "epoch n°1450 : train_loss = 2.079202175140381, val_loss = 0.791632354259491\n",
      "epoch n°1451 : train_loss = 2.0775671005249023, val_loss = 0.7936886548995972\n",
      "epoch n°1452 : train_loss = 2.078838586807251, val_loss = 0.7956164479255676\n",
      "epoch n°1453 : train_loss = 2.0769293308258057, val_loss = 0.7933890223503113\n",
      "epoch n°1454 : train_loss = 2.0838465690612793, val_loss = 0.7933024168014526\n",
      "epoch n°1455 : train_loss = 2.0738461017608643, val_loss = 0.7960492968559265\n",
      "epoch n°1456 : train_loss = 2.0755677223205566, val_loss = 0.797635018825531\n",
      "epoch n°1457 : train_loss = 2.0750410556793213, val_loss = 0.796233057975769\n",
      "epoch n°1458 : train_loss = 2.07387638092041, val_loss = 0.7980002760887146\n",
      "epoch n°1459 : train_loss = 2.08504581451416, val_loss = 0.7916773557662964\n",
      "epoch n°1460 : train_loss = 2.0842816829681396, val_loss = 0.7958464622497559\n",
      "epoch n°1461 : train_loss = 2.0794689655303955, val_loss = 0.7955700159072876\n",
      "epoch n°1462 : train_loss = 2.073197364807129, val_loss = 0.7948278188705444\n",
      "epoch n°1463 : train_loss = 2.073802947998047, val_loss = 0.7933045625686646\n",
      "epoch n°1464 : train_loss = 2.082385778427124, val_loss = 0.7981156706809998\n",
      "epoch n°1465 : train_loss = 2.080608367919922, val_loss = 0.7959660291671753\n",
      "epoch n°1466 : train_loss = 2.081526041030884, val_loss = 0.7934869527816772\n",
      "epoch n°1467 : train_loss = 2.0772571563720703, val_loss = 0.7945846915245056\n",
      "epoch n°1468 : train_loss = 2.082704782485962, val_loss = 0.7942039370536804\n",
      "epoch n°1469 : train_loss = 2.075244188308716, val_loss = 0.7923279404640198\n",
      "epoch n°1470 : train_loss = 2.0735421180725098, val_loss = 0.7930744886398315\n",
      "epoch n°1471 : train_loss = 2.0855660438537598, val_loss = 0.7942726612091064\n",
      "epoch n°1472 : train_loss = 2.0815846920013428, val_loss = 0.7902640104293823\n",
      "epoch n°1473 : train_loss = 2.066088914871216, val_loss = 0.792169451713562\n",
      "epoch n°1474 : train_loss = 2.081793785095215, val_loss = 0.7961723804473877\n",
      "epoch n°1475 : train_loss = 2.069307327270508, val_loss = 0.7949978113174438\n",
      "epoch n°1476 : train_loss = 2.0756919384002686, val_loss = 0.7984147071838379\n",
      "epoch n°1477 : train_loss = 2.0707952976226807, val_loss = 0.7962443828582764\n",
      "epoch n°1478 : train_loss = 2.0881991386413574, val_loss = 0.7897861003875732\n",
      "epoch n°1479 : train_loss = 2.0791122913360596, val_loss = 0.7934029698371887\n",
      "epoch n°1480 : train_loss = 2.082927703857422, val_loss = 0.7940975427627563\n",
      "epoch n°1481 : train_loss = 2.0876052379608154, val_loss = 0.7915641069412231\n",
      "epoch n°1482 : train_loss = 2.073914051055908, val_loss = 0.791560709476471\n",
      "epoch n°1483 : train_loss = 2.077671766281128, val_loss = 0.7977034449577332\n",
      "epoch n°1484 : train_loss = 2.0730395317077637, val_loss = 0.7892761826515198\n",
      "epoch n°1485 : train_loss = 2.071373224258423, val_loss = 0.7937601208686829\n",
      "epoch n°1486 : train_loss = 2.0778183937072754, val_loss = 0.7969714403152466\n",
      "epoch n°1487 : train_loss = 2.0693161487579346, val_loss = 0.7964196801185608\n",
      "epoch n°1488 : train_loss = 2.085449457168579, val_loss = 0.7926222085952759\n",
      "epoch n°1489 : train_loss = 2.0794050693511963, val_loss = 0.7911460399627686\n",
      "epoch n°1490 : train_loss = 2.085627794265747, val_loss = 0.7977421283721924\n",
      "epoch n°1491 : train_loss = 2.068295478820801, val_loss = 0.792499840259552\n",
      "epoch n°1492 : train_loss = 2.07366681098938, val_loss = 0.7934505343437195\n",
      "epoch n°1493 : train_loss = 2.076014518737793, val_loss = 0.7958349585533142\n",
      "epoch n°1494 : train_loss = 2.0863265991210938, val_loss = 0.7939023971557617\n",
      "epoch n°1495 : train_loss = 2.0721333026885986, val_loss = 0.795089602470398\n",
      "epoch n°1496 : train_loss = 2.0766587257385254, val_loss = 0.7980953454971313\n",
      "epoch n°1497 : train_loss = 2.0790669918060303, val_loss = 0.7952507138252258\n",
      "epoch n°1498 : train_loss = 2.0719261169433594, val_loss = 0.7992592453956604\n",
      "epoch n°1499 : train_loss = 2.065322160720825, val_loss = 0.7925646901130676\n",
      "epoch n°1500 : train_loss = 2.0725765228271484, val_loss = 0.7973806858062744\n",
      "epoch n°1501 : train_loss = 2.077158212661743, val_loss = 0.7918201684951782\n",
      "epoch n°1502 : train_loss = 2.076038122177124, val_loss = 0.792739748954773\n",
      "epoch n°1503 : train_loss = 2.0769846439361572, val_loss = 0.7930831909179688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°1504 : train_loss = 2.073406934738159, val_loss = 0.7958030104637146\n",
      "epoch n°1505 : train_loss = 2.0681416988372803, val_loss = 0.7938876748085022\n",
      "epoch n°1506 : train_loss = 2.0815300941467285, val_loss = 0.7958853244781494\n",
      "epoch n°1507 : train_loss = 2.0715463161468506, val_loss = 0.7921621203422546\n",
      "epoch n°1508 : train_loss = 2.074373722076416, val_loss = 0.7926411628723145\n",
      "epoch n°1509 : train_loss = 2.072723627090454, val_loss = 0.7919037938117981\n",
      "epoch n°1510 : train_loss = 2.065016746520996, val_loss = 0.7906702756881714\n",
      "epoch n°1511 : train_loss = 2.077275037765503, val_loss = 0.7977227568626404\n",
      "epoch n°1512 : train_loss = 2.0755465030670166, val_loss = 0.7902873754501343\n",
      "epoch n°1513 : train_loss = 2.072005033493042, val_loss = 0.7944962978363037\n",
      "epoch n°1514 : train_loss = 2.072032928466797, val_loss = 0.7948098182678223\n",
      "epoch n°1515 : train_loss = 2.0705628395080566, val_loss = 0.795509934425354\n",
      "epoch n°1516 : train_loss = 2.0759854316711426, val_loss = 0.7908632159233093\n",
      "epoch n°1517 : train_loss = 2.0686194896698, val_loss = 0.7996447682380676\n",
      "epoch n°1518 : train_loss = 2.0721585750579834, val_loss = 0.7966151237487793\n",
      "epoch n°1519 : train_loss = 2.0766353607177734, val_loss = 0.7927214503288269\n",
      "epoch n°1520 : train_loss = 2.0737924575805664, val_loss = 0.7966346740722656\n",
      "epoch n°1521 : train_loss = 2.073329448699951, val_loss = 0.7939034700393677\n",
      "epoch n°1522 : train_loss = 2.076592445373535, val_loss = 0.7968065738677979\n",
      "epoch n°1523 : train_loss = 2.0720393657684326, val_loss = 0.7985245585441589\n",
      "epoch n°1524 : train_loss = 2.0692124366760254, val_loss = 0.793160617351532\n",
      "epoch n°1525 : train_loss = 2.0702102184295654, val_loss = 0.793388843536377\n",
      "epoch n°1526 : train_loss = 2.072176933288574, val_loss = 0.7941081523895264\n",
      "epoch n°1527 : train_loss = 2.072221040725708, val_loss = 0.7921447157859802\n",
      "epoch n°1528 : train_loss = 2.0690317153930664, val_loss = 0.7972149848937988\n",
      "epoch n°1529 : train_loss = 2.0761148929595947, val_loss = 0.7936815023422241\n",
      "epoch n°1530 : train_loss = 2.0733253955841064, val_loss = 0.796012282371521\n",
      "epoch n°1531 : train_loss = 2.071380853652954, val_loss = 0.7930514812469482\n",
      "epoch n°1532 : train_loss = 2.075167417526245, val_loss = 0.7940347790718079\n",
      "epoch n°1533 : train_loss = 2.079716205596924, val_loss = 0.7936932444572449\n",
      "epoch n°1534 : train_loss = 2.078850269317627, val_loss = 0.7903975248336792\n",
      "epoch n°1535 : train_loss = 2.0776405334472656, val_loss = 0.7962620258331299\n",
      "epoch n°1536 : train_loss = 2.061617612838745, val_loss = 0.7955803871154785\n",
      "epoch n°1537 : train_loss = 2.0769312381744385, val_loss = 0.7957663536071777\n",
      "epoch n°1538 : train_loss = 2.0683534145355225, val_loss = 0.7957473993301392\n",
      "epoch n°1539 : train_loss = 2.0684163570404053, val_loss = 0.7939885854721069\n",
      "epoch n°1540 : train_loss = 2.075436592102051, val_loss = 0.7978724837303162\n",
      "epoch n°1541 : train_loss = 2.0664174556732178, val_loss = 0.797676146030426\n",
      "epoch n°1542 : train_loss = 2.0655431747436523, val_loss = 0.7941597700119019\n",
      "epoch n°1543 : train_loss = 2.0758731365203857, val_loss = 0.792905867099762\n",
      "epoch n°1544 : train_loss = 2.072373867034912, val_loss = 0.7938006520271301\n",
      "epoch n°1545 : train_loss = 2.075434923171997, val_loss = 0.7929242253303528\n",
      "epoch n°1546 : train_loss = 2.074352264404297, val_loss = 0.7929418087005615\n",
      "epoch n°1547 : train_loss = 2.06908917427063, val_loss = 0.7946998476982117\n",
      "epoch n°1548 : train_loss = 2.076061248779297, val_loss = 0.7916519045829773\n",
      "epoch n°1549 : train_loss = 2.072523355484009, val_loss = 0.7930411100387573\n",
      "epoch n°1550 : train_loss = 2.0714011192321777, val_loss = 0.7965893745422363\n",
      "epoch n°1551 : train_loss = 2.0777907371520996, val_loss = 0.7896459102630615\n",
      "epoch n°1552 : train_loss = 2.0767621994018555, val_loss = 0.7914422750473022\n",
      "epoch n°1553 : train_loss = 2.06369686126709, val_loss = 0.7930940985679626\n",
      "epoch n°1554 : train_loss = 2.0674617290496826, val_loss = 0.7897760272026062\n",
      "epoch n°1555 : train_loss = 2.0635337829589844, val_loss = 0.7939878702163696\n",
      "epoch n°1556 : train_loss = 2.0705909729003906, val_loss = 0.7960156202316284\n",
      "epoch n°1557 : train_loss = 2.0628230571746826, val_loss = 0.793774425983429\n",
      "epoch n°1558 : train_loss = 2.0648353099823, val_loss = 0.7983922362327576\n",
      "epoch n°1559 : train_loss = 2.0717086791992188, val_loss = 0.7929840087890625\n",
      "epoch n°1560 : train_loss = 2.0705385208129883, val_loss = 0.794930636882782\n",
      "epoch n°1561 : train_loss = 2.077754020690918, val_loss = 0.7893025875091553\n",
      "epoch n°1562 : train_loss = 2.067936897277832, val_loss = 0.7969174981117249\n",
      "epoch n°1563 : train_loss = 2.0660793781280518, val_loss = 0.7948159575462341\n",
      "epoch n°1564 : train_loss = 2.06378436088562, val_loss = 0.7931889891624451\n",
      "epoch n°1565 : train_loss = 2.0701894760131836, val_loss = 0.7921220660209656\n",
      "epoch n°1566 : train_loss = 2.074460029602051, val_loss = 0.7943735718727112\n",
      "epoch n°1567 : train_loss = 2.068234443664551, val_loss = 0.7906506657600403\n",
      "epoch n°1568 : train_loss = 2.0749447345733643, val_loss = 0.7907648682594299\n",
      "epoch n°1569 : train_loss = 2.068056106567383, val_loss = 0.7934565544128418\n",
      "epoch n°1570 : train_loss = 2.066265106201172, val_loss = 0.7957687377929688\n",
      "epoch n°1571 : train_loss = 2.062105655670166, val_loss = 0.7887924909591675\n",
      "epoch n°1572 : train_loss = 2.069376230239868, val_loss = 0.7952507138252258\n",
      "epoch n°1573 : train_loss = 2.062455654144287, val_loss = 0.7900912761688232\n",
      "epoch n°1574 : train_loss = 2.067690372467041, val_loss = 0.7940571308135986\n",
      "epoch n°1575 : train_loss = 2.059934139251709, val_loss = 0.7957913875579834\n",
      "epoch n°1576 : train_loss = 2.062516689300537, val_loss = 0.7951791882514954\n",
      "epoch n°1577 : train_loss = 2.066819906234741, val_loss = 0.7957661747932434\n",
      "epoch n°1578 : train_loss = 2.060924530029297, val_loss = 0.7924350500106812\n",
      "epoch n°1579 : train_loss = 2.0697765350341797, val_loss = 0.7961869835853577\n",
      "epoch n°1580 : train_loss = 2.05652117729187, val_loss = 0.7923831343650818\n",
      "epoch n°1581 : train_loss = 2.0717341899871826, val_loss = 0.7933278679847717\n",
      "epoch n°1582 : train_loss = 2.066439628601074, val_loss = 0.79234379529953\n",
      "epoch n°1583 : train_loss = 2.060149908065796, val_loss = 0.7952700853347778\n",
      "epoch n°1584 : train_loss = 2.0665667057037354, val_loss = 0.7930687665939331\n",
      "epoch n°1585 : train_loss = 2.0663905143737793, val_loss = 0.7943326234817505\n",
      "epoch n°1586 : train_loss = 2.0707974433898926, val_loss = 0.7979819774627686\n",
      "epoch n°1587 : train_loss = 2.0703859329223633, val_loss = 0.7962756156921387\n",
      "epoch n°1588 : train_loss = 2.076185464859009, val_loss = 0.7952665090560913\n",
      "epoch n°1589 : train_loss = 2.0647237300872803, val_loss = 0.7958847880363464\n",
      "epoch n°1590 : train_loss = 2.0614664554595947, val_loss = 0.7948472499847412\n",
      "epoch n°1591 : train_loss = 2.067565441131592, val_loss = 0.7920615673065186\n",
      "epoch n°1592 : train_loss = 2.0693187713623047, val_loss = 0.794577419757843\n",
      "epoch n°1593 : train_loss = 2.06850528717041, val_loss = 0.7916527986526489\n",
      "epoch n°1594 : train_loss = 2.0675854682922363, val_loss = 0.7906558513641357\n",
      "epoch n°1595 : train_loss = 2.0646800994873047, val_loss = 0.7932394742965698\n",
      "epoch n°1596 : train_loss = 2.0697100162506104, val_loss = 0.7949833869934082\n",
      "epoch n°1597 : train_loss = 2.0591111183166504, val_loss = 0.7954512238502502\n",
      "epoch n°1598 : train_loss = 2.0673630237579346, val_loss = 0.7882372736930847\n",
      "epoch n°1599 : train_loss = 2.067641258239746, val_loss = 0.7964860796928406\n",
      "epoch n°1600 : train_loss = 2.0695552825927734, val_loss = 0.7948924899101257\n",
      "epoch n°1601 : train_loss = 2.0583746433258057, val_loss = 0.7922727465629578\n",
      "epoch n°1602 : train_loss = 2.066901683807373, val_loss = 0.787899911403656\n",
      "epoch n°1603 : train_loss = 2.0619654655456543, val_loss = 0.7964480519294739\n",
      "epoch n°1604 : train_loss = 2.068502187728882, val_loss = 0.7965657711029053\n",
      "epoch n°1605 : train_loss = 2.0640833377838135, val_loss = 0.7975077629089355\n",
      "epoch n°1606 : train_loss = 2.0599231719970703, val_loss = 0.7936717867851257\n",
      "epoch n°1607 : train_loss = 2.0692574977874756, val_loss = 0.7952427864074707\n",
      "epoch n°1608 : train_loss = 2.0660274028778076, val_loss = 0.7946221232414246\n",
      "epoch n°1609 : train_loss = 2.067291021347046, val_loss = 0.7970958352088928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°1610 : train_loss = 2.067066192626953, val_loss = 0.7940394282341003\n",
      "epoch n°1611 : train_loss = 2.065549612045288, val_loss = 0.7958130836486816\n",
      "epoch n°1612 : train_loss = 2.0522186756134033, val_loss = 0.7917007207870483\n",
      "epoch n°1613 : train_loss = 2.0647568702697754, val_loss = 0.7950882315635681\n",
      "epoch n°1614 : train_loss = 2.0643255710601807, val_loss = 0.7963700294494629\n",
      "epoch n°1615 : train_loss = 2.0663628578186035, val_loss = 0.7972254753112793\n",
      "epoch n°1616 : train_loss = 2.068795919418335, val_loss = 0.7938092350959778\n",
      "epoch n°1617 : train_loss = 2.0684401988983154, val_loss = 0.7942777872085571\n",
      "epoch n°1618 : train_loss = 2.0667569637298584, val_loss = 0.7930254340171814\n",
      "epoch n°1619 : train_loss = 2.068998098373413, val_loss = 0.7956603169441223\n",
      "epoch n°1620 : train_loss = 2.0627503395080566, val_loss = 0.7906712889671326\n",
      "epoch n°1621 : train_loss = 2.066612958908081, val_loss = 0.795521080493927\n",
      "epoch n°1622 : train_loss = 2.0565249919891357, val_loss = 0.7960038781166077\n",
      "epoch n°1623 : train_loss = 2.0566253662109375, val_loss = 0.7911635637283325\n",
      "epoch n°1624 : train_loss = 2.0592262744903564, val_loss = 0.7996952533721924\n",
      "epoch n°1625 : train_loss = 2.064441204071045, val_loss = 0.7922797203063965\n",
      "epoch n°1626 : train_loss = 2.063382863998413, val_loss = 0.7901471257209778\n",
      "epoch n°1627 : train_loss = 2.064086437225342, val_loss = 0.7937543988227844\n",
      "epoch n°1628 : train_loss = 2.0732007026672363, val_loss = 0.7937726974487305\n",
      "epoch n°1629 : train_loss = 2.064859628677368, val_loss = 0.7930870056152344\n",
      "epoch n°1630 : train_loss = 2.061774253845215, val_loss = 0.792644739151001\n",
      "epoch n°1631 : train_loss = 2.0645227432250977, val_loss = 0.7986634373664856\n",
      "epoch n°1632 : train_loss = 2.065919876098633, val_loss = 0.7930246591567993\n",
      "epoch n°1633 : train_loss = 2.069930076599121, val_loss = 0.7927463054656982\n",
      "epoch n°1634 : train_loss = 2.0518994331359863, val_loss = 0.7936031222343445\n",
      "epoch n°1635 : train_loss = 2.0585572719573975, val_loss = 0.7950240969657898\n",
      "epoch n°1636 : train_loss = 2.050821542739868, val_loss = 0.7919295430183411\n",
      "epoch n°1637 : train_loss = 2.057931423187256, val_loss = 0.796163022518158\n",
      "epoch n°1638 : train_loss = 2.063838243484497, val_loss = 0.791417121887207\n",
      "epoch n°1639 : train_loss = 2.0601325035095215, val_loss = 0.79605633020401\n",
      "epoch n°1640 : train_loss = 2.055255889892578, val_loss = 0.7940273880958557\n",
      "epoch n°1641 : train_loss = 2.0660881996154785, val_loss = 0.7941949367523193\n",
      "epoch n°1642 : train_loss = 2.0606510639190674, val_loss = 0.7953003644943237\n",
      "epoch n°1643 : train_loss = 2.0616226196289062, val_loss = 0.793042778968811\n",
      "epoch n°1644 : train_loss = 2.0648577213287354, val_loss = 0.7910254597663879\n",
      "epoch n°1645 : train_loss = 2.0624020099639893, val_loss = 0.7918987274169922\n",
      "epoch n°1646 : train_loss = 2.059203863143921, val_loss = 0.7919436097145081\n",
      "epoch n°1647 : train_loss = 2.057626724243164, val_loss = 0.7928882837295532\n",
      "epoch n°1648 : train_loss = 2.0555272102355957, val_loss = 0.7941006422042847\n",
      "epoch n°1649 : train_loss = 2.0525197982788086, val_loss = 0.7950038313865662\n",
      "epoch n°1650 : train_loss = 2.0587337017059326, val_loss = 0.7942434549331665\n",
      "epoch n°1651 : train_loss = 2.0670909881591797, val_loss = 0.7952115535736084\n",
      "epoch n°1652 : train_loss = 2.057159900665283, val_loss = 0.7958981394767761\n",
      "epoch n°1653 : train_loss = 2.0640017986297607, val_loss = 0.7934773564338684\n",
      "epoch n°1654 : train_loss = 2.0530691146850586, val_loss = 0.7924402356147766\n",
      "epoch n°1655 : train_loss = 2.0599417686462402, val_loss = 0.797433614730835\n",
      "epoch n°1656 : train_loss = 2.060041666030884, val_loss = 0.7956711649894714\n",
      "epoch n°1657 : train_loss = 2.0470967292785645, val_loss = 0.7971139550209045\n",
      "epoch n°1658 : train_loss = 2.0573601722717285, val_loss = 0.7911672592163086\n",
      "epoch n°1659 : train_loss = 2.0596866607666016, val_loss = 0.7956624031066895\n",
      "epoch n°1660 : train_loss = 2.0640387535095215, val_loss = 0.7917923927307129\n",
      "epoch n°1661 : train_loss = 2.069873809814453, val_loss = 0.7909746766090393\n",
      "epoch n°1662 : train_loss = 2.0725674629211426, val_loss = 0.793052613735199\n",
      "epoch n°1663 : train_loss = 2.0525102615356445, val_loss = 0.7946790456771851\n",
      "epoch n°1664 : train_loss = 2.0630950927734375, val_loss = 0.7915325164794922\n",
      "epoch n°1665 : train_loss = 2.0597121715545654, val_loss = 0.7932454347610474\n",
      "epoch n°1666 : train_loss = 2.0696511268615723, val_loss = 0.791796863079071\n",
      "epoch n°1667 : train_loss = 2.058828115463257, val_loss = 0.7949552536010742\n",
      "epoch n°1668 : train_loss = 2.0603220462799072, val_loss = 0.7838118076324463\n",
      "epoch n°1669 : train_loss = 2.057706832885742, val_loss = 0.7950140237808228\n",
      "epoch n°1670 : train_loss = 2.051823616027832, val_loss = 0.7905219793319702\n",
      "epoch n°1671 : train_loss = 2.0558860301971436, val_loss = 0.7956979870796204\n",
      "epoch n°1672 : train_loss = 2.050684690475464, val_loss = 0.794793963432312\n",
      "epoch n°1673 : train_loss = 2.059191942214966, val_loss = 0.7921479940414429\n",
      "epoch n°1674 : train_loss = 2.0506300926208496, val_loss = 0.7924020290374756\n",
      "epoch n°1675 : train_loss = 2.0593202114105225, val_loss = 0.794623613357544\n",
      "epoch n°1676 : train_loss = 2.054964303970337, val_loss = 0.7901548743247986\n",
      "epoch n°1677 : train_loss = 2.0490736961364746, val_loss = 0.7930962443351746\n",
      "epoch n°1678 : train_loss = 2.0628042221069336, val_loss = 0.7918659448623657\n",
      "epoch n°1679 : train_loss = 2.0576553344726562, val_loss = 0.7959290742874146\n",
      "epoch n°1680 : train_loss = 2.053807497024536, val_loss = 0.7938563823699951\n",
      "epoch n°1681 : train_loss = 2.062877655029297, val_loss = 0.7949210405349731\n",
      "epoch n°1682 : train_loss = 2.0671818256378174, val_loss = 0.7919684052467346\n",
      "epoch n°1683 : train_loss = 2.0590896606445312, val_loss = 0.7993597388267517\n",
      "epoch n°1684 : train_loss = 2.053575038909912, val_loss = 0.7917624711990356\n",
      "epoch n°1685 : train_loss = 2.0656914710998535, val_loss = 0.793914794921875\n",
      "epoch n°1686 : train_loss = 2.049347400665283, val_loss = 0.7977443933486938\n",
      "epoch n°1687 : train_loss = 2.063286542892456, val_loss = 0.7898216843605042\n",
      "epoch n°1688 : train_loss = 2.0648930072784424, val_loss = 0.7957389950752258\n",
      "epoch n°1689 : train_loss = 2.06862735748291, val_loss = 0.7887522578239441\n",
      "epoch n°1690 : train_loss = 2.061725616455078, val_loss = 0.7927833199501038\n",
      "epoch n°1691 : train_loss = 2.056572914123535, val_loss = 0.7940751910209656\n",
      "epoch n°1692 : train_loss = 2.051197052001953, val_loss = 0.7900142669677734\n",
      "epoch n°1693 : train_loss = 2.0486505031585693, val_loss = 0.7975972294807434\n",
      "epoch n°1694 : train_loss = 2.056980848312378, val_loss = 0.7947121858596802\n",
      "epoch n°1695 : train_loss = 2.062203884124756, val_loss = 0.7885468006134033\n",
      "epoch n°1696 : train_loss = 2.05031156539917, val_loss = 0.7915239334106445\n",
      "epoch n°1697 : train_loss = 2.0609779357910156, val_loss = 0.7945330739021301\n",
      "epoch n°1698 : train_loss = 2.0597262382507324, val_loss = 0.7916983962059021\n",
      "epoch n°1699 : train_loss = 2.056222438812256, val_loss = 0.7966771125793457\n",
      "epoch n°1700 : train_loss = 2.051731824874878, val_loss = 0.7930744290351868\n",
      "epoch n°1701 : train_loss = 2.0451338291168213, val_loss = 0.7893067002296448\n",
      "epoch n°1702 : train_loss = 2.062340259552002, val_loss = 0.7972831726074219\n",
      "epoch n°1703 : train_loss = 2.0527987480163574, val_loss = 0.7919719815254211\n",
      "epoch n°1704 : train_loss = 2.052598476409912, val_loss = 0.7943018674850464\n",
      "epoch n°1705 : train_loss = 2.052570104598999, val_loss = 0.7934392094612122\n",
      "epoch n°1706 : train_loss = 2.0595128536224365, val_loss = 0.7943771481513977\n",
      "epoch n°1707 : train_loss = 2.0531704425811768, val_loss = 0.7946059107780457\n",
      "epoch n°1708 : train_loss = 2.0558459758758545, val_loss = 0.7887557148933411\n",
      "epoch n°1709 : train_loss = 2.0572166442871094, val_loss = 0.7962885499000549\n",
      "epoch n°1710 : train_loss = 2.06360125541687, val_loss = 0.7918408513069153\n",
      "epoch n°1711 : train_loss = 2.059277296066284, val_loss = 0.7951458692550659\n",
      "epoch n°1712 : train_loss = 2.058596134185791, val_loss = 0.7940896153450012\n",
      "epoch n°1713 : train_loss = 2.0596179962158203, val_loss = 0.7869572043418884\n",
      "epoch n°1714 : train_loss = 2.0555191040039062, val_loss = 0.7980926036834717\n",
      "epoch n°1715 : train_loss = 2.0528557300567627, val_loss = 0.7969602346420288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°1716 : train_loss = 2.0528690814971924, val_loss = 0.7929670214653015\n",
      "epoch n°1717 : train_loss = 2.0531373023986816, val_loss = 0.7962546944618225\n",
      "epoch n°1718 : train_loss = 2.0531749725341797, val_loss = 0.7914204001426697\n",
      "epoch n°1719 : train_loss = 2.0516304969787598, val_loss = 0.7919653058052063\n",
      "epoch n°1720 : train_loss = 2.0607030391693115, val_loss = 0.7917218804359436\n",
      "epoch n°1721 : train_loss = 2.0567119121551514, val_loss = 0.7906481027603149\n",
      "epoch n°1722 : train_loss = 2.057494640350342, val_loss = 0.789695680141449\n",
      "epoch n°1723 : train_loss = 2.059636354446411, val_loss = 0.7973007559776306\n",
      "epoch n°1724 : train_loss = 2.060004234313965, val_loss = 0.7925360798835754\n",
      "epoch n°1725 : train_loss = 2.0586307048797607, val_loss = 0.7886516451835632\n",
      "epoch n°1726 : train_loss = 2.053795337677002, val_loss = 0.7884158492088318\n",
      "epoch n°1727 : train_loss = 2.0498580932617188, val_loss = 0.7939173579216003\n",
      "epoch n°1728 : train_loss = 2.063645362854004, val_loss = 0.7928035855293274\n",
      "epoch n°1729 : train_loss = 2.047379970550537, val_loss = 0.7931810617446899\n",
      "epoch n°1730 : train_loss = 2.061465263366699, val_loss = 0.7922008037567139\n",
      "epoch n°1731 : train_loss = 2.0523431301116943, val_loss = 0.7963722348213196\n",
      "epoch n°1732 : train_loss = 2.060925245285034, val_loss = 0.7946456670761108\n",
      "epoch n°1733 : train_loss = 2.0461575984954834, val_loss = 0.7888084650039673\n",
      "epoch n°1734 : train_loss = 2.055870294570923, val_loss = 0.79414963722229\n",
      "epoch n°1735 : train_loss = 2.0644567012786865, val_loss = 0.7958754897117615\n",
      "epoch n°1736 : train_loss = 2.0576181411743164, val_loss = 0.7894057035446167\n",
      "epoch n°1737 : train_loss = 2.0611894130706787, val_loss = 0.7901031374931335\n",
      "epoch n°1738 : train_loss = 2.0490057468414307, val_loss = 0.7940340638160706\n",
      "epoch n°1739 : train_loss = 2.0591986179351807, val_loss = 0.7941398024559021\n",
      "epoch n°1740 : train_loss = 2.0601677894592285, val_loss = 0.7942766547203064\n",
      "epoch n°1741 : train_loss = 2.053332805633545, val_loss = 0.7892051339149475\n",
      "epoch n°1742 : train_loss = 2.0549380779266357, val_loss = 0.794998824596405\n",
      "epoch n°1743 : train_loss = 2.0587875843048096, val_loss = 0.7947314381599426\n",
      "epoch n°1744 : train_loss = 2.055588722229004, val_loss = 0.7963544130325317\n",
      "epoch n°1745 : train_loss = 2.0634984970092773, val_loss = 0.7929230332374573\n",
      "epoch n°1746 : train_loss = 2.056009292602539, val_loss = 0.7945132851600647\n",
      "epoch n°1747 : train_loss = 2.054605007171631, val_loss = 0.794379711151123\n",
      "epoch n°1748 : train_loss = 2.0435612201690674, val_loss = 0.7935871481895447\n",
      "epoch n°1749 : train_loss = 2.053114175796509, val_loss = 0.7922810912132263\n",
      "epoch n°1750 : train_loss = 2.0570504665374756, val_loss = 0.7982349395751953\n",
      "epoch n°1751 : train_loss = 2.0621514320373535, val_loss = 0.7921070456504822\n",
      "epoch n°1752 : train_loss = 2.0582423210144043, val_loss = 0.7926439046859741\n",
      "epoch n°1753 : train_loss = 2.047360420227051, val_loss = 0.7958488464355469\n",
      "epoch n°1754 : train_loss = 2.0525095462799072, val_loss = 0.794687032699585\n",
      "epoch n°1755 : train_loss = 2.051927089691162, val_loss = 0.7946216464042664\n",
      "epoch n°1756 : train_loss = 2.049466133117676, val_loss = 0.7927290201187134\n",
      "epoch n°1757 : train_loss = 2.0559988021850586, val_loss = 0.792445182800293\n",
      "epoch n°1758 : train_loss = 2.050414800643921, val_loss = 0.7868868112564087\n",
      "epoch n°1759 : train_loss = 2.0526387691497803, val_loss = 0.7919807434082031\n",
      "epoch n°1760 : train_loss = 2.056631326675415, val_loss = 0.7886785268783569\n",
      "epoch n°1761 : train_loss = 2.048794984817505, val_loss = 0.7956557869911194\n",
      "epoch n°1762 : train_loss = 2.0535311698913574, val_loss = 0.7897759675979614\n",
      "epoch n°1763 : train_loss = 2.0542027950286865, val_loss = 0.7915081977844238\n",
      "epoch n°1764 : train_loss = 2.0604710578918457, val_loss = 0.7923039197921753\n",
      "epoch n°1765 : train_loss = 2.057983636856079, val_loss = 0.7921888828277588\n",
      "epoch n°1766 : train_loss = 2.061525583267212, val_loss = 0.792352557182312\n",
      "epoch n°1767 : train_loss = 2.0490212440490723, val_loss = 0.7945499420166016\n",
      "epoch n°1768 : train_loss = 2.0597665309906006, val_loss = 0.7921894788742065\n",
      "epoch n°1769 : train_loss = 2.0568177700042725, val_loss = 0.7940818667411804\n",
      "epoch n°1770 : train_loss = 2.0601816177368164, val_loss = 0.7908372282981873\n",
      "epoch n°1771 : train_loss = 2.0485825538635254, val_loss = 0.7904362082481384\n",
      "epoch n°1772 : train_loss = 2.0538368225097656, val_loss = 0.7901354432106018\n",
      "epoch n°1773 : train_loss = 2.058154821395874, val_loss = 0.7966001629829407\n",
      "epoch n°1774 : train_loss = 2.0460636615753174, val_loss = 0.7907091379165649\n",
      "epoch n°1775 : train_loss = 2.0491864681243896, val_loss = 0.7950344085693359\n",
      "epoch n°1776 : train_loss = 2.0562546253204346, val_loss = 0.7931289672851562\n",
      "epoch n°1777 : train_loss = 2.0520706176757812, val_loss = 0.7923005819320679\n",
      "epoch n°1778 : train_loss = 2.0572633743286133, val_loss = 0.7933463454246521\n",
      "epoch n°1779 : train_loss = 2.042185068130493, val_loss = 0.7923212051391602\n",
      "epoch n°1780 : train_loss = 2.0511515140533447, val_loss = 0.7918164730072021\n",
      "epoch n°1781 : train_loss = 2.0511693954467773, val_loss = 0.7938368916511536\n",
      "epoch n°1782 : train_loss = 2.0518243312835693, val_loss = 0.7922151684761047\n",
      "epoch n°1783 : train_loss = 2.0505969524383545, val_loss = 0.7947381138801575\n",
      "epoch n°1784 : train_loss = 2.0464963912963867, val_loss = 0.7964662313461304\n",
      "epoch n°1785 : train_loss = 2.0510289669036865, val_loss = 0.7898253798484802\n",
      "epoch n°1786 : train_loss = 2.051136016845703, val_loss = 0.7959364652633667\n",
      "epoch n°1787 : train_loss = 2.049962282180786, val_loss = 0.7926537394523621\n",
      "epoch n°1788 : train_loss = 2.057772636413574, val_loss = 0.789587140083313\n",
      "epoch n°1789 : train_loss = 2.049532890319824, val_loss = 0.7936548590660095\n",
      "epoch n°1790 : train_loss = 2.0495927333831787, val_loss = 0.792928159236908\n",
      "epoch n°1791 : train_loss = 2.053534507751465, val_loss = 0.7914989590644836\n",
      "epoch n°1792 : train_loss = 2.050853729248047, val_loss = 0.7945858240127563\n",
      "epoch n°1793 : train_loss = 2.059067487716675, val_loss = 0.7955785989761353\n",
      "epoch n°1794 : train_loss = 2.045217275619507, val_loss = 0.7957412004470825\n",
      "epoch n°1795 : train_loss = 2.0481789112091064, val_loss = 0.7928934693336487\n",
      "epoch n°1796 : train_loss = 2.04520583152771, val_loss = 0.7919322848320007\n",
      "epoch n°1797 : train_loss = 2.0516881942749023, val_loss = 0.7953169941902161\n",
      "epoch n°1798 : train_loss = 2.0471701622009277, val_loss = 0.7942178249359131\n",
      "epoch n°1799 : train_loss = 2.049074411392212, val_loss = 0.7956367135047913\n",
      "epoch n°1800 : train_loss = 2.042970657348633, val_loss = 0.7933336496353149\n",
      "epoch n°1801 : train_loss = 2.0555622577667236, val_loss = 0.7900750637054443\n",
      "epoch n°1802 : train_loss = 2.0556557178497314, val_loss = 0.792170524597168\n",
      "epoch n°1803 : train_loss = 2.058344602584839, val_loss = 0.7934747338294983\n",
      "epoch n°1804 : train_loss = 2.0507848262786865, val_loss = 0.7916586995124817\n",
      "epoch n°1805 : train_loss = 2.0593767166137695, val_loss = 0.7968654036521912\n",
      "epoch n°1806 : train_loss = 2.04836106300354, val_loss = 0.7857832908630371\n",
      "epoch n°1807 : train_loss = 2.052410364151001, val_loss = 0.7948179244995117\n",
      "epoch n°1808 : train_loss = 2.061652183532715, val_loss = 0.7902278900146484\n",
      "epoch n°1809 : train_loss = 2.0543060302734375, val_loss = 0.7921800017356873\n",
      "epoch n°1810 : train_loss = 2.05806827545166, val_loss = 0.7944273352622986\n",
      "epoch n°1811 : train_loss = 2.052163600921631, val_loss = 0.7948898673057556\n",
      "epoch n°1812 : train_loss = 2.051069736480713, val_loss = 0.7878065705299377\n",
      "epoch n°1813 : train_loss = 2.055114984512329, val_loss = 0.7973086833953857\n",
      "epoch n°1814 : train_loss = 2.043071985244751, val_loss = 0.7959356904029846\n",
      "epoch n°1815 : train_loss = 2.049225091934204, val_loss = 0.7927747368812561\n",
      "epoch n°1816 : train_loss = 2.041609048843384, val_loss = 0.7893502712249756\n",
      "epoch n°1817 : train_loss = 2.0491435527801514, val_loss = 0.7906603813171387\n",
      "epoch n°1818 : train_loss = 2.046786308288574, val_loss = 0.7905757427215576\n",
      "epoch n°1819 : train_loss = 2.0497190952301025, val_loss = 0.7945287823677063\n",
      "epoch n°1820 : train_loss = 2.0507149696350098, val_loss = 0.7960970997810364\n",
      "epoch n°1821 : train_loss = 2.050959825515747, val_loss = 0.7943686246871948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°1822 : train_loss = 2.0476293563842773, val_loss = 0.7885520458221436\n",
      "epoch n°1823 : train_loss = 2.0516746044158936, val_loss = 0.7942059636116028\n",
      "epoch n°1824 : train_loss = 2.0487325191497803, val_loss = 0.7900503277778625\n",
      "epoch n°1825 : train_loss = 2.052325487136841, val_loss = 0.7936899662017822\n",
      "epoch n°1826 : train_loss = 2.055264711380005, val_loss = 0.7869281768798828\n",
      "epoch n°1827 : train_loss = 2.0501227378845215, val_loss = 0.7898303270339966\n",
      "epoch n°1828 : train_loss = 2.047653913497925, val_loss = 0.7914480566978455\n",
      "epoch n°1829 : train_loss = 2.057260751724243, val_loss = 0.7927433848381042\n",
      "epoch n°1830 : train_loss = 2.0544066429138184, val_loss = 0.7965286374092102\n",
      "epoch n°1831 : train_loss = 2.0458996295928955, val_loss = 0.7923217415809631\n",
      "epoch n°1832 : train_loss = 2.0513839721679688, val_loss = 0.7894191145896912\n",
      "epoch n°1833 : train_loss = 2.049201488494873, val_loss = 0.7896466851234436\n",
      "epoch n°1834 : train_loss = 2.0476958751678467, val_loss = 0.7904712557792664\n",
      "epoch n°1835 : train_loss = 2.051555871963501, val_loss = 0.7922101020812988\n",
      "epoch n°1836 : train_loss = 2.04494047164917, val_loss = 0.794780969619751\n",
      "epoch n°1837 : train_loss = 2.0429720878601074, val_loss = 0.7961809039115906\n",
      "epoch n°1838 : train_loss = 2.050119638442993, val_loss = 0.7957625985145569\n",
      "epoch n°1839 : train_loss = 2.0470197200775146, val_loss = 0.7936700582504272\n",
      "epoch n°1840 : train_loss = 2.044802665710449, val_loss = 0.7887596487998962\n",
      "epoch n°1841 : train_loss = 2.0497567653656006, val_loss = 0.7899761199951172\n",
      "epoch n°1842 : train_loss = 2.0512754917144775, val_loss = 0.7947245240211487\n",
      "epoch n°1843 : train_loss = 2.052241086959839, val_loss = 0.79295414686203\n",
      "epoch n°1844 : train_loss = 2.0510799884796143, val_loss = 0.7924342155456543\n",
      "epoch n°1845 : train_loss = 2.0572328567504883, val_loss = 0.7965728044509888\n",
      "epoch n°1846 : train_loss = 2.0470755100250244, val_loss = 0.7912291288375854\n",
      "epoch n°1847 : train_loss = 2.049267053604126, val_loss = 0.7960975766181946\n",
      "epoch n°1848 : train_loss = 2.038236141204834, val_loss = 0.793168306350708\n",
      "epoch n°1849 : train_loss = 2.0538387298583984, val_loss = 0.7915318012237549\n",
      "epoch n°1850 : train_loss = 2.048408031463623, val_loss = 0.7928348183631897\n",
      "epoch n°1851 : train_loss = 2.0519349575042725, val_loss = 0.7931355237960815\n",
      "epoch n°1852 : train_loss = 2.0428075790405273, val_loss = 0.7918767333030701\n",
      "epoch n°1853 : train_loss = 2.048717975616455, val_loss = 0.7903057336807251\n",
      "epoch n°1854 : train_loss = 2.0564301013946533, val_loss = 0.7912409901618958\n",
      "epoch n°1855 : train_loss = 2.049950122833252, val_loss = 0.7954286336898804\n",
      "epoch n°1856 : train_loss = 2.0493035316467285, val_loss = 0.7929707765579224\n",
      "epoch n°1857 : train_loss = 2.0519559383392334, val_loss = 0.790398359298706\n",
      "epoch n°1858 : train_loss = 2.047396421432495, val_loss = 0.7951026558876038\n",
      "epoch n°1859 : train_loss = 2.0467851161956787, val_loss = 0.7949408292770386\n",
      "epoch n°1860 : train_loss = 2.0523009300231934, val_loss = 0.7906622290611267\n",
      "epoch n°1861 : train_loss = 2.0489375591278076, val_loss = 0.7879222631454468\n",
      "epoch n°1862 : train_loss = 2.0494675636291504, val_loss = 0.7915765047073364\n",
      "epoch n°1863 : train_loss = 2.0581674575805664, val_loss = 0.7962190508842468\n",
      "epoch n°1864 : train_loss = 2.04819917678833, val_loss = 0.7930780649185181\n",
      "epoch n°1865 : train_loss = 2.0506327152252197, val_loss = 0.7918451428413391\n",
      "epoch n°1866 : train_loss = 2.0492167472839355, val_loss = 0.7912850975990295\n",
      "epoch n°1867 : train_loss = 2.058720588684082, val_loss = 0.7941208481788635\n",
      "epoch n°1868 : train_loss = 2.047293186187744, val_loss = 0.790822446346283\n",
      "epoch n°1869 : train_loss = 2.048821449279785, val_loss = 0.7934309840202332\n",
      "epoch n°1870 : train_loss = 2.051952362060547, val_loss = 0.7915021777153015\n",
      "epoch n°1871 : train_loss = 2.038896322250366, val_loss = 0.7913282513618469\n",
      "epoch n°1872 : train_loss = 2.0571448802948, val_loss = 0.7912394404411316\n",
      "epoch n°1873 : train_loss = 2.0468497276306152, val_loss = 0.794851541519165\n",
      "epoch n°1874 : train_loss = 2.0429511070251465, val_loss = 0.7902200222015381\n",
      "epoch n°1875 : train_loss = 2.0453383922576904, val_loss = 0.7897608280181885\n",
      "epoch n°1876 : train_loss = 2.04827618598938, val_loss = 0.7939403653144836\n",
      "epoch n°1877 : train_loss = 2.0475234985351562, val_loss = 0.7932917475700378\n",
      "epoch n°1878 : train_loss = 2.0435292720794678, val_loss = 0.793953001499176\n",
      "epoch n°1879 : train_loss = 2.0462658405303955, val_loss = 0.7929345369338989\n",
      "epoch n°1880 : train_loss = 2.036752223968506, val_loss = 0.7914893627166748\n",
      "epoch n°1881 : train_loss = 2.044023036956787, val_loss = 0.791265070438385\n",
      "epoch n°1882 : train_loss = 2.051203727722168, val_loss = 0.7952961921691895\n",
      "epoch n°1883 : train_loss = 2.047776699066162, val_loss = 0.7918614745140076\n",
      "epoch n°1884 : train_loss = 2.053375244140625, val_loss = 0.7951779365539551\n",
      "epoch n°1885 : train_loss = 2.0530812740325928, val_loss = 0.7960719466209412\n",
      "epoch n°1886 : train_loss = 2.0379297733306885, val_loss = 0.7879214882850647\n",
      "epoch n°1887 : train_loss = 2.047018051147461, val_loss = 0.7913745045661926\n",
      "epoch n°1888 : train_loss = 2.0390748977661133, val_loss = 0.7901675701141357\n",
      "epoch n°1889 : train_loss = 2.0469822883605957, val_loss = 0.7966272830963135\n",
      "epoch n°1890 : train_loss = 2.0559756755828857, val_loss = 0.7922468185424805\n",
      "epoch n°1891 : train_loss = 2.044048309326172, val_loss = 0.7929068803787231\n",
      "epoch n°1892 : train_loss = 2.0490052700042725, val_loss = 0.790992021560669\n",
      "epoch n°1893 : train_loss = 2.052619695663452, val_loss = 0.7889537215232849\n",
      "epoch n°1894 : train_loss = 2.0466785430908203, val_loss = 0.7925548553466797\n",
      "epoch n°1895 : train_loss = 2.0427589416503906, val_loss = 0.7912892699241638\n",
      "epoch n°1896 : train_loss = 2.058398485183716, val_loss = 0.7940471172332764\n",
      "epoch n°1897 : train_loss = 2.0474328994750977, val_loss = 0.7892225384712219\n",
      "epoch n°1898 : train_loss = 2.0468320846557617, val_loss = 0.7892283201217651\n",
      "epoch n°1899 : train_loss = 2.04886531829834, val_loss = 0.7953249216079712\n",
      "epoch n°1900 : train_loss = 2.0469858646392822, val_loss = 0.7904965877532959\n",
      "epoch n°1901 : train_loss = 2.0497870445251465, val_loss = 0.7962045073509216\n",
      "epoch n°1902 : train_loss = 2.04636812210083, val_loss = 0.7927796840667725\n",
      "epoch n°1903 : train_loss = 2.0415189266204834, val_loss = 0.7938197255134583\n",
      "epoch n°1904 : train_loss = 2.0501537322998047, val_loss = 0.7919281721115112\n",
      "epoch n°1905 : train_loss = 2.0572845935821533, val_loss = 0.7903071045875549\n",
      "epoch n°1906 : train_loss = 2.0507357120513916, val_loss = 0.793868362903595\n",
      "epoch n°1907 : train_loss = 2.046908378601074, val_loss = 0.7938409447669983\n",
      "epoch n°1908 : train_loss = 2.039006233215332, val_loss = 0.7956985831260681\n",
      "epoch n°1909 : train_loss = 2.038553237915039, val_loss = 0.7907465696334839\n",
      "epoch n°1910 : train_loss = 2.048780918121338, val_loss = 0.7926686406135559\n",
      "epoch n°1911 : train_loss = 2.0487074851989746, val_loss = 0.7899954915046692\n",
      "epoch n°1912 : train_loss = 2.046017646789551, val_loss = 0.7905611395835876\n",
      "epoch n°1913 : train_loss = 2.043250560760498, val_loss = 0.7881145477294922\n",
      "epoch n°1914 : train_loss = 2.04923939704895, val_loss = 0.7924156188964844\n",
      "epoch n°1915 : train_loss = 2.0400846004486084, val_loss = 0.7935474514961243\n",
      "epoch n°1916 : train_loss = 2.0490667819976807, val_loss = 0.7961204648017883\n",
      "epoch n°1917 : train_loss = 2.044135332107544, val_loss = 0.7895573973655701\n",
      "epoch n°1918 : train_loss = 2.0489349365234375, val_loss = 0.7891014814376831\n",
      "epoch n°1919 : train_loss = 2.0563395023345947, val_loss = 0.7899172902107239\n",
      "epoch n°1920 : train_loss = 2.052612066268921, val_loss = 0.7891548275947571\n",
      "epoch n°1921 : train_loss = 2.050261974334717, val_loss = 0.7944715023040771\n",
      "epoch n°1922 : train_loss = 2.0493836402893066, val_loss = 0.7926658987998962\n",
      "epoch n°1923 : train_loss = 2.037752866744995, val_loss = 0.7937403321266174\n",
      "epoch n°1924 : train_loss = 2.0434651374816895, val_loss = 0.7872800827026367\n",
      "epoch n°1925 : train_loss = 2.0471582412719727, val_loss = 0.7924479842185974\n",
      "epoch n°1926 : train_loss = 2.047642469406128, val_loss = 0.7907652258872986\n",
      "epoch n°1927 : train_loss = 2.0387520790100098, val_loss = 0.7923112511634827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°1928 : train_loss = 2.0425162315368652, val_loss = 0.7912387847900391\n",
      "epoch n°1929 : train_loss = 2.055044651031494, val_loss = 0.791564404964447\n",
      "epoch n°1930 : train_loss = 2.0475363731384277, val_loss = 0.7928693890571594\n",
      "epoch n°1931 : train_loss = 2.05267071723938, val_loss = 0.7918727993965149\n",
      "epoch n°1932 : train_loss = 2.0410211086273193, val_loss = 0.7937671542167664\n",
      "epoch n°1933 : train_loss = 2.0422303676605225, val_loss = 0.7919063568115234\n",
      "epoch n°1934 : train_loss = 2.051815986633301, val_loss = 0.7911953926086426\n",
      "epoch n°1935 : train_loss = 2.0521509647369385, val_loss = 0.7905537486076355\n",
      "epoch n°1936 : train_loss = 2.0535318851470947, val_loss = 0.7937097549438477\n",
      "epoch n°1937 : train_loss = 2.045029640197754, val_loss = 0.7933563590049744\n",
      "epoch n°1938 : train_loss = 2.046346664428711, val_loss = 0.7908198237419128\n",
      "epoch n°1939 : train_loss = 2.0501129627227783, val_loss = 0.7929078936576843\n",
      "epoch n°1940 : train_loss = 2.0452489852905273, val_loss = 0.7936273813247681\n",
      "epoch n°1941 : train_loss = 2.0496668815612793, val_loss = 0.791770875453949\n",
      "epoch n°1942 : train_loss = 2.0483272075653076, val_loss = 0.7956171035766602\n",
      "epoch n°1943 : train_loss = 2.0390002727508545, val_loss = 0.7957741022109985\n",
      "epoch n°1944 : train_loss = 2.045703887939453, val_loss = 0.7909286022186279\n",
      "epoch n°1945 : train_loss = 2.0473248958587646, val_loss = 0.7906959056854248\n",
      "epoch n°1946 : train_loss = 2.047288417816162, val_loss = 0.7896479368209839\n",
      "epoch n°1947 : train_loss = 2.0367584228515625, val_loss = 0.7920892238616943\n",
      "epoch n°1948 : train_loss = 2.045452117919922, val_loss = 0.7884445190429688\n",
      "epoch n°1949 : train_loss = 2.0557336807250977, val_loss = 0.7943845391273499\n",
      "epoch n°1950 : train_loss = 2.051835298538208, val_loss = 0.7919610142707825\n",
      "epoch n°1951 : train_loss = 2.0466997623443604, val_loss = 0.7952630519866943\n",
      "epoch n°1952 : train_loss = 2.0353779792785645, val_loss = 0.7927030324935913\n",
      "epoch n°1953 : train_loss = 2.038012742996216, val_loss = 0.7982961535453796\n",
      "epoch n°1954 : train_loss = 2.048229932785034, val_loss = 0.7935560941696167\n",
      "epoch n°1955 : train_loss = 2.0442428588867188, val_loss = 0.7957481145858765\n",
      "epoch n°1956 : train_loss = 2.055459976196289, val_loss = 0.7897911071777344\n",
      "epoch n°1957 : train_loss = 2.054286003112793, val_loss = 0.7891643047332764\n",
      "epoch n°1958 : train_loss = 2.052720546722412, val_loss = 0.7914420962333679\n",
      "epoch n°1959 : train_loss = 2.047058582305908, val_loss = 0.7928749322891235\n",
      "epoch n°1960 : train_loss = 2.042771577835083, val_loss = 0.7911537885665894\n",
      "epoch n°1961 : train_loss = 2.040026903152466, val_loss = 0.7920902967453003\n",
      "epoch n°1962 : train_loss = 2.0447771549224854, val_loss = 0.794571042060852\n",
      "epoch n°1963 : train_loss = 2.0491063594818115, val_loss = 0.7925537824630737\n",
      "epoch n°1964 : train_loss = 2.0455687046051025, val_loss = 0.7922554016113281\n",
      "epoch n°1965 : train_loss = 2.0364413261413574, val_loss = 0.7928147912025452\n",
      "epoch n°1966 : train_loss = 2.056194543838501, val_loss = 0.7935616970062256\n",
      "epoch n°1967 : train_loss = 2.040213108062744, val_loss = 0.7929345965385437\n",
      "epoch n°1968 : train_loss = 2.0405795574188232, val_loss = 0.792029619216919\n",
      "epoch n°1969 : train_loss = 2.042520523071289, val_loss = 0.7915380001068115\n",
      "epoch n°1970 : train_loss = 2.0489604473114014, val_loss = 0.7919299006462097\n",
      "epoch n°1971 : train_loss = 2.0472939014434814, val_loss = 0.7921239137649536\n",
      "epoch n°1972 : train_loss = 2.056701898574829, val_loss = 0.7916111946105957\n",
      "epoch n°1973 : train_loss = 2.0453507900238037, val_loss = 0.794323205947876\n",
      "epoch n°1974 : train_loss = 2.0442538261413574, val_loss = 0.7947393655776978\n",
      "epoch n°1975 : train_loss = 2.0504348278045654, val_loss = 0.7935574650764465\n",
      "epoch n°1976 : train_loss = 2.0450291633605957, val_loss = 0.7923678159713745\n",
      "epoch n°1977 : train_loss = 2.050248384475708, val_loss = 0.790641725063324\n",
      "epoch n°1978 : train_loss = 2.046280860900879, val_loss = 0.7922887206077576\n",
      "epoch n°1979 : train_loss = 2.059796094894409, val_loss = 0.7910683751106262\n",
      "epoch n°1980 : train_loss = 2.0452659130096436, val_loss = 0.7885299921035767\n",
      "epoch n°1981 : train_loss = 2.045123338699341, val_loss = 0.7875710129737854\n",
      "epoch n°1982 : train_loss = 2.0473217964172363, val_loss = 0.7925921082496643\n",
      "epoch n°1983 : train_loss = 2.046086072921753, val_loss = 0.7936476469039917\n",
      "epoch n°1984 : train_loss = 2.0444536209106445, val_loss = 0.7976667284965515\n",
      "epoch n°1985 : train_loss = 2.0401065349578857, val_loss = 0.795806348323822\n",
      "epoch n°1986 : train_loss = 2.056142568588257, val_loss = 0.794102132320404\n",
      "epoch n°1987 : train_loss = 2.053506851196289, val_loss = 0.7920393943786621\n",
      "epoch n°1988 : train_loss = 2.045971632003784, val_loss = 0.786835253238678\n",
      "epoch n°1989 : train_loss = 2.03918719291687, val_loss = 0.7945041656494141\n",
      "epoch n°1990 : train_loss = 2.040619134902954, val_loss = 0.795390248298645\n",
      "epoch n°1991 : train_loss = 2.047058582305908, val_loss = 0.791901171207428\n",
      "epoch n°1992 : train_loss = 2.0486066341400146, val_loss = 0.7919764518737793\n",
      "epoch n°1993 : train_loss = 2.0363476276397705, val_loss = 0.7925363183021545\n",
      "epoch n°1994 : train_loss = 2.0422520637512207, val_loss = 0.7910664677619934\n",
      "epoch n°1995 : train_loss = 2.041074752807617, val_loss = 0.7942756414413452\n",
      "epoch n°1996 : train_loss = 2.052901029586792, val_loss = 0.7885535955429077\n",
      "epoch n°1997 : train_loss = 2.055316686630249, val_loss = 0.7904971837997437\n",
      "epoch n°1998 : train_loss = 2.0465476512908936, val_loss = 0.7897399067878723\n",
      "epoch n°1999 : train_loss = 2.044680118560791, val_loss = 0.7948250770568848\n",
      "epoch n°2000 : train_loss = 2.043560266494751, val_loss = 0.7939170598983765\n",
      "epoch n°2001 : train_loss = 2.0378005504608154, val_loss = 0.7906708121299744\n",
      "epoch n°2002 : train_loss = 2.0479178428649902, val_loss = 0.7917752265930176\n",
      "epoch n°2003 : train_loss = 2.045621633529663, val_loss = 0.7938352227210999\n",
      "epoch n°2004 : train_loss = 2.0387861728668213, val_loss = 0.7901474237442017\n",
      "epoch n°2005 : train_loss = 2.0433506965637207, val_loss = 0.7898823618888855\n",
      "epoch n°2006 : train_loss = 2.046832323074341, val_loss = 0.7947107553482056\n",
      "epoch n°2007 : train_loss = 2.0464704036712646, val_loss = 0.7949990630149841\n",
      "epoch n°2008 : train_loss = 2.0492665767669678, val_loss = 0.7908274531364441\n",
      "epoch n°2009 : train_loss = 2.0435843467712402, val_loss = 0.7950571775436401\n",
      "epoch n°2010 : train_loss = 2.051232099533081, val_loss = 0.7902324795722961\n",
      "epoch n°2011 : train_loss = 2.039553642272949, val_loss = 0.7928714156150818\n",
      "epoch n°2012 : train_loss = 2.03997540473938, val_loss = 0.7941192984580994\n",
      "epoch n°2013 : train_loss = 2.038569450378418, val_loss = 0.7943287491798401\n",
      "epoch n°2014 : train_loss = 2.0434210300445557, val_loss = 0.7892457246780396\n",
      "epoch n°2015 : train_loss = 2.046969413757324, val_loss = 0.7939946055412292\n",
      "epoch n°2016 : train_loss = 2.0493500232696533, val_loss = 0.7932652831077576\n",
      "epoch n°2017 : train_loss = 2.051067352294922, val_loss = 0.7941439151763916\n",
      "epoch n°2018 : train_loss = 2.0456790924072266, val_loss = 0.7980325222015381\n",
      "epoch n°2019 : train_loss = 2.0437843799591064, val_loss = 0.7969683408737183\n",
      "epoch n°2020 : train_loss = 2.0465450286865234, val_loss = 0.7887426018714905\n",
      "epoch n°2021 : train_loss = 2.0556256771087646, val_loss = 0.7928116917610168\n",
      "epoch n°2022 : train_loss = 2.0479207038879395, val_loss = 0.7893717288970947\n",
      "epoch n°2023 : train_loss = 2.050028085708618, val_loss = 0.7923265695571899\n",
      "epoch n°2024 : train_loss = 2.043515205383301, val_loss = 0.793674111366272\n",
      "epoch n°2025 : train_loss = 2.0406715869903564, val_loss = 0.7903531789779663\n",
      "epoch n°2026 : train_loss = 2.046621561050415, val_loss = 0.7960712313652039\n",
      "epoch n°2027 : train_loss = 2.0406975746154785, val_loss = 0.7918739914894104\n",
      "epoch n°2028 : train_loss = 2.0420522689819336, val_loss = 0.7944899797439575\n",
      "epoch n°2029 : train_loss = 2.0543363094329834, val_loss = 0.7960804104804993\n",
      "epoch n°2030 : train_loss = 2.046832799911499, val_loss = 0.7933498024940491\n",
      "epoch n°2031 : train_loss = 2.0499227046966553, val_loss = 0.791479229927063\n",
      "epoch n°2032 : train_loss = 2.083320140838623, val_loss = 0.7975809574127197\n",
      "epoch n°2033 : train_loss = 2.070237636566162, val_loss = 0.7950855493545532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°2034 : train_loss = 2.0830535888671875, val_loss = 0.794701337814331\n",
      "epoch n°2035 : train_loss = 2.069838047027588, val_loss = 0.797335147857666\n",
      "epoch n°2036 : train_loss = 2.086618661880493, val_loss = 0.7954832911491394\n",
      "epoch n°2037 : train_loss = 2.0721187591552734, val_loss = 0.7940311431884766\n",
      "epoch n°2038 : train_loss = 2.0729782581329346, val_loss = 0.7962014079093933\n",
      "epoch n°2039 : train_loss = 2.072737693786621, val_loss = 0.7986769080162048\n",
      "epoch n°2040 : train_loss = 2.0771169662475586, val_loss = 0.7974206805229187\n",
      "epoch n°2041 : train_loss = 2.0775604248046875, val_loss = 0.8007815480232239\n",
      "epoch n°2042 : train_loss = 2.0865635871887207, val_loss = 0.7966481447219849\n",
      "epoch n°2043 : train_loss = 2.080552577972412, val_loss = 0.8001405000686646\n",
      "epoch n°2044 : train_loss = 2.0748941898345947, val_loss = 0.7955760359764099\n",
      "epoch n°2045 : train_loss = 2.0787360668182373, val_loss = 0.7938288450241089\n",
      "epoch n°2046 : train_loss = 2.0710248947143555, val_loss = 0.7930526733398438\n",
      "epoch n°2047 : train_loss = 2.0788676738739014, val_loss = 0.8012650609016418\n",
      "epoch n°2048 : train_loss = 2.0823278427124023, val_loss = 0.7945404648780823\n",
      "epoch n°2049 : train_loss = 2.077366590499878, val_loss = 0.7993819117546082\n",
      "epoch n°2050 : train_loss = 2.084817409515381, val_loss = 0.7977246046066284\n",
      "epoch n°2051 : train_loss = 2.08215069770813, val_loss = 0.7973601818084717\n",
      "epoch n°2052 : train_loss = 2.0772480964660645, val_loss = 0.7956733107566833\n",
      "epoch n°2053 : train_loss = 2.088449001312256, val_loss = 0.7963904738426208\n",
      "epoch n°2054 : train_loss = 2.084246873855591, val_loss = 0.7973066568374634\n",
      "epoch n°2055 : train_loss = 2.078441619873047, val_loss = 0.7952173352241516\n",
      "epoch n°2056 : train_loss = 2.078181266784668, val_loss = 0.7995322942733765\n",
      "epoch n°2057 : train_loss = 2.0819475650787354, val_loss = 0.7990410923957825\n",
      "epoch n°2058 : train_loss = 2.077749013900757, val_loss = 0.7900022268295288\n",
      "epoch n°2059 : train_loss = 2.076355218887329, val_loss = 0.7940535545349121\n",
      "epoch n°2060 : train_loss = 2.064692497253418, val_loss = 0.7988695502281189\n",
      "epoch n°2061 : train_loss = 2.0761306285858154, val_loss = 0.7967309355735779\n",
      "epoch n°2062 : train_loss = 2.08417010307312, val_loss = 0.7977895736694336\n",
      "epoch n°2063 : train_loss = 2.0842533111572266, val_loss = 0.7987887263298035\n",
      "epoch n°2064 : train_loss = 2.0848841667175293, val_loss = 0.7917793393135071\n",
      "epoch n°2065 : train_loss = 2.085667371749878, val_loss = 0.7955676913261414\n",
      "epoch n°2066 : train_loss = 2.0741376876831055, val_loss = 0.7989537715911865\n",
      "epoch n°2067 : train_loss = 2.077298402786255, val_loss = 0.7935964465141296\n",
      "epoch n°2068 : train_loss = 2.0867528915405273, val_loss = 0.7956415414810181\n",
      "epoch n°2069 : train_loss = 2.0869805812835693, val_loss = 0.7957143187522888\n",
      "epoch n°2070 : train_loss = 2.091219425201416, val_loss = 0.7944474816322327\n",
      "epoch n°2071 : train_loss = 2.0833847522735596, val_loss = 0.7987603545188904\n",
      "epoch n°2072 : train_loss = 2.079852342605591, val_loss = 0.7936145663261414\n",
      "epoch n°2073 : train_loss = 2.077427625656128, val_loss = 0.7946689128875732\n",
      "epoch n°2074 : train_loss = 2.0851080417633057, val_loss = 0.7961099147796631\n",
      "epoch n°2075 : train_loss = 2.087834596633911, val_loss = 0.7994391918182373\n",
      "epoch n°2076 : train_loss = 2.080029010772705, val_loss = 0.8000547289848328\n",
      "epoch n°2077 : train_loss = 2.084209442138672, val_loss = 0.7913814187049866\n",
      "epoch n°2078 : train_loss = 2.076953172683716, val_loss = 0.7988402843475342\n",
      "epoch n°2079 : train_loss = 2.0771100521087646, val_loss = 0.7968012690544128\n",
      "epoch n°2080 : train_loss = 2.0857419967651367, val_loss = 0.8020057082176208\n",
      "epoch n°2081 : train_loss = 2.081775426864624, val_loss = 0.791110634803772\n",
      "epoch n°2082 : train_loss = 2.0843725204467773, val_loss = 0.79458087682724\n",
      "epoch n°2083 : train_loss = 2.0848336219787598, val_loss = 0.7906523942947388\n",
      "epoch n°2084 : train_loss = 2.088773488998413, val_loss = 0.795728325843811\n",
      "epoch n°2085 : train_loss = 2.082122564315796, val_loss = 0.7976851463317871\n",
      "epoch n°2086 : train_loss = 2.087433099746704, val_loss = 0.7941782474517822\n",
      "epoch n°2087 : train_loss = 2.0964956283569336, val_loss = 0.7958858013153076\n",
      "epoch n°2088 : train_loss = 2.0828616619110107, val_loss = 0.7910608649253845\n",
      "epoch n°2089 : train_loss = 2.0841546058654785, val_loss = 0.7995470762252808\n",
      "epoch n°2090 : train_loss = 2.0885605812072754, val_loss = 0.7946449518203735\n",
      "epoch n°2091 : train_loss = 2.0870797634124756, val_loss = 0.7979767918586731\n",
      "epoch n°2092 : train_loss = 2.089198350906372, val_loss = 0.795592188835144\n",
      "epoch n°2093 : train_loss = 2.0804169178009033, val_loss = 0.7936096787452698\n",
      "epoch n°2094 : train_loss = 2.0854508876800537, val_loss = 0.7995699644088745\n",
      "epoch n°2095 : train_loss = 2.089179515838623, val_loss = 0.7948866486549377\n",
      "epoch n°2096 : train_loss = 2.0802173614501953, val_loss = 0.7988142371177673\n",
      "epoch n°2097 : train_loss = 2.0953147411346436, val_loss = 0.794325053691864\n",
      "epoch n°2098 : train_loss = 2.0842084884643555, val_loss = 0.7989941239356995\n",
      "epoch n°2099 : train_loss = 2.081542730331421, val_loss = 0.8034286499023438\n",
      "epoch n°2100 : train_loss = 2.085012912750244, val_loss = 0.7961169481277466\n",
      "epoch n°2101 : train_loss = 2.082461357116699, val_loss = 0.796762228012085\n",
      "epoch n°2102 : train_loss = 2.0827438831329346, val_loss = 0.7979322075843811\n",
      "epoch n°2103 : train_loss = 2.0865836143493652, val_loss = 0.7953177690505981\n",
      "epoch n°2104 : train_loss = 2.090777635574341, val_loss = 0.8023194074630737\n",
      "epoch n°2105 : train_loss = 2.089109420776367, val_loss = 0.7963162064552307\n",
      "epoch n°2106 : train_loss = 2.083824634552002, val_loss = 0.7974578738212585\n",
      "epoch n°2107 : train_loss = 2.076338768005371, val_loss = 0.796550452709198\n",
      "epoch n°2108 : train_loss = 2.0800299644470215, val_loss = 0.795330286026001\n",
      "epoch n°2109 : train_loss = 2.0931973457336426, val_loss = 0.7984833717346191\n",
      "epoch n°2110 : train_loss = 2.0831034183502197, val_loss = 0.7938759326934814\n",
      "epoch n°2111 : train_loss = 2.0860397815704346, val_loss = 0.7962296009063721\n",
      "epoch n°2112 : train_loss = 2.0828258991241455, val_loss = 0.7974918484687805\n",
      "epoch n°2113 : train_loss = 2.08270263671875, val_loss = 0.7930557131767273\n",
      "epoch n°2114 : train_loss = 2.0845208168029785, val_loss = 0.7999880313873291\n",
      "epoch n°2115 : train_loss = 2.080177068710327, val_loss = 0.7951453328132629\n",
      "epoch n°2116 : train_loss = 2.0839998722076416, val_loss = 0.79237300157547\n",
      "epoch n°2117 : train_loss = 2.0908713340759277, val_loss = 0.793032705783844\n",
      "epoch n°2118 : train_loss = 2.081068754196167, val_loss = 0.7950193285942078\n",
      "epoch n°2119 : train_loss = 2.1017658710479736, val_loss = 0.7966508865356445\n",
      "epoch n°2120 : train_loss = 2.0809009075164795, val_loss = 0.7931829690933228\n",
      "epoch n°2121 : train_loss = 2.089144468307495, val_loss = 0.7981739044189453\n",
      "epoch n°2122 : train_loss = 2.0774648189544678, val_loss = 0.7976828813552856\n",
      "epoch n°2123 : train_loss = 2.0905539989471436, val_loss = 0.7976313233375549\n",
      "epoch n°2124 : train_loss = 2.0844833850860596, val_loss = 0.7942752838134766\n",
      "epoch n°2125 : train_loss = 2.0770881175994873, val_loss = 0.7951918840408325\n",
      "epoch n°2126 : train_loss = 2.082150459289551, val_loss = 0.7968538999557495\n",
      "epoch n°2127 : train_loss = 2.080536127090454, val_loss = 0.7959698438644409\n",
      "epoch n°2128 : train_loss = 2.0865073204040527, val_loss = 0.7986515760421753\n",
      "epoch n°2129 : train_loss = 2.0832223892211914, val_loss = 0.7968231439590454\n",
      "epoch n°2130 : train_loss = 2.085106611251831, val_loss = 0.7922305464744568\n",
      "epoch n°2131 : train_loss = 2.0823802947998047, val_loss = 0.7948508858680725\n",
      "epoch n°2132 : train_loss = 2.083162307739258, val_loss = 0.7962601780891418\n",
      "epoch n°2133 : train_loss = 2.080150604248047, val_loss = 0.7948562502861023\n",
      "epoch n°2134 : train_loss = 2.0953197479248047, val_loss = 0.7970749139785767\n",
      "epoch n°2135 : train_loss = 2.07816743850708, val_loss = 0.7961434125900269\n",
      "epoch n°2136 : train_loss = 2.0937647819519043, val_loss = 0.7976582646369934\n",
      "epoch n°2137 : train_loss = 2.092000961303711, val_loss = 0.794722855091095\n",
      "epoch n°2138 : train_loss = 2.0837039947509766, val_loss = 0.8009730577468872\n",
      "epoch n°2139 : train_loss = 2.080660581588745, val_loss = 0.7928735017776489\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°2140 : train_loss = 2.084346055984497, val_loss = 0.7936672568321228\n",
      "epoch n°2141 : train_loss = 2.079902172088623, val_loss = 0.7992623448371887\n",
      "epoch n°2142 : train_loss = 2.0900702476501465, val_loss = 0.7967392206192017\n",
      "epoch n°2143 : train_loss = 2.0887112617492676, val_loss = 0.7935173511505127\n",
      "epoch n°2144 : train_loss = 2.0972702503204346, val_loss = 0.7970023155212402\n",
      "epoch n°2145 : train_loss = 2.090153217315674, val_loss = 0.7995020747184753\n",
      "epoch n°2146 : train_loss = 2.085897922515869, val_loss = 0.7957119941711426\n",
      "epoch n°2147 : train_loss = 2.078033447265625, val_loss = 0.7964492440223694\n",
      "epoch n°2148 : train_loss = 2.0816550254821777, val_loss = 0.7976094484329224\n",
      "epoch n°2149 : train_loss = 2.0785582065582275, val_loss = 0.7965735197067261\n",
      "epoch n°2150 : train_loss = 2.087175130844116, val_loss = 0.7993032336235046\n",
      "epoch n°2151 : train_loss = 2.080585241317749, val_loss = 0.7974944710731506\n",
      "epoch n°2152 : train_loss = 2.0889532566070557, val_loss = 0.795416533946991\n",
      "epoch n°2153 : train_loss = 2.080465793609619, val_loss = 0.7972699999809265\n",
      "epoch n°2154 : train_loss = 2.0791797637939453, val_loss = 0.7936578392982483\n",
      "epoch n°2155 : train_loss = 2.0786385536193848, val_loss = 0.7974492907524109\n",
      "epoch n°2156 : train_loss = 2.0822155475616455, val_loss = 0.7975895404815674\n",
      "epoch n°2157 : train_loss = 2.0902795791625977, val_loss = 0.7980332970619202\n",
      "epoch n°2158 : train_loss = 2.0873148441314697, val_loss = 0.7989458441734314\n",
      "epoch n°2159 : train_loss = 2.0859789848327637, val_loss = 0.7952431440353394\n",
      "epoch n°2160 : train_loss = 2.0777974128723145, val_loss = 0.7988468408584595\n",
      "epoch n°2161 : train_loss = 2.0906732082366943, val_loss = 0.7969620227813721\n",
      "epoch n°2162 : train_loss = 2.0891988277435303, val_loss = 0.8007524013519287\n",
      "epoch n°2163 : train_loss = 2.085777521133423, val_loss = 0.7986871600151062\n",
      "epoch n°2164 : train_loss = 2.0838558673858643, val_loss = 0.8000288605690002\n",
      "epoch n°2165 : train_loss = 2.095245838165283, val_loss = 0.7993149161338806\n",
      "epoch n°2166 : train_loss = 2.097390651702881, val_loss = 0.7980780005455017\n",
      "epoch n°2167 : train_loss = 2.086125135421753, val_loss = 0.798291802406311\n",
      "epoch n°2168 : train_loss = 2.0842232704162598, val_loss = 0.8003764748573303\n",
      "epoch n°2169 : train_loss = 2.085508108139038, val_loss = 0.7952403426170349\n",
      "epoch n°2170 : train_loss = 2.0907115936279297, val_loss = 0.7956241965293884\n",
      "epoch n°2171 : train_loss = 2.090911865234375, val_loss = 0.7958438992500305\n",
      "epoch n°2172 : train_loss = 2.0801336765289307, val_loss = 0.7943336963653564\n",
      "epoch n°2173 : train_loss = 2.0872762203216553, val_loss = 0.7921307682991028\n",
      "epoch n°2174 : train_loss = 2.0812530517578125, val_loss = 0.7903521656990051\n",
      "epoch n°2175 : train_loss = 2.081298589706421, val_loss = 0.7959910035133362\n",
      "epoch n°2176 : train_loss = 2.082965612411499, val_loss = 0.8011474013328552\n",
      "epoch n°2177 : train_loss = 2.086979866027832, val_loss = 0.7980453968048096\n",
      "epoch n°2178 : train_loss = 2.0838704109191895, val_loss = 0.793643057346344\n",
      "epoch n°2179 : train_loss = 2.0889973640441895, val_loss = 0.7979243993759155\n",
      "epoch n°2180 : train_loss = 2.0768749713897705, val_loss = 0.7924111485481262\n",
      "epoch n°2181 : train_loss = 2.08575701713562, val_loss = 0.7940371632575989\n",
      "epoch n°2182 : train_loss = 2.0813968181610107, val_loss = 0.7951984405517578\n",
      "epoch n°2183 : train_loss = 2.0775392055511475, val_loss = 0.7943182587623596\n",
      "epoch n°2184 : train_loss = 2.0847296714782715, val_loss = 0.7976446747779846\n",
      "epoch n°2185 : train_loss = 2.0848886966705322, val_loss = 0.7954801321029663\n",
      "epoch n°2186 : train_loss = 2.084282398223877, val_loss = 0.7956979870796204\n",
      "epoch n°2187 : train_loss = 2.0807673931121826, val_loss = 0.7932972311973572\n",
      "epoch n°2188 : train_loss = 2.088970184326172, val_loss = 0.7963437438011169\n",
      "epoch n°2189 : train_loss = 2.085314989089966, val_loss = 0.7922526597976685\n",
      "epoch n°2190 : train_loss = 2.087756395339966, val_loss = 0.7975624203681946\n",
      "epoch n°2191 : train_loss = 2.084172248840332, val_loss = 0.8020383715629578\n",
      "epoch n°2192 : train_loss = 2.09167742729187, val_loss = 0.7983385920524597\n",
      "epoch n°2193 : train_loss = 2.0899882316589355, val_loss = 0.7987375855445862\n",
      "epoch n°2194 : train_loss = 2.0819010734558105, val_loss = 0.7935517430305481\n",
      "epoch n°2195 : train_loss = 2.079918384552002, val_loss = 0.7956728339195251\n",
      "epoch n°2196 : train_loss = 2.081467628479004, val_loss = 0.7990242838859558\n",
      "epoch n°2197 : train_loss = 2.092836856842041, val_loss = 0.7929912805557251\n",
      "epoch n°2198 : train_loss = 2.08266282081604, val_loss = 0.7876163125038147\n",
      "epoch n°2199 : train_loss = 2.088045835494995, val_loss = 0.7927525639533997\n",
      "epoch n°2200 : train_loss = 2.0831825733184814, val_loss = 0.7946990728378296\n",
      "epoch n°2201 : train_loss = 2.0857765674591064, val_loss = 0.7962672710418701\n",
      "epoch n°2202 : train_loss = 2.08841609954834, val_loss = 0.7939819693565369\n",
      "epoch n°2203 : train_loss = 2.0886905193328857, val_loss = 0.7927590012550354\n",
      "epoch n°2204 : train_loss = 2.0717849731445312, val_loss = 0.7973438501358032\n",
      "epoch n°2205 : train_loss = 2.088630437850952, val_loss = 0.7969301342964172\n",
      "epoch n°2206 : train_loss = 2.077840805053711, val_loss = 0.8000803589820862\n",
      "epoch n°2207 : train_loss = 2.0857303142547607, val_loss = 0.7989751100540161\n",
      "epoch n°2208 : train_loss = 2.0792112350463867, val_loss = 0.7971384525299072\n",
      "epoch n°2209 : train_loss = 2.084878921508789, val_loss = 0.793350338935852\n",
      "epoch n°2210 : train_loss = 2.0862035751342773, val_loss = 0.7960197329521179\n",
      "epoch n°2211 : train_loss = 2.082524061203003, val_loss = 0.7964361310005188\n",
      "epoch n°2212 : train_loss = 2.0832629203796387, val_loss = 0.7994524240493774\n",
      "epoch n°2213 : train_loss = 2.0848870277404785, val_loss = 0.7949130535125732\n",
      "epoch n°2214 : train_loss = 2.089608669281006, val_loss = 0.7967163324356079\n",
      "epoch n°2215 : train_loss = 2.0794143676757812, val_loss = 0.7985643148422241\n",
      "epoch n°2216 : train_loss = 2.0815932750701904, val_loss = 0.7980538010597229\n",
      "epoch n°2217 : train_loss = 2.0903408527374268, val_loss = 0.7985498309135437\n",
      "epoch n°2218 : train_loss = 2.0824649333953857, val_loss = 0.797916054725647\n",
      "epoch n°2219 : train_loss = 2.0898807048797607, val_loss = 0.795301079750061\n",
      "epoch n°2220 : train_loss = 2.074065685272217, val_loss = 0.7980527877807617\n",
      "epoch n°2221 : train_loss = 2.0818116664886475, val_loss = 0.7955622673034668\n",
      "epoch n°2222 : train_loss = 2.0836222171783447, val_loss = 0.7906739115715027\n",
      "epoch n°2223 : train_loss = 2.0933284759521484, val_loss = 0.7987307906150818\n",
      "epoch n°2224 : train_loss = 2.083820104598999, val_loss = 0.7975616455078125\n",
      "epoch n°2225 : train_loss = 2.0740435123443604, val_loss = 0.7960801720619202\n",
      "epoch n°2226 : train_loss = 2.0768678188323975, val_loss = 0.7935746908187866\n",
      "epoch n°2227 : train_loss = 2.077591896057129, val_loss = 0.7987073063850403\n",
      "epoch n°2228 : train_loss = 2.0870203971862793, val_loss = 0.7937654852867126\n",
      "epoch n°2229 : train_loss = 2.0813353061676025, val_loss = 0.7984247207641602\n",
      "epoch n°2230 : train_loss = 2.0730693340301514, val_loss = 0.7931263446807861\n",
      "epoch n°2231 : train_loss = 2.080946683883667, val_loss = 0.7927488684654236\n",
      "epoch n°2232 : train_loss = 2.0823254585266113, val_loss = 0.7988145351409912\n",
      "epoch n°2233 : train_loss = 2.0864498615264893, val_loss = 0.7927370071411133\n",
      "epoch n°2234 : train_loss = 2.0787293910980225, val_loss = 0.7965185642242432\n",
      "epoch n°2235 : train_loss = 2.0793635845184326, val_loss = 0.7960121631622314\n",
      "epoch n°2236 : train_loss = 2.0777580738067627, val_loss = 0.7943689227104187\n",
      "epoch n°2237 : train_loss = 2.079930305480957, val_loss = 0.7955779433250427\n",
      "epoch n°2238 : train_loss = 2.081942558288574, val_loss = 0.7977314591407776\n",
      "epoch n°2239 : train_loss = 2.0717427730560303, val_loss = 0.7961083650588989\n",
      "epoch n°2240 : train_loss = 2.083897113800049, val_loss = 0.798824667930603\n",
      "epoch n°2241 : train_loss = 2.086329221725464, val_loss = 0.7968330383300781\n",
      "epoch n°2242 : train_loss = 2.0798730850219727, val_loss = 0.7929487824440002\n",
      "epoch n°2243 : train_loss = 2.0805599689483643, val_loss = 0.7935248017311096\n",
      "epoch n°2244 : train_loss = 2.080423593521118, val_loss = 0.7996708750724792\n",
      "epoch n°2245 : train_loss = 2.0781731605529785, val_loss = 0.7963348031044006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°2246 : train_loss = 2.0897886753082275, val_loss = 0.7949420213699341\n",
      "epoch n°2247 : train_loss = 2.0879743099212646, val_loss = 0.7964387536048889\n",
      "epoch n°2248 : train_loss = 2.0821032524108887, val_loss = 0.7921889424324036\n",
      "epoch n°2249 : train_loss = 2.085263967514038, val_loss = 0.7922530174255371\n",
      "epoch n°2250 : train_loss = 2.0802135467529297, val_loss = 0.7968684434890747\n",
      "epoch n°2251 : train_loss = 2.0886459350585938, val_loss = 0.799882173538208\n",
      "epoch n°2252 : train_loss = 2.0898914337158203, val_loss = 0.7933930158615112\n",
      "epoch n°2253 : train_loss = 2.076796054840088, val_loss = 0.7957336902618408\n",
      "epoch n°2254 : train_loss = 2.0784711837768555, val_loss = 0.7937808632850647\n",
      "epoch n°2255 : train_loss = 2.076357364654541, val_loss = 0.7946049571037292\n",
      "epoch n°2256 : train_loss = 2.0795328617095947, val_loss = 0.7994171380996704\n",
      "epoch n°2257 : train_loss = 2.0834689140319824, val_loss = 0.7987583875656128\n",
      "epoch n°2258 : train_loss = 2.081749200820923, val_loss = 0.7926614284515381\n",
      "epoch n°2259 : train_loss = 2.0832464694976807, val_loss = 0.7997334003448486\n",
      "epoch n°2260 : train_loss = 2.08502459526062, val_loss = 0.7930428385734558\n",
      "epoch n°2261 : train_loss = 2.0858519077301025, val_loss = 0.798028290271759\n",
      "epoch n°2262 : train_loss = 2.0838444232940674, val_loss = 0.7964067459106445\n",
      "epoch n°2263 : train_loss = 2.0931522846221924, val_loss = 0.7954556941986084\n",
      "epoch n°2264 : train_loss = 2.0817198753356934, val_loss = 0.7951557636260986\n",
      "epoch n°2265 : train_loss = 2.079831123352051, val_loss = 0.796413004398346\n",
      "epoch n°2266 : train_loss = 2.089425563812256, val_loss = 0.7960946559906006\n",
      "epoch n°2267 : train_loss = 2.077200412750244, val_loss = 0.7962998747825623\n",
      "epoch n°2268 : train_loss = 2.078401803970337, val_loss = 0.794445276260376\n",
      "epoch n°2269 : train_loss = 2.0895419120788574, val_loss = 0.7923731207847595\n",
      "epoch n°2270 : train_loss = 2.0856010913848877, val_loss = 0.8007593750953674\n",
      "epoch n°2271 : train_loss = 2.08156156539917, val_loss = 0.7938024401664734\n",
      "epoch n°2272 : train_loss = 2.07794451713562, val_loss = 0.7935159802436829\n",
      "epoch n°2273 : train_loss = 2.0765814781188965, val_loss = 0.7929441928863525\n",
      "epoch n°2274 : train_loss = 2.087378978729248, val_loss = 0.7973953485488892\n",
      "epoch n°2275 : train_loss = 2.0807905197143555, val_loss = 0.7986688017845154\n",
      "epoch n°2276 : train_loss = 2.0752243995666504, val_loss = 0.7991762161254883\n",
      "epoch n°2277 : train_loss = 2.085296869277954, val_loss = 0.800627589225769\n",
      "epoch n°2278 : train_loss = 2.0947823524475098, val_loss = 0.7971036434173584\n",
      "epoch n°2279 : train_loss = 2.0868935585021973, val_loss = 0.8008854389190674\n",
      "epoch n°2280 : train_loss = 2.076090097427368, val_loss = 0.7987784743309021\n",
      "epoch n°2281 : train_loss = 2.075483798980713, val_loss = 0.7946463823318481\n",
      "epoch n°2282 : train_loss = 2.0762009620666504, val_loss = 0.8010708689689636\n",
      "epoch n°2283 : train_loss = 2.0867748260498047, val_loss = 0.7938923239707947\n",
      "epoch n°2284 : train_loss = 2.0833075046539307, val_loss = 0.7924145460128784\n",
      "epoch n°2285 : train_loss = 2.088567018508911, val_loss = 0.796846866607666\n",
      "epoch n°2286 : train_loss = 2.0825769901275635, val_loss = 0.7905685305595398\n",
      "epoch n°2287 : train_loss = 2.0792291164398193, val_loss = 0.7979876399040222\n",
      "epoch n°2288 : train_loss = 2.0811920166015625, val_loss = 0.7939538359642029\n",
      "epoch n°2289 : train_loss = 2.079867124557495, val_loss = 0.7938964366912842\n",
      "epoch n°2290 : train_loss = 2.078537940979004, val_loss = 0.7943190932273865\n",
      "epoch n°2291 : train_loss = 2.078202247619629, val_loss = 0.7940951585769653\n",
      "epoch n°2292 : train_loss = 2.085347890853882, val_loss = 0.7965003252029419\n",
      "epoch n°2293 : train_loss = 2.0789551734924316, val_loss = 0.8020741939544678\n",
      "epoch n°2294 : train_loss = 2.083754301071167, val_loss = 0.7975711226463318\n",
      "epoch n°2295 : train_loss = 2.0763115882873535, val_loss = 0.7984263896942139\n",
      "epoch n°2296 : train_loss = 2.0911436080932617, val_loss = 0.7933288216590881\n",
      "epoch n°2297 : train_loss = 2.070700168609619, val_loss = 0.7950411438941956\n",
      "epoch n°2298 : train_loss = 2.072683811187744, val_loss = 0.7978033423423767\n",
      "epoch n°2299 : train_loss = 2.084456443786621, val_loss = 0.7935146689414978\n",
      "epoch n°2300 : train_loss = 2.088672637939453, val_loss = 0.8029665946960449\n",
      "epoch n°2301 : train_loss = 2.1038477420806885, val_loss = 0.7958303093910217\n",
      "epoch n°2302 : train_loss = 2.0800070762634277, val_loss = 0.8007273077964783\n",
      "epoch n°2303 : train_loss = 2.078669309616089, val_loss = 0.7955513596534729\n",
      "epoch n°2304 : train_loss = 2.083332061767578, val_loss = 0.7929965853691101\n",
      "epoch n°2305 : train_loss = 2.0742483139038086, val_loss = 0.7957214713096619\n",
      "epoch n°2306 : train_loss = 2.0785818099975586, val_loss = 0.7899284958839417\n",
      "epoch n°2307 : train_loss = 2.08345890045166, val_loss = 0.8002249002456665\n",
      "epoch n°2308 : train_loss = 2.0774612426757812, val_loss = 0.7969123125076294\n",
      "epoch n°2309 : train_loss = 2.0865044593811035, val_loss = 0.7940512895584106\n",
      "epoch n°2310 : train_loss = 2.080674886703491, val_loss = 0.7961163520812988\n",
      "epoch n°2311 : train_loss = 2.071031093597412, val_loss = 0.7924408912658691\n",
      "epoch n°2312 : train_loss = 2.07528018951416, val_loss = 0.7994096279144287\n",
      "epoch n°2313 : train_loss = 2.082960367202759, val_loss = 0.7968165278434753\n",
      "epoch n°2314 : train_loss = 2.079467296600342, val_loss = 0.7987517714500427\n",
      "epoch n°2315 : train_loss = 2.080836534500122, val_loss = 0.7954834699630737\n",
      "epoch n°2316 : train_loss = 2.0731136798858643, val_loss = 0.797670841217041\n",
      "epoch n°2317 : train_loss = 2.0834946632385254, val_loss = 0.7926210165023804\n",
      "epoch n°2318 : train_loss = 2.0809061527252197, val_loss = 0.7957448959350586\n",
      "epoch n°2319 : train_loss = 2.075636386871338, val_loss = 0.7955517768859863\n",
      "epoch n°2320 : train_loss = 2.074436664581299, val_loss = 0.7994505167007446\n",
      "epoch n°2321 : train_loss = 2.078233242034912, val_loss = 0.7940397262573242\n",
      "epoch n°2322 : train_loss = 2.0738465785980225, val_loss = 0.797393798828125\n",
      "epoch n°2323 : train_loss = 2.0903515815734863, val_loss = 0.7972036004066467\n",
      "epoch n°2324 : train_loss = 2.077261447906494, val_loss = 0.7962170243263245\n",
      "epoch n°2325 : train_loss = 2.069864511489868, val_loss = 0.7973610758781433\n",
      "epoch n°2326 : train_loss = 2.082273244857788, val_loss = 0.7984382510185242\n",
      "epoch n°2327 : train_loss = 2.082980155944824, val_loss = 0.7922238111495972\n",
      "epoch n°2328 : train_loss = 2.0707688331604004, val_loss = 0.7925000190734863\n",
      "epoch n°2329 : train_loss = 2.080479383468628, val_loss = 0.7960458397865295\n",
      "epoch n°2330 : train_loss = 2.0759260654449463, val_loss = 0.7943822741508484\n",
      "epoch n°2331 : train_loss = 2.0864293575286865, val_loss = 0.7958469986915588\n",
      "epoch n°2332 : train_loss = 2.0807535648345947, val_loss = 0.794921338558197\n",
      "epoch n°2333 : train_loss = 2.0835249423980713, val_loss = 0.7998549938201904\n",
      "epoch n°2334 : train_loss = 2.075580358505249, val_loss = 0.7950583100318909\n",
      "epoch n°2335 : train_loss = 2.0861642360687256, val_loss = 0.7954297661781311\n",
      "epoch n°2336 : train_loss = 2.0827202796936035, val_loss = 0.7962304353713989\n",
      "epoch n°2337 : train_loss = 2.0817313194274902, val_loss = 0.796165406703949\n",
      "epoch n°2338 : train_loss = 2.0841000080108643, val_loss = 0.7979996204376221\n",
      "epoch n°2339 : train_loss = 2.0716912746429443, val_loss = 0.7915077805519104\n",
      "epoch n°2340 : train_loss = 2.073953628540039, val_loss = 0.7949198484420776\n",
      "epoch n°2341 : train_loss = 2.077782392501831, val_loss = 0.793426513671875\n",
      "epoch n°2342 : train_loss = 2.0770041942596436, val_loss = 0.7963332533836365\n",
      "epoch n°2343 : train_loss = 2.0738348960876465, val_loss = 0.7955296039581299\n",
      "epoch n°2344 : train_loss = 2.0855605602264404, val_loss = 0.7953182458877563\n",
      "epoch n°2345 : train_loss = 2.0830204486846924, val_loss = 0.8002841472625732\n",
      "epoch n°2346 : train_loss = 2.0793509483337402, val_loss = 0.7941817045211792\n",
      "epoch n°2347 : train_loss = 2.0744731426239014, val_loss = 0.7935663461685181\n",
      "epoch n°2348 : train_loss = 2.0776565074920654, val_loss = 0.790665864944458\n",
      "epoch n°2349 : train_loss = 2.0839381217956543, val_loss = 0.7981348633766174\n",
      "epoch n°2350 : train_loss = 2.0759973526000977, val_loss = 0.7957816123962402\n",
      "epoch n°2351 : train_loss = 2.0793721675872803, val_loss = 0.7915111780166626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°2352 : train_loss = 2.075806140899658, val_loss = 0.7946057319641113\n",
      "epoch n°2353 : train_loss = 2.0794730186462402, val_loss = 0.795504093170166\n",
      "epoch n°2354 : train_loss = 2.0754482746124268, val_loss = 0.7976140975952148\n",
      "epoch n°2355 : train_loss = 2.0761001110076904, val_loss = 0.7981002330780029\n",
      "epoch n°2356 : train_loss = 2.0840656757354736, val_loss = 0.7962779998779297\n",
      "epoch n°2357 : train_loss = 2.0833685398101807, val_loss = 0.7972710728645325\n",
      "epoch n°2358 : train_loss = 2.089900016784668, val_loss = 0.792864203453064\n",
      "epoch n°2359 : train_loss = 2.0820794105529785, val_loss = 0.7920889258384705\n",
      "epoch n°2360 : train_loss = 2.068296194076538, val_loss = 0.7956326007843018\n",
      "epoch n°2361 : train_loss = 2.0719614028930664, val_loss = 0.7971944808959961\n",
      "epoch n°2362 : train_loss = 2.0719563961029053, val_loss = 0.7956191897392273\n",
      "epoch n°2363 : train_loss = 2.0804519653320312, val_loss = 0.796035885810852\n",
      "epoch n°2364 : train_loss = 2.0694923400878906, val_loss = 0.7955206036567688\n",
      "epoch n°2365 : train_loss = 2.077479362487793, val_loss = 0.7976629734039307\n",
      "epoch n°2366 : train_loss = 2.0659141540527344, val_loss = 0.7946012616157532\n",
      "epoch n°2367 : train_loss = 2.0773396492004395, val_loss = 0.7975371479988098\n",
      "epoch n°2368 : train_loss = 2.07541823387146, val_loss = 0.7985658645629883\n",
      "epoch n°2369 : train_loss = 2.0756285190582275, val_loss = 0.7949182987213135\n",
      "epoch n°2370 : train_loss = 2.0787513256073, val_loss = 0.7952006459236145\n",
      "epoch n°2371 : train_loss = 2.0878782272338867, val_loss = 0.797577977180481\n",
      "epoch n°2372 : train_loss = 2.0742437839508057, val_loss = 0.79608154296875\n",
      "epoch n°2373 : train_loss = 2.0788888931274414, val_loss = 0.7971600294113159\n",
      "epoch n°2374 : train_loss = 2.0849695205688477, val_loss = 0.7977885603904724\n",
      "epoch n°2375 : train_loss = 2.085839033126831, val_loss = 0.7938898801803589\n",
      "epoch n°2376 : train_loss = 2.077214241027832, val_loss = 0.7921276688575745\n",
      "epoch n°2377 : train_loss = 2.082996368408203, val_loss = 0.794241726398468\n",
      "epoch n°2378 : train_loss = 2.0686562061309814, val_loss = 0.7964078187942505\n",
      "epoch n°2379 : train_loss = 2.076202392578125, val_loss = 0.7944031357765198\n",
      "epoch n°2380 : train_loss = 2.078892707824707, val_loss = 0.7926132678985596\n",
      "epoch n°2381 : train_loss = 2.074941873550415, val_loss = 0.7952165007591248\n",
      "epoch n°2382 : train_loss = 2.08089017868042, val_loss = 0.797673225402832\n",
      "epoch n°2383 : train_loss = 2.0770347118377686, val_loss = 0.7942102551460266\n",
      "epoch n°2384 : train_loss = 2.0927574634552, val_loss = 0.7949338555335999\n",
      "epoch n°2385 : train_loss = 2.0784945487976074, val_loss = 0.7957752346992493\n",
      "epoch n°2386 : train_loss = 2.075809955596924, val_loss = 0.7959104180335999\n",
      "epoch n°2387 : train_loss = 2.070697069168091, val_loss = 0.8005753755569458\n",
      "epoch n°2388 : train_loss = 2.081036329269409, val_loss = 0.7952829599380493\n",
      "epoch n°2389 : train_loss = 2.073003053665161, val_loss = 0.7942219972610474\n",
      "epoch n°2390 : train_loss = 2.076878309249878, val_loss = 0.7932985424995422\n",
      "epoch n°2391 : train_loss = 2.074526071548462, val_loss = 0.7929661273956299\n",
      "epoch n°2392 : train_loss = 2.0771872997283936, val_loss = 0.7946344614028931\n",
      "epoch n°2393 : train_loss = 2.0777230262756348, val_loss = 0.7976304888725281\n",
      "epoch n°2394 : train_loss = 2.084170341491699, val_loss = 0.7933611869812012\n",
      "epoch n°2395 : train_loss = 2.083348035812378, val_loss = 0.7906450033187866\n",
      "epoch n°2396 : train_loss = 2.0772955417633057, val_loss = 0.7939268350601196\n",
      "epoch n°2397 : train_loss = 2.0687592029571533, val_loss = 0.7924280166625977\n",
      "epoch n°2398 : train_loss = 2.0798134803771973, val_loss = 0.7943710088729858\n",
      "epoch n°2399 : train_loss = 2.0673694610595703, val_loss = 0.7973389029502869\n",
      "epoch n°2400 : train_loss = 2.0735843181610107, val_loss = 0.7968922257423401\n",
      "epoch n°2401 : train_loss = 2.0727853775024414, val_loss = 0.7919001579284668\n",
      "epoch n°2402 : train_loss = 2.0740818977355957, val_loss = 0.7956462502479553\n",
      "epoch n°2403 : train_loss = 2.082193374633789, val_loss = 0.7975860834121704\n",
      "epoch n°2404 : train_loss = 2.0707828998565674, val_loss = 0.7966939806938171\n",
      "epoch n°2405 : train_loss = 2.078677177429199, val_loss = 0.7962551712989807\n",
      "epoch n°2406 : train_loss = 2.0717735290527344, val_loss = 0.7949943542480469\n",
      "epoch n°2407 : train_loss = 2.0717902183532715, val_loss = 0.7952284812927246\n",
      "epoch n°2408 : train_loss = 2.0809192657470703, val_loss = 0.7937090992927551\n",
      "epoch n°2409 : train_loss = 2.068310022354126, val_loss = 0.7969895005226135\n",
      "epoch n°2410 : train_loss = 2.077596426010132, val_loss = 0.7970178127288818\n",
      "epoch n°2411 : train_loss = 2.080890655517578, val_loss = 0.7956612706184387\n",
      "epoch n°2412 : train_loss = 2.0728862285614014, val_loss = 0.7928298711776733\n",
      "epoch n°2413 : train_loss = 2.0791566371917725, val_loss = 0.7958632707595825\n",
      "epoch n°2414 : train_loss = 2.073655605316162, val_loss = 0.7900251746177673\n",
      "epoch n°2415 : train_loss = 2.0851776599884033, val_loss = 0.7959318161010742\n",
      "epoch n°2416 : train_loss = 2.0721116065979004, val_loss = 0.7945238351821899\n",
      "epoch n°2417 : train_loss = 2.0822627544403076, val_loss = 0.7955278158187866\n",
      "epoch n°2418 : train_loss = 2.084643602371216, val_loss = 0.794994592666626\n",
      "epoch n°2419 : train_loss = 2.078436851501465, val_loss = 0.7977544069290161\n",
      "epoch n°2420 : train_loss = 2.0749361515045166, val_loss = 0.7926689386367798\n",
      "epoch n°2421 : train_loss = 2.06976056098938, val_loss = 0.7919659614562988\n",
      "epoch n°2422 : train_loss = 2.0713326930999756, val_loss = 0.7928109169006348\n",
      "epoch n°2423 : train_loss = 2.076601266860962, val_loss = 0.7951716780662537\n",
      "epoch n°2424 : train_loss = 2.0799453258514404, val_loss = 0.7969073057174683\n",
      "epoch n°2425 : train_loss = 2.076986312866211, val_loss = 0.7994704246520996\n",
      "epoch n°2426 : train_loss = 2.073404550552368, val_loss = 0.7968937754631042\n",
      "epoch n°2427 : train_loss = 2.072282552719116, val_loss = 0.7973613142967224\n",
      "epoch n°2428 : train_loss = 2.0785040855407715, val_loss = 0.7912205457687378\n",
      "epoch n°2429 : train_loss = 2.0819249153137207, val_loss = 0.7943094968795776\n",
      "epoch n°2430 : train_loss = 2.0722479820251465, val_loss = 0.7948878407478333\n",
      "epoch n°2431 : train_loss = 2.0745019912719727, val_loss = 0.7967447638511658\n",
      "epoch n°2432 : train_loss = 2.084101915359497, val_loss = 0.7939804196357727\n",
      "epoch n°2433 : train_loss = 2.0723769664764404, val_loss = 0.7950685024261475\n",
      "epoch n°2434 : train_loss = 2.077895164489746, val_loss = 0.7931827902793884\n",
      "epoch n°2435 : train_loss = 2.0728423595428467, val_loss = 0.7952936887741089\n",
      "epoch n°2436 : train_loss = 2.062704086303711, val_loss = 0.7978429198265076\n",
      "epoch n°2437 : train_loss = 2.074387788772583, val_loss = 0.7973841428756714\n",
      "epoch n°2438 : train_loss = 2.071214437484741, val_loss = 0.796865701675415\n",
      "epoch n°2439 : train_loss = 2.076975107192993, val_loss = 0.7941325306892395\n",
      "epoch n°2440 : train_loss = 2.0719478130340576, val_loss = 0.7940926551818848\n",
      "epoch n°2441 : train_loss = 2.0686848163604736, val_loss = 0.7998090982437134\n",
      "epoch n°2442 : train_loss = 2.0724384784698486, val_loss = 0.7958014607429504\n",
      "epoch n°2443 : train_loss = 2.0715744495391846, val_loss = 0.7992317080497742\n",
      "epoch n°2444 : train_loss = 2.07312273979187, val_loss = 0.7948455214500427\n",
      "epoch n°2445 : train_loss = 2.0812177658081055, val_loss = 0.797282874584198\n",
      "epoch n°2446 : train_loss = 2.075092077255249, val_loss = 0.7962594628334045\n",
      "epoch n°2447 : train_loss = 2.0736656188964844, val_loss = 0.7994425892829895\n",
      "epoch n°2448 : train_loss = 2.079349994659424, val_loss = 0.7937913537025452\n",
      "epoch n°2449 : train_loss = 2.0741310119628906, val_loss = 0.7944725751876831\n",
      "epoch n°2450 : train_loss = 2.0697264671325684, val_loss = 0.7935925722122192\n",
      "epoch n°2451 : train_loss = 2.0676352977752686, val_loss = 0.7920997142791748\n",
      "epoch n°2452 : train_loss = 2.078476667404175, val_loss = 0.7986966371536255\n",
      "epoch n°2453 : train_loss = 2.074744701385498, val_loss = 0.7939132452011108\n",
      "epoch n°2454 : train_loss = 2.071045398712158, val_loss = 0.7984747290611267\n",
      "epoch n°2455 : train_loss = 2.076519012451172, val_loss = 0.7961481213569641\n",
      "epoch n°2456 : train_loss = 2.0722813606262207, val_loss = 0.7939823865890503\n",
      "epoch n°2457 : train_loss = 2.0679285526275635, val_loss = 0.7943843603134155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°2458 : train_loss = 2.0761380195617676, val_loss = 0.7924602627754211\n",
      "epoch n°2459 : train_loss = 2.066833019256592, val_loss = 0.7969042658805847\n",
      "epoch n°2460 : train_loss = 2.075873851776123, val_loss = 0.7993742227554321\n",
      "epoch n°2461 : train_loss = 2.079108715057373, val_loss = 0.7976351976394653\n",
      "epoch n°2462 : train_loss = 2.064790725708008, val_loss = 0.7890793681144714\n",
      "epoch n°2463 : train_loss = 2.074547052383423, val_loss = 0.7956620454788208\n",
      "epoch n°2464 : train_loss = 2.0754830837249756, val_loss = 0.794634997844696\n",
      "epoch n°2465 : train_loss = 2.0771164894104004, val_loss = 0.7902213335037231\n",
      "epoch n°2466 : train_loss = 2.08648681640625, val_loss = 0.794048547744751\n",
      "epoch n°2467 : train_loss = 2.0615360736846924, val_loss = 0.7948229908943176\n",
      "epoch n°2468 : train_loss = 2.07049822807312, val_loss = 0.7961206436157227\n",
      "epoch n°2469 : train_loss = 2.0683064460754395, val_loss = 0.7928538918495178\n",
      "epoch n°2470 : train_loss = 2.0835211277008057, val_loss = 0.7931339144706726\n",
      "epoch n°2471 : train_loss = 2.073302745819092, val_loss = 0.7937737107276917\n",
      "epoch n°2472 : train_loss = 2.0775091648101807, val_loss = 0.7998483777046204\n",
      "epoch n°2473 : train_loss = 2.085369825363159, val_loss = 0.7996574640274048\n",
      "epoch n°2474 : train_loss = 2.0606396198272705, val_loss = 0.7968857884407043\n",
      "epoch n°2475 : train_loss = 2.0605850219726562, val_loss = 0.7938559651374817\n",
      "epoch n°2476 : train_loss = 2.071244716644287, val_loss = 0.7948279976844788\n",
      "epoch n°2477 : train_loss = 2.078474521636963, val_loss = 0.7965747117996216\n",
      "epoch n°2478 : train_loss = 2.0774996280670166, val_loss = 0.7957830429077148\n",
      "epoch n°2479 : train_loss = 2.062946319580078, val_loss = 0.7959226369857788\n",
      "epoch n°2480 : train_loss = 2.068220615386963, val_loss = 0.7974685430526733\n",
      "epoch n°2481 : train_loss = 2.069835901260376, val_loss = 0.7976418137550354\n",
      "epoch n°2482 : train_loss = 2.064312696456909, val_loss = 0.7963813543319702\n",
      "epoch n°2483 : train_loss = 2.0784552097320557, val_loss = 0.7927666306495667\n",
      "epoch n°2484 : train_loss = 2.0727269649505615, val_loss = 0.7915945649147034\n",
      "epoch n°2485 : train_loss = 2.0737929344177246, val_loss = 0.7958868741989136\n",
      "epoch n°2486 : train_loss = 2.068535566329956, val_loss = 0.7941672801971436\n",
      "epoch n°2487 : train_loss = 2.0708584785461426, val_loss = 0.7943242788314819\n",
      "epoch n°2488 : train_loss = 2.079688549041748, val_loss = 0.7943374514579773\n",
      "epoch n°2489 : train_loss = 2.079608917236328, val_loss = 0.7949856519699097\n",
      "epoch n°2490 : train_loss = 2.072126865386963, val_loss = 0.7959268689155579\n",
      "epoch n°2491 : train_loss = 2.0665769577026367, val_loss = 0.8031625151634216\n",
      "epoch n°2492 : train_loss = 2.0788745880126953, val_loss = 0.7973943948745728\n",
      "epoch n°2493 : train_loss = 2.0706560611724854, val_loss = 0.7946256995201111\n",
      "epoch n°2494 : train_loss = 2.0708940029144287, val_loss = 0.7915892601013184\n",
      "epoch n°2495 : train_loss = 2.0780534744262695, val_loss = 0.7934134602546692\n",
      "epoch n°2496 : train_loss = 2.067171573638916, val_loss = 0.7966883182525635\n",
      "epoch n°2497 : train_loss = 2.0704174041748047, val_loss = 0.7951463460922241\n",
      "epoch n°2498 : train_loss = 2.0750081539154053, val_loss = 0.7937692403793335\n",
      "epoch n°2499 : train_loss = 2.0717825889587402, val_loss = 0.7950046062469482\n",
      "epoch n°2500 : train_loss = 2.0677881240844727, val_loss = 0.7899929285049438\n",
      "epoch n°2501 : train_loss = 2.0806267261505127, val_loss = 0.7907530069351196\n",
      "epoch n°2502 : train_loss = 2.0809061527252197, val_loss = 0.7952125668525696\n",
      "epoch n°2503 : train_loss = 2.074087142944336, val_loss = 0.7993823289871216\n",
      "epoch n°2504 : train_loss = 2.073647975921631, val_loss = 0.7945746779441833\n",
      "epoch n°2505 : train_loss = 2.0659537315368652, val_loss = 0.7927793264389038\n",
      "epoch n°2506 : train_loss = 2.071669101715088, val_loss = 0.7954444289207458\n",
      "epoch n°2507 : train_loss = 2.0649211406707764, val_loss = 0.7934116721153259\n",
      "epoch n°2508 : train_loss = 2.0707504749298096, val_loss = 0.7935698628425598\n",
      "epoch n°2509 : train_loss = 2.069951057434082, val_loss = 0.7966367602348328\n",
      "epoch n°2510 : train_loss = 2.0733301639556885, val_loss = 0.8028239607810974\n",
      "epoch n°2511 : train_loss = 2.079970121383667, val_loss = 0.796660840511322\n",
      "epoch n°2512 : train_loss = 2.06453013420105, val_loss = 0.7931510806083679\n",
      "epoch n°2513 : train_loss = 2.0746753215789795, val_loss = 0.7952697277069092\n",
      "epoch n°2514 : train_loss = 2.0712246894836426, val_loss = 0.7984182238578796\n",
      "epoch n°2515 : train_loss = 2.071139335632324, val_loss = 0.7950924038887024\n",
      "epoch n°2516 : train_loss = 2.0722832679748535, val_loss = 0.7952603101730347\n",
      "epoch n°2517 : train_loss = 2.0722897052764893, val_loss = 0.7944259643554688\n",
      "epoch n°2518 : train_loss = 2.070683240890503, val_loss = 0.7965999841690063\n",
      "epoch n°2519 : train_loss = 2.0697803497314453, val_loss = 0.7934508323669434\n",
      "epoch n°2520 : train_loss = 2.0682995319366455, val_loss = 0.7979728579521179\n",
      "epoch n°2521 : train_loss = 2.0796399116516113, val_loss = 0.793859601020813\n",
      "epoch n°2522 : train_loss = 2.072935104370117, val_loss = 0.7950705289840698\n",
      "epoch n°2523 : train_loss = 2.0659868717193604, val_loss = 0.792586624622345\n",
      "epoch n°2524 : train_loss = 2.0719454288482666, val_loss = 0.7926358580589294\n",
      "epoch n°2525 : train_loss = 2.0776469707489014, val_loss = 0.7946190237998962\n",
      "epoch n°2526 : train_loss = 2.0704853534698486, val_loss = 0.7968124151229858\n",
      "epoch n°2527 : train_loss = 2.0710489749908447, val_loss = 0.7920627593994141\n",
      "epoch n°2528 : train_loss = 2.075761079788208, val_loss = 0.799395740032196\n",
      "epoch n°2529 : train_loss = 2.077773094177246, val_loss = 0.7925973534584045\n",
      "epoch n°2530 : train_loss = 2.0728776454925537, val_loss = 0.7944552302360535\n",
      "epoch n°2531 : train_loss = 2.067211627960205, val_loss = 0.7973270416259766\n",
      "epoch n°2532 : train_loss = 2.066573143005371, val_loss = 0.7902677059173584\n",
      "epoch n°2533 : train_loss = 2.06182861328125, val_loss = 0.7934569120407104\n",
      "epoch n°2534 : train_loss = 2.0673630237579346, val_loss = 0.7988802194595337\n",
      "epoch n°2535 : train_loss = 2.0721588134765625, val_loss = 0.7967263460159302\n",
      "epoch n°2536 : train_loss = 2.072066068649292, val_loss = 0.7931755781173706\n",
      "epoch n°2537 : train_loss = 2.07137393951416, val_loss = 0.7977719306945801\n",
      "epoch n°2538 : train_loss = 2.0700523853302, val_loss = 0.7933252453804016\n",
      "epoch n°2539 : train_loss = 2.0830204486846924, val_loss = 0.792039692401886\n",
      "epoch n°2540 : train_loss = 2.067403554916382, val_loss = 0.799730122089386\n",
      "epoch n°2541 : train_loss = 2.0732693672180176, val_loss = 0.7934302091598511\n",
      "epoch n°2542 : train_loss = 2.0704286098480225, val_loss = 0.7961665391921997\n",
      "epoch n°2543 : train_loss = 2.0719985961914062, val_loss = 0.7898352742195129\n",
      "epoch n°2544 : train_loss = 2.072603464126587, val_loss = 0.7962201237678528\n",
      "epoch n°2545 : train_loss = 2.0690665245056152, val_loss = 0.798147439956665\n",
      "epoch n°2546 : train_loss = 2.0629847049713135, val_loss = 0.7960135340690613\n",
      "epoch n°2547 : train_loss = 2.070220470428467, val_loss = 0.7944188117980957\n",
      "epoch n°2548 : train_loss = 2.0639808177948, val_loss = 0.7961269021034241\n",
      "epoch n°2549 : train_loss = 2.0713534355163574, val_loss = 0.7939749360084534\n",
      "epoch n°2550 : train_loss = 2.070063352584839, val_loss = 0.7959186434745789\n",
      "epoch n°2551 : train_loss = 2.0646650791168213, val_loss = 0.7945561408996582\n",
      "epoch n°2552 : train_loss = 2.0712499618530273, val_loss = 0.7947783470153809\n",
      "epoch n°2553 : train_loss = 2.076829433441162, val_loss = 0.7918115854263306\n",
      "epoch n°2554 : train_loss = 2.0699639320373535, val_loss = 0.7921602129936218\n",
      "epoch n°2555 : train_loss = 2.0639450550079346, val_loss = 0.7922937870025635\n",
      "epoch n°2556 : train_loss = 2.0647506713867188, val_loss = 0.793573796749115\n",
      "epoch n°2557 : train_loss = 2.069046974182129, val_loss = 0.7939483523368835\n",
      "epoch n°2558 : train_loss = 2.078779697418213, val_loss = 0.7918152809143066\n",
      "epoch n°2559 : train_loss = 2.0625898838043213, val_loss = 0.7951764464378357\n",
      "epoch n°2560 : train_loss = 2.063420534133911, val_loss = 0.7964991331100464\n",
      "epoch n°2561 : train_loss = 2.0686404705047607, val_loss = 0.7932979464530945\n",
      "epoch n°2562 : train_loss = 2.0660288333892822, val_loss = 0.7920316457748413\n",
      "epoch n°2563 : train_loss = 2.068803310394287, val_loss = 0.7993542551994324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°2564 : train_loss = 2.080104351043701, val_loss = 0.7970274090766907\n",
      "epoch n°2565 : train_loss = 2.0702080726623535, val_loss = 0.7948424220085144\n",
      "epoch n°2566 : train_loss = 2.0659167766571045, val_loss = 0.7979874014854431\n",
      "epoch n°2567 : train_loss = 2.06240177154541, val_loss = 0.7958927154541016\n",
      "epoch n°2568 : train_loss = 2.066502332687378, val_loss = 0.7954502105712891\n",
      "epoch n°2569 : train_loss = 2.0689918994903564, val_loss = 0.7977456450462341\n",
      "epoch n°2570 : train_loss = 2.0666213035583496, val_loss = 0.7955062389373779\n",
      "epoch n°2571 : train_loss = 2.069141149520874, val_loss = 0.7962725162506104\n",
      "epoch n°2572 : train_loss = 2.063840627670288, val_loss = 0.7952845096588135\n",
      "epoch n°2573 : train_loss = 2.074042320251465, val_loss = 0.7944539785385132\n",
      "epoch n°2574 : train_loss = 2.068006992340088, val_loss = 0.7906416058540344\n",
      "epoch n°2575 : train_loss = 2.067474603652954, val_loss = 0.7915813326835632\n",
      "epoch n°2576 : train_loss = 2.0699462890625, val_loss = 0.7938066720962524\n",
      "epoch n°2577 : train_loss = 2.068861246109009, val_loss = 0.7968428730964661\n",
      "epoch n°2578 : train_loss = 2.0680978298187256, val_loss = 0.7948395609855652\n",
      "epoch n°2579 : train_loss = 2.071681022644043, val_loss = 0.7964827418327332\n",
      "epoch n°2580 : train_loss = 2.069338321685791, val_loss = 0.7934671640396118\n",
      "epoch n°2581 : train_loss = 2.0629146099090576, val_loss = 0.7926071286201477\n",
      "epoch n°2582 : train_loss = 2.066930055618286, val_loss = 0.7925218939781189\n",
      "epoch n°2583 : train_loss = 2.0675506591796875, val_loss = 0.7950162887573242\n",
      "epoch n°2584 : train_loss = 2.0658023357391357, val_loss = 0.792223334312439\n",
      "epoch n°2585 : train_loss = 2.0704879760742188, val_loss = 0.7982180714607239\n",
      "epoch n°2586 : train_loss = 2.0734715461730957, val_loss = 0.7954774498939514\n",
      "epoch n°2587 : train_loss = 2.071254014968872, val_loss = 0.7940913438796997\n",
      "epoch n°2588 : train_loss = 2.065054416656494, val_loss = 0.7965905666351318\n",
      "epoch n°2589 : train_loss = 2.067905902862549, val_loss = 0.7973387837409973\n",
      "epoch n°2590 : train_loss = 2.0755982398986816, val_loss = 0.795183539390564\n",
      "epoch n°2591 : train_loss = 2.0668108463287354, val_loss = 0.7934271693229675\n",
      "epoch n°2592 : train_loss = 2.070019483566284, val_loss = 0.8009438514709473\n",
      "epoch n°2593 : train_loss = 2.0616700649261475, val_loss = 0.792378306388855\n",
      "epoch n°2594 : train_loss = 2.070371627807617, val_loss = 0.7962102890014648\n",
      "epoch n°2595 : train_loss = 2.0655572414398193, val_loss = 0.7970673441886902\n",
      "epoch n°2596 : train_loss = 2.0680465698242188, val_loss = 0.7974614500999451\n",
      "epoch n°2597 : train_loss = 2.0665860176086426, val_loss = 0.7950116395950317\n",
      "epoch n°2598 : train_loss = 2.062771797180176, val_loss = 0.7925916314125061\n",
      "epoch n°2599 : train_loss = 2.0683224201202393, val_loss = 0.7937383055686951\n",
      "epoch n°2600 : train_loss = 2.0698482990264893, val_loss = 0.7975207567214966\n",
      "epoch n°2601 : train_loss = 2.060471296310425, val_loss = 0.7909286618232727\n",
      "epoch n°2602 : train_loss = 2.0688061714172363, val_loss = 0.7975974082946777\n",
      "epoch n°2603 : train_loss = 2.0683090686798096, val_loss = 0.7947460412979126\n",
      "epoch n°2604 : train_loss = 2.063673734664917, val_loss = 0.7962013483047485\n",
      "epoch n°2605 : train_loss = 2.0722908973693848, val_loss = 0.7903602123260498\n",
      "epoch n°2606 : train_loss = 2.069873571395874, val_loss = 0.8008821606636047\n",
      "epoch n°2607 : train_loss = 2.0729966163635254, val_loss = 0.7964413166046143\n",
      "epoch n°2608 : train_loss = 2.066875696182251, val_loss = 0.7899331450462341\n",
      "epoch n°2609 : train_loss = 2.0690667629241943, val_loss = 0.7934623956680298\n",
      "epoch n°2610 : train_loss = 2.0641403198242188, val_loss = 0.7939741015434265\n",
      "epoch n°2611 : train_loss = 2.0747296810150146, val_loss = 0.7932539582252502\n",
      "epoch n°2612 : train_loss = 2.068613290786743, val_loss = 0.7910030484199524\n",
      "epoch n°2613 : train_loss = 2.0571677684783936, val_loss = 0.797441303730011\n",
      "epoch n°2614 : train_loss = 2.058534860610962, val_loss = 0.7960272431373596\n",
      "epoch n°2615 : train_loss = 2.068410873413086, val_loss = 0.7920282483100891\n",
      "epoch n°2616 : train_loss = 2.0600147247314453, val_loss = 0.7983390688896179\n",
      "epoch n°2617 : train_loss = 2.0677337646484375, val_loss = 0.7956530451774597\n",
      "epoch n°2618 : train_loss = 2.0687453746795654, val_loss = 0.7955602407455444\n",
      "epoch n°2619 : train_loss = 2.0727672576904297, val_loss = 0.793998122215271\n",
      "epoch n°2620 : train_loss = 2.070995330810547, val_loss = 0.7972820401191711\n",
      "epoch n°2621 : train_loss = 2.075937032699585, val_loss = 0.7941849827766418\n",
      "epoch n°2622 : train_loss = 2.064786672592163, val_loss = 0.7972815036773682\n",
      "epoch n°2623 : train_loss = 2.0686159133911133, val_loss = 0.7907751798629761\n",
      "epoch n°2624 : train_loss = 2.066404104232788, val_loss = 0.7950287461280823\n",
      "epoch n°2625 : train_loss = 2.075263261795044, val_loss = 0.7924023866653442\n",
      "epoch n°2626 : train_loss = 2.0691094398498535, val_loss = 0.7938724756240845\n",
      "epoch n°2627 : train_loss = 2.0583581924438477, val_loss = 0.7974418997764587\n",
      "epoch n°2628 : train_loss = 2.0624241828918457, val_loss = 0.7923166155815125\n",
      "epoch n°2629 : train_loss = 2.066328763961792, val_loss = 0.7964351773262024\n",
      "epoch n°2630 : train_loss = 2.0584781169891357, val_loss = 0.7954878807067871\n",
      "epoch n°2631 : train_loss = 2.065559148788452, val_loss = 0.7972267270088196\n",
      "epoch n°2632 : train_loss = 2.0663211345672607, val_loss = 0.7889178991317749\n",
      "epoch n°2633 : train_loss = 2.0653247833251953, val_loss = 0.7981230020523071\n",
      "epoch n°2634 : train_loss = 2.0744612216949463, val_loss = 0.7940593361854553\n",
      "epoch n°2635 : train_loss = 2.0545928478240967, val_loss = 0.7900643944740295\n",
      "epoch n°2636 : train_loss = 2.058732032775879, val_loss = 0.7934366464614868\n",
      "epoch n°2637 : train_loss = 2.0636942386627197, val_loss = 0.7961517572402954\n",
      "epoch n°2638 : train_loss = 2.0692808628082275, val_loss = 0.7932850122451782\n",
      "epoch n°2639 : train_loss = 2.0692622661590576, val_loss = 0.794786274433136\n",
      "epoch n°2640 : train_loss = 2.0633139610290527, val_loss = 0.7928884625434875\n",
      "epoch n°2641 : train_loss = 2.0717575550079346, val_loss = 0.7925474047660828\n",
      "epoch n°2642 : train_loss = 2.0547585487365723, val_loss = 0.7922614216804504\n",
      "epoch n°2643 : train_loss = 2.064246416091919, val_loss = 0.7978510856628418\n",
      "epoch n°2644 : train_loss = 2.0668554306030273, val_loss = 0.799415111541748\n",
      "epoch n°2645 : train_loss = 2.0642337799072266, val_loss = 0.8008957505226135\n",
      "epoch n°2646 : train_loss = 2.0587220191955566, val_loss = 0.7956776022911072\n",
      "epoch n°2647 : train_loss = 2.066415786743164, val_loss = 0.7957999110221863\n",
      "epoch n°2648 : train_loss = 2.068911552429199, val_loss = 0.7957978248596191\n",
      "epoch n°2649 : train_loss = 2.0653622150421143, val_loss = 0.7938576936721802\n",
      "epoch n°2650 : train_loss = 2.067007541656494, val_loss = 0.7966272830963135\n",
      "epoch n°2651 : train_loss = 2.0586371421813965, val_loss = 0.7935423851013184\n",
      "epoch n°2652 : train_loss = 2.055204153060913, val_loss = 0.7929962277412415\n",
      "epoch n°2653 : train_loss = 2.0663504600524902, val_loss = 0.7949020862579346\n",
      "epoch n°2654 : train_loss = 2.075329303741455, val_loss = 0.7978811860084534\n",
      "epoch n°2655 : train_loss = 2.0609302520751953, val_loss = 0.7954696416854858\n",
      "epoch n°2656 : train_loss = 2.0616674423217773, val_loss = 0.7915216684341431\n",
      "epoch n°2657 : train_loss = 2.066195249557495, val_loss = 0.7954301238059998\n",
      "epoch n°2658 : train_loss = 2.0645275115966797, val_loss = 0.7939314246177673\n",
      "epoch n°2659 : train_loss = 2.065096855163574, val_loss = 0.7937576770782471\n",
      "epoch n°2660 : train_loss = 2.064636707305908, val_loss = 0.79324871301651\n",
      "epoch n°2661 : train_loss = 2.0576233863830566, val_loss = 0.7912139296531677\n",
      "epoch n°2662 : train_loss = 2.0628271102905273, val_loss = 0.7961941957473755\n",
      "epoch n°2663 : train_loss = 2.0619640350341797, val_loss = 0.7955071926116943\n",
      "epoch n°2664 : train_loss = 2.0607292652130127, val_loss = 0.7949918508529663\n",
      "epoch n°2665 : train_loss = 2.063640832901001, val_loss = 0.7948024272918701\n",
      "epoch n°2666 : train_loss = 2.0648748874664307, val_loss = 0.7927020192146301\n",
      "epoch n°2667 : train_loss = 2.070728302001953, val_loss = 0.7967328429222107\n",
      "epoch n°2668 : train_loss = 2.064157724380493, val_loss = 0.7993665933609009\n",
      "epoch n°2669 : train_loss = 2.0569305419921875, val_loss = 0.7935890555381775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°2670 : train_loss = 2.0649633407592773, val_loss = 0.7933745384216309\n",
      "epoch n°2671 : train_loss = 2.066453695297241, val_loss = 0.797985851764679\n",
      "epoch n°2672 : train_loss = 2.0578935146331787, val_loss = 0.7947227954864502\n",
      "epoch n°2673 : train_loss = 2.064446210861206, val_loss = 0.8007156252861023\n",
      "epoch n°2674 : train_loss = 2.066132068634033, val_loss = 0.7959911227226257\n",
      "epoch n°2675 : train_loss = 2.0668256282806396, val_loss = 0.7964301109313965\n",
      "epoch n°2676 : train_loss = 2.0652828216552734, val_loss = 0.7916955947875977\n",
      "epoch n°2677 : train_loss = 2.064474105834961, val_loss = 0.7902123928070068\n",
      "epoch n°2678 : train_loss = 2.0657882690429688, val_loss = 0.795642077922821\n",
      "epoch n°2679 : train_loss = 2.0729804039001465, val_loss = 0.7931274175643921\n",
      "epoch n°2680 : train_loss = 2.0576000213623047, val_loss = 0.7980756163597107\n",
      "epoch n°2681 : train_loss = 2.0635111331939697, val_loss = 0.7944830656051636\n",
      "epoch n°2682 : train_loss = 2.0695137977600098, val_loss = 0.7931466698646545\n",
      "epoch n°2683 : train_loss = 2.0662333965301514, val_loss = 0.7971284985542297\n",
      "epoch n°2684 : train_loss = 2.0616705417633057, val_loss = 0.80098557472229\n",
      "epoch n°2685 : train_loss = 2.0681896209716797, val_loss = 0.7933892011642456\n",
      "epoch n°2686 : train_loss = 2.064844846725464, val_loss = 0.7960370779037476\n",
      "epoch n°2687 : train_loss = 2.0661814212799072, val_loss = 0.7935758829116821\n",
      "epoch n°2688 : train_loss = 2.0690243244171143, val_loss = 0.7936882972717285\n",
      "epoch n°2689 : train_loss = 2.0596323013305664, val_loss = 0.7959572672843933\n",
      "epoch n°2690 : train_loss = 2.070370674133301, val_loss = 0.7948954105377197\n",
      "epoch n°2691 : train_loss = 2.0577001571655273, val_loss = 0.7959688305854797\n",
      "epoch n°2692 : train_loss = 2.059105396270752, val_loss = 0.7938446998596191\n",
      "epoch n°2693 : train_loss = 2.057089328765869, val_loss = 0.7914276719093323\n",
      "epoch n°2694 : train_loss = 2.0688581466674805, val_loss = 0.7983455061912537\n",
      "epoch n°2695 : train_loss = 2.0667736530303955, val_loss = 0.7987625002861023\n",
      "epoch n°2696 : train_loss = 2.0622012615203857, val_loss = 0.7962139248847961\n",
      "epoch n°2697 : train_loss = 2.069007158279419, val_loss = 0.7958037853240967\n",
      "epoch n°2698 : train_loss = 2.0585219860076904, val_loss = 0.7942733764648438\n",
      "epoch n°2699 : train_loss = 2.06402850151062, val_loss = 0.7946842908859253\n",
      "epoch n°2700 : train_loss = 2.0651679039001465, val_loss = 0.7952705025672913\n",
      "epoch n°2701 : train_loss = 2.063640832901001, val_loss = 0.7961812615394592\n",
      "epoch n°2702 : train_loss = 2.0613393783569336, val_loss = 0.7936129570007324\n",
      "epoch n°2703 : train_loss = 2.0569653511047363, val_loss = 0.7960566282272339\n",
      "epoch n°2704 : train_loss = 2.064002275466919, val_loss = 0.7910369038581848\n",
      "epoch n°2705 : train_loss = 2.0708813667297363, val_loss = 0.7938269972801208\n",
      "epoch n°2706 : train_loss = 2.0635323524475098, val_loss = 0.7906851172447205\n",
      "epoch n°2707 : train_loss = 2.057649612426758, val_loss = 0.795624315738678\n",
      "epoch n°2708 : train_loss = 2.067439317703247, val_loss = 0.7943922877311707\n",
      "epoch n°2709 : train_loss = 2.069272518157959, val_loss = 0.7915805578231812\n",
      "epoch n°2710 : train_loss = 2.0710272789001465, val_loss = 0.7952094674110413\n",
      "epoch n°2711 : train_loss = 2.065606117248535, val_loss = 0.7940643429756165\n",
      "epoch n°2712 : train_loss = 2.0638530254364014, val_loss = 0.7907646298408508\n",
      "epoch n°2713 : train_loss = 2.0592706203460693, val_loss = 0.7966247797012329\n",
      "epoch n°2714 : train_loss = 2.062748670578003, val_loss = 0.7964047789573669\n",
      "epoch n°2715 : train_loss = 2.0622029304504395, val_loss = 0.796676516532898\n",
      "epoch n°2716 : train_loss = 2.063385248184204, val_loss = 0.793315589427948\n",
      "epoch n°2717 : train_loss = 2.065591812133789, val_loss = 0.7968663573265076\n",
      "epoch n°2718 : train_loss = 2.060936689376831, val_loss = 0.797130286693573\n",
      "epoch n°2719 : train_loss = 2.0669655799865723, val_loss = 0.7934433221817017\n",
      "epoch n°2720 : train_loss = 2.0525898933410645, val_loss = 0.7911237478256226\n",
      "epoch n°2721 : train_loss = 2.051745891571045, val_loss = 0.7983365654945374\n",
      "epoch n°2722 : train_loss = 2.0590803623199463, val_loss = 0.7948223948478699\n",
      "epoch n°2723 : train_loss = 2.0640816688537598, val_loss = 0.7899811863899231\n",
      "epoch n°2724 : train_loss = 2.0638225078582764, val_loss = 0.7940797805786133\n",
      "epoch n°2725 : train_loss = 2.0654401779174805, val_loss = 0.7963559627532959\n",
      "epoch n°2726 : train_loss = 2.06316876411438, val_loss = 0.7925108671188354\n",
      "epoch n°2727 : train_loss = 2.0640313625335693, val_loss = 0.7933432459831238\n",
      "epoch n°2728 : train_loss = 2.0653250217437744, val_loss = 0.7909542918205261\n",
      "epoch n°2729 : train_loss = 2.060622215270996, val_loss = 0.7956382632255554\n",
      "epoch n°2730 : train_loss = 2.0592989921569824, val_loss = 0.7943462133407593\n",
      "epoch n°2731 : train_loss = 2.070988655090332, val_loss = 0.7923506498336792\n",
      "epoch n°2732 : train_loss = 2.0650033950805664, val_loss = 0.7966691255569458\n",
      "epoch n°2733 : train_loss = 2.056736946105957, val_loss = 0.7910388708114624\n",
      "epoch n°2734 : train_loss = 2.0525736808776855, val_loss = 0.7958134412765503\n",
      "epoch n°2735 : train_loss = 2.052873134613037, val_loss = 0.794795572757721\n",
      "epoch n°2736 : train_loss = 2.061112642288208, val_loss = 0.7926158308982849\n",
      "epoch n°2737 : train_loss = 2.0561344623565674, val_loss = 0.7973163723945618\n",
      "epoch n°2738 : train_loss = 2.0660910606384277, val_loss = 0.7921602129936218\n",
      "epoch n°2739 : train_loss = 2.0696091651916504, val_loss = 0.7921521067619324\n",
      "epoch n°2740 : train_loss = 2.0580923557281494, val_loss = 0.796059250831604\n",
      "epoch n°2741 : train_loss = 2.0668959617614746, val_loss = 0.7949392199516296\n",
      "epoch n°2742 : train_loss = 2.058520555496216, val_loss = 0.7895145416259766\n",
      "epoch n°2743 : train_loss = 2.0512428283691406, val_loss = 0.7939713597297668\n",
      "epoch n°2744 : train_loss = 2.0556869506835938, val_loss = 0.7939925193786621\n",
      "epoch n°2745 : train_loss = 2.05964732170105, val_loss = 0.7978878617286682\n",
      "epoch n°2746 : train_loss = 2.075089693069458, val_loss = 0.7961307168006897\n",
      "epoch n°2747 : train_loss = 2.0637478828430176, val_loss = 0.7951133847236633\n",
      "epoch n°2748 : train_loss = 2.0630457401275635, val_loss = 0.793494701385498\n",
      "epoch n°2749 : train_loss = 2.0580689907073975, val_loss = 0.7955312132835388\n",
      "epoch n°2750 : train_loss = 2.0668022632598877, val_loss = 0.7951896786689758\n",
      "epoch n°2751 : train_loss = 2.0649197101593018, val_loss = 0.7965624928474426\n",
      "epoch n°2752 : train_loss = 2.051708221435547, val_loss = 0.7960389256477356\n",
      "epoch n°2753 : train_loss = 2.0488626956939697, val_loss = 0.7916060090065002\n",
      "epoch n°2754 : train_loss = 2.063692092895508, val_loss = 0.7944266200065613\n",
      "epoch n°2755 : train_loss = 2.059985876083374, val_loss = 0.7953632473945618\n",
      "epoch n°2756 : train_loss = 2.057037591934204, val_loss = 0.7957295775413513\n",
      "epoch n°2757 : train_loss = 2.0550622940063477, val_loss = 0.7945528626441956\n",
      "epoch n°2758 : train_loss = 2.072350025177002, val_loss = 0.79572993516922\n",
      "epoch n°2759 : train_loss = 2.05426287651062, val_loss = 0.7936633825302124\n",
      "epoch n°2760 : train_loss = 2.049983263015747, val_loss = 0.7921715974807739\n",
      "epoch n°2761 : train_loss = 2.0654444694519043, val_loss = 0.7929051518440247\n",
      "epoch n°2762 : train_loss = 2.0562796592712402, val_loss = 0.7942419052124023\n",
      "epoch n°2763 : train_loss = 2.0620017051696777, val_loss = 0.7973794937133789\n",
      "epoch n°2764 : train_loss = 2.0616655349731445, val_loss = 0.7949119210243225\n",
      "epoch n°2765 : train_loss = 2.0633978843688965, val_loss = 0.7939687371253967\n",
      "epoch n°2766 : train_loss = 2.060305118560791, val_loss = 0.7916428446769714\n",
      "epoch n°2767 : train_loss = 2.0530765056610107, val_loss = 0.7957174777984619\n",
      "epoch n°2768 : train_loss = 2.0591583251953125, val_loss = 0.7955144047737122\n",
      "epoch n°2769 : train_loss = 2.05259108543396, val_loss = 0.795064389705658\n",
      "epoch n°2770 : train_loss = 2.0623559951782227, val_loss = 0.794768214225769\n",
      "epoch n°2771 : train_loss = 2.048663377761841, val_loss = 0.7952104210853577\n",
      "epoch n°2772 : train_loss = 2.0568857192993164, val_loss = 0.7908285856246948\n",
      "epoch n°2773 : train_loss = 2.0588109493255615, val_loss = 0.7912997007369995\n",
      "epoch n°2774 : train_loss = 2.0629494190216064, val_loss = 0.796447217464447\n",
      "epoch n°2775 : train_loss = 2.0542733669281006, val_loss = 0.7927641868591309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°2776 : train_loss = 2.061394214630127, val_loss = 0.7932475805282593\n",
      "epoch n°2777 : train_loss = 2.0600383281707764, val_loss = 0.7960668206214905\n",
      "epoch n°2778 : train_loss = 2.052992343902588, val_loss = 0.7963016033172607\n",
      "epoch n°2779 : train_loss = 2.060129404067993, val_loss = 0.7997118234634399\n",
      "epoch n°2780 : train_loss = 2.062008857727051, val_loss = 0.7913984060287476\n",
      "epoch n°2781 : train_loss = 2.0568935871124268, val_loss = 0.7923591136932373\n",
      "epoch n°2782 : train_loss = 2.0638515949249268, val_loss = 0.7959922552108765\n",
      "epoch n°2783 : train_loss = 2.0645594596862793, val_loss = 0.7981419563293457\n",
      "epoch n°2784 : train_loss = 2.05869197845459, val_loss = 0.7935437560081482\n",
      "epoch n°2785 : train_loss = 2.060377597808838, val_loss = 0.7947568297386169\n",
      "epoch n°2786 : train_loss = 2.055619955062866, val_loss = 0.7974889874458313\n",
      "epoch n°2787 : train_loss = 2.0567567348480225, val_loss = 0.7929900288581848\n",
      "epoch n°2788 : train_loss = 2.057819128036499, val_loss = 0.7917365431785583\n",
      "epoch n°2789 : train_loss = 2.0551087856292725, val_loss = 0.7977901101112366\n",
      "epoch n°2790 : train_loss = 2.0580546855926514, val_loss = 0.7957825064659119\n",
      "epoch n°2791 : train_loss = 2.056382894515991, val_loss = 0.7939503788948059\n",
      "epoch n°2792 : train_loss = 2.0602774620056152, val_loss = 0.7930768132209778\n",
      "epoch n°2793 : train_loss = 2.0506889820098877, val_loss = 0.7979701161384583\n",
      "epoch n°2794 : train_loss = 2.062954902648926, val_loss = 0.7974141836166382\n",
      "epoch n°2795 : train_loss = 2.0475552082061768, val_loss = 0.7964540123939514\n",
      "epoch n°2796 : train_loss = 2.065804958343506, val_loss = 0.7946353554725647\n",
      "epoch n°2797 : train_loss = 2.0619442462921143, val_loss = 0.796964704990387\n",
      "epoch n°2798 : train_loss = 2.0518269538879395, val_loss = 0.7968041300773621\n",
      "epoch n°2799 : train_loss = 2.05976939201355, val_loss = 0.797179102897644\n",
      "epoch n°2800 : train_loss = 2.0688111782073975, val_loss = 0.7965231537818909\n",
      "epoch n°2801 : train_loss = 2.054194450378418, val_loss = 0.794514000415802\n",
      "epoch n°2802 : train_loss = 2.0549983978271484, val_loss = 0.7922817468643188\n",
      "epoch n°2803 : train_loss = 2.0546908378601074, val_loss = 0.7927423715591431\n",
      "epoch n°2804 : train_loss = 2.056227207183838, val_loss = 0.7912007570266724\n",
      "epoch n°2805 : train_loss = 2.057312488555908, val_loss = 0.795678973197937\n",
      "epoch n°2806 : train_loss = 2.0637881755828857, val_loss = 0.7972471117973328\n",
      "epoch n°2807 : train_loss = 2.0602660179138184, val_loss = 0.7988063097000122\n",
      "epoch n°2808 : train_loss = 2.0616602897644043, val_loss = 0.7972728610038757\n",
      "epoch n°2809 : train_loss = 2.055941104888916, val_loss = 0.7973856925964355\n",
      "epoch n°2810 : train_loss = 2.058361053466797, val_loss = 0.7948424816131592\n",
      "epoch n°2811 : train_loss = 2.059833288192749, val_loss = 0.7954361438751221\n",
      "epoch n°2812 : train_loss = 2.0474188327789307, val_loss = 0.7932897806167603\n",
      "epoch n°2813 : train_loss = 2.0500552654266357, val_loss = 0.7941966652870178\n",
      "epoch n°2814 : train_loss = 2.05295467376709, val_loss = 0.7963860034942627\n",
      "epoch n°2815 : train_loss = 2.0539391040802, val_loss = 0.7944226861000061\n",
      "epoch n°2816 : train_loss = 2.0601963996887207, val_loss = 0.7941316962242126\n",
      "epoch n°2817 : train_loss = 2.059865713119507, val_loss = 0.790388286113739\n",
      "epoch n°2818 : train_loss = 2.0638864040374756, val_loss = 0.798162043094635\n",
      "epoch n°2819 : train_loss = 2.0613255500793457, val_loss = 0.7922013401985168\n",
      "epoch n°2820 : train_loss = 2.0616114139556885, val_loss = 0.7942560315132141\n",
      "epoch n°2821 : train_loss = 2.066396951675415, val_loss = 0.79261314868927\n",
      "epoch n°2822 : train_loss = 2.0641872882843018, val_loss = 0.7954858541488647\n",
      "epoch n°2823 : train_loss = 2.059830904006958, val_loss = 0.7961984276771545\n",
      "epoch n°2824 : train_loss = 2.062880277633667, val_loss = 0.7958473563194275\n",
      "epoch n°2825 : train_loss = 2.0501182079315186, val_loss = 0.7935906052589417\n",
      "epoch n°2826 : train_loss = 2.061666250228882, val_loss = 0.7945297956466675\n",
      "epoch n°2827 : train_loss = 2.05903959274292, val_loss = 0.7927860617637634\n",
      "epoch n°2828 : train_loss = 2.0621044635772705, val_loss = 0.7932724356651306\n",
      "epoch n°2829 : train_loss = 2.0605709552764893, val_loss = 0.7940237522125244\n",
      "epoch n°2830 : train_loss = 2.0495433807373047, val_loss = 0.7923583388328552\n",
      "epoch n°2831 : train_loss = 2.056504249572754, val_loss = 0.7943838834762573\n",
      "epoch n°2832 : train_loss = 2.0602564811706543, val_loss = 0.7950447201728821\n",
      "epoch n°2833 : train_loss = 2.0526845455169678, val_loss = 0.7933560013771057\n",
      "epoch n°2834 : train_loss = 2.0536928176879883, val_loss = 0.7982088327407837\n",
      "epoch n°2835 : train_loss = 2.050995349884033, val_loss = 0.7931324243545532\n",
      "epoch n°2836 : train_loss = 2.0614309310913086, val_loss = 0.7960903644561768\n",
      "epoch n°2837 : train_loss = 2.0576555728912354, val_loss = 0.7925017476081848\n",
      "epoch n°2838 : train_loss = 2.064931631088257, val_loss = 0.7977858185768127\n",
      "epoch n°2839 : train_loss = 2.0527279376983643, val_loss = 0.8013085722923279\n",
      "epoch n°2840 : train_loss = 2.061380386352539, val_loss = 0.7922731637954712\n",
      "epoch n°2841 : train_loss = 2.057720184326172, val_loss = 0.7922054529190063\n",
      "epoch n°2842 : train_loss = 2.0556833744049072, val_loss = 0.793084442615509\n",
      "epoch n°2843 : train_loss = 2.063225507736206, val_loss = 0.7948479652404785\n",
      "epoch n°2844 : train_loss = 2.059537887573242, val_loss = 0.792309045791626\n",
      "epoch n°2845 : train_loss = 2.0486080646514893, val_loss = 0.7981398701667786\n",
      "epoch n°2846 : train_loss = 2.0614888668060303, val_loss = 0.7954047322273254\n",
      "epoch n°2847 : train_loss = 2.056900978088379, val_loss = 0.7951337695121765\n",
      "epoch n°2848 : train_loss = 2.058328151702881, val_loss = 0.7976723909378052\n",
      "epoch n°2849 : train_loss = 2.057161569595337, val_loss = 0.791255533695221\n",
      "epoch n°2850 : train_loss = 2.045095682144165, val_loss = 0.7947136759757996\n",
      "epoch n°2851 : train_loss = 2.0517876148223877, val_loss = 0.789996325969696\n",
      "epoch n°2852 : train_loss = 2.063929796218872, val_loss = 0.7906715273857117\n",
      "epoch n°2853 : train_loss = 2.060690402984619, val_loss = 0.7940425276756287\n",
      "epoch n°2854 : train_loss = 2.0585618019104004, val_loss = 0.794236958026886\n",
      "epoch n°2855 : train_loss = 2.054511308670044, val_loss = 0.794800877571106\n",
      "epoch n°2856 : train_loss = 2.0593056678771973, val_loss = 0.7988855242729187\n",
      "epoch n°2857 : train_loss = 2.050663948059082, val_loss = 0.793308436870575\n",
      "epoch n°2858 : train_loss = 2.055729389190674, val_loss = 0.7938034534454346\n",
      "epoch n°2859 : train_loss = 2.060579776763916, val_loss = 0.792985737323761\n",
      "epoch n°2860 : train_loss = 2.0517616271972656, val_loss = 0.795382022857666\n",
      "epoch n°2861 : train_loss = 2.0585498809814453, val_loss = 0.794002115726471\n",
      "epoch n°2862 : train_loss = 2.062791585922241, val_loss = 0.7951845526695251\n",
      "epoch n°2863 : train_loss = 2.0473361015319824, val_loss = 0.7866716384887695\n",
      "epoch n°2864 : train_loss = 2.0626494884490967, val_loss = 0.7929229736328125\n",
      "epoch n°2865 : train_loss = 2.059554100036621, val_loss = 0.7984768152236938\n",
      "epoch n°2866 : train_loss = 2.057314157485962, val_loss = 0.7933509945869446\n",
      "epoch n°2867 : train_loss = 2.0511655807495117, val_loss = 0.7912110090255737\n",
      "epoch n°2868 : train_loss = 2.064603567123413, val_loss = 0.79310542345047\n",
      "epoch n°2869 : train_loss = 2.063448667526245, val_loss = 0.7967478036880493\n",
      "epoch n°2870 : train_loss = 2.0514979362487793, val_loss = 0.7915534973144531\n",
      "epoch n°2871 : train_loss = 2.0539016723632812, val_loss = 0.7928811311721802\n",
      "epoch n°2872 : train_loss = 2.0631346702575684, val_loss = 0.7892648577690125\n",
      "epoch n°2873 : train_loss = 2.048707962036133, val_loss = 0.7968244552612305\n",
      "epoch n°2874 : train_loss = 2.0539536476135254, val_loss = 0.8003847002983093\n",
      "epoch n°2875 : train_loss = 2.053297758102417, val_loss = 0.7938156723976135\n",
      "epoch n°2876 : train_loss = 2.0502476692199707, val_loss = 0.7938336730003357\n",
      "epoch n°2877 : train_loss = 2.049889326095581, val_loss = 0.7937405109405518\n",
      "epoch n°2878 : train_loss = 2.0523667335510254, val_loss = 0.7962744832038879\n",
      "epoch n°2879 : train_loss = 2.054208278656006, val_loss = 0.7924004793167114\n",
      "epoch n°2880 : train_loss = 2.0586318969726562, val_loss = 0.7935348153114319\n",
      "epoch n°2881 : train_loss = 2.0523521900177, val_loss = 0.7944469451904297\n",
      "epoch n°2882 : train_loss = 2.0556912422180176, val_loss = 0.7916335463523865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°2883 : train_loss = 2.050869941711426, val_loss = 0.794858455657959\n",
      "epoch n°2884 : train_loss = 2.054370880126953, val_loss = 0.7964816093444824\n",
      "epoch n°2885 : train_loss = 2.0576937198638916, val_loss = 0.7909227609634399\n",
      "epoch n°2886 : train_loss = 2.053743362426758, val_loss = 0.7935798168182373\n",
      "epoch n°2887 : train_loss = 2.056135654449463, val_loss = 0.7964557409286499\n",
      "epoch n°2888 : train_loss = 2.043368101119995, val_loss = 0.7923924326896667\n",
      "epoch n°2889 : train_loss = 2.052386522293091, val_loss = 0.7913411259651184\n",
      "epoch n°2890 : train_loss = 2.049285888671875, val_loss = 0.7951844930648804\n",
      "epoch n°2891 : train_loss = 2.059156656265259, val_loss = 0.7923597693443298\n",
      "epoch n°2892 : train_loss = 2.059976100921631, val_loss = 0.7953454256057739\n",
      "epoch n°2893 : train_loss = 2.0559849739074707, val_loss = 0.7928661108016968\n",
      "epoch n°2894 : train_loss = 2.055562973022461, val_loss = 0.7927262187004089\n",
      "epoch n°2895 : train_loss = 2.0513744354248047, val_loss = 0.7942379713058472\n",
      "epoch n°2896 : train_loss = 2.053246259689331, val_loss = 0.7937363386154175\n",
      "epoch n°2897 : train_loss = 2.0464155673980713, val_loss = 0.7958146929740906\n",
      "epoch n°2898 : train_loss = 2.0558111667633057, val_loss = 0.7910252213478088\n",
      "epoch n°2899 : train_loss = 2.044952154159546, val_loss = 0.7962886691093445\n",
      "epoch n°2900 : train_loss = 2.049614906311035, val_loss = 0.7967682480812073\n",
      "epoch n°2901 : train_loss = 2.0484485626220703, val_loss = 0.7949526906013489\n",
      "epoch n°2902 : train_loss = 2.0625689029693604, val_loss = 0.7952188849449158\n",
      "epoch n°2903 : train_loss = 2.0544395446777344, val_loss = 0.7924900054931641\n",
      "epoch n°2904 : train_loss = 2.042689561843872, val_loss = 0.7986459732055664\n",
      "epoch n°2905 : train_loss = 2.059471607208252, val_loss = 0.7945957779884338\n",
      "epoch n°2906 : train_loss = 2.0503690242767334, val_loss = 0.7961628437042236\n",
      "epoch n°2907 : train_loss = 2.0552780628204346, val_loss = 0.7883089780807495\n",
      "epoch n°2908 : train_loss = 2.0532078742980957, val_loss = 0.7957280278205872\n",
      "epoch n°2909 : train_loss = 2.0529356002807617, val_loss = 0.7933481335639954\n",
      "epoch n°2910 : train_loss = 2.0493438243865967, val_loss = 0.7947615385055542\n",
      "epoch n°2911 : train_loss = 2.0491645336151123, val_loss = 0.7919706702232361\n",
      "epoch n°2912 : train_loss = 2.0509896278381348, val_loss = 0.7948086261749268\n",
      "epoch n°2913 : train_loss = 2.051089286804199, val_loss = 0.7929202914237976\n",
      "epoch n°2914 : train_loss = 2.057434558868408, val_loss = 0.7925264835357666\n",
      "epoch n°2915 : train_loss = 2.0510425567626953, val_loss = 0.7959019541740417\n",
      "epoch n°2916 : train_loss = 2.0609097480773926, val_loss = 0.7952809929847717\n",
      "epoch n°2917 : train_loss = 2.048112154006958, val_loss = 0.7935212254524231\n",
      "epoch n°2918 : train_loss = 2.053248405456543, val_loss = 0.7955208420753479\n",
      "epoch n°2919 : train_loss = 2.055450916290283, val_loss = 0.7949323654174805\n",
      "epoch n°2920 : train_loss = 2.0512630939483643, val_loss = 0.7926584482192993\n",
      "epoch n°2921 : train_loss = 2.059830665588379, val_loss = 0.7982091903686523\n",
      "epoch n°2922 : train_loss = 2.051553249359131, val_loss = 0.7925273776054382\n",
      "epoch n°2923 : train_loss = 2.0514559745788574, val_loss = 0.800667941570282\n",
      "epoch n°2924 : train_loss = 2.0490405559539795, val_loss = 0.7926619052886963\n",
      "epoch n°2925 : train_loss = 2.0500664710998535, val_loss = 0.7913405299186707\n",
      "epoch n°2926 : train_loss = 2.0487210750579834, val_loss = 0.7909801006317139\n",
      "epoch n°2927 : train_loss = 2.0443291664123535, val_loss = 0.7979404926300049\n",
      "epoch n°2928 : train_loss = 2.0492630004882812, val_loss = 0.800547182559967\n",
      "epoch n°2929 : train_loss = 2.0442683696746826, val_loss = 0.7903225421905518\n",
      "epoch n°2930 : train_loss = 2.051848888397217, val_loss = 0.792193591594696\n",
      "epoch n°2931 : train_loss = 2.0483758449554443, val_loss = 0.7923598885536194\n",
      "epoch n°2932 : train_loss = 2.044297695159912, val_loss = 0.7921621203422546\n",
      "epoch n°2933 : train_loss = 2.050837516784668, val_loss = 0.7940024137496948\n",
      "epoch n°2934 : train_loss = 2.052851915359497, val_loss = 0.7955678105354309\n",
      "epoch n°2935 : train_loss = 2.053326368331909, val_loss = 0.7928493022918701\n",
      "epoch n°2936 : train_loss = 2.054865837097168, val_loss = 0.7939619421958923\n",
      "epoch n°2937 : train_loss = 2.0468223094940186, val_loss = 0.7946463227272034\n",
      "epoch n°2938 : train_loss = 2.0484063625335693, val_loss = 0.7957859635353088\n",
      "epoch n°2939 : train_loss = 2.0617635250091553, val_loss = 0.7956754565238953\n",
      "epoch n°2940 : train_loss = 2.056952476501465, val_loss = 0.7944057583808899\n",
      "epoch n°2941 : train_loss = 2.0497543811798096, val_loss = 0.7940220236778259\n",
      "epoch n°2942 : train_loss = 2.0598535537719727, val_loss = 0.7884097099304199\n",
      "epoch n°2943 : train_loss = 2.050072193145752, val_loss = 0.7942661643028259\n",
      "epoch n°2944 : train_loss = 2.0456621646881104, val_loss = 0.7936067581176758\n",
      "epoch n°2945 : train_loss = 2.045539140701294, val_loss = 0.7923793196678162\n",
      "epoch n°2946 : train_loss = 2.0573956966400146, val_loss = 0.7953813672065735\n",
      "epoch n°2947 : train_loss = 2.0471601486206055, val_loss = 0.7926125526428223\n",
      "epoch n°2948 : train_loss = 2.0470633506774902, val_loss = 0.7959399819374084\n",
      "epoch n°2949 : train_loss = 2.057828664779663, val_loss = 0.7979599237442017\n",
      "epoch n°2950 : train_loss = 2.0491597652435303, val_loss = 0.7926377058029175\n",
      "epoch n°2951 : train_loss = 2.0554869174957275, val_loss = 0.7976028919219971\n",
      "epoch n°2952 : train_loss = 2.045518636703491, val_loss = 0.7929506897926331\n",
      "epoch n°2953 : train_loss = 2.061290740966797, val_loss = 0.7973815202713013\n",
      "epoch n°2954 : train_loss = 2.0460078716278076, val_loss = 0.7934305667877197\n",
      "epoch n°2955 : train_loss = 2.0558764934539795, val_loss = 0.7942355275154114\n",
      "epoch n°2956 : train_loss = 2.04838490486145, val_loss = 0.7939550280570984\n",
      "epoch n°2957 : train_loss = 2.0498878955841064, val_loss = 0.7959154844284058\n",
      "epoch n°2958 : train_loss = 2.0530548095703125, val_loss = 0.7937574982643127\n",
      "epoch n°2959 : train_loss = 2.055213689804077, val_loss = 0.7903124690055847\n",
      "epoch n°2960 : train_loss = 2.046942949295044, val_loss = 0.7925167083740234\n",
      "epoch n°2961 : train_loss = 2.0424118041992188, val_loss = 0.7894086837768555\n",
      "epoch n°2962 : train_loss = 2.0523135662078857, val_loss = 0.794998049736023\n",
      "epoch n°2963 : train_loss = 2.0530502796173096, val_loss = 0.7930632829666138\n",
      "epoch n°2964 : train_loss = 2.050842046737671, val_loss = 0.7958187460899353\n",
      "epoch n°2965 : train_loss = 2.0550014972686768, val_loss = 0.7923417091369629\n",
      "epoch n°2966 : train_loss = 2.0475454330444336, val_loss = 0.7949553728103638\n",
      "epoch n°2967 : train_loss = 2.0472285747528076, val_loss = 0.7933489084243774\n",
      "epoch n°2968 : train_loss = 2.050184726715088, val_loss = 0.7935620546340942\n",
      "epoch n°2969 : train_loss = 2.050161123275757, val_loss = 0.7919048070907593\n",
      "epoch n°2970 : train_loss = 2.055612087249756, val_loss = 0.7927214503288269\n",
      "epoch n°2971 : train_loss = 2.052915334701538, val_loss = 0.7944034934043884\n",
      "epoch n°2972 : train_loss = 2.0526108741760254, val_loss = 0.7960416674613953\n",
      "epoch n°2973 : train_loss = 2.053678035736084, val_loss = 0.7948082685470581\n",
      "epoch n°2974 : train_loss = 2.046272039413452, val_loss = 0.7895532846450806\n",
      "epoch n°2975 : train_loss = 2.0467967987060547, val_loss = 0.7987239956855774\n",
      "epoch n°2976 : train_loss = 2.0492124557495117, val_loss = 0.792355477809906\n",
      "epoch n°2977 : train_loss = 2.049299955368042, val_loss = 0.7880272269248962\n",
      "epoch n°2978 : train_loss = 2.0577890872955322, val_loss = 0.7893744707107544\n",
      "epoch n°2979 : train_loss = 2.050717353820801, val_loss = 0.7936473488807678\n",
      "epoch n°2980 : train_loss = 2.0536739826202393, val_loss = 0.7902178764343262\n",
      "epoch n°2981 : train_loss = 2.0556955337524414, val_loss = 0.791161060333252\n",
      "epoch n°2982 : train_loss = 2.046952486038208, val_loss = 0.7914056777954102\n",
      "epoch n°2983 : train_loss = 2.0433433055877686, val_loss = 0.7895519733428955\n",
      "epoch n°2984 : train_loss = 2.052666187286377, val_loss = 0.792824923992157\n",
      "epoch n°2985 : train_loss = 2.0583550930023193, val_loss = 0.7953341007232666\n",
      "epoch n°2986 : train_loss = 2.0582869052886963, val_loss = 0.792966365814209\n",
      "epoch n°2987 : train_loss = 2.0436480045318604, val_loss = 0.7950543761253357\n",
      "epoch n°2988 : train_loss = 2.0508594512939453, val_loss = 0.7878772020339966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°2989 : train_loss = 2.049650192260742, val_loss = 0.7912436723709106\n",
      "epoch n°2990 : train_loss = 2.050290107727051, val_loss = 0.7922056317329407\n",
      "epoch n°2991 : train_loss = 2.0521113872528076, val_loss = 0.7951812148094177\n",
      "epoch n°2992 : train_loss = 2.0495948791503906, val_loss = 0.7946453094482422\n",
      "epoch n°2993 : train_loss = 2.0444915294647217, val_loss = 0.7965961694717407\n",
      "epoch n°2994 : train_loss = 2.0487186908721924, val_loss = 0.7936671376228333\n",
      "epoch n°2995 : train_loss = 2.04487943649292, val_loss = 0.7945451140403748\n",
      "epoch n°2996 : train_loss = 2.0526363849639893, val_loss = 0.7920135855674744\n",
      "epoch n°2997 : train_loss = 2.0441839694976807, val_loss = 0.7936134934425354\n",
      "epoch n°2998 : train_loss = 2.04767107963562, val_loss = 0.7921671271324158\n",
      "epoch n°2999 : train_loss = 2.0526349544525146, val_loss = 0.7939581274986267\n",
      "epoch n°3000 : train_loss = 2.0418624877929688, val_loss = 0.7930604815483093\n",
      "epoch n°3001 : train_loss = 2.0453758239746094, val_loss = 0.7965317368507385\n",
      "epoch n°3002 : train_loss = 2.0530917644500732, val_loss = 0.7900336384773254\n",
      "epoch n°3003 : train_loss = 2.045063018798828, val_loss = 0.7929005026817322\n",
      "epoch n°3004 : train_loss = 2.0458054542541504, val_loss = 0.7899513244628906\n",
      "epoch n°3005 : train_loss = 2.0475735664367676, val_loss = 0.7937545776367188\n",
      "epoch n°3006 : train_loss = 2.068511724472046, val_loss = 0.7958328127861023\n",
      "epoch n°3007 : train_loss = 2.0485732555389404, val_loss = 0.7964363694190979\n",
      "epoch n°3008 : train_loss = 2.040437936782837, val_loss = 0.7950184941291809\n",
      "epoch n°3009 : train_loss = 2.0448765754699707, val_loss = 0.791512668132782\n",
      "epoch n°3010 : train_loss = 2.0462629795074463, val_loss = 0.7933035492897034\n",
      "epoch n°3011 : train_loss = 2.044369697570801, val_loss = 0.7910590767860413\n",
      "epoch n°3012 : train_loss = 2.0516791343688965, val_loss = 0.7935943603515625\n",
      "epoch n°3013 : train_loss = 2.0475051403045654, val_loss = 0.7938145399093628\n",
      "epoch n°3014 : train_loss = 2.04496693611145, val_loss = 0.7905510067939758\n",
      "epoch n°3015 : train_loss = 2.0511205196380615, val_loss = 0.7947443723678589\n",
      "epoch n°3016 : train_loss = 2.041050910949707, val_loss = 0.7956117987632751\n",
      "epoch n°3017 : train_loss = 2.0499250888824463, val_loss = 0.7955830693244934\n",
      "epoch n°3018 : train_loss = 2.0536446571350098, val_loss = 0.796927273273468\n",
      "epoch n°3019 : train_loss = 2.049649238586426, val_loss = 0.793562114238739\n",
      "epoch n°3020 : train_loss = 2.0468075275421143, val_loss = 0.800135612487793\n",
      "epoch n°3021 : train_loss = 2.0395267009735107, val_loss = 0.7942153811454773\n",
      "epoch n°3022 : train_loss = 2.0456435680389404, val_loss = 0.7941848635673523\n",
      "epoch n°3023 : train_loss = 2.050055503845215, val_loss = 0.7943868041038513\n",
      "epoch n°3024 : train_loss = 2.0377390384674072, val_loss = 0.7948653697967529\n",
      "epoch n°3025 : train_loss = 2.039219379425049, val_loss = 0.793880820274353\n",
      "epoch n°3026 : train_loss = 2.0448989868164062, val_loss = 0.7942032814025879\n",
      "epoch n°3027 : train_loss = 2.0385544300079346, val_loss = 0.7967094779014587\n",
      "epoch n°3028 : train_loss = 2.0542330741882324, val_loss = 0.7917020916938782\n",
      "epoch n°3029 : train_loss = 2.04335880279541, val_loss = 0.7955963015556335\n",
      "epoch n°3030 : train_loss = 2.045639753341675, val_loss = 0.7963400483131409\n",
      "epoch n°3031 : train_loss = 2.0513617992401123, val_loss = 0.7941685318946838\n",
      "epoch n°3032 : train_loss = 2.044506788253784, val_loss = 0.7935538291931152\n",
      "epoch n°3033 : train_loss = 2.046334743499756, val_loss = 0.7935903072357178\n",
      "epoch n°3034 : train_loss = 2.045811653137207, val_loss = 0.798872172832489\n",
      "epoch n°3035 : train_loss = 2.0525882244110107, val_loss = 0.792822003364563\n",
      "epoch n°3036 : train_loss = 2.0444252490997314, val_loss = 0.7916556000709534\n",
      "epoch n°3037 : train_loss = 2.0527396202087402, val_loss = 0.7915457487106323\n",
      "epoch n°3038 : train_loss = 2.051668643951416, val_loss = 0.7936392426490784\n",
      "epoch n°3039 : train_loss = 2.0472264289855957, val_loss = 0.791576087474823\n",
      "epoch n°3040 : train_loss = 2.0377368927001953, val_loss = 0.7944098114967346\n",
      "epoch n°3041 : train_loss = 2.0398151874542236, val_loss = 0.7949674725532532\n",
      "epoch n°3042 : train_loss = 2.05136775970459, val_loss = 0.7974176406860352\n",
      "epoch n°3043 : train_loss = 2.037282943725586, val_loss = 0.7936635613441467\n",
      "epoch n°3044 : train_loss = 2.04233980178833, val_loss = 0.7958247661590576\n",
      "epoch n°3045 : train_loss = 2.0469794273376465, val_loss = 0.7944602370262146\n",
      "epoch n°3046 : train_loss = 2.046477794647217, val_loss = 0.7924104928970337\n",
      "epoch n°3047 : train_loss = 2.0432090759277344, val_loss = 0.7978788018226624\n",
      "epoch n°3048 : train_loss = 2.0460259914398193, val_loss = 0.7946434020996094\n",
      "epoch n°3049 : train_loss = 2.0407450199127197, val_loss = 0.7962721586227417\n",
      "epoch n°3050 : train_loss = 2.041766405105591, val_loss = 0.7897185683250427\n",
      "epoch n°3051 : train_loss = 2.0420889854431152, val_loss = 0.7957186102867126\n",
      "epoch n°3052 : train_loss = 2.047811269760132, val_loss = 0.793323814868927\n",
      "epoch n°3053 : train_loss = 2.0492660999298096, val_loss = 0.7966268062591553\n",
      "epoch n°3054 : train_loss = 2.0498244762420654, val_loss = 0.7953306436538696\n",
      "epoch n°3055 : train_loss = 2.0426793098449707, val_loss = 0.7918676733970642\n",
      "epoch n°3056 : train_loss = 2.043799638748169, val_loss = 0.7943220138549805\n",
      "epoch n°3057 : train_loss = 2.0452463626861572, val_loss = 0.7946630716323853\n",
      "epoch n°3058 : train_loss = 2.0481433868408203, val_loss = 0.7946224212646484\n",
      "epoch n°3059 : train_loss = 2.045928716659546, val_loss = 0.7965463995933533\n",
      "epoch n°3060 : train_loss = 2.0374934673309326, val_loss = 0.7936392426490784\n",
      "epoch n°3061 : train_loss = 2.043074607849121, val_loss = 0.7902941703796387\n",
      "epoch n°3062 : train_loss = 2.044952154159546, val_loss = 0.7907156348228455\n",
      "epoch n°3063 : train_loss = 2.0398876667022705, val_loss = 0.7972409129142761\n",
      "epoch n°3064 : train_loss = 2.044504404067993, val_loss = 0.7898610830307007\n",
      "epoch n°3065 : train_loss = 2.040905714035034, val_loss = 0.7940461039543152\n",
      "epoch n°3066 : train_loss = 2.0570592880249023, val_loss = 0.7922987341880798\n",
      "epoch n°3067 : train_loss = 2.0430362224578857, val_loss = 0.7940183281898499\n",
      "epoch n°3068 : train_loss = 2.046055793762207, val_loss = 0.7914332747459412\n",
      "epoch n°3069 : train_loss = 2.0412960052490234, val_loss = 0.79459547996521\n",
      "epoch n°3070 : train_loss = 2.034614324569702, val_loss = 0.7932514548301697\n",
      "epoch n°3071 : train_loss = 2.047464370727539, val_loss = 0.7965058088302612\n",
      "epoch n°3072 : train_loss = 2.038060188293457, val_loss = 0.7965264320373535\n",
      "epoch n°3073 : train_loss = 2.044698715209961, val_loss = 0.7923919558525085\n",
      "epoch n°3074 : train_loss = 2.041442394256592, val_loss = 0.7950899600982666\n",
      "epoch n°3075 : train_loss = 2.035088300704956, val_loss = 0.7921540141105652\n",
      "epoch n°3076 : train_loss = 2.0494513511657715, val_loss = 0.7894712090492249\n",
      "epoch n°3077 : train_loss = 2.0385653972625732, val_loss = 0.7936426997184753\n",
      "epoch n°3078 : train_loss = 2.0470974445343018, val_loss = 0.7946434020996094\n",
      "epoch n°3079 : train_loss = 2.046365261077881, val_loss = 0.78619784116745\n",
      "epoch n°3080 : train_loss = 2.051013946533203, val_loss = 0.7919549345970154\n",
      "epoch n°3081 : train_loss = 2.0466346740722656, val_loss = 0.7899187803268433\n",
      "epoch n°3082 : train_loss = 2.04506778717041, val_loss = 0.7949612140655518\n",
      "epoch n°3083 : train_loss = 2.0455470085144043, val_loss = 0.7986356616020203\n",
      "epoch n°3084 : train_loss = 2.0464587211608887, val_loss = 0.7975517511367798\n",
      "epoch n°3085 : train_loss = 2.051058769226074, val_loss = 0.7955049276351929\n",
      "epoch n°3086 : train_loss = 2.0455093383789062, val_loss = 0.7910289764404297\n",
      "epoch n°3087 : train_loss = 2.0405373573303223, val_loss = 0.7945935726165771\n",
      "epoch n°3088 : train_loss = 2.0448715686798096, val_loss = 0.7963904142379761\n",
      "epoch n°3089 : train_loss = 2.0340585708618164, val_loss = 0.7934099435806274\n",
      "epoch n°3090 : train_loss = 2.0495758056640625, val_loss = 0.7936057448387146\n",
      "epoch n°3091 : train_loss = 2.0380184650421143, val_loss = 0.7902610301971436\n",
      "epoch n°3092 : train_loss = 2.04404354095459, val_loss = 0.7912409901618958\n",
      "epoch n°3093 : train_loss = 2.0525400638580322, val_loss = 0.79413241147995\n",
      "epoch n°3094 : train_loss = 2.0415427684783936, val_loss = 0.7918472290039062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°3095 : train_loss = 2.03889799118042, val_loss = 0.7914630174636841\n",
      "epoch n°3096 : train_loss = 2.0389819145202637, val_loss = 0.7933796048164368\n",
      "epoch n°3097 : train_loss = 2.0475990772247314, val_loss = 0.7963065505027771\n",
      "epoch n°3098 : train_loss = 2.0443716049194336, val_loss = 0.7920445203781128\n",
      "epoch n°3099 : train_loss = 2.0390658378601074, val_loss = 0.7927496433258057\n",
      "epoch n°3100 : train_loss = 2.0518393516540527, val_loss = 0.7942494750022888\n",
      "epoch n°3101 : train_loss = 2.0357470512390137, val_loss = 0.7914257049560547\n",
      "epoch n°3102 : train_loss = 2.041677474975586, val_loss = 0.7923133969306946\n",
      "epoch n°3103 : train_loss = 2.0325756072998047, val_loss = 0.7942034006118774\n",
      "epoch n°3104 : train_loss = 2.035407304763794, val_loss = 0.7960848808288574\n",
      "epoch n°3105 : train_loss = 2.0407238006591797, val_loss = 0.7916898727416992\n",
      "epoch n°3106 : train_loss = 2.046086549758911, val_loss = 0.7928257584571838\n",
      "epoch n°3107 : train_loss = 2.0353634357452393, val_loss = 0.7932987213134766\n",
      "epoch n°3108 : train_loss = 2.0424718856811523, val_loss = 0.7930280566215515\n",
      "epoch n°3109 : train_loss = 2.0443429946899414, val_loss = 0.7949436902999878\n",
      "epoch n°3110 : train_loss = 2.038872718811035, val_loss = 0.8014103770256042\n",
      "epoch n°3111 : train_loss = 2.0514609813690186, val_loss = 0.7943994998931885\n",
      "epoch n°3112 : train_loss = 2.0512707233428955, val_loss = 0.7968873381614685\n",
      "epoch n°3113 : train_loss = 2.0438241958618164, val_loss = 0.79168301820755\n",
      "epoch n°3114 : train_loss = 2.047006607055664, val_loss = 0.7888842225074768\n",
      "epoch n°3115 : train_loss = 2.041898012161255, val_loss = 0.7958227396011353\n",
      "epoch n°3116 : train_loss = 2.044687032699585, val_loss = 0.7879937291145325\n",
      "epoch n°3117 : train_loss = 2.0477285385131836, val_loss = 0.7912662625312805\n",
      "epoch n°3118 : train_loss = 2.0436840057373047, val_loss = 0.7928315997123718\n",
      "epoch n°3119 : train_loss = 2.0418365001678467, val_loss = 0.7964776158332825\n",
      "epoch n°3120 : train_loss = 2.0395686626434326, val_loss = 0.7940530180931091\n",
      "epoch n°3121 : train_loss = 2.044405937194824, val_loss = 0.7930150032043457\n",
      "epoch n°3122 : train_loss = 2.0367274284362793, val_loss = 0.791949987411499\n",
      "epoch n°3123 : train_loss = 2.0357089042663574, val_loss = 0.7957283854484558\n",
      "epoch n°3124 : train_loss = 2.0327541828155518, val_loss = 0.7906986474990845\n",
      "epoch n°3125 : train_loss = 2.0391759872436523, val_loss = 0.7928769588470459\n",
      "epoch n°3126 : train_loss = 2.0344009399414062, val_loss = 0.792102575302124\n",
      "epoch n°3127 : train_loss = 2.0494470596313477, val_loss = 0.7897047996520996\n",
      "epoch n°3128 : train_loss = 2.0371952056884766, val_loss = 0.7919222712516785\n",
      "epoch n°3129 : train_loss = 2.044583320617676, val_loss = 0.7913281321525574\n",
      "epoch n°3130 : train_loss = 2.0365514755249023, val_loss = 0.7921299934387207\n",
      "epoch n°3131 : train_loss = 2.0400876998901367, val_loss = 0.7955925464630127\n",
      "epoch n°3132 : train_loss = 2.0420210361480713, val_loss = 0.794701874256134\n",
      "epoch n°3133 : train_loss = 2.0385501384735107, val_loss = 0.7896856069564819\n",
      "epoch n°3134 : train_loss = 2.044901132583618, val_loss = 0.7942526936531067\n",
      "epoch n°3135 : train_loss = 2.0366244316101074, val_loss = 0.7962651252746582\n",
      "epoch n°3136 : train_loss = 2.0460689067840576, val_loss = 0.7914111614227295\n",
      "epoch n°3137 : train_loss = 2.0351150035858154, val_loss = 0.7938647866249084\n",
      "epoch n°3138 : train_loss = 2.040036678314209, val_loss = 0.7939363121986389\n",
      "epoch n°3139 : train_loss = 2.0493528842926025, val_loss = 0.7882903814315796\n",
      "epoch n°3140 : train_loss = 2.0439183712005615, val_loss = 0.7941440939903259\n",
      "epoch n°3141 : train_loss = 2.0435476303100586, val_loss = 0.7888660430908203\n",
      "epoch n°3142 : train_loss = 2.041043519973755, val_loss = 0.7918965220451355\n",
      "epoch n°3143 : train_loss = 2.037053346633911, val_loss = 0.7955002784729004\n",
      "epoch n°3144 : train_loss = 2.037907361984253, val_loss = 0.7936323881149292\n",
      "epoch n°3145 : train_loss = 2.040973424911499, val_loss = 0.7945961356163025\n",
      "epoch n°3146 : train_loss = 2.0430314540863037, val_loss = 0.7925528287887573\n",
      "epoch n°3147 : train_loss = 2.044602632522583, val_loss = 0.7934094071388245\n",
      "epoch n°3148 : train_loss = 2.0413708686828613, val_loss = 0.7936453223228455\n",
      "epoch n°3149 : train_loss = 2.055750846862793, val_loss = 0.7939574122428894\n",
      "epoch n°3150 : train_loss = 2.045362949371338, val_loss = 0.7926797866821289\n",
      "epoch n°3151 : train_loss = 2.0413129329681396, val_loss = 0.7905102968215942\n",
      "epoch n°3152 : train_loss = 2.0402355194091797, val_loss = 0.7951921224594116\n",
      "epoch n°3153 : train_loss = 2.0387370586395264, val_loss = 0.7920481562614441\n",
      "epoch n°3154 : train_loss = 2.0410046577453613, val_loss = 0.7926636338233948\n",
      "epoch n°3155 : train_loss = 2.041771411895752, val_loss = 0.7936992645263672\n",
      "epoch n°3156 : train_loss = 2.039867639541626, val_loss = 0.7944987416267395\n",
      "epoch n°3157 : train_loss = 2.0372564792633057, val_loss = 0.7946078181266785\n",
      "epoch n°3158 : train_loss = 2.0335347652435303, val_loss = 0.7905728816986084\n",
      "epoch n°3159 : train_loss = 2.0286216735839844, val_loss = 0.7928052544593811\n",
      "epoch n°3160 : train_loss = 2.0479094982147217, val_loss = 0.7958399653434753\n",
      "epoch n°3161 : train_loss = 2.032449960708618, val_loss = 0.7912399172782898\n",
      "epoch n°3162 : train_loss = 2.039581775665283, val_loss = 0.793414831161499\n",
      "epoch n°3163 : train_loss = 2.043444871902466, val_loss = 0.7963070869445801\n",
      "epoch n°3164 : train_loss = 2.0392439365386963, val_loss = 0.7963151335716248\n",
      "epoch n°3165 : train_loss = 2.0459439754486084, val_loss = 0.7996100187301636\n",
      "epoch n°3166 : train_loss = 2.036102771759033, val_loss = 0.7908616662025452\n",
      "epoch n°3167 : train_loss = 2.0347697734832764, val_loss = 0.7950049042701721\n",
      "epoch n°3168 : train_loss = 2.0313847064971924, val_loss = 0.7927930355072021\n",
      "epoch n°3169 : train_loss = 2.0454916954040527, val_loss = 0.7905064821243286\n",
      "epoch n°3170 : train_loss = 2.038017988204956, val_loss = 0.7915792465209961\n",
      "epoch n°3171 : train_loss = 2.0351669788360596, val_loss = 0.7906568646430969\n",
      "epoch n°3172 : train_loss = 2.0386641025543213, val_loss = 0.7953606843948364\n",
      "epoch n°3173 : train_loss = 2.034496307373047, val_loss = 0.7949507832527161\n",
      "epoch n°3174 : train_loss = 2.0392909049987793, val_loss = 0.7937548160552979\n",
      "epoch n°3175 : train_loss = 2.033168077468872, val_loss = 0.7921266555786133\n",
      "epoch n°3176 : train_loss = 2.0344889163970947, val_loss = 0.7930629849433899\n",
      "epoch n°3177 : train_loss = 2.0365540981292725, val_loss = 0.794658899307251\n",
      "epoch n°3178 : train_loss = 2.0395498275756836, val_loss = 0.7914779782295227\n",
      "epoch n°3179 : train_loss = 2.038221836090088, val_loss = 0.791264533996582\n",
      "epoch n°3180 : train_loss = 2.035494089126587, val_loss = 0.793197751045227\n",
      "epoch n°3181 : train_loss = 2.0348291397094727, val_loss = 0.7909365892410278\n",
      "epoch n°3182 : train_loss = 2.042959213256836, val_loss = 0.7952178716659546\n",
      "epoch n°3183 : train_loss = 2.0485894680023193, val_loss = 0.7896871566772461\n",
      "epoch n°3184 : train_loss = 2.0367016792297363, val_loss = 0.7911207675933838\n",
      "epoch n°3185 : train_loss = 2.032015562057495, val_loss = 0.7941117286682129\n",
      "epoch n°3186 : train_loss = 2.040743827819824, val_loss = 0.7920482754707336\n",
      "epoch n°3187 : train_loss = 2.042083978652954, val_loss = 0.7891480922698975\n",
      "epoch n°3188 : train_loss = 2.02944278717041, val_loss = 0.7947355508804321\n",
      "epoch n°3189 : train_loss = 2.0325169563293457, val_loss = 0.793544352054596\n",
      "epoch n°3190 : train_loss = 2.0325756072998047, val_loss = 0.7942827939987183\n",
      "epoch n°3191 : train_loss = 2.0432822704315186, val_loss = 0.7947500348091125\n",
      "epoch n°3192 : train_loss = 2.0424318313598633, val_loss = 0.791288435459137\n",
      "epoch n°3193 : train_loss = 2.036254405975342, val_loss = 0.79757159948349\n",
      "epoch n°3194 : train_loss = 2.052375555038452, val_loss = 0.7929348349571228\n",
      "epoch n°3195 : train_loss = 2.0367259979248047, val_loss = 0.7985244393348694\n",
      "epoch n°3196 : train_loss = 2.037534475326538, val_loss = 0.7961037158966064\n",
      "epoch n°3197 : train_loss = 2.0322606563568115, val_loss = 0.7919492721557617\n",
      "epoch n°3198 : train_loss = 2.037090301513672, val_loss = 0.7937530875205994\n",
      "epoch n°3199 : train_loss = 2.0439727306365967, val_loss = 0.7937244772911072\n",
      "epoch n°3200 : train_loss = 2.0387232303619385, val_loss = 0.7930325269699097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°3201 : train_loss = 2.0430221557617188, val_loss = 0.7984341979026794\n",
      "epoch n°3202 : train_loss = 2.042081356048584, val_loss = 0.7874875664710999\n",
      "epoch n°3203 : train_loss = 2.0364367961883545, val_loss = 0.7912449240684509\n",
      "epoch n°3204 : train_loss = 2.0388309955596924, val_loss = 0.7941177487373352\n",
      "epoch n°3205 : train_loss = 2.0346646308898926, val_loss = 0.7923726439476013\n",
      "epoch n°3206 : train_loss = 2.038255214691162, val_loss = 0.7923747301101685\n",
      "epoch n°3207 : train_loss = 2.034355640411377, val_loss = 0.7942266464233398\n",
      "epoch n°3208 : train_loss = 2.032715320587158, val_loss = 0.7953342199325562\n",
      "epoch n°3209 : train_loss = 2.040722131729126, val_loss = 0.795613706111908\n",
      "epoch n°3210 : train_loss = 2.0363194942474365, val_loss = 0.7964946627616882\n",
      "epoch n°3211 : train_loss = 2.0426383018493652, val_loss = 0.7891143560409546\n",
      "epoch n°3212 : train_loss = 2.0337421894073486, val_loss = 0.7935155630111694\n",
      "epoch n°3213 : train_loss = 2.0477676391601562, val_loss = 0.7922050356864929\n",
      "epoch n°3214 : train_loss = 2.0354740619659424, val_loss = 0.7928707599639893\n",
      "epoch n°3215 : train_loss = 2.0276691913604736, val_loss = 0.7924954295158386\n",
      "epoch n°3216 : train_loss = 2.0483458042144775, val_loss = 0.7907804846763611\n",
      "epoch n°3217 : train_loss = 2.038196325302124, val_loss = 0.7944607138633728\n",
      "epoch n°3218 : train_loss = 2.0406103134155273, val_loss = 0.7990078926086426\n",
      "epoch n°3219 : train_loss = 2.0319788455963135, val_loss = 0.7922518253326416\n",
      "epoch n°3220 : train_loss = 2.0390026569366455, val_loss = 0.7872845530509949\n",
      "epoch n°3221 : train_loss = 2.039072275161743, val_loss = 0.7980095744132996\n",
      "epoch n°3222 : train_loss = 2.0372421741485596, val_loss = 0.7929831743240356\n",
      "epoch n°3223 : train_loss = 2.041065216064453, val_loss = 0.7953636646270752\n",
      "epoch n°3224 : train_loss = 2.0285885334014893, val_loss = 0.7908770442008972\n",
      "epoch n°3225 : train_loss = 2.0404345989227295, val_loss = 0.7923528552055359\n",
      "epoch n°3226 : train_loss = 2.032346487045288, val_loss = 0.7976144552230835\n",
      "epoch n°3227 : train_loss = 2.0382580757141113, val_loss = 0.7914717793464661\n",
      "epoch n°3228 : train_loss = 2.040492057800293, val_loss = 0.796238362789154\n",
      "epoch n°3229 : train_loss = 2.0453286170959473, val_loss = 0.7924615740776062\n",
      "epoch n°3230 : train_loss = 2.0320961475372314, val_loss = 0.7886044383049011\n",
      "epoch n°3231 : train_loss = 2.033501148223877, val_loss = 0.7933737635612488\n",
      "epoch n°3232 : train_loss = 2.0405917167663574, val_loss = 0.7953290939331055\n",
      "epoch n°3233 : train_loss = 2.0367136001586914, val_loss = 0.7900764346122742\n",
      "epoch n°3234 : train_loss = 2.0375168323516846, val_loss = 0.7911197543144226\n",
      "epoch n°3235 : train_loss = 2.0367109775543213, val_loss = 0.793785572052002\n",
      "epoch n°3236 : train_loss = 2.036095380783081, val_loss = 0.7942216396331787\n",
      "epoch n°3237 : train_loss = 2.036654472351074, val_loss = 0.7930875420570374\n",
      "epoch n°3238 : train_loss = 2.036203384399414, val_loss = 0.7900214195251465\n",
      "epoch n°3239 : train_loss = 2.040625810623169, val_loss = 0.7979041934013367\n",
      "epoch n°3240 : train_loss = 2.0301525592803955, val_loss = 0.7943699359893799\n",
      "epoch n°3241 : train_loss = 2.0434484481811523, val_loss = 0.7983690500259399\n",
      "epoch n°3242 : train_loss = 2.0370264053344727, val_loss = 0.7945995926856995\n",
      "epoch n°3243 : train_loss = 2.029604196548462, val_loss = 0.7868368029594421\n",
      "epoch n°3244 : train_loss = 2.0413124561309814, val_loss = 0.7945381999015808\n",
      "epoch n°3245 : train_loss = 2.0406856536865234, val_loss = 0.7920390367507935\n",
      "epoch n°3246 : train_loss = 2.0383622646331787, val_loss = 0.7926679253578186\n",
      "epoch n°3247 : train_loss = 2.0281291007995605, val_loss = 0.7910969257354736\n",
      "epoch n°3248 : train_loss = 2.0297441482543945, val_loss = 0.7945746183395386\n",
      "epoch n°3249 : train_loss = 2.0253350734710693, val_loss = 0.7867074608802795\n",
      "epoch n°3250 : train_loss = 2.044455051422119, val_loss = 0.7904444336891174\n",
      "epoch n°3251 : train_loss = 2.038792610168457, val_loss = 0.7941712141036987\n",
      "epoch n°3252 : train_loss = 2.0270071029663086, val_loss = 0.7949221730232239\n",
      "epoch n°3253 : train_loss = 2.032810926437378, val_loss = 0.7942883372306824\n",
      "epoch n°3254 : train_loss = 2.0356690883636475, val_loss = 0.7928752899169922\n",
      "epoch n°3255 : train_loss = 2.035707473754883, val_loss = 0.7931795120239258\n",
      "epoch n°3256 : train_loss = 2.0302910804748535, val_loss = 0.7929775714874268\n",
      "epoch n°3257 : train_loss = 2.0246214866638184, val_loss = 0.7979389429092407\n",
      "epoch n°3258 : train_loss = 2.034898281097412, val_loss = 0.7880136966705322\n",
      "epoch n°3259 : train_loss = 2.0324532985687256, val_loss = 0.7936812043190002\n",
      "epoch n°3260 : train_loss = 2.0335593223571777, val_loss = 0.8004041910171509\n",
      "epoch n°3261 : train_loss = 2.033853530883789, val_loss = 0.795689046382904\n",
      "epoch n°3262 : train_loss = 2.041501045227051, val_loss = 0.7943386435508728\n",
      "epoch n°3263 : train_loss = 2.032806158065796, val_loss = 0.7934326529502869\n",
      "epoch n°3264 : train_loss = 2.0331592559814453, val_loss = 0.796392560005188\n",
      "epoch n°3265 : train_loss = 2.0385935306549072, val_loss = 0.7947719693183899\n",
      "epoch n°3266 : train_loss = 2.042786121368408, val_loss = 0.7990583181381226\n",
      "epoch n°3267 : train_loss = 2.0383520126342773, val_loss = 0.798007071018219\n",
      "epoch n°3268 : train_loss = 2.0345025062561035, val_loss = 0.7912992238998413\n",
      "epoch n°3269 : train_loss = 2.032597303390503, val_loss = 0.7934780120849609\n",
      "epoch n°3270 : train_loss = 2.0281479358673096, val_loss = 0.7890628576278687\n",
      "epoch n°3271 : train_loss = 2.0393030643463135, val_loss = 0.7967579364776611\n",
      "epoch n°3272 : train_loss = 2.031726837158203, val_loss = 0.7875877022743225\n",
      "epoch n°3273 : train_loss = 2.034977912902832, val_loss = 0.7919023633003235\n",
      "epoch n°3274 : train_loss = 2.0363290309906006, val_loss = 0.7954025864601135\n",
      "epoch n°3275 : train_loss = 2.0346035957336426, val_loss = 0.7896166443824768\n",
      "epoch n°3276 : train_loss = 2.0301592350006104, val_loss = 0.7894740104675293\n",
      "epoch n°3277 : train_loss = 2.0348145961761475, val_loss = 0.7908384203910828\n",
      "epoch n°3278 : train_loss = 2.0379462242126465, val_loss = 0.7937893271446228\n",
      "epoch n°3279 : train_loss = 2.0330746173858643, val_loss = 0.78873610496521\n",
      "epoch n°3280 : train_loss = 2.035562038421631, val_loss = 0.7990674376487732\n",
      "epoch n°3281 : train_loss = 2.027413845062256, val_loss = 0.7897913455963135\n",
      "epoch n°3282 : train_loss = 2.029878854751587, val_loss = 0.7916569709777832\n",
      "epoch n°3283 : train_loss = 2.04097318649292, val_loss = 0.7931337952613831\n",
      "epoch n°3284 : train_loss = 2.0357377529144287, val_loss = 0.7938498258590698\n",
      "epoch n°3285 : train_loss = 2.034106492996216, val_loss = 0.7911567687988281\n",
      "epoch n°3286 : train_loss = 2.0349340438842773, val_loss = 0.7966485023498535\n",
      "epoch n°3287 : train_loss = 2.0338058471679688, val_loss = 0.7925258278846741\n",
      "epoch n°3288 : train_loss = 2.030722141265869, val_loss = 0.7917107343673706\n",
      "epoch n°3289 : train_loss = 2.0393829345703125, val_loss = 0.7989982962608337\n",
      "epoch n°3290 : train_loss = 2.0300657749176025, val_loss = 0.7941210269927979\n",
      "epoch n°3291 : train_loss = 2.0344576835632324, val_loss = 0.79001784324646\n",
      "epoch n°3292 : train_loss = 2.0316147804260254, val_loss = 0.7906888723373413\n",
      "epoch n°3293 : train_loss = 2.0312204360961914, val_loss = 0.7897919416427612\n",
      "epoch n°3294 : train_loss = 2.037055730819702, val_loss = 0.7938761115074158\n",
      "epoch n°3295 : train_loss = 2.0281269550323486, val_loss = 0.7982359528541565\n",
      "epoch n°3296 : train_loss = 2.0355687141418457, val_loss = 0.7954016327857971\n",
      "epoch n°3297 : train_loss = 2.038731813430786, val_loss = 0.7940744757652283\n",
      "epoch n°3298 : train_loss = 2.036393404006958, val_loss = 0.7968679666519165\n",
      "epoch n°3299 : train_loss = 2.044450283050537, val_loss = 0.791344404220581\n",
      "epoch n°3300 : train_loss = 2.0324318408966064, val_loss = 0.7948175668716431\n",
      "epoch n°3301 : train_loss = 2.0321974754333496, val_loss = 0.7936339378356934\n",
      "epoch n°3302 : train_loss = 2.0315897464752197, val_loss = 0.7923888564109802\n",
      "epoch n°3303 : train_loss = 2.032822847366333, val_loss = 0.7947389483451843\n",
      "epoch n°3304 : train_loss = 2.033022165298462, val_loss = 0.7910594940185547\n",
      "epoch n°3305 : train_loss = 2.040066719055176, val_loss = 0.7933996319770813\n",
      "epoch n°3306 : train_loss = 2.0400032997131348, val_loss = 0.7932331562042236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°3307 : train_loss = 2.029017686843872, val_loss = 0.7912734150886536\n",
      "epoch n°3308 : train_loss = 2.0292420387268066, val_loss = 0.7945892810821533\n",
      "epoch n°3309 : train_loss = 2.024249792098999, val_loss = 0.7924929261207581\n",
      "epoch n°3310 : train_loss = 2.0263917446136475, val_loss = 0.7917742729187012\n",
      "epoch n°3311 : train_loss = 2.0367870330810547, val_loss = 0.7949346303939819\n",
      "epoch n°3312 : train_loss = 2.03702974319458, val_loss = 0.7874361276626587\n",
      "epoch n°3313 : train_loss = 2.0350341796875, val_loss = 0.7918745279312134\n",
      "epoch n°3314 : train_loss = 2.0343356132507324, val_loss = 0.7907124757766724\n",
      "epoch n°3315 : train_loss = 2.030606269836426, val_loss = 0.7918067574501038\n",
      "epoch n°3316 : train_loss = 2.0293564796447754, val_loss = 0.7912185788154602\n",
      "epoch n°3317 : train_loss = 2.032087802886963, val_loss = 0.792349100112915\n",
      "epoch n°3318 : train_loss = 2.032881498336792, val_loss = 0.792455792427063\n",
      "epoch n°3319 : train_loss = 2.0312297344207764, val_loss = 0.7931738495826721\n",
      "epoch n°3320 : train_loss = 2.0247998237609863, val_loss = 0.7909528613090515\n",
      "epoch n°3321 : train_loss = 2.028578519821167, val_loss = 0.7939662337303162\n",
      "epoch n°3322 : train_loss = 2.0206923484802246, val_loss = 0.7938967943191528\n",
      "epoch n°3323 : train_loss = 2.0349557399749756, val_loss = 0.7921453714370728\n",
      "epoch n°3324 : train_loss = 2.0300912857055664, val_loss = 0.7943075299263\n",
      "epoch n°3325 : train_loss = 2.04268217086792, val_loss = 0.7923260927200317\n",
      "epoch n°3326 : train_loss = 2.0363430976867676, val_loss = 0.789236843585968\n",
      "epoch n°3327 : train_loss = 2.032256841659546, val_loss = 0.794427216053009\n",
      "epoch n°3328 : train_loss = 2.0331804752349854, val_loss = 0.7960905432701111\n",
      "epoch n°3329 : train_loss = 2.028796911239624, val_loss = 0.7974300384521484\n",
      "epoch n°3330 : train_loss = 2.0333197116851807, val_loss = 0.7932081818580627\n",
      "epoch n°3331 : train_loss = 2.032186269760132, val_loss = 0.7940301299095154\n",
      "epoch n°3332 : train_loss = 2.039726495742798, val_loss = 0.7922431826591492\n",
      "epoch n°3333 : train_loss = 2.037632942199707, val_loss = 0.7951836585998535\n",
      "epoch n°3334 : train_loss = 2.031094789505005, val_loss = 0.793827474117279\n",
      "epoch n°3335 : train_loss = 2.0295119285583496, val_loss = 0.7949199676513672\n",
      "epoch n°3336 : train_loss = 2.02478289604187, val_loss = 0.7905911207199097\n",
      "epoch n°3337 : train_loss = 2.037102699279785, val_loss = 0.7962121963500977\n",
      "epoch n°3338 : train_loss = 2.0286636352539062, val_loss = 0.7868431210517883\n",
      "epoch n°3339 : train_loss = 2.0304489135742188, val_loss = 0.7958751320838928\n",
      "epoch n°3340 : train_loss = 2.0415308475494385, val_loss = 0.791161060333252\n",
      "epoch n°3341 : train_loss = 2.0390608310699463, val_loss = 0.7948527932167053\n",
      "epoch n°3342 : train_loss = 2.028303861618042, val_loss = 0.7924306988716125\n",
      "epoch n°3343 : train_loss = 2.036062002182007, val_loss = 0.7908254861831665\n",
      "epoch n°3344 : train_loss = 2.0274431705474854, val_loss = 0.794189989566803\n",
      "epoch n°3345 : train_loss = 2.0348894596099854, val_loss = 0.795346736907959\n",
      "epoch n°3346 : train_loss = 2.031017303466797, val_loss = 0.7940801978111267\n",
      "epoch n°3347 : train_loss = 2.0296287536621094, val_loss = 0.793507993221283\n",
      "epoch n°3348 : train_loss = 2.028568983078003, val_loss = 0.7944790720939636\n",
      "epoch n°3349 : train_loss = 2.0264713764190674, val_loss = 0.7952149510383606\n",
      "epoch n°3350 : train_loss = 2.030337333679199, val_loss = 0.790009081363678\n",
      "epoch n°3351 : train_loss = 2.0284335613250732, val_loss = 0.7936732769012451\n",
      "epoch n°3352 : train_loss = 2.0313878059387207, val_loss = 0.7939475774765015\n",
      "epoch n°3353 : train_loss = 2.0270824432373047, val_loss = 0.7937716245651245\n",
      "epoch n°3354 : train_loss = 2.0369887351989746, val_loss = 0.7922616600990295\n",
      "epoch n°3355 : train_loss = 2.0331716537475586, val_loss = 0.7937580347061157\n",
      "epoch n°3356 : train_loss = 2.021613121032715, val_loss = 0.7911496758460999\n",
      "epoch n°3357 : train_loss = 2.0348103046417236, val_loss = 0.7870063781738281\n",
      "epoch n°3358 : train_loss = 2.0356132984161377, val_loss = 0.7947642803192139\n",
      "epoch n°3359 : train_loss = 2.0229358673095703, val_loss = 0.7929235696792603\n",
      "epoch n°3360 : train_loss = 2.036254644393921, val_loss = 0.7935194969177246\n",
      "epoch n°3361 : train_loss = 2.0339083671569824, val_loss = 0.7901147603988647\n",
      "epoch n°3362 : train_loss = 2.026099443435669, val_loss = 0.7909373641014099\n",
      "epoch n°3363 : train_loss = 2.021742105484009, val_loss = 0.7920912504196167\n",
      "epoch n°3364 : train_loss = 2.0261497497558594, val_loss = 0.796726644039154\n",
      "epoch n°3365 : train_loss = 2.029120922088623, val_loss = 0.7946168184280396\n",
      "epoch n°3366 : train_loss = 2.0301077365875244, val_loss = 0.7928745150566101\n",
      "epoch n°3367 : train_loss = 2.0339677333831787, val_loss = 0.7933663725852966\n",
      "epoch n°3368 : train_loss = 2.029895305633545, val_loss = 0.7917315363883972\n",
      "epoch n°3369 : train_loss = 2.0289032459259033, val_loss = 0.7916629314422607\n",
      "epoch n°3370 : train_loss = 2.0386457443237305, val_loss = 0.7935574650764465\n",
      "epoch n°3371 : train_loss = 2.0454423427581787, val_loss = 0.792496919631958\n",
      "epoch n°3372 : train_loss = 2.0270836353302, val_loss = 0.792024552822113\n",
      "epoch n°3373 : train_loss = 2.029496192932129, val_loss = 0.7934321761131287\n",
      "epoch n°3374 : train_loss = 2.026585578918457, val_loss = 0.7907958030700684\n",
      "epoch n°3375 : train_loss = 2.0343620777130127, val_loss = 0.7887750864028931\n",
      "epoch n°3376 : train_loss = 2.021453857421875, val_loss = 0.793960690498352\n",
      "epoch n°3377 : train_loss = 2.031320810317993, val_loss = 0.7913731336593628\n",
      "epoch n°3378 : train_loss = 2.0364348888397217, val_loss = 0.7901797294616699\n",
      "epoch n°3379 : train_loss = 2.0287623405456543, val_loss = 0.7971830368041992\n",
      "epoch n°3380 : train_loss = 2.033315420150757, val_loss = 0.7922277450561523\n",
      "epoch n°3381 : train_loss = 2.033599853515625, val_loss = 0.7925058603286743\n",
      "epoch n°3382 : train_loss = 2.0322680473327637, val_loss = 0.7911539673805237\n",
      "epoch n°3383 : train_loss = 2.034132719039917, val_loss = 0.7895095348358154\n",
      "epoch n°3384 : train_loss = 2.0302960872650146, val_loss = 0.7914385795593262\n",
      "epoch n°3385 : train_loss = 2.0276026725769043, val_loss = 0.7923145890235901\n",
      "epoch n°3386 : train_loss = 2.023855209350586, val_loss = 0.7975720167160034\n",
      "epoch n°3387 : train_loss = 2.03420352935791, val_loss = 0.793843686580658\n",
      "epoch n°3388 : train_loss = 2.035252809524536, val_loss = 0.7937955260276794\n",
      "epoch n°3389 : train_loss = 2.035856246948242, val_loss = 0.7954651713371277\n",
      "epoch n°3390 : train_loss = 2.0200068950653076, val_loss = 0.7905579209327698\n",
      "epoch n°3391 : train_loss = 2.023923397064209, val_loss = 0.7931851744651794\n",
      "epoch n°3392 : train_loss = 2.02453351020813, val_loss = 0.7939993739128113\n",
      "epoch n°3393 : train_loss = 2.0348997116088867, val_loss = 0.7954411506652832\n",
      "epoch n°3394 : train_loss = 2.03670334815979, val_loss = 0.7921572923660278\n",
      "epoch n°3395 : train_loss = 2.0269546508789062, val_loss = 0.7933915853500366\n",
      "epoch n°3396 : train_loss = 2.0245118141174316, val_loss = 0.7948426604270935\n",
      "epoch n°3397 : train_loss = 2.0288054943084717, val_loss = 0.7931956052780151\n",
      "epoch n°3398 : train_loss = 2.0331332683563232, val_loss = 0.7952793836593628\n",
      "epoch n°3399 : train_loss = 2.0347001552581787, val_loss = 0.7949663996696472\n",
      "epoch n°3400 : train_loss = 2.021482229232788, val_loss = 0.7914569973945618\n",
      "epoch n°3401 : train_loss = 2.0368289947509766, val_loss = 0.7936277985572815\n",
      "epoch n°3402 : train_loss = 2.0331506729125977, val_loss = 0.787376344203949\n",
      "epoch n°3403 : train_loss = 2.0308785438537598, val_loss = 0.7935708165168762\n",
      "epoch n°3404 : train_loss = 2.0277767181396484, val_loss = 0.7900523543357849\n",
      "epoch n°3405 : train_loss = 2.0378241539001465, val_loss = 0.7913386225700378\n",
      "epoch n°3406 : train_loss = 2.0323715209960938, val_loss = 0.7952573895454407\n",
      "epoch n°3407 : train_loss = 2.0292534828186035, val_loss = 0.7871184945106506\n",
      "epoch n°3408 : train_loss = 2.0242221355438232, val_loss = 0.7962426543235779\n",
      "epoch n°3409 : train_loss = 2.038893699645996, val_loss = 0.7927035093307495\n",
      "epoch n°3410 : train_loss = 2.026474714279175, val_loss = 0.7962386608123779\n",
      "epoch n°3411 : train_loss = 2.0364115238189697, val_loss = 0.7954154014587402\n",
      "epoch n°3412 : train_loss = 2.0247700214385986, val_loss = 0.7944854497909546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°3413 : train_loss = 2.0338501930236816, val_loss = 0.7925199270248413\n",
      "epoch n°3414 : train_loss = 2.0329220294952393, val_loss = 0.7900111675262451\n",
      "epoch n°3415 : train_loss = 2.033552646636963, val_loss = 0.7935681343078613\n",
      "epoch n°3416 : train_loss = 2.029850721359253, val_loss = 0.7903528809547424\n",
      "epoch n°3417 : train_loss = 2.0324344635009766, val_loss = 0.7979212999343872\n",
      "epoch n°3418 : train_loss = 2.026163339614868, val_loss = 0.7877604365348816\n",
      "epoch n°3419 : train_loss = 2.0288047790527344, val_loss = 0.7920109629631042\n",
      "epoch n°3420 : train_loss = 2.025299310684204, val_loss = 0.7910645604133606\n",
      "epoch n°3421 : train_loss = 2.0329487323760986, val_loss = 0.7938616871833801\n",
      "epoch n°3422 : train_loss = 2.0304391384124756, val_loss = 0.7930106520652771\n",
      "epoch n°3423 : train_loss = 2.028888463973999, val_loss = 0.7934586405754089\n",
      "epoch n°3424 : train_loss = 2.0329673290252686, val_loss = 0.7916716933250427\n",
      "epoch n°3425 : train_loss = 2.0242865085601807, val_loss = 0.79344242811203\n",
      "epoch n°3426 : train_loss = 2.034799814224243, val_loss = 0.7921007871627808\n",
      "epoch n°3427 : train_loss = 2.0288455486297607, val_loss = 0.7943434715270996\n",
      "epoch n°3428 : train_loss = 2.0296409130096436, val_loss = 0.7932117581367493\n",
      "epoch n°3429 : train_loss = 2.034022331237793, val_loss = 0.791211724281311\n",
      "epoch n°3430 : train_loss = 2.0297799110412598, val_loss = 0.7905915379524231\n",
      "epoch n°3431 : train_loss = 2.027188539505005, val_loss = 0.7968782186508179\n",
      "epoch n°3432 : train_loss = 2.0364458560943604, val_loss = 0.7907971739768982\n",
      "epoch n°3433 : train_loss = 2.027676820755005, val_loss = 0.7921815514564514\n",
      "epoch n°3434 : train_loss = 2.026097059249878, val_loss = 0.7904444932937622\n",
      "epoch n°3435 : train_loss = 2.029218912124634, val_loss = 0.7931028604507446\n",
      "epoch n°3436 : train_loss = 2.019351005554199, val_loss = 0.7880967259407043\n",
      "epoch n°3437 : train_loss = 2.0214123725891113, val_loss = 0.7905967831611633\n",
      "epoch n°3438 : train_loss = 2.022832155227661, val_loss = 0.7928929924964905\n",
      "epoch n°3439 : train_loss = 2.0315120220184326, val_loss = 0.7933692336082458\n",
      "epoch n°3440 : train_loss = 2.0282843112945557, val_loss = 0.7933815717697144\n",
      "epoch n°3441 : train_loss = 2.0319883823394775, val_loss = 0.7957730889320374\n",
      "epoch n°3442 : train_loss = 2.0222432613372803, val_loss = 0.7889454960823059\n",
      "epoch n°3443 : train_loss = 2.0244803428649902, val_loss = 0.7905819416046143\n",
      "epoch n°3444 : train_loss = 2.0313069820404053, val_loss = 0.7939274907112122\n",
      "epoch n°3445 : train_loss = 2.0236051082611084, val_loss = 0.7922458052635193\n",
      "epoch n°3446 : train_loss = 2.02828049659729, val_loss = 0.7908268570899963\n",
      "epoch n°3447 : train_loss = 2.0298783779144287, val_loss = 0.7932744026184082\n",
      "epoch n°3448 : train_loss = 2.0337932109832764, val_loss = 0.791219174861908\n",
      "epoch n°3449 : train_loss = 2.0232644081115723, val_loss = 0.7924460768699646\n",
      "epoch n°3450 : train_loss = 2.024538040161133, val_loss = 0.791230320930481\n",
      "epoch n°3451 : train_loss = 2.0281169414520264, val_loss = 0.792746901512146\n",
      "epoch n°3452 : train_loss = 2.0332882404327393, val_loss = 0.7950387597084045\n",
      "epoch n°3453 : train_loss = 2.029788017272949, val_loss = 0.7916397452354431\n",
      "epoch n°3454 : train_loss = 2.0280752182006836, val_loss = 0.794504702091217\n",
      "epoch n°3455 : train_loss = 2.0278916358947754, val_loss = 0.7921227216720581\n",
      "epoch n°3456 : train_loss = 2.0303893089294434, val_loss = 0.7909064292907715\n",
      "epoch n°3457 : train_loss = 2.0220017433166504, val_loss = 0.7924763560295105\n",
      "epoch n°3458 : train_loss = 2.024301767349243, val_loss = 0.7896115183830261\n",
      "epoch n°3459 : train_loss = 2.024700164794922, val_loss = 0.790477454662323\n",
      "epoch n°3460 : train_loss = 2.0304670333862305, val_loss = 0.7944796681404114\n",
      "epoch n°3461 : train_loss = 2.0407776832580566, val_loss = 0.7923606634140015\n",
      "epoch n°3462 : train_loss = 2.0297791957855225, val_loss = 0.7879462838172913\n",
      "epoch n°3463 : train_loss = 2.029275417327881, val_loss = 0.790016233921051\n",
      "epoch n°3464 : train_loss = 2.028202772140503, val_loss = 0.7918400168418884\n",
      "epoch n°3465 : train_loss = 2.0338916778564453, val_loss = 0.7923060059547424\n",
      "epoch n°3466 : train_loss = 2.031931161880493, val_loss = 0.7903705835342407\n",
      "epoch n°3467 : train_loss = 2.0254085063934326, val_loss = 0.7909132242202759\n",
      "epoch n°3468 : train_loss = 2.020787477493286, val_loss = 0.7942089438438416\n",
      "epoch n°3469 : train_loss = 2.034393548965454, val_loss = 0.787778377532959\n",
      "epoch n°3470 : train_loss = 2.0242655277252197, val_loss = 0.7924804091453552\n",
      "epoch n°3471 : train_loss = 2.029256820678711, val_loss = 0.7938340306282043\n",
      "epoch n°3472 : train_loss = 2.026333808898926, val_loss = 0.7864575386047363\n",
      "epoch n°3473 : train_loss = 2.0293405055999756, val_loss = 0.7890753746032715\n",
      "epoch n°3474 : train_loss = 2.032318592071533, val_loss = 0.7904682159423828\n",
      "epoch n°3475 : train_loss = 2.021888256072998, val_loss = 0.7948543429374695\n",
      "epoch n°3476 : train_loss = 2.026709794998169, val_loss = 0.7917553782463074\n",
      "epoch n°3477 : train_loss = 2.0336501598358154, val_loss = 0.7931707501411438\n",
      "epoch n°3478 : train_loss = 2.0244500637054443, val_loss = 0.7924855351448059\n",
      "epoch n°3479 : train_loss = 2.0311195850372314, val_loss = 0.7910608053207397\n",
      "epoch n°3480 : train_loss = 2.0311639308929443, val_loss = 0.7949292659759521\n",
      "epoch n°3481 : train_loss = 2.033933401107788, val_loss = 0.7895929217338562\n",
      "epoch n°3482 : train_loss = 2.0235610008239746, val_loss = 0.7908042073249817\n",
      "epoch n°3483 : train_loss = 2.0196311473846436, val_loss = 0.7933437824249268\n",
      "epoch n°3484 : train_loss = 2.022918701171875, val_loss = 0.7961807250976562\n",
      "epoch n°3485 : train_loss = 2.0244944095611572, val_loss = 0.7916505336761475\n",
      "epoch n°3486 : train_loss = 2.024968147277832, val_loss = 0.7962404489517212\n",
      "epoch n°3487 : train_loss = 2.02217960357666, val_loss = 0.7903217673301697\n",
      "epoch n°3488 : train_loss = 2.029970407485962, val_loss = 0.7934836745262146\n",
      "epoch n°3489 : train_loss = 2.0235533714294434, val_loss = 0.7891784906387329\n",
      "epoch n°3490 : train_loss = 2.040560007095337, val_loss = 0.7941914200782776\n",
      "epoch n°3491 : train_loss = 2.0310397148132324, val_loss = 0.7917676568031311\n",
      "epoch n°3492 : train_loss = 2.0294597148895264, val_loss = 0.7955889701843262\n",
      "epoch n°3493 : train_loss = 2.0288491249084473, val_loss = 0.79277503490448\n",
      "epoch n°3494 : train_loss = 2.031963348388672, val_loss = 0.7913352847099304\n",
      "epoch n°3495 : train_loss = 2.0334010124206543, val_loss = 0.7931928634643555\n",
      "epoch n°3496 : train_loss = 2.01977276802063, val_loss = 0.7938216328620911\n",
      "epoch n°3497 : train_loss = 2.020014524459839, val_loss = 0.79493248462677\n",
      "epoch n°3498 : train_loss = 2.029470920562744, val_loss = 0.7923095226287842\n",
      "epoch n°3499 : train_loss = 2.0237464904785156, val_loss = 0.7920924425125122\n",
      "epoch n°3500 : train_loss = 2.0244085788726807, val_loss = 0.7927700877189636\n",
      "epoch n°3501 : train_loss = 2.0225632190704346, val_loss = 0.7958280444145203\n",
      "epoch n°3502 : train_loss = 2.032182455062866, val_loss = 0.7947918772697449\n",
      "epoch n°3503 : train_loss = 2.0162620544433594, val_loss = 0.7943477630615234\n",
      "epoch n°3504 : train_loss = 2.0314557552337646, val_loss = 0.7959672808647156\n",
      "epoch n°3505 : train_loss = 2.0287065505981445, val_loss = 0.7923073768615723\n",
      "epoch n°3506 : train_loss = 2.0317959785461426, val_loss = 0.7928565144538879\n",
      "epoch n°3507 : train_loss = 2.024120569229126, val_loss = 0.7949082851409912\n",
      "epoch n°3508 : train_loss = 2.0309813022613525, val_loss = 0.7920088171958923\n",
      "epoch n°3509 : train_loss = 2.023667573928833, val_loss = 0.7927496433258057\n",
      "epoch n°3510 : train_loss = 2.020535469055176, val_loss = 0.7917635440826416\n",
      "epoch n°3511 : train_loss = 2.0220277309417725, val_loss = 0.794086217880249\n",
      "epoch n°3512 : train_loss = 2.0198206901550293, val_loss = 0.7949895858764648\n",
      "epoch n°3513 : train_loss = 2.024430274963379, val_loss = 0.7939116954803467\n",
      "epoch n°3514 : train_loss = 2.0186703205108643, val_loss = 0.7920311093330383\n",
      "epoch n°3515 : train_loss = 2.0276107788085938, val_loss = 0.791250467300415\n",
      "epoch n°3516 : train_loss = 2.0269131660461426, val_loss = 0.7904273867607117\n",
      "epoch n°3517 : train_loss = 2.0305609703063965, val_loss = 0.7967319488525391\n",
      "epoch n°3518 : train_loss = 2.0258142948150635, val_loss = 0.7890326380729675\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°3519 : train_loss = 2.025848388671875, val_loss = 0.7928685545921326\n",
      "epoch n°3520 : train_loss = 2.0218029022216797, val_loss = 0.7898856997489929\n",
      "epoch n°3521 : train_loss = 2.0165350437164307, val_loss = 0.7923181653022766\n",
      "epoch n°3522 : train_loss = 2.033024787902832, val_loss = 0.790270209312439\n",
      "epoch n°3523 : train_loss = 2.0227317810058594, val_loss = 0.7946923971176147\n",
      "epoch n°3524 : train_loss = 2.020996332168579, val_loss = 0.791409969329834\n",
      "epoch n°3525 : train_loss = 2.0228419303894043, val_loss = 0.7933187484741211\n",
      "epoch n°3526 : train_loss = 2.029761791229248, val_loss = 0.794736385345459\n",
      "epoch n°3527 : train_loss = 2.028942108154297, val_loss = 0.7913132905960083\n",
      "epoch n°3528 : train_loss = 2.022890329360962, val_loss = 0.7939503788948059\n",
      "epoch n°3529 : train_loss = 2.022724151611328, val_loss = 0.7966133952140808\n",
      "epoch n°3530 : train_loss = 2.035919666290283, val_loss = 0.7920951843261719\n",
      "epoch n°3531 : train_loss = 2.0210533142089844, val_loss = 0.7907290458679199\n",
      "epoch n°3532 : train_loss = 2.027778387069702, val_loss = 0.7911754846572876\n",
      "epoch n°3533 : train_loss = 2.0267510414123535, val_loss = 0.7919852137565613\n",
      "epoch n°3534 : train_loss = 2.0234227180480957, val_loss = 0.7876684665679932\n",
      "epoch n°3535 : train_loss = 2.0240347385406494, val_loss = 0.7880776524543762\n",
      "epoch n°3536 : train_loss = 2.009967803955078, val_loss = 0.7911579608917236\n",
      "epoch n°3537 : train_loss = 2.0151431560516357, val_loss = 0.7904267907142639\n",
      "epoch n°3538 : train_loss = 2.026205539703369, val_loss = 0.7901467680931091\n",
      "epoch n°3539 : train_loss = 2.0226833820343018, val_loss = 0.7926669120788574\n",
      "epoch n°3540 : train_loss = 2.0388989448547363, val_loss = 0.7911738753318787\n",
      "epoch n°3541 : train_loss = 2.0213029384613037, val_loss = 0.7916760444641113\n",
      "epoch n°3542 : train_loss = 2.024775743484497, val_loss = 0.7915878295898438\n",
      "epoch n°3543 : train_loss = 2.024912118911743, val_loss = 0.7911823987960815\n",
      "epoch n°3544 : train_loss = 2.0223889350891113, val_loss = 0.7926599979400635\n",
      "epoch n°3545 : train_loss = 2.01973819732666, val_loss = 0.7919440269470215\n",
      "epoch n°3546 : train_loss = 2.0177948474884033, val_loss = 0.7879300713539124\n",
      "epoch n°3547 : train_loss = 2.025923490524292, val_loss = 0.7876051068305969\n",
      "epoch n°3548 : train_loss = 2.020228624343872, val_loss = 0.7897194027900696\n",
      "epoch n°3549 : train_loss = 2.0311050415039062, val_loss = 0.7907213568687439\n",
      "epoch n°3550 : train_loss = 2.0240020751953125, val_loss = 0.7914209365844727\n",
      "epoch n°3551 : train_loss = 2.0149028301239014, val_loss = 0.7936796545982361\n",
      "epoch n°3552 : train_loss = 2.0264477729797363, val_loss = 0.7948240637779236\n",
      "epoch n°3553 : train_loss = 2.0183401107788086, val_loss = 0.7902321219444275\n",
      "epoch n°3554 : train_loss = 2.0253794193267822, val_loss = 0.7898595333099365\n",
      "epoch n°3555 : train_loss = 2.0176315307617188, val_loss = 0.7934627532958984\n",
      "epoch n°3556 : train_loss = 2.02105975151062, val_loss = 0.7912712693214417\n",
      "epoch n°3557 : train_loss = 2.023399829864502, val_loss = 0.7950608134269714\n",
      "epoch n°3558 : train_loss = 2.0250935554504395, val_loss = 0.79072105884552\n",
      "epoch n°3559 : train_loss = 2.0397236347198486, val_loss = 0.7922917008399963\n",
      "epoch n°3560 : train_loss = 2.022841215133667, val_loss = 0.7966688871383667\n",
      "epoch n°3561 : train_loss = 2.019146203994751, val_loss = 0.7911885380744934\n",
      "epoch n°3562 : train_loss = 2.0149598121643066, val_loss = 0.7908552289009094\n",
      "epoch n°3563 : train_loss = 2.023404359817505, val_loss = 0.7895416617393494\n",
      "epoch n°3564 : train_loss = 2.014051914215088, val_loss = 0.7906090021133423\n",
      "epoch n°3565 : train_loss = 2.021195411682129, val_loss = 0.7891932725906372\n",
      "epoch n°3566 : train_loss = 2.0185887813568115, val_loss = 0.7908585667610168\n",
      "epoch n°3567 : train_loss = 2.021507740020752, val_loss = 0.7953543066978455\n",
      "epoch n°3568 : train_loss = 2.0313851833343506, val_loss = 0.7943565845489502\n",
      "epoch n°3569 : train_loss = 2.0169992446899414, val_loss = 0.795156717300415\n",
      "epoch n°3570 : train_loss = 2.0211708545684814, val_loss = 0.797672688961029\n",
      "epoch n°3571 : train_loss = 2.021204948425293, val_loss = 0.7900848984718323\n",
      "epoch n°3572 : train_loss = 2.023097276687622, val_loss = 0.7919389605522156\n",
      "epoch n°3573 : train_loss = 2.022634983062744, val_loss = 0.7965359091758728\n",
      "epoch n°3574 : train_loss = 2.0375962257385254, val_loss = 0.7955026626586914\n",
      "epoch n°3575 : train_loss = 2.025357484817505, val_loss = 0.792289674282074\n",
      "epoch n°3576 : train_loss = 2.0211410522460938, val_loss = 0.7959142923355103\n",
      "epoch n°3577 : train_loss = 2.0247855186462402, val_loss = 0.7911912798881531\n",
      "epoch n°3578 : train_loss = 2.021843671798706, val_loss = 0.793378472328186\n",
      "epoch n°3579 : train_loss = 2.0251379013061523, val_loss = 0.7952874302864075\n",
      "epoch n°3580 : train_loss = 2.0301308631896973, val_loss = 0.791146457195282\n",
      "epoch n°3581 : train_loss = 2.0158116817474365, val_loss = 0.7896058559417725\n",
      "epoch n°3582 : train_loss = 2.025876760482788, val_loss = 0.7918956279754639\n",
      "epoch n°3583 : train_loss = 2.0305936336517334, val_loss = 0.7916643023490906\n",
      "epoch n°3584 : train_loss = 2.0276951789855957, val_loss = 0.7896414399147034\n",
      "epoch n°3585 : train_loss = 2.0276951789855957, val_loss = 0.7895743250846863\n",
      "epoch n°3586 : train_loss = 2.0192818641662598, val_loss = 0.7918570041656494\n",
      "epoch n°3587 : train_loss = 2.025742292404175, val_loss = 0.7897746562957764\n",
      "epoch n°3588 : train_loss = 2.0235607624053955, val_loss = 0.7939275503158569\n",
      "epoch n°3589 : train_loss = 2.027863025665283, val_loss = 0.7895095348358154\n",
      "epoch n°3590 : train_loss = 2.02604079246521, val_loss = 0.7915747165679932\n",
      "epoch n°3591 : train_loss = 2.0296478271484375, val_loss = 0.7914659380912781\n",
      "epoch n°3592 : train_loss = 2.0209786891937256, val_loss = 0.79435133934021\n",
      "epoch n°3593 : train_loss = 2.01328444480896, val_loss = 0.7880110740661621\n",
      "epoch n°3594 : train_loss = 2.0269176959991455, val_loss = 0.7901407480239868\n",
      "epoch n°3595 : train_loss = 2.024763822555542, val_loss = 0.7936105132102966\n",
      "epoch n°3596 : train_loss = 2.0270721912384033, val_loss = 0.7871463298797607\n",
      "epoch n°3597 : train_loss = 2.02925181388855, val_loss = 0.7922230958938599\n",
      "epoch n°3598 : train_loss = 2.0214762687683105, val_loss = 0.7919813990592957\n",
      "epoch n°3599 : train_loss = 2.026397943496704, val_loss = 0.7937833666801453\n",
      "epoch n°3600 : train_loss = 2.0216760635375977, val_loss = 0.7914533615112305\n",
      "epoch n°3601 : train_loss = 2.0232841968536377, val_loss = 0.7904567122459412\n",
      "epoch n°3602 : train_loss = 2.026276111602783, val_loss = 0.7912794351577759\n",
      "epoch n°3603 : train_loss = 2.029672145843506, val_loss = 0.7922612428665161\n",
      "epoch n°3604 : train_loss = 2.0228734016418457, val_loss = 0.7915149331092834\n",
      "epoch n°3605 : train_loss = 2.0234293937683105, val_loss = 0.787595808506012\n",
      "epoch n°3606 : train_loss = 2.016118049621582, val_loss = 0.7903077602386475\n",
      "epoch n°3607 : train_loss = 2.0246784687042236, val_loss = 0.7896628975868225\n",
      "epoch n°3608 : train_loss = 2.0165529251098633, val_loss = 0.7951350212097168\n",
      "epoch n°3609 : train_loss = 2.030243158340454, val_loss = 0.7911622524261475\n",
      "epoch n°3610 : train_loss = 2.030261993408203, val_loss = 0.792438805103302\n",
      "epoch n°3611 : train_loss = 2.032200813293457, val_loss = 0.7941967248916626\n",
      "epoch n°3612 : train_loss = 2.0269079208374023, val_loss = 0.7914800047874451\n",
      "epoch n°3613 : train_loss = 2.0238912105560303, val_loss = 0.7896604537963867\n",
      "epoch n°3614 : train_loss = 2.013313055038452, val_loss = 0.7929190993309021\n",
      "epoch n°3615 : train_loss = 2.0211851596832275, val_loss = 0.7929072380065918\n",
      "epoch n°3616 : train_loss = 2.020890235900879, val_loss = 0.7905102372169495\n",
      "epoch n°3617 : train_loss = 2.0246434211730957, val_loss = 0.7927693128585815\n",
      "epoch n°3618 : train_loss = 2.0208029747009277, val_loss = 0.7943651080131531\n",
      "epoch n°3619 : train_loss = 2.021178722381592, val_loss = 0.7976001501083374\n",
      "epoch n°3620 : train_loss = 2.022780656814575, val_loss = 0.7913488745689392\n",
      "epoch n°3621 : train_loss = 2.023638963699341, val_loss = 0.7915667295455933\n",
      "epoch n°3622 : train_loss = 2.020648717880249, val_loss = 0.7940466403961182\n",
      "epoch n°3623 : train_loss = 2.022693634033203, val_loss = 0.7928032279014587\n",
      "epoch n°3624 : train_loss = 2.0224835872650146, val_loss = 0.7909821271896362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°3625 : train_loss = 2.023667812347412, val_loss = 0.7925688028335571\n",
      "epoch n°3626 : train_loss = 2.023810386657715, val_loss = 0.7897059917449951\n",
      "epoch n°3627 : train_loss = 2.0209944248199463, val_loss = 0.7899292707443237\n",
      "epoch n°3628 : train_loss = 2.0331673622131348, val_loss = 0.7908260822296143\n",
      "epoch n°3629 : train_loss = 2.02471661567688, val_loss = 0.7919877767562866\n",
      "epoch n°3630 : train_loss = 2.0270798206329346, val_loss = 0.7929365634918213\n",
      "epoch n°3631 : train_loss = 2.027400255203247, val_loss = 0.7872515320777893\n",
      "epoch n°3632 : train_loss = 2.022260904312134, val_loss = 0.7885178327560425\n",
      "epoch n°3633 : train_loss = 2.024932861328125, val_loss = 0.7889397740364075\n",
      "epoch n°3634 : train_loss = 2.0281050205230713, val_loss = 0.7912409901618958\n",
      "epoch n°3635 : train_loss = 2.027357816696167, val_loss = 0.7883908152580261\n",
      "epoch n°3636 : train_loss = 2.0219779014587402, val_loss = 0.7891734838485718\n",
      "epoch n°3637 : train_loss = 2.023719072341919, val_loss = 0.7876824736595154\n",
      "epoch n°3638 : train_loss = 2.014099359512329, val_loss = 0.7893521189689636\n",
      "epoch n°3639 : train_loss = 2.015066146850586, val_loss = 0.7946745157241821\n",
      "epoch n°3640 : train_loss = 2.019514799118042, val_loss = 0.7897254824638367\n",
      "epoch n°3641 : train_loss = 2.0268805027008057, val_loss = 0.792603611946106\n",
      "epoch n°3642 : train_loss = 2.0145645141601562, val_loss = 0.7950274348258972\n",
      "epoch n°3643 : train_loss = 2.0172252655029297, val_loss = 0.7894002199172974\n",
      "epoch n°3644 : train_loss = 2.020155668258667, val_loss = 0.7926172018051147\n",
      "epoch n°3645 : train_loss = 2.0201380252838135, val_loss = 0.7908766865730286\n",
      "epoch n°3646 : train_loss = 2.0241663455963135, val_loss = 0.7924627065658569\n",
      "epoch n°3647 : train_loss = 2.0164268016815186, val_loss = 0.7939527630805969\n",
      "epoch n°3648 : train_loss = 2.0183839797973633, val_loss = 0.7910773158073425\n",
      "epoch n°3649 : train_loss = 2.0140764713287354, val_loss = 0.7912598848342896\n",
      "epoch n°3650 : train_loss = 2.0231432914733887, val_loss = 0.7949459552764893\n",
      "epoch n°3651 : train_loss = 2.022718667984009, val_loss = 0.7970795631408691\n",
      "epoch n°3652 : train_loss = 2.0140974521636963, val_loss = 0.7902507781982422\n",
      "epoch n°3653 : train_loss = 2.0343286991119385, val_loss = 0.7899079918861389\n",
      "epoch n°3654 : train_loss = 2.026401996612549, val_loss = 0.7909557819366455\n",
      "epoch n°3655 : train_loss = 2.0290117263793945, val_loss = 0.7891188859939575\n",
      "epoch n°3656 : train_loss = 2.0192477703094482, val_loss = 0.7892489433288574\n",
      "epoch n°3657 : train_loss = 2.0260963439941406, val_loss = 0.7924983501434326\n",
      "epoch n°3658 : train_loss = 2.020521879196167, val_loss = 0.7936460971832275\n",
      "epoch n°3659 : train_loss = 2.0183753967285156, val_loss = 0.7890658974647522\n",
      "epoch n°3660 : train_loss = 2.0204644203186035, val_loss = 0.7937023639678955\n",
      "epoch n°3661 : train_loss = 2.0303988456726074, val_loss = 0.7865490317344666\n",
      "epoch n°3662 : train_loss = 2.026859760284424, val_loss = 0.7923435568809509\n",
      "epoch n°3663 : train_loss = 2.014138698577881, val_loss = 0.7911830544471741\n",
      "epoch n°3664 : train_loss = 2.0192618370056152, val_loss = 0.7911098599433899\n",
      "epoch n°3665 : train_loss = 2.0264172554016113, val_loss = 0.7916189432144165\n",
      "epoch n°3666 : train_loss = 2.0273077487945557, val_loss = 0.792335033416748\n",
      "epoch n°3667 : train_loss = 2.0238308906555176, val_loss = 0.7901984453201294\n",
      "epoch n°3668 : train_loss = 2.0170021057128906, val_loss = 0.7945964932441711\n",
      "epoch n°3669 : train_loss = 2.0104427337646484, val_loss = 0.7926143407821655\n",
      "epoch n°3670 : train_loss = 2.029407262802124, val_loss = 0.7883180975914001\n",
      "epoch n°3671 : train_loss = 2.021927833557129, val_loss = 0.7901240587234497\n",
      "epoch n°3672 : train_loss = 2.021127700805664, val_loss = 0.7926744818687439\n",
      "epoch n°3673 : train_loss = 2.0106818675994873, val_loss = 0.7923150658607483\n",
      "epoch n°3674 : train_loss = 2.018933057785034, val_loss = 0.7892314195632935\n",
      "epoch n°3675 : train_loss = 2.011662483215332, val_loss = 0.7922837734222412\n",
      "epoch n°3676 : train_loss = 2.0183424949645996, val_loss = 0.7921499013900757\n",
      "epoch n°3677 : train_loss = 2.0075674057006836, val_loss = 0.7924558520317078\n",
      "epoch n°3678 : train_loss = 2.0213708877563477, val_loss = 0.7930985689163208\n",
      "epoch n°3679 : train_loss = 2.02458119392395, val_loss = 0.7902460694313049\n",
      "epoch n°3680 : train_loss = 2.015045642852783, val_loss = 0.7925419807434082\n",
      "epoch n°3681 : train_loss = 2.0200486183166504, val_loss = 0.7932397723197937\n",
      "epoch n°3682 : train_loss = 2.0230510234832764, val_loss = 0.7917464971542358\n",
      "epoch n°3683 : train_loss = 2.0137391090393066, val_loss = 0.787395715713501\n",
      "epoch n°3684 : train_loss = 2.0172367095947266, val_loss = 0.7907363176345825\n",
      "epoch n°3685 : train_loss = 2.0134501457214355, val_loss = 0.7906395792961121\n",
      "epoch n°3686 : train_loss = 2.022347927093506, val_loss = 0.7934385538101196\n",
      "epoch n°3687 : train_loss = 2.019979238510132, val_loss = 0.7906101942062378\n",
      "epoch n°3688 : train_loss = 2.021756172180176, val_loss = 0.7901973128318787\n",
      "epoch n°3689 : train_loss = 2.015345811843872, val_loss = 0.7906728386878967\n",
      "epoch n°3690 : train_loss = 2.0252692699432373, val_loss = 0.7883468270301819\n",
      "epoch n°3691 : train_loss = 2.014991283416748, val_loss = 0.7931616306304932\n",
      "epoch n°3692 : train_loss = 2.031137466430664, val_loss = 0.7909680604934692\n",
      "epoch n°3693 : train_loss = 2.0255625247955322, val_loss = 0.7905569076538086\n",
      "epoch n°3694 : train_loss = 2.016270875930786, val_loss = 0.793176531791687\n",
      "epoch n°3695 : train_loss = 2.0144612789154053, val_loss = 0.7895492911338806\n",
      "epoch n°3696 : train_loss = 2.030184745788574, val_loss = 0.7939242124557495\n",
      "epoch n°3697 : train_loss = 2.0242652893066406, val_loss = 0.7900751233100891\n",
      "epoch n°3698 : train_loss = 2.0161921977996826, val_loss = 0.7925041913986206\n",
      "epoch n°3699 : train_loss = 2.0172009468078613, val_loss = 0.7927798628807068\n",
      "epoch n°3700 : train_loss = 2.0187549591064453, val_loss = 0.7925868034362793\n",
      "epoch n°3701 : train_loss = 2.0284183025360107, val_loss = 0.7933549284934998\n",
      "epoch n°3702 : train_loss = 2.013021230697632, val_loss = 0.794317901134491\n",
      "epoch n°3703 : train_loss = 2.017735242843628, val_loss = 0.7925277352333069\n",
      "epoch n°3704 : train_loss = 2.0273234844207764, val_loss = 0.7923150658607483\n",
      "epoch n°3705 : train_loss = 2.020962953567505, val_loss = 0.7966723442077637\n",
      "epoch n°3706 : train_loss = 2.0154454708099365, val_loss = 0.7888280749320984\n",
      "epoch n°3707 : train_loss = 2.0150039196014404, val_loss = 0.7898949384689331\n",
      "epoch n°3708 : train_loss = 2.01704478263855, val_loss = 0.7916877269744873\n",
      "epoch n°3709 : train_loss = 2.0174553394317627, val_loss = 0.7937166690826416\n",
      "epoch n°3710 : train_loss = 2.024702548980713, val_loss = 0.7919968962669373\n",
      "epoch n°3711 : train_loss = 2.0267131328582764, val_loss = 0.7894413471221924\n",
      "epoch n°3712 : train_loss = 2.011437177658081, val_loss = 0.7885861992835999\n",
      "epoch n°3713 : train_loss = 2.019361972808838, val_loss = 0.794599711894989\n",
      "epoch n°3714 : train_loss = 2.017465829849243, val_loss = 0.7942087054252625\n",
      "epoch n°3715 : train_loss = 2.014193534851074, val_loss = 0.7920641303062439\n",
      "epoch n°3716 : train_loss = 2.022449493408203, val_loss = 0.7923327684402466\n",
      "epoch n°3717 : train_loss = 2.012960910797119, val_loss = 0.7877573370933533\n",
      "epoch n°3718 : train_loss = 2.002307891845703, val_loss = 0.788567841053009\n",
      "epoch n°3719 : train_loss = 2.0162007808685303, val_loss = 0.7912366390228271\n",
      "epoch n°3720 : train_loss = 2.0145010948181152, val_loss = 0.7929390072822571\n",
      "epoch n°3721 : train_loss = 2.0234458446502686, val_loss = 0.7937784790992737\n",
      "epoch n°3722 : train_loss = 2.022606372833252, val_loss = 0.7891892194747925\n",
      "epoch n°3723 : train_loss = 2.0252726078033447, val_loss = 0.7921218276023865\n",
      "epoch n°3724 : train_loss = 2.0224380493164062, val_loss = 0.7912456393241882\n",
      "epoch n°3725 : train_loss = 2.0178301334381104, val_loss = 0.794887125492096\n",
      "epoch n°3726 : train_loss = 2.0270864963531494, val_loss = 0.795240581035614\n",
      "epoch n°3727 : train_loss = 2.0170211791992188, val_loss = 0.7939354181289673\n",
      "epoch n°3728 : train_loss = 2.0212461948394775, val_loss = 0.7967809438705444\n",
      "epoch n°3729 : train_loss = 2.014540433883667, val_loss = 0.7929017543792725\n",
      "epoch n°3730 : train_loss = 2.0246286392211914, val_loss = 0.7901146411895752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°3731 : train_loss = 2.014434337615967, val_loss = 0.7908327579498291\n",
      "epoch n°3732 : train_loss = 2.0156264305114746, val_loss = 0.7921072840690613\n",
      "epoch n°3733 : train_loss = 2.0179977416992188, val_loss = 0.7923351526260376\n",
      "epoch n°3734 : train_loss = 2.0170705318450928, val_loss = 0.7974264025688171\n",
      "epoch n°3735 : train_loss = 2.030379295349121, val_loss = 0.7918828129768372\n",
      "epoch n°3736 : train_loss = 2.0181801319122314, val_loss = 0.7939960956573486\n",
      "epoch n°3737 : train_loss = 2.0298900604248047, val_loss = 0.7933679819107056\n",
      "epoch n°3738 : train_loss = 2.0277669429779053, val_loss = 0.7863484025001526\n",
      "epoch n°3739 : train_loss = 2.023834228515625, val_loss = 0.7893823981285095\n",
      "epoch n°3740 : train_loss = 2.019606828689575, val_loss = 0.7892364263534546\n",
      "epoch n°3741 : train_loss = 2.020435094833374, val_loss = 0.7930689454078674\n",
      "epoch n°3742 : train_loss = 2.0236191749572754, val_loss = 0.7929866313934326\n",
      "epoch n°3743 : train_loss = 2.016726016998291, val_loss = 0.7914563417434692\n",
      "epoch n°3744 : train_loss = 2.0269157886505127, val_loss = 0.7895159125328064\n",
      "epoch n°3745 : train_loss = 2.018641948699951, val_loss = 0.7935490608215332\n",
      "epoch n°3746 : train_loss = 2.0171737670898438, val_loss = 0.7905598282814026\n",
      "epoch n°3747 : train_loss = 2.0183732509613037, val_loss = 0.7935234308242798\n",
      "epoch n°3748 : train_loss = 2.0172533988952637, val_loss = 0.7899226546287537\n",
      "epoch n°3749 : train_loss = 2.0194292068481445, val_loss = 0.7929558753967285\n",
      "epoch n°3750 : train_loss = 2.0163357257843018, val_loss = 0.7905067205429077\n",
      "epoch n°3751 : train_loss = 2.0212910175323486, val_loss = 0.7908860445022583\n",
      "epoch n°3752 : train_loss = 2.021172523498535, val_loss = 0.7917537093162537\n",
      "epoch n°3753 : train_loss = 2.03249454498291, val_loss = 0.7955196499824524\n",
      "epoch n°3754 : train_loss = 2.0236783027648926, val_loss = 0.7901009917259216\n",
      "epoch n°3755 : train_loss = 2.021674871444702, val_loss = 0.788808286190033\n",
      "epoch n°3756 : train_loss = 2.0216236114501953, val_loss = 0.7931463122367859\n",
      "epoch n°3757 : train_loss = 2.0055768489837646, val_loss = 0.791626513004303\n",
      "epoch n°3758 : train_loss = 2.0138790607452393, val_loss = 0.7932279706001282\n",
      "epoch n°3759 : train_loss = 2.0273327827453613, val_loss = 0.793510913848877\n",
      "epoch n°3760 : train_loss = 2.009838342666626, val_loss = 0.7950928807258606\n",
      "epoch n°3761 : train_loss = 2.019773244857788, val_loss = 0.7906385660171509\n",
      "epoch n°3762 : train_loss = 2.023810625076294, val_loss = 0.7877914309501648\n",
      "epoch n°3763 : train_loss = 2.014737367630005, val_loss = 0.7913686633110046\n",
      "epoch n°3764 : train_loss = 2.017212390899658, val_loss = 0.7895500063896179\n",
      "epoch n°3765 : train_loss = 2.0146548748016357, val_loss = 0.7919062972068787\n",
      "epoch n°3766 : train_loss = 2.0159995555877686, val_loss = 0.7912347316741943\n",
      "epoch n°3767 : train_loss = 2.019130229949951, val_loss = 0.7939245700836182\n",
      "epoch n°3768 : train_loss = 2.0138237476348877, val_loss = 0.7934141159057617\n",
      "epoch n°3769 : train_loss = 2.020723581314087, val_loss = 0.7965728044509888\n",
      "epoch n°3770 : train_loss = 2.0261764526367188, val_loss = 0.7930015921592712\n",
      "epoch n°3771 : train_loss = 2.0215775966644287, val_loss = 0.7914568185806274\n",
      "epoch n°3772 : train_loss = 2.0226902961730957, val_loss = 0.7926256656646729\n",
      "epoch n°3773 : train_loss = 2.0294177532196045, val_loss = 0.7914369106292725\n",
      "epoch n°3774 : train_loss = 2.0230820178985596, val_loss = 0.7918083071708679\n",
      "epoch n°3775 : train_loss = 2.014437198638916, val_loss = 0.7972244024276733\n",
      "epoch n°3776 : train_loss = 2.0198800563812256, val_loss = 0.7915388941764832\n",
      "epoch n°3777 : train_loss = 2.0172746181488037, val_loss = 0.792224645614624\n",
      "epoch n°3778 : train_loss = 2.0251924991607666, val_loss = 0.7911145091056824\n",
      "epoch n°3779 : train_loss = 2.0110528469085693, val_loss = 0.7909097075462341\n",
      "epoch n°3780 : train_loss = 2.01989483833313, val_loss = 0.7901579737663269\n",
      "epoch n°3781 : train_loss = 2.021225690841675, val_loss = 0.7894142270088196\n",
      "epoch n°3782 : train_loss = 2.0260629653930664, val_loss = 0.7898116111755371\n",
      "epoch n°3783 : train_loss = 2.0199201107025146, val_loss = 0.7875231504440308\n",
      "epoch n°3784 : train_loss = 2.022853374481201, val_loss = 0.7928195595741272\n",
      "epoch n°3785 : train_loss = 2.0154523849487305, val_loss = 0.7905721068382263\n",
      "epoch n°3786 : train_loss = 2.0178780555725098, val_loss = 0.7887403964996338\n",
      "epoch n°3787 : train_loss = 2.02488112449646, val_loss = 0.79727703332901\n",
      "epoch n°3788 : train_loss = 2.013317108154297, val_loss = 0.7899692058563232\n",
      "epoch n°3789 : train_loss = 2.0267231464385986, val_loss = 0.7908478379249573\n",
      "epoch n°3790 : train_loss = 2.0255367755889893, val_loss = 0.7913745641708374\n",
      "epoch n°3791 : train_loss = 2.0172619819641113, val_loss = 0.791059672832489\n",
      "epoch n°3792 : train_loss = 2.0054547786712646, val_loss = 0.788302481174469\n",
      "epoch n°3793 : train_loss = 2.0185225009918213, val_loss = 0.7941904664039612\n",
      "epoch n°3794 : train_loss = 2.020475149154663, val_loss = 0.790705680847168\n",
      "epoch n°3795 : train_loss = 2.009636163711548, val_loss = 0.790789783000946\n",
      "epoch n°3796 : train_loss = 2.0168018341064453, val_loss = 0.7923109531402588\n",
      "epoch n°3797 : train_loss = 2.0152883529663086, val_loss = 0.7938818335533142\n",
      "epoch n°3798 : train_loss = 2.0122852325439453, val_loss = 0.7919783592224121\n",
      "epoch n°3799 : train_loss = 2.021925687789917, val_loss = 0.7910671830177307\n",
      "epoch n°3800 : train_loss = 2.010469675064087, val_loss = 0.792445719242096\n",
      "epoch n°3801 : train_loss = 2.0190253257751465, val_loss = 0.7907900810241699\n",
      "epoch n°3802 : train_loss = 2.028090238571167, val_loss = 0.7935397624969482\n",
      "epoch n°3803 : train_loss = 2.0175063610076904, val_loss = 0.7908463478088379\n",
      "epoch n°3804 : train_loss = 2.0217554569244385, val_loss = 0.7902864813804626\n",
      "epoch n°3805 : train_loss = 2.0157413482666016, val_loss = 0.795401394367218\n",
      "epoch n°3806 : train_loss = 2.0132036209106445, val_loss = 0.7921643853187561\n",
      "epoch n°3807 : train_loss = 2.023054838180542, val_loss = 0.7933446168899536\n",
      "epoch n°3808 : train_loss = 2.008145570755005, val_loss = 0.7939087748527527\n",
      "epoch n°3809 : train_loss = 2.0277445316314697, val_loss = 0.7873534560203552\n",
      "epoch n°3810 : train_loss = 2.023181915283203, val_loss = 0.7941444516181946\n",
      "epoch n°3811 : train_loss = 2.0144083499908447, val_loss = 0.7893916368484497\n",
      "epoch n°3812 : train_loss = 2.0124504566192627, val_loss = 0.7941750288009644\n",
      "epoch n°3813 : train_loss = 2.014127492904663, val_loss = 0.7945802211761475\n",
      "epoch n°3814 : train_loss = 2.016730308532715, val_loss = 0.7879481911659241\n",
      "epoch n°3815 : train_loss = 2.0210561752319336, val_loss = 0.7949170470237732\n",
      "epoch n°3816 : train_loss = 2.0163702964782715, val_loss = 0.7900949716567993\n",
      "epoch n°3817 : train_loss = 2.0098936557769775, val_loss = 0.7911785244941711\n",
      "epoch n°3818 : train_loss = 2.0187182426452637, val_loss = 0.7876362204551697\n",
      "epoch n°3819 : train_loss = 2.014080286026001, val_loss = 0.7920018434524536\n",
      "epoch n°3820 : train_loss = 2.0182559490203857, val_loss = 0.7928166389465332\n",
      "epoch n°3821 : train_loss = 2.0172464847564697, val_loss = 0.7938240766525269\n",
      "epoch n°3822 : train_loss = 2.014958620071411, val_loss = 0.7916966080665588\n",
      "epoch n°3823 : train_loss = 2.0166964530944824, val_loss = 0.7904733419418335\n",
      "epoch n°3824 : train_loss = 2.014995813369751, val_loss = 0.7921226024627686\n",
      "epoch n°3825 : train_loss = 2.023676872253418, val_loss = 0.7886144518852234\n",
      "epoch n°3826 : train_loss = 2.0207509994506836, val_loss = 0.7914273142814636\n",
      "epoch n°3827 : train_loss = 2.0265331268310547, val_loss = 0.7902201414108276\n",
      "epoch n°3828 : train_loss = 2.017204999923706, val_loss = 0.7867484092712402\n",
      "epoch n°3829 : train_loss = 2.0218541622161865, val_loss = 0.7913674712181091\n",
      "epoch n°3830 : train_loss = 2.018639326095581, val_loss = 0.7904332876205444\n",
      "epoch n°3831 : train_loss = 2.010551929473877, val_loss = 0.7902302742004395\n",
      "epoch n°3832 : train_loss = 2.0127670764923096, val_loss = 0.7886991500854492\n",
      "epoch n°3833 : train_loss = 2.0190083980560303, val_loss = 0.7911068797111511\n",
      "epoch n°3834 : train_loss = 2.018608570098877, val_loss = 0.7971628904342651\n",
      "epoch n°3835 : train_loss = 2.011767625808716, val_loss = 0.7896464467048645\n",
      "epoch n°3836 : train_loss = 2.017657995223999, val_loss = 0.7942669987678528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°3837 : train_loss = 2.022946357727051, val_loss = 0.7927790284156799\n",
      "epoch n°3838 : train_loss = 2.015068769454956, val_loss = 0.7936939001083374\n",
      "epoch n°3839 : train_loss = 2.018878221511841, val_loss = 0.7909035086631775\n",
      "epoch n°3840 : train_loss = 2.023221492767334, val_loss = 0.787031888961792\n",
      "epoch n°3841 : train_loss = 2.020254373550415, val_loss = 0.7940657734870911\n",
      "epoch n°3842 : train_loss = 2.0179495811462402, val_loss = 0.7904491424560547\n",
      "epoch n°3843 : train_loss = 2.0142486095428467, val_loss = 0.7965977191925049\n",
      "epoch n°3844 : train_loss = 2.0090065002441406, val_loss = 0.7889878749847412\n",
      "epoch n°3845 : train_loss = 2.0179452896118164, val_loss = 0.7922489047050476\n",
      "epoch n°3846 : train_loss = 2.02412486076355, val_loss = 0.7944772243499756\n",
      "epoch n°3847 : train_loss = 2.0139787197113037, val_loss = 0.7919553518295288\n",
      "epoch n°3848 : train_loss = 2.029695749282837, val_loss = 0.7929470539093018\n",
      "epoch n°3849 : train_loss = 2.0165047645568848, val_loss = 0.7959941029548645\n",
      "epoch n°3850 : train_loss = 2.0143373012542725, val_loss = 0.78913414478302\n",
      "epoch n°3851 : train_loss = 2.0098788738250732, val_loss = 0.789922833442688\n",
      "epoch n°3852 : train_loss = 2.0274007320404053, val_loss = 0.7896208167076111\n",
      "epoch n°3853 : train_loss = 2.0152430534362793, val_loss = 0.7934789061546326\n",
      "epoch n°3854 : train_loss = 2.025148391723633, val_loss = 0.7928785085678101\n",
      "epoch n°3855 : train_loss = 2.013688087463379, val_loss = 0.7940629720687866\n",
      "epoch n°3856 : train_loss = 2.0269405841827393, val_loss = 0.7919975519180298\n",
      "epoch n°3857 : train_loss = 2.012117862701416, val_loss = 0.7934012413024902\n",
      "epoch n°3858 : train_loss = 2.012089967727661, val_loss = 0.789392352104187\n",
      "epoch n°3859 : train_loss = 2.0223772525787354, val_loss = 0.7912495732307434\n",
      "epoch n°3860 : train_loss = 2.015942335128784, val_loss = 0.7923799157142639\n",
      "epoch n°3861 : train_loss = 2.0202829837799072, val_loss = 0.791205883026123\n",
      "epoch n°3862 : train_loss = 2.0208942890167236, val_loss = 0.7893136143684387\n",
      "epoch n°3863 : train_loss = 2.0176525115966797, val_loss = 0.7955463528633118\n",
      "epoch n°3864 : train_loss = 2.008936882019043, val_loss = 0.790113091468811\n",
      "epoch n°3865 : train_loss = 2.015619993209839, val_loss = 0.791179895401001\n",
      "epoch n°3866 : train_loss = 2.0161938667297363, val_loss = 0.786709189414978\n",
      "epoch n°3867 : train_loss = 2.0156619548797607, val_loss = 0.7939644455909729\n",
      "epoch n°3868 : train_loss = 2.01895809173584, val_loss = 0.7910426259040833\n",
      "epoch n°3869 : train_loss = 2.0150346755981445, val_loss = 0.7913021445274353\n",
      "epoch n°3870 : train_loss = 2.011033058166504, val_loss = 0.797502338886261\n",
      "epoch n°3871 : train_loss = 2.0158920288085938, val_loss = 0.7908203601837158\n",
      "epoch n°3872 : train_loss = 2.021650791168213, val_loss = 0.7916056513786316\n",
      "epoch n°3873 : train_loss = 2.0141584873199463, val_loss = 0.7890910506248474\n",
      "epoch n°3874 : train_loss = 2.0125772953033447, val_loss = 0.7907589673995972\n",
      "epoch n°3875 : train_loss = 2.0116021633148193, val_loss = 0.7905775308609009\n",
      "epoch n°3876 : train_loss = 2.026244640350342, val_loss = 0.7913031578063965\n",
      "epoch n°3877 : train_loss = 2.010265350341797, val_loss = 0.7948806285858154\n",
      "epoch n°3878 : train_loss = 2.0187299251556396, val_loss = 0.7902289032936096\n",
      "epoch n°3879 : train_loss = 2.0223464965820312, val_loss = 0.7868611216545105\n",
      "epoch n°3880 : train_loss = 2.0135743618011475, val_loss = 0.789652407169342\n",
      "epoch n°3881 : train_loss = 2.0140039920806885, val_loss = 0.7889335751533508\n",
      "epoch n°3882 : train_loss = 2.014375686645508, val_loss = 0.7892637848854065\n",
      "epoch n°3883 : train_loss = 2.0138471126556396, val_loss = 0.7912464141845703\n",
      "epoch n°3884 : train_loss = 2.019530773162842, val_loss = 0.7890851497650146\n",
      "epoch n°3885 : train_loss = 2.0212442874908447, val_loss = 0.7928780317306519\n",
      "epoch n°3886 : train_loss = 2.015263557434082, val_loss = 0.7950605750083923\n",
      "epoch n°3887 : train_loss = 2.011154890060425, val_loss = 0.7938756346702576\n",
      "epoch n°3888 : train_loss = 2.0184123516082764, val_loss = 0.7859128713607788\n",
      "epoch n°3889 : train_loss = 2.0196728706359863, val_loss = 0.791224479675293\n",
      "epoch n°3890 : train_loss = 2.0180985927581787, val_loss = 0.7920342087745667\n",
      "epoch n°3891 : train_loss = 2.0136544704437256, val_loss = 0.7916848063468933\n",
      "epoch n°3892 : train_loss = 2.02169132232666, val_loss = 0.7929736971855164\n",
      "epoch n°3893 : train_loss = 2.021188497543335, val_loss = 0.7916728854179382\n",
      "epoch n°3894 : train_loss = 2.01442551612854, val_loss = 0.7905561923980713\n",
      "epoch n°3895 : train_loss = 2.023158311843872, val_loss = 0.7938039302825928\n",
      "epoch n°3896 : train_loss = 2.0187454223632812, val_loss = 0.7950499057769775\n",
      "epoch n°3897 : train_loss = 2.0200083255767822, val_loss = 0.7857751846313477\n",
      "epoch n°3898 : train_loss = 2.0075392723083496, val_loss = 0.7907617688179016\n",
      "epoch n°3899 : train_loss = 2.0185482501983643, val_loss = 0.7927908301353455\n",
      "epoch n°3900 : train_loss = 2.0268993377685547, val_loss = 0.7893012762069702\n",
      "epoch n°3901 : train_loss = 2.0144588947296143, val_loss = 0.7882855534553528\n",
      "epoch n°3902 : train_loss = 2.0223968029022217, val_loss = 0.7874338626861572\n",
      "epoch n°3903 : train_loss = 2.015458345413208, val_loss = 0.7935062050819397\n",
      "epoch n°3904 : train_loss = 2.0173487663269043, val_loss = 0.7877704501152039\n",
      "epoch n°3905 : train_loss = 2.0234756469726562, val_loss = 0.7896259427070618\n",
      "epoch n°3906 : train_loss = 2.0183427333831787, val_loss = 0.7887412905693054\n",
      "epoch n°3907 : train_loss = 2.019273042678833, val_loss = 0.7912169098854065\n",
      "epoch n°3908 : train_loss = 2.023559331893921, val_loss = 0.791117250919342\n",
      "epoch n°3909 : train_loss = 2.017078161239624, val_loss = 0.7948562502861023\n",
      "epoch n°3910 : train_loss = 2.024836778640747, val_loss = 0.7927485704421997\n",
      "epoch n°3911 : train_loss = 2.0220603942871094, val_loss = 0.7912832498550415\n",
      "epoch n°3912 : train_loss = 2.0129191875457764, val_loss = 0.7915757894515991\n",
      "epoch n°3913 : train_loss = 2.0213146209716797, val_loss = 0.7886767983436584\n",
      "epoch n°3914 : train_loss = 2.0194754600524902, val_loss = 0.7917563319206238\n",
      "epoch n°3915 : train_loss = 2.019444704055786, val_loss = 0.795798122882843\n",
      "epoch n°3916 : train_loss = 2.020270347595215, val_loss = 0.792576014995575\n",
      "epoch n°3917 : train_loss = 2.0223379135131836, val_loss = 0.792365550994873\n",
      "epoch n°3918 : train_loss = 2.0174834728240967, val_loss = 0.7960111498832703\n",
      "epoch n°3919 : train_loss = 2.009143829345703, val_loss = 0.7892794609069824\n",
      "epoch n°3920 : train_loss = 2.007270336151123, val_loss = 0.7933460474014282\n",
      "epoch n°3921 : train_loss = 2.021042585372925, val_loss = 0.792858362197876\n",
      "epoch n°3922 : train_loss = 2.0231800079345703, val_loss = 0.7914831042289734\n",
      "epoch n°3923 : train_loss = 2.0116355419158936, val_loss = 0.7960482239723206\n",
      "epoch n°3924 : train_loss = 2.0164716243743896, val_loss = 0.7903744578361511\n",
      "epoch n°3925 : train_loss = 2.009561061859131, val_loss = 0.7927666306495667\n",
      "epoch n°3926 : train_loss = 2.007183074951172, val_loss = 0.7937228083610535\n",
      "epoch n°3927 : train_loss = 2.0183041095733643, val_loss = 0.7907112240791321\n",
      "epoch n°3928 : train_loss = 2.0114853382110596, val_loss = 0.7942468523979187\n",
      "epoch n°3929 : train_loss = 2.026630401611328, val_loss = 0.7919529676437378\n",
      "epoch n°3930 : train_loss = 2.0200579166412354, val_loss = 0.791498601436615\n",
      "epoch n°3931 : train_loss = 2.0123131275177, val_loss = 0.787721574306488\n",
      "epoch n°3932 : train_loss = 2.025090217590332, val_loss = 0.7932977080345154\n",
      "epoch n°3933 : train_loss = 2.0225162506103516, val_loss = 0.7931384444236755\n",
      "epoch n°3934 : train_loss = 2.0158121585845947, val_loss = 0.7934304475784302\n",
      "epoch n°3935 : train_loss = 2.012827157974243, val_loss = 0.7898153066635132\n",
      "epoch n°3936 : train_loss = 2.0234785079956055, val_loss = 0.7911139130592346\n",
      "epoch n°3937 : train_loss = 2.010979175567627, val_loss = 0.7933279871940613\n",
      "epoch n°3938 : train_loss = 2.0227692127227783, val_loss = 0.7927680015563965\n",
      "epoch n°3939 : train_loss = 2.017812728881836, val_loss = 0.7909913659095764\n",
      "epoch n°3940 : train_loss = 2.01982045173645, val_loss = 0.7913957834243774\n",
      "epoch n°3941 : train_loss = 2.0236690044403076, val_loss = 0.7904332280158997\n",
      "epoch n°3942 : train_loss = 2.011002779006958, val_loss = 0.7902908325195312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°3943 : train_loss = 2.0193517208099365, val_loss = 0.7954893112182617\n",
      "epoch n°3944 : train_loss = 2.020547866821289, val_loss = 0.7942403554916382\n",
      "epoch n°3945 : train_loss = 2.0221574306488037, val_loss = 0.7917677760124207\n",
      "epoch n°3946 : train_loss = 2.0169425010681152, val_loss = 0.7896422147750854\n",
      "epoch n°3947 : train_loss = 2.023258924484253, val_loss = 0.7901322841644287\n",
      "epoch n°3948 : train_loss = 2.0155625343322754, val_loss = 0.7886518836021423\n",
      "epoch n°3949 : train_loss = 2.0203323364257812, val_loss = 0.7935002446174622\n",
      "epoch n°3950 : train_loss = 2.013791561126709, val_loss = 0.7883797287940979\n",
      "epoch n°3951 : train_loss = 2.0218584537506104, val_loss = 0.7914360165596008\n",
      "epoch n°3952 : train_loss = 2.025477647781372, val_loss = 0.7892099618911743\n",
      "epoch n°3953 : train_loss = 2.0185446739196777, val_loss = 0.7968189120292664\n",
      "epoch n°3954 : train_loss = 2.017169713973999, val_loss = 0.7939343452453613\n",
      "epoch n°3955 : train_loss = 2.0150599479675293, val_loss = 0.7933989763259888\n",
      "epoch n°3956 : train_loss = 2.0210189819335938, val_loss = 0.7903457880020142\n",
      "epoch n°3957 : train_loss = 2.0220396518707275, val_loss = 0.794802188873291\n",
      "epoch n°3958 : train_loss = 2.017669916152954, val_loss = 0.7884674072265625\n",
      "epoch n°3959 : train_loss = 2.0197482109069824, val_loss = 0.7932446599006653\n",
      "epoch n°3960 : train_loss = 2.0129690170288086, val_loss = 0.790729284286499\n",
      "epoch n°3961 : train_loss = 2.0102827548980713, val_loss = 0.7922610640525818\n",
      "epoch n°3962 : train_loss = 2.014389753341675, val_loss = 0.7915652990341187\n",
      "epoch n°3963 : train_loss = 2.0183112621307373, val_loss = 0.7909054160118103\n",
      "epoch n°3964 : train_loss = 2.0116679668426514, val_loss = 0.7894223928451538\n",
      "epoch n°3965 : train_loss = 2.0152926445007324, val_loss = 0.7915877103805542\n",
      "epoch n°3966 : train_loss = 2.023186683654785, val_loss = 0.7926285862922668\n",
      "epoch n°3967 : train_loss = 2.013950824737549, val_loss = 0.7938732504844666\n",
      "epoch n°3968 : train_loss = 2.0147063732147217, val_loss = 0.7903915643692017\n",
      "epoch n°3969 : train_loss = 2.0135629177093506, val_loss = 0.7920577526092529\n",
      "epoch n°3970 : train_loss = 2.0056540966033936, val_loss = 0.79094398021698\n",
      "epoch n°3971 : train_loss = 2.014863967895508, val_loss = 0.7905195355415344\n",
      "epoch n°3972 : train_loss = 2.0126230716705322, val_loss = 0.7907379865646362\n",
      "epoch n°3973 : train_loss = 2.012709856033325, val_loss = 0.7897862792015076\n",
      "epoch n°3974 : train_loss = 2.0124638080596924, val_loss = 0.791043758392334\n",
      "epoch n°3975 : train_loss = 2.0153579711914062, val_loss = 0.7900585532188416\n",
      "epoch n°3976 : train_loss = 2.0226526260375977, val_loss = 0.7886859178543091\n",
      "epoch n°3977 : train_loss = 2.0162408351898193, val_loss = 0.7965978980064392\n",
      "epoch n°3978 : train_loss = 2.0126914978027344, val_loss = 0.7904543876647949\n",
      "epoch n°3979 : train_loss = 2.0169551372528076, val_loss = 0.7915034294128418\n",
      "epoch n°3980 : train_loss = 2.0176100730895996, val_loss = 0.7932219505310059\n",
      "epoch n°3981 : train_loss = 2.0140035152435303, val_loss = 0.791038990020752\n",
      "epoch n°3982 : train_loss = 2.014333724975586, val_loss = 0.795660674571991\n",
      "epoch n°3983 : train_loss = 2.016183376312256, val_loss = 0.7943750619888306\n",
      "epoch n°3984 : train_loss = 2.01460599899292, val_loss = 0.7893937230110168\n",
      "epoch n°3985 : train_loss = 2.0237228870391846, val_loss = 0.7880626916885376\n",
      "epoch n°3986 : train_loss = 2.0226356983184814, val_loss = 0.7890579104423523\n",
      "epoch n°3987 : train_loss = 2.0129404067993164, val_loss = 0.7895427942276001\n",
      "epoch n°3988 : train_loss = 2.014735221862793, val_loss = 0.79164057970047\n",
      "epoch n°3989 : train_loss = 2.0176892280578613, val_loss = 0.7943001985549927\n",
      "epoch n°3990 : train_loss = 2.0166685581207275, val_loss = 0.7946860790252686\n",
      "epoch n°3991 : train_loss = 2.012279748916626, val_loss = 0.7921338677406311\n",
      "epoch n°3992 : train_loss = 2.0160105228424072, val_loss = 0.7913762331008911\n",
      "epoch n°3993 : train_loss = 2.019129753112793, val_loss = 0.7885565161705017\n",
      "epoch n°3994 : train_loss = 2.019231081008911, val_loss = 0.791156530380249\n",
      "epoch n°3995 : train_loss = 2.0102639198303223, val_loss = 0.7939249873161316\n",
      "epoch n°3996 : train_loss = 2.017943859100342, val_loss = 0.7946059703826904\n",
      "epoch n°3997 : train_loss = 2.0242316722869873, val_loss = 0.7909133434295654\n",
      "epoch n°3998 : train_loss = 2.0100021362304688, val_loss = 0.7895812392234802\n",
      "epoch n°3999 : train_loss = 2.018003225326538, val_loss = 0.7916275858879089\n",
      "epoch n°4000 : train_loss = 2.0110416412353516, val_loss = 0.793035089969635\n",
      "epoch n°4001 : train_loss = 2.014512062072754, val_loss = 0.7907547354698181\n",
      "epoch n°4002 : train_loss = 2.0072412490844727, val_loss = 0.790511965751648\n",
      "epoch n°4003 : train_loss = 2.0231664180755615, val_loss = 0.7897931933403015\n",
      "epoch n°4004 : train_loss = 2.0220932960510254, val_loss = 0.7922196984291077\n",
      "epoch n°4005 : train_loss = 2.0198276042938232, val_loss = 0.7869448661804199\n",
      "epoch n°4006 : train_loss = 2.0145151615142822, val_loss = 0.7917079925537109\n",
      "epoch n°4007 : train_loss = 2.0167365074157715, val_loss = 0.7907859683036804\n",
      "epoch n°4008 : train_loss = 2.0104987621307373, val_loss = 0.7913093566894531\n",
      "epoch n°4009 : train_loss = 2.0159502029418945, val_loss = 0.7876608967781067\n",
      "epoch n°4010 : train_loss = 2.012131929397583, val_loss = 0.7895844578742981\n",
      "epoch n°4011 : train_loss = 2.0190229415893555, val_loss = 0.788914680480957\n",
      "epoch n°4012 : train_loss = 2.0144171714782715, val_loss = 0.7916384935379028\n",
      "epoch n°4013 : train_loss = 2.014054536819458, val_loss = 0.788949728012085\n",
      "epoch n°4014 : train_loss = 2.0194926261901855, val_loss = 0.7898966670036316\n",
      "epoch n°4015 : train_loss = 2.0142009258270264, val_loss = 0.7966657876968384\n",
      "epoch n°4016 : train_loss = 2.0182902812957764, val_loss = 0.7866595983505249\n",
      "epoch n°4017 : train_loss = 2.0260374546051025, val_loss = 0.7925799489021301\n",
      "epoch n°4018 : train_loss = 2.0129239559173584, val_loss = 0.7944020628929138\n",
      "epoch n°4019 : train_loss = 2.009610414505005, val_loss = 0.7856931686401367\n",
      "epoch n°4020 : train_loss = 2.015542507171631, val_loss = 0.7932045459747314\n",
      "epoch n°4021 : train_loss = 2.014364004135132, val_loss = 0.7901998162269592\n",
      "epoch n°4022 : train_loss = 2.0123655796051025, val_loss = 0.7927556037902832\n",
      "epoch n°4023 : train_loss = 2.019432783126831, val_loss = 0.7893198132514954\n",
      "epoch n°4024 : train_loss = 2.019394636154175, val_loss = 0.7886702418327332\n",
      "epoch n°4025 : train_loss = 2.009958505630493, val_loss = 0.7880620956420898\n",
      "epoch n°4026 : train_loss = 2.0128796100616455, val_loss = 0.7912000417709351\n",
      "epoch n°4027 : train_loss = 2.0182082653045654, val_loss = 0.7902502417564392\n",
      "epoch n°4028 : train_loss = 2.0230400562286377, val_loss = 0.789931058883667\n",
      "epoch n°4029 : train_loss = 2.022623300552368, val_loss = 0.7929393649101257\n",
      "epoch n°4030 : train_loss = 2.01501202583313, val_loss = 0.793642520904541\n",
      "epoch n°4031 : train_loss = 2.025243043899536, val_loss = 0.7929271459579468\n",
      "epoch n°4032 : train_loss = 2.0191104412078857, val_loss = 0.7930454015731812\n",
      "epoch n°4033 : train_loss = 2.00958251953125, val_loss = 0.7891298532485962\n",
      "epoch n°4034 : train_loss = 2.0102005004882812, val_loss = 0.7897164821624756\n",
      "epoch n°4035 : train_loss = 2.0167183876037598, val_loss = 0.79584801197052\n",
      "epoch n°4036 : train_loss = 2.0146021842956543, val_loss = 0.7894454598426819\n",
      "epoch n°4037 : train_loss = 2.0233330726623535, val_loss = 0.7963936924934387\n",
      "epoch n°4038 : train_loss = 2.0191233158111572, val_loss = 0.7949944138526917\n",
      "epoch n°4039 : train_loss = 2.009753465652466, val_loss = 0.7924226522445679\n",
      "epoch n°4040 : train_loss = 2.0126521587371826, val_loss = 0.7935760021209717\n",
      "epoch n°4041 : train_loss = 2.02188777923584, val_loss = 0.7900193333625793\n",
      "epoch n°4042 : train_loss = 2.015880584716797, val_loss = 0.794378936290741\n",
      "epoch n°4043 : train_loss = 2.011838912963867, val_loss = 0.7882606387138367\n",
      "epoch n°4044 : train_loss = 2.013218402862549, val_loss = 0.7885658740997314\n",
      "epoch n°4045 : train_loss = 2.0165164470672607, val_loss = 0.7924478054046631\n",
      "epoch n°4046 : train_loss = 2.0219647884368896, val_loss = 0.7935011982917786\n",
      "epoch n°4047 : train_loss = 2.0073812007904053, val_loss = 0.7890516519546509\n",
      "epoch n°4048 : train_loss = 2.015069007873535, val_loss = 0.7900213003158569\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n°4049 : train_loss = 2.0156242847442627, val_loss = 0.7878194451332092\n",
      "epoch n°4050 : train_loss = 2.0151820182800293, val_loss = 0.7916815280914307\n",
      "epoch n°4051 : train_loss = 2.0238239765167236, val_loss = 0.7924900054931641\n",
      "epoch n°4052 : train_loss = 2.016989231109619, val_loss = 0.7932640314102173\n",
      "epoch n°4053 : train_loss = 2.020737648010254, val_loss = 0.7954919934272766\n",
      "epoch n°4054 : train_loss = 2.0162720680236816, val_loss = 0.7935669422149658\n",
      "epoch n°4055 : train_loss = 2.0123300552368164, val_loss = 0.7920802235603333\n",
      "epoch n°4056 : train_loss = 2.015678644180298, val_loss = 0.7959753274917603\n",
      "epoch n°4057 : train_loss = 2.0134243965148926, val_loss = 0.7899112701416016\n",
      "epoch n°4058 : train_loss = 2.013160228729248, val_loss = 0.7925094962120056\n",
      "epoch n°4059 : train_loss = 2.0184097290039062, val_loss = 0.7937132120132446\n",
      "epoch n°4060 : train_loss = 2.018641710281372, val_loss = 0.7893060445785522\n",
      "epoch n°4061 : train_loss = 2.0188405513763428, val_loss = 0.7896462678909302\n",
      "epoch n°4062 : train_loss = 2.0270702838897705, val_loss = 0.7913351655006409\n",
      "epoch n°4063 : train_loss = 2.0146257877349854, val_loss = 0.7929844260215759\n",
      "epoch n°4064 : train_loss = 2.020535469055176, val_loss = 0.7933491468429565\n",
      "epoch n°4065 : train_loss = 2.008439302444458, val_loss = 0.7947154641151428\n",
      "epoch n°4066 : train_loss = 2.015413522720337, val_loss = 0.7857664227485657\n",
      "epoch n°4067 : train_loss = 2.012958526611328, val_loss = 0.7906873226165771\n",
      "epoch n°4068 : train_loss = 2.0128092765808105, val_loss = 0.7898274064064026\n",
      "epoch n°4069 : train_loss = 2.014207601547241, val_loss = 0.7932812571525574\n",
      "epoch n°4070 : train_loss = 2.0117948055267334, val_loss = 0.7945420145988464\n",
      "epoch n°4071 : train_loss = 2.01865816116333, val_loss = 0.7913284301757812\n",
      "epoch n°4072 : train_loss = 2.017951726913452, val_loss = 0.7934754490852356\n",
      "epoch n°4073 : train_loss = 2.0104854106903076, val_loss = 0.7936640381813049\n",
      "epoch n°4074 : train_loss = 2.01611328125, val_loss = 0.7920486330986023\n",
      "epoch n°4075 : train_loss = 2.01430082321167, val_loss = 0.7900243997573853\n",
      "epoch n°4076 : train_loss = 2.014965534210205, val_loss = 0.7908954620361328\n",
      "epoch n°4077 : train_loss = 2.0153050422668457, val_loss = 0.7887275218963623\n",
      "epoch n°4078 : train_loss = 2.0170533657073975, val_loss = 0.7935818433761597\n",
      "epoch n°4079 : train_loss = 2.017612934112549, val_loss = 0.7904824614524841\n",
      "63745.33233952522\n"
     ]
    }
   ],
   "source": [
    "params = get_params(32,6,8,32,4,0.1)\n",
    "model = AttNet(*params,clf_dims=[1024,256,64])\n",
    "model = model.to(device)\n",
    "optim = torch.optim.AdamW(model.parameters(),lr = 0.0003)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optim,16,2)\n",
    "state = State(model,optim,scheduler)\n",
    "\n",
    "fname = \"models/stateATT_6L_fixed.pth\" \n",
    "start = time.time()\n",
    "Train,Eval,_ = main(train_dataloader, val_dataloader,fname=fname,epochs=4080,state=state,use_mut=False)\n",
    "stop = time.time()\n",
    "print(stop-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0f1bd836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f487823e910>]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(len(Train)),Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "209065c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f487812a520>]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAGdCAYAAAAxCSikAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABVz0lEQVR4nO3deVwUdeMH8M9yC3J4cigimTdKiqmgVB5hPmaaT4llmqaWPZmSZo/kfYX2lFmadGllWfrz6BRNLDUVvBAv8AwURA5FBRQFgfn9gbvuMbuzCwszwOf9evFSZmdn58vA7me+p0oQBAFERERECmYj9wkQERERSWFgISIiIsVjYCEiIiLFY2AhIiIixWNgISIiIsVjYCEiIiLFY2AhIiIixWNgISIiIsWzk/sErKWsrAxXrlyBq6srVCqV3KdDREREZhAEAQUFBfDx8YGNjfF6lFoTWK5cuQJfX1+5T4OIiIgqID09Hc2bNzf6eK0JLK6urgDKC+zm5ibz2RAREZE58vPz4evrq/kcN6bWBBZ1M5CbmxsDCxERUQ0j1Z2DnW6JiIhI8RhYiIiISPEYWIiIiEjxGFiIiIhI8RhYiIiISPEYWIiIiEjxGFiIiIhI8RhYiIiISPEYWIiIiEjxGFiIiIhI8RhYiIiISPEYWIiIiEjxas3ih1Vl9b5UpF8vxIjuvmjnxUUViYiI5MAaFglbT1zBN3EXkZZbKPepEBER1VkMLERERKR4FQosq1atgr+/P5ycnBAUFIS9e/ea3H/dunUIDAyEs7MzvL29MXbsWOTm5urss3z5crRt2xb16tWDr68v3nrrLdy9e7cip1clBLlPgIiIqA6zOLBs2LABERERmDlzJhITExEaGoqBAwciLS1NdP99+/Zh9OjRGDduHJKSkrBx40YcPnwY48eP1+yzbt06zJgxA3PnzsXp06exevVqbNiwAZGRkRUvmZWoVCq5T4GIiKjOsziwLFu2DOPGjcP48ePRvn17LF++HL6+voiOjhbd/8CBA2jZsiUmT54Mf39/9O7dG6+99hqOHDmi2Sc+Ph69evXCiy++iJYtWyIsLAwvvPCCzj5ERERUd1kUWIqLi5GQkICwsDCd7WFhYYiLixN9TkhICC5fvoyYmBgIgoDs7Gxs2rQJgwYN0uzTu3dvJCQk4NChQwCAlJQUxMTE6Oyjr6ioCPn5+TpfVUlgmxAREZFsLBrWfO3aNZSWlsLT01Nnu6enJ7KyskSfExISgnXr1iE8PBx3795FSUkJnnnmGaxYsUKzz4gRI3D16lX07t0bgiCgpKQEr7/+OmbMmGH0XKKiojB//nxLTp+IiIhqqAp1utXv1yEIgtG+HsnJyZg8eTLmzJmDhIQEbN++HampqZg4caJmn927d2Px4sVYtWoVjh49ii1btuD333/HwoULjZ5DZGQk8vLyNF/p6ekVKYok9mAhIiKSn0U1LI0bN4atra1BbUpOTo5BrYtaVFQUevXqhenTpwMAOnfuDBcXF4SGhmLRokXw9vbG7NmzMWrUKE1H3E6dOuH27dt49dVXMXPmTNjYGOYqR0dHODo6WnL6REREVENZVMPi4OCAoKAgxMbG6myPjY1FSEiI6HMKCwsNAoetrS2A8poZU/sIgqDZR35KOQ8iIqK6x+Kp+adOnYpRo0ahW7duCA4OxhdffIG0tDRNE09kZCQyMjKwdu1aAMDgwYMxYcIEREdHY8CAAcjMzERERAS6d+8OHx8fzT7Lli1Dly5d0KNHD1y4cAGzZ8/GM888owk3cuGoZiIiIvlZHFjCw8ORm5uLBQsWIDMzEwEBAYiJiYGfnx8AIDMzU2dOljFjxqCgoAArV67EtGnT4OHhgb59+2Lp0qWafWbNmgWVSoVZs2YhIyMDTZo0weDBg7F48WIrFJGIiIhqOpWgnDaXSsnPz4e7uzvy8vLg5ma9RQqf/ywOhy/eQPTIrhjYydtqxyUiIiLzP7+5lpAEFccJERERyY6BhYiIiBSPgcVMtaLdjIiIqIZiYCEiIiLFY2CRwi4sREREsmNgISIiIsVjYDFT7Rj8TUREVDMxsEhgixAREZH8GFiIiIhI8RhYzCRwYDMREZFsGFgkcPFDIiIi+TGwEBERkeIxsJiJo4SIiIjkw8BCREREisfAIoGrNRMREcmPgcVMbBEiIiKSDwMLERERKR4DiwQOayYiIpIfAwsREREpHgOLmQSOayYiIpINA4sENgkRERHJj4GFiIiIFI+BhYiIiBSPgYWIiIgUj4FFAme6JSIikh8Di5k4SIiIiEg+DCxERESkeAwsEjismYiISH4MLERERKR4DCxmErheMxERkWwYWIiIiEjxGFiIiIhI8RhYzMRhzURERPJhYCEiIiLFY2CRoOK4ZiIiItkxsJiJTUJERETyYWAhIiIixWNgkcAGISIiIvkxsJiJLUJERETyYWAhIiIixWNgkcBBQkRERPJjYCEiIiLFY2Axk8BxzURERLJhYCEiIiLFY2CRwC4sRERE8mNgMRMbhIiIiOTDwEJERESKx8AigYsfEhERyY+BxVxsEyIiIpINAwsREREpHgOLBDYIERERyY+BhYiIiBSPgcVMAjuxEBERyYaBhYiIiBSPgUUCRzUTERHJj4HFTFz7kIiISD4MLERERKR4DCyS2CZEREQktwoFllWrVsHf3x9OTk4ICgrC3r17Te6/bt06BAYGwtnZGd7e3hg7dixyc3N19rl58ybeeOMNeHt7w8nJCe3bt0dMTExFTq9KsEWIiIhIPhYHlg0bNiAiIgIzZ85EYmIiQkNDMXDgQKSlpYnuv2/fPowePRrjxo1DUlISNm7ciMOHD2P8+PGafYqLi/Hkk0/i4sWL2LRpE86ePYsvv/wSzZo1q3jJiIiIqNaws/QJy5Ytw7hx4zSBY/ny5fjjjz8QHR2NqKgog/0PHDiAli1bYvLkyQAAf39/vPbaa3j//fc1+6xZswbXr19HXFwc7O3tAQB+fn4VKpC1cZQQERGR/CyqYSkuLkZCQgLCwsJ0toeFhSEuLk70OSEhIbh8+TJiYmIgCAKys7OxadMmDBo0SLPPr7/+iuDgYLzxxhvw9PREQEAA3nvvPZSWlho9l6KiIuTn5+t8VSWOEiIiIpKPRYHl2rVrKC0thaenp852T09PZGVliT4nJCQE69atQ3h4OBwcHODl5QUPDw+sWLFCs09KSgo2bdqE0tJSxMTEYNasWfjwww+xePFio+cSFRUFd3d3zZevr68lRSEiIqIapEKdblV67SSCIBhsU0tOTsbkyZMxZ84cJCQkYPv27UhNTcXEiRM1+5SVlaFp06b44osvEBQUhBEjRmDmzJmIjo42eg6RkZHIy8vTfKWnp1ekKERERFQDWNSHpXHjxrC1tTWoTcnJyTGodVGLiopCr169MH36dABA586d4eLigtDQUCxatAje3t7w9vaGvb09bG1tNc9r3749srKyUFxcDAcHB4PjOjo6wtHR0ZLTrxB2YSEiIpKfRTUsDg4OCAoKQmxsrM722NhYhISEiD6nsLAQNja6L6MOJsL9jiG9evXChQsXUFZWptnn3Llz8Pb2Fg0rcuDih0RERPKxuElo6tSp+Oqrr7BmzRqcPn0ab731FtLS0jRNPJGRkRg9erRm/8GDB2PLli2Ijo5GSkoK9u/fj8mTJ6N79+7w8fEBALz++uvIzc3FlClTcO7cOWzduhXvvfce3njjDSsVk4iIiGoyi4c1h4eHIzc3FwsWLEBmZiYCAgIQExOjGYacmZmpMyfLmDFjUFBQgJUrV2LatGnw8PBA3759sXTpUs0+vr6+2LFjB9566y107twZzZo1w5QpU/Df//7XCkWsHA5rJiIikp9KEGrHgN38/Hy4u7sjLy8Pbm5uVjvua98dwR9J2Vg0NAAv9VTG3DBERES1hbmf31xLiIiIiBSPgUWCiuOEiIiIZMfAYqZa0W5GRERUQzGwEBERkeIxsBAREZHiMbBI4LBmIiIi+TGwmKt2jP4mIiKqkRhYiIiISPEYWCSwSYiIiEh+DCxmYoMQERGRfBhYiIiISPEYWCRwplsiIiL5MbCYiYOEiIiI5MPAQkRERIrHwEJERESKx8Ai5X4XFoFtQkRERLJhYCEiIiLFY2AhIiIixWNgkcBBzURERPJjYDETe7AQERHJh4GFiIiIFI+BhYiIiBSPgUWC6v5yzRzVTEREJB8GFiIiIlI8BhYiIiJSPAYWCephzWwRIiIikg8DCxERESkeAwsREREpHgOLBBWnuiUiIpIdA4uZuFozERGRfBhYiIiISPEYWIiIiEjxGFgksAsLERGR/BhYiIiISPEYWIiIiEjxGFgkcPFDIiIi+TGwEBERkeIxsBAREZHiMbBIeLD4IduEiIiI5MLAQkRERIrHwEJERESKx8BCREREisfAIuV+JxYOayYiIpIPAwsREREpHgMLERERKR4DiwTV/TYhtggRERHJh4GFiIiIFI+BhYiIiBSPgUWCiqOEiIiIZMfAQkRERIrHwEJERESKx8BCREREisfAIoGrNRMREcmPgYWIiIgUj4GFiIiIFI+BRQKHNRMREcmPgYWIiIgUr0KBZdWqVfD394eTkxOCgoKwd+9ek/uvW7cOgYGBcHZ2hre3N8aOHYvc3FzRfdevXw+VSoWhQ4dW5NSIiIioFrI4sGzYsAERERGYOXMmEhMTERoaioEDByItLU10/3379mH06NEYN24ckpKSsHHjRhw+fBjjx4832PfSpUt4++23ERoaanlJqohKM06IiIiI5GJxYFm2bBnGjRuH8ePHo3379li+fDl8fX0RHR0tuv+BAwfQsmVLTJ48Gf7+/ujduzdee+01HDlyRGe/0tJSjBw5EvPnz8dDDz1UsdIQERFRrWRRYCkuLkZCQgLCwsJ0toeFhSEuLk70OSEhIbh8+TJiYmIgCAKys7OxadMmDBo0SGe/BQsWoEmTJhg3bpyFRSAiIqLazs6Sna9du4bS0lJ4enrqbPf09ERWVpboc0JCQrBu3TqEh4fj7t27KCkpwTPPPIMVK1Zo9tm/fz9Wr16NY8eOmX0uRUVFKCoq0nyfn59vSVEsJnCYEBERkWwq1OlWpdLt1yEIgsE2teTkZEyePBlz5sxBQkICtm/fjtTUVEycOBEAUFBQgJdeeglffvklGjdubPY5REVFwd3dXfPl6+tbkaJIMlIsIiIiqkYW1bA0btwYtra2BrUpOTk5BrUualFRUejVqxemT58OAOjcuTNcXFwQGhqKRYsWITs7GxcvXsTgwYM1zykrKys/OTs7nD17Fq1atTI4bmRkJKZOnar5Pj8/v8pCCxEREcnLosDi4OCAoKAgxMbG4tlnn9Vsj42NxZAhQ0SfU1hYCDs73ZextbUFUF4z065dO5w8eVLn8VmzZqGgoAAff/yx0RDi6OgIR0dHS06fiIiIaiiLAgsATJ06FaNGjUK3bt0QHByML774AmlpaZomnsjISGRkZGDt2rUAgMGDB2PChAmIjo7GgAEDkJmZiYiICHTv3h0+Pj4AgICAAJ3X8PDwEN0uB850S0REJD+LA0t4eDhyc3OxYMECZGZmIiAgADExMfDz8wMAZGZm6szJMmbMGBQUFGDlypWYNm0aPDw80LdvXyxdutR6pSAiIqJaTSXUkuEv+fn5cHd3R15eHtzc3Kx23MgtJ/DjoXRMe7IN3uzX2mrHJSIiIvM/v7mWkKTyNqFakeqIiIhqKAYWIiIiUjwGFiIiIlI8BhYz1Y6ePkRERDUTA4sEznRLREQkPwYWIiIiUjwGFjMJHCdEREQkGwYWCWwRIiIikh8DCxERESkeAwsREREpHgOLBC5+SEREJD8GFiIiIlI8BhYiIiJSPAYWM7FFiIiISD4MLBJUHNhMREQkOwYWIiIiUjwGFnNxmBAREZFsGFgkcPFDIiIi+TGwEBERkeIxsBAREZHiMbBIULcIsQcLERGRfBhYiIiISPEYWIiIiEjxGFjMxFHNRERE8mFgkaDiuGYiIiLZMbAQERGR4jGwmEngOCEiIiLZMLAQERGR4jGwEBERkeIxsJiJo4SIiIjkw8AigYOEiIiI5MfAQkRERIrHwEJERESKx8BiJnZhISIikg8DiwQV2ImFiIhIbgwsREREpHgMLGbisGYiIiL5MLBIUA9r5tT8RERE8mFgkaDpwcK8QkREJBsGFgkPaliIiIhILgwsEmzuJxaBnViIiIhkw8AiRV3DwrxCREQkGwYWCep5WJhXiIiI5MPAIkHdh6WMVSxERESyYWCRoB4lxLxCREQkHwYWCSrOzE9ERCQ7BhYJmj4srGIhIiKSDQOLBM7DQkREJD8GFgkqzTwsMp8IERFRHcbAIkHT6ZZ1LERERLJhYJGg4sRxREREsmNgkcCJ44iIiOTHwCKBNSxERETyY2CRkJl3BwDw46E0mc+EiIio7mJgkfDjoXS5T4GIiKjOY2AhIiIixWNgISIiIsVjYCEiIiLFq1BgWbVqFfz9/eHk5ISgoCDs3bvX5P7r1q1DYGAgnJ2d4e3tjbFjxyI3N1fz+JdffonQ0FA0aNAADRo0QP/+/XHo0KGKnBoRERHVQhYHlg0bNiAiIgIzZ85EYmIiQkNDMXDgQKSliY+i2bdvH0aPHo1x48YhKSkJGzduxOHDhzF+/HjNPrt378YLL7yAXbt2IT4+Hi1atEBYWBgyMjIqXjIiIiKqNVSChcsQ9+jRA127dkV0dLRmW/v27TF06FBERUUZ7P/BBx8gOjoa//zzj2bbihUr8P777yM9XXwETmlpKRo0aICVK1di9OjRZp1Xfn4+3N3dkZeXBzc3N0uKZFLLGVs1/7+4ZJDVjktERETmf35bVMNSXFyMhIQEhIWF6WwPCwtDXFyc6HNCQkJw+fJlxMTEQBAEZGdnY9OmTRg0yPiHf2FhIe7du4eGDRsa3aeoqAj5+fk6X0RERFQ7WRRYrl27htLSUnh6eups9/T0RFZWluhzQkJCsG7dOoSHh8PBwQFeXl7w8PDAihUrjL7OjBkz0KxZM/Tv39/oPlFRUXB3d9d8+fr6WlIUs3X3Nx6aiIiIqHpUqNOtSj1f/X2CIBhsU0tOTsbkyZMxZ84cJCQkYPv27UhNTcXEiRNF93///ffx448/YsuWLXBycjJ6DpGRkcjLy9N8GWteqqxJfR4GADRvUK9Kjk9ERETS7CzZuXHjxrC1tTWoTcnJyTGodVGLiopCr169MH36dABA586d4eLigtDQUCxatAje3t6afT/44AO899572LlzJzp37mzyXBwdHeHo6GjJ6VeIvW15pqtnb1vlr0VERETiLKphcXBwQFBQEGJjY3W2x8bGIiQkRPQ5hYWFsLHRfRlb2/IPf+3+vv/73/+wcOFCbN++Hd26dbPktKqUzf2KozKufkhERCQbi2pYAGDq1KkYNWoUunXrhuDgYHzxxRdIS0vTNPFERkYiIyMDa9euBQAMHjwYEyZMQHR0NAYMGIDMzExERESge/fu8PHxAVDeDDR79mz88MMPaNmypaYGp379+qhfv761ylohNvcTC/MKERGRfCwOLOHh4cjNzcWCBQuQmZmJgIAAxMTEwM/PDwCQmZmpMyfLmDFjUFBQgJUrV2LatGnw8PBA3759sXTpUs0+q1atQnFxMZ577jmd15o7dy7mzZtXwaJZB2tYiIiI5GfxPCxKVVXzsBxNu4Fhq+LQoqEz/n6nj9WOS0RERFU0D0tdZHN/9BNrWIiIiOTDwCJB3STEvEJERCQfBhYJ6hqW0jImFiIiIrkwsEhQsdMtERGR7BhYJNjaqPuwyHwiREREdRgDiwR1k9C1W0XYcvQyyphciIiIqh0DiwQbrSWSpv7fcWxJzJDvZIiIiOooBhYJ+os6Hrl4XaYzISIiqrsYWCTYGKxMLdOJEBER1WEMLBJsdPMKRwsRERHJgIFFgkENi0znQUREVJcxsEhQsYaFiIhIdgwsEvRrWFjFQkREVP0YWCTY6XViYQ0LERFR9WNgkWBnq/sj4rxxRERE1Y+BRYIta1iIiIhkx8Aiwd5WN7D8fiJTpjMhIiKquxhYJNjZ8EdEREQkN34aS9DvdEtERETVj4FFgo2NymC2WyIiIqpeDCxmYLMQERGRvPhJbIbi0jK5T4GIiKhOY2AhIiIixWNgISIiIsVjYCEiIiLFY2CpgKKSUrlPgYiIqE5hYKmAb/ZflPsUiIiI6hQGlgq4cvOO3KdARERUpzCwVIBKxZnkiIiIqhMDSwXYMLAQERFVKwaWCmBeISIiql4MLGbQXwCRawsRERFVLwYWM4zr7a/zvY1KhZLSMly8dlumMyIiIqpbGFjMUCYIOt/n3i7Gq98l4IkPduP3E1dkOisiIqK6g4HFDGW6eQU5BUX460wOAGD1vlQZzoiIiKhuYWAxg14FC1o1cdH8n91ZiIiIqh4Dixn0m4Q6+rhr/n807WY1nw0REVHdw8BiBkEvsHCUEBERUfViYDGDfh8WThxHRERUvRhYzKDfJHQgJVemMyEiIqqbGFjMUKpXxbL+cLpMZ0JERFQ3MbCYobikTO5TICIiqtMYWMxQVMrAQkREJCcGFjOEd/Ot8HP/OpON/zvCJiQiIqLKYGAxw2NtmmDP9Ccses6N28XIuHkHr3xzBO9sOoGUq7eq5uSIiIjqAAYWM/k1cjH62Ktrj+h8f/JyHrosjEWvJX9ptuUUFFXZuREREdV2DCxWsCM5GzcLizXfD165z2CfMv3JXIiIiMhsDCxWcv12scnHSxhYiIiIKoyBxQJ+jZyNPtb3wz0oMTGaSH/yOSIiIjIfA4sFPn2xq8nH8+7cM/qYNedyKS0T2MREBGDdwUt4avnfyMq7K/epmEV/XTIiMh8DiwUc7Cr+43r1uwT8Y8ZIoaKSUhxKvW60tqaktAz9l+3BkE/3W+3N72ZhMeb8cgrH029a5XhE1WXmT6dwJqsAS7adtupx75WW4UBKLopKSq12zKQreei2aCfWHbxktWMS1SUMLBawtzX94zqXbTqQfLjjLPIK7yGnwPjd4NT/O47hn8fj/T/O4kLOLRxKva7z+KXrhUi9dhsnM/Ks1i9m/m/JWBt/CUM+3W+V4xFVt7v3rDu54/zfkjDiiwOYsfmk1Y759sYTyL1djJk/ncLIrw5gU8Jlqx2bqC5gYLGAva3pVZpf+PKAycdLywQELtiB7ov/xP+JrEd0/XYxtp7IBAB88XcK+i/bg+Gfx+Pitduix0u+km/mmZt2NqvA4ucIApulqPb6/kAaAOCnxAyrHVO7RnT/hVy8vfG41Y5NVBcwsFhAqoYFMN1Grf35/s7mEzqPlZYJ6LowVvR52k1J2ocf8ul+nMrIkzwnaxMEAeGfH8DQVftrfWi5frtY0/8o5mQmBn2yFylXb+Eel2uQnfbv3vakLMn9TfUxIyLlY2CxgDmBxdTnd/r1QqOPmeqUqzJRsRP/T67kOVnbnXulOHTxOk5czkPGzTvV/vrVJePmHXRdGIunPv4bAPCfdUeRdCUffT/cg9Yzt+Gb/akyn2HdNfvnU+gR9afZ+3++5x8Ezt+BHw+lSe5bVX9TKlN/yEQkiYHFAnYSTUJAeU2JMWdMNL2Yei9Tofre6KK2nZacU0ZbbXkP3n/hmkF/odj7d+0pV8Wb5Ob9lmz28UtKy5CZV3vDXXX77sAlXLVg9uiobWcAAJFbpPuk/Hr8SoXPy5Ra8qdidRw5ReZiYLGAgxk1LBVd6NDk36ypMKP12NWCIuw9f9XiNwDtY3y+JwXvbDphfGdInGsNlHfnHkZ+dRDDP4/XaeqxZmvXy18fQnDUX9h/4Zr1DlqHFNy9h3UHL+HaLcuXuLB0pE9VhXAlh/vfT1zBZ3v+qfbXff37BAyLjjN5o0ekxsBiATsb6XecuH8q9oEkwPgfrI2Z73SP/28XRq0+hG/iLpr1BlBYXIJfjmUYdOo9mGq6SlzqcSUSBAH/3O97MvbrQ1i6/YzmsXytvg03tGqXrDnZ3/4L5T+z7+IfDGnVDpbZ+Xc13288ko6/z1212mvXBjO2nMTMn07h5TWHTO53p7gUPx5K08zLklNwFx3n/GH265y8nIcfDko3G1WEpYFl/4VryLh5xyCkpV8v1Pn73n4qE7vO5lTq3Cb9kIgl287gxOWblTqOpbadykJi2k2rDSCg2q1CgWXVqlXw9/eHk5MTgoKCsHfvXpP7r1u3DoGBgXB2doa3tzfGjh2L3FzdD73NmzejQ4cOcHR0RIcOHfDTTz9V5NSqlK0ZgcWS5hvtDyxTn41RMafxr4/34pdjGZj1s/Eq7cLi8jvJ+b8l45VvDku+/vxfkzFl/THcLta9Ay24W2L0OVuOXsYr3xwx+rhSrd6Xin4f7sHj7+/CrrNXEb37wd2kdlNf/2V7NP/XDiwXcqTn0BEEARO/S8B/1iXobL+Ua9iklH69EEGLduLjneexOeEyerz3J+b9moTz2QWYvukERq85xKry+8rKBM3ouSSJD7al288gcstJDP10P/48nY3ui/80e/j/z4kZouuAmVJaJuBOsXk1OJa8N8T/k4uRXx1EryV/oduindh1pjyQbDuZidD3d+H17xNwr7QMc385hYnfH8XYrw9bpQN8ronm4NxbRfjlWIZV56YhsoTFgWXDhg2IiIjAzJkzkZiYiNDQUAwcOBBpaeJ3Jfv27cPo0aMxbtw4JCUlYePGjTh8+DDGjx+v2Sc+Ph7h4eEYNWoUjh8/jlGjRmH48OE4ePBgxUtWBczpNLf1ZKbZx/vhUBru3iv/4zd1N38mqwDJmfmYsv4YDqTo9rMwdk57zLhD/+mY8SGbxt785uv126gpHQk/ij0HALgiMiOqdhDN1wpr2gOBtAOOMdduFWN7UhZiTmYhr7C81uZ2UQke/99uzT7qH9f7f5zF9dvF+GjnOSy5X9vzbfwlZOU/OL+eUX9i4e/m95OprfZbUGv51/0P9qz8uxj3rWXBOmLDMcl9bhfphvlh0XFoP2e7Ts2cMZb8qRy+qPt3vuKv8wCgabbZkZyNHw6m4VvtGjvzDy9p33nDPl3ProrDlPXH0HbWdiu+UuXcKS7F6n2pSMs1PqCBag+LA8uyZcswbtw4jB8/Hu3bt8fy5cvh6+uL6Oho0f0PHDiAli1bYvLkyfD390fv3r3x2muv4ciRB28my5cvx5NPPonIyEi0a9cOkZGR6NevH5YvX17hgtUEM386hQ93nAVg3an7zVXP3tboY/pvfrHJ2Zj6f8eQf1d3aGjklpM6K1VLSbh0XZbqX9NdhMQ/SbRnGzbVZCe2jzqAfm6kX4A5tSfZ+UVYvY8jkQrNrMEoKS0z6zrtPW9Zc1v2/RD5/YFL6Dj3D52RRurZoXefk26SqUy0V5dKu7ZIv9bPmjNfv7S6vE+XdtNTmolRjvpik7Mlf3etcb4f7DiLhb8no9+y3ZU+FimfRYGluLgYCQkJCAsL09keFhaGuLg40eeEhITg8uXLiImJgSAIyM7OxqZNmzBo0CDNPvHx8QbHHDBggNFjAkBRURHy8/N1vmqi3WfL3zzXi0wkZ47KvAmaGqatfjMpLilD0pU8TFh7BFuOZhg0Xf197ioeWSA+f4y23FvlHYL/HR2Pf31iugnREreKSjD5x0TskJiHw9SHnrE3Tu0OuOb0I9IOPmWCgGPpN/HJXxd09vnzTA4m/5iIW0XizW4xJ6XnE6mMu/dKa1xTk/7pGqs97PvhHtHt+katPoRz2Q9G7H0XfxFvmahdWbLtDHYmZ2PWz6cAiI800j/Ho2k3sP1UeW1rVt5dvBdzGpdviI8Sy797z+yReab6pplzVc2pCbpuhX5cE9YewcLfk00u92GNX0N1f7p7pTXrd5oqxqLAcu3aNZSWlsLT01Nnu6enJ7KyxN9oQ0JCsG7dOoSHh8PBwQFeXl7w8PDAihUrNPtkZWVZdEwAiIqKgru7u+bL19fXkqIojiVDicWom5b0Ld95zujIJVODnk5k5KGktAyvfHMYgz6xrF1fTNCinRi12nSHyYqI3n0Bvx6/gle/S5DeWc8b644i78497D0v3uRwT+vDwdJgOO+3ZNG+K8UlZfj1+BVNUNVnzjwhaoIgYNw3hzHVjKYMALhy8w7azd6O178/avZrKNG6A+Jr8aRdL0SZmRWVRy/dAAB8tTcFs39JMjmj7cmMPIxfa17z0q2iEhy5eB3DVsVh4vdHcSojD7N/OYUv/k4R7R9yr7QMneftQNeFsQbNTdrUH+7aNSz6GVoqAHy66wK6LIyt1rWMsvONL0Oifbr6Zflqbwom/5goOXigOqd8IPlVqNOtfr8FQRCM9mVITk7G5MmTMWfOHCQkJGD79u1ITU3FxIkTK3xMAIiMjEReXp7mKz29YjUUSlHZu41HF+802HYqIw/Ld543OkzZ1sTPd9iqOCzaehr7FD4MNztfdwRF3p17mlEVV27eQdhHe4y+QW89mYmghbGYpjdF+jf7U7F0+xnc02qm22hk3ZetJzI1nS61f5y/Hb9SZcO/BUHAV3tT8G3cRfx5JgdbEjPMGhWmrsUTmxX2+wOX0PfD3bh8Q4l9AXTLtiM52/ieZv7QZ9yvJVm0VXrRRPM6XJf/O/yzeDz3Wbxm+9Mr9iHWxPm2m/2gP8iO5Cz0+3A3tp/KMvjdUX+rfZ3Xxuv+XkvVhvzvj/Lm55k/nTK5nyXHlH6+8cdMDTpYtPU0fj1+RdMnyZga0oWOrMSiwNK4cWPY2toa1Hzk5OQY1JCoRUVFoVevXpg+fTo6d+6MAQMGYNWqVVizZg0yM8urTL28vCw6JgA4OjrCzc1N56smM6ftXUx8SnmVqNjInpuFpqcit5WYCO+buIsVOqeyMsGgr4s+/Q+W309cwaBP9oqum3T9drFBDdLmhMtYtfuCzv3Vz4kZCJy/A90W7cTtohIs2XYG57JvmXyDFhtBMu+3ZETv/gcnzVj24I0fjmL2L+LHN6cTJ2B5WD2Qch2Ltp7WmbjOnA9qU1d71s+nkHL1Nhb9bt1Vj6ubWKdqY6w594f6SMmZljVNa5/DWxuO45+rtzHxe5HawvvX15rNeWLlT8stRLpW01VlX+5MVr7RUUXm/Pjv6P3df/Lneaz487zme+2b2u6Ld6LljK34xcRgAqrZLAosDg4OCAoKQmysbp+F2NhYhISEiD6nsLAQNja6L2NrW97ZU/3HFxwcbHDMHTt2GD1mbXL+/orMFX1jiE3ONvrGa+yDVM1UDYulTmXkQRAE5N25h4fejUHneTtwIMX4fC03Cu/pzFQ66YdEJF3JN+gfcO1WEboujEW72duRorWm0rSNx/H+9rM6fRG0A0La9UKjzWTmumFmZ+LqXnVXbDkEc978tS+3sSUVlDhk9XZR1ZxTq3djKvzcvDu6/U6qq1+QqVd5/rN4s4ZYq1RA3IVr6DzvD2xOuKxz7nN/TTKY6yb12m2sN9FU+f2BS5ix+YToyMLlO89jtF5T8LH0m9hz7qrOTZqxtyL1e1RxSRnyCu9hWew5fBh7TnNDpP20nPvvJ1PWHzN6rlSzWdwkNHXqVHz11VdYs2YNTp8+jbfeegtpaWmaJp7IyEiMHj1as//gwYOxZcsWREdHIyUlBfv378fkyZPRvXt3+Pj4AACmTJmCHTt2YOnSpThz5gyWLl2KnTt3IiIiwjqltKLokV2tfszhn8dX6g3P2BtvqpFVntVszJhXxlxPr9iHjUcu49lP92u2jfjiAE5cvonvRfocdF0Yi0cX7zTofHq7WPf7w1pDK/t+uMdgNJWpBe3MnXDPGHPn71AL++jvSr2elOQr+Xhn03FkiUzxv3JXeefejJt3ELXtNK6IBBLt9v7hWs0W5qiqUWw3bhfjQo7p1cI/2nmuSl67MgLn79BZrNTacUW/xvX45TwUFpeYvLE5mZGHDYfTcPJynsmbBRuVCuO+PYLbxaWYtvG4yWMKAtDng92aJjQxs34+hfWH041OXndQb3j00E/34+U1h4x2QtZma1Per6vNrG0IXLBDsz33VjE+3/OPRcszUM1nZ+kTwsPDkZubiwULFiAzMxMBAQGIiYmBn58fACAzM1NnTpYxY8agoKAAK1euxLRp0+Dh4YG+ffti6dKlmn1CQkKwfv16zJo1C7Nnz0arVq2wYcMG9OjRwwpFtK6Bnbxxcckg5N25h8D5O6SfYKYcGf7wzJm51xIrdp1H+nXdN6FnVu43sne589kF6NKigeZ77SrerScy8V+9Va3v3CuFg515ObuyFUgtG7kYXUdIX1SMZWswaZOabv5eaRne334GX+41Pkz0kz/PY+qTbTB69UH8c/U29py9iu0RjyH9eiGaedQzCKemFq28V1qGz3b/g96tG6NLiwa4kFOA/sv+xsvBfpg/JMCywknocv9Df+fUx/BwU1edx27cLkZi+g2zPthqm+U7zxtse2r5XsmhxYX3SjWT3x16tx+aujkZ7FNaJuBO2YOamMnrE40ez1gflrIyAbeLS+DqZK/ZJtUMrM/UYrBqNiqV6KistzYcwzETI5A2JVzGc0HNzT4X9Q1jTZlXqq6qUKfb//znP7h48SKKioqQkJCAxx57TPPYN998g927d+vs/+abbyIpKQmFhYW4cuUKvv/+ezRr1kxnn+eeew5nzpxBcXExTp8+jWHDhlXk1GqsbaeqdjirmMrWQOirSI/9CWt12+ttVOVvHvN+TcIbPxw1qIHRr4ky9QZT2fJZUqvw+d8plXotU97ZdMJkWFF7/rM4/HM/YJ3JKsCGw2kIfX8X3v2p/A3fnB/H9cJ7WHfgEj6MPYdnV5VPK7Di/tDsb+PFOy9bg3pCxAKtD71/R8fVnFmVBd15e6qCOfOgaDfLnLqShyEr95lszgGA308Yn+zSWOXLa98noNO8HTit1WfHVE3Na98dMWgyMqcPkbHZxU2FFQB4W68jvSmCIGDEFwfw4pcHK1XTfauoRJb5tOoSriVUh1k7sFgysZSafu2CjUqFhEs3jHb41X+TM1aEHUnZle6PoZQRUqaG3Go7fPGGzvfL7s/uu/5wOj758zzOZOl2CM29VYTENN3nHE+/iRgZwjMAbD+VhU7zdmhmJU6RaNJUknc2n0Cnedarca0o7cz0vz/O4fjlPMzYctJk06kpxj7A1SOfJv9ovHZG2x9J2TikN3uvsSZX7desbLN13p17OJZ+06Ac/1y9hdFrDuHwxeu4WlCEg6nXEZ+SKzlQwZj8u/cQMPcPPP6/XTrbNydcxqBP9pqs0dR35eYd0cEH5vjrTDY2VnAB3pqAgaWOuVVUovnjzTIxR4JcEi7dMFjbSNv5nFtm3QV9tPMcjly6IblfbabdqXpZ7DmDSemCo/7Cs6viDKZg1/5eaiHAKzfvYNAne63yJqmemO3jPw2bQ2oC/REtcijVmohGu/ajos3XUpUg57WGfEv9WUbFnNasCQUAJUYme9O+KanswICwj/Zg6Kf7deY9EgQB/T7cg7/PXcXzn8WbnA/GXMfSbgIAMvVGqU3beBxJV/Kx4LckAOXzZZla80kQBIQs+QtPfLBbU9uYe6sIS7adwfDP4w1mzj6fXaDz9/rKN0cwfdOJCgcepWNgqSM2HE6Df+RWBMz9A2PvL4xY0buuqmbqTWrEFwfQfo55a5nU9epZqWHrxfdvx0evMb5ml7o5yZhnVu5H0pV8TDcy148lrNylqk7aebpyqzYbsGJv4uOX8/DGDw8mLSzRClfaIUW75sWcBWdNUc/TtCP5QVg3tbL1bycyLe6LA0jPV3PnXhluFhaj3ezt+Pdnxmdw1/45qCfde3vjcXy25x8cSr2OqG1ndPZ/8qO/MfzzeIP+QKYWsSwuKRPtlF8TMLDUEf/dfFJzB6S+27DmsObK0F/SfuUu03fYd+89eKMzVQJLOt3VRnY25v15a/88xWi/F1+8dhs/JV5GWZmAAym5Ok16l3JvIyvvLuL0FivcfTbH6GzLmteA9Zso6yJL54GRYslNTXJmPjYlXDYZCLRp17Bs0Pr90P7QttbvhDr4vL/9jMl+UbN/PoWJErNmT994HAM++hvf7E/FneJSlJSWSU4hYaN6EJQS79fGqJWWCZj7yyn8cizDYCkPANhlZFZsbV/vvyi5j9qw6P0IWfIXEtNu4K8z2Trvv/93JB0f/HFWsct3WDxKiGqH/Lv3YGMDQP5abIORRPorUptiqtNtk/qOFT4neuDX41c0/3/ig90Ayic56+bXQGc/7VWp177SHYHNPeDubI8xX5fX6LX3ckOn5u5GX4d5RXke0+uTYYqlC3W+velBx9gfDqZhxKO+aOZRD3Zaa4ZUtoZFreh+KF8lsuq6fjNO3D+GQ8JTrt6CXyMX2NqoNLNez/stGRdzC9HB201ndGTCpRsI0vvbsFGpjDaZbTuViW/jL4l2aje378ua/akYE9LSrH1PZZSH2g93nNP007u4pHxtP/Ws6P6NXbDzdDbe6PMwApoZ/5utbqxhqaPuFpcqpoalMkxNm27NeWZqIql5eCrLVB+h0WsOIXDBDp3RHINX7sO/Pt6LtzceF72DYw1L3aL/K/DMyv0IWrRTtw+LlT6hNiZcNjpny9BPTU+9MPzzePT9cA96LfnLYDHH/ReuIadAN/CIzbRr6q3omtEpLVRINXNaBaB8wU0xVwuK8NJXBxFzUnc0mKn3h2kbj2PbqSw8s3Ifjly8jsJi4+tcVScGlgpyc7JD8EON8GjLBtI7K1B8Sq7Jzq21AT8A5af/YaBuNki6ko+fEh/MEFxYVAIzW7ColtMfzWYtq3YbNrcYk3TlwbIc6k6tWfl3MUQk3OjX8uqv8SS2jzZrNb4YWwrk0cU7se/CNfxnne6ip9r9bow1AZUJwHOfxVfJwrUVwbeIClKpVPhhQg/832vBJvebPqBtNZ2RZerC9NV1vIJF0YpLy/DWhgdNAlHbzjBgEgDgxS8fdAK/ZcVlGSzp52HJCvXm/NqWzy8l/pix7T8cTEPkT4ad2U9ezjNr0j0x2089qGXRrskSayrTlqCQEZcMLJWgUqlMJueI/q3xnydaYcgjPhYf+9MXrb8EQF1jalVfkpfYm7R2YPn7nHRHQ6r99Nc1qk6mhh+rqVTGJ8zUHlZuo1LpjIrSZuxV1uxPNZg5HChvWg1933TfopuFxci7c89gPbWJ3z+oZdEunnolb6Vjp9sqpEJ5oPl4RBf8cuyK9BPui4/sC2/3enjjhyo8uTpAKXcFZEhsGKj2G/poGT+oqHaIMLHkgDlGfHEAK0d2kdxv6fYzotsHfrxX8/8790rx383iUwRUdESOqU7O476VniH6dpEy+qVYgjUsVvD5qCA4iPQOq2iHMW/3epU8IyJlE5s0TOxukqiifrbgJlHMoYvXERz1l8l9rtw0b/LN3XpDkz/ddUFyeQEpC39PrtTz9Sc6VM+MbcykH46afLw6MLBYwYCOXjgxL8xg+6ieLSt13CauHJZLtZPUvBVESiC13pH+Wmdqb0osWfC/P85qOqRbMm1/VfpEYobp309kIuGS+VNOVAUGFisRW/nY3dleZE/z/Tapd6WeT6RUpoajE9V0vx03v3bHks7ActOf9K66MbBYif4ER808Kt+s4+VuuDQ8ERHVDv9crVnBveCuvP1eGFisRH+00MshfjKdifUsD39E7lMgIqq1hn8WL/cpWOTjP88bjDyqTgwsVUS/6fPjEY/Ich6VMbRLM7lPgUiSez3xptc+bZtU85kQWcbUIoVKZe31qizBwFJF9DtrDXmkWYXmYyEi04wtcvn12O7VfCZEtZ+c6yIysFjRoqEBmv+Lja1/rLWy7/iCH2qEqU+2kfs0qt1Creum79tX+KGndAM6ehlsq+/IKaaIqoZ8iYWBxYpe6vmg34rYaLhnuzRD8EONLDrmsuGBqO9ohx7+DSt7ekZFj+yKHyf0xI+v9kRDF4cqex2lGtXTDyfmheGTF3QniQrya4DH2xgPmeHdfKv61EjLG31aiW4Xm2x619tPVO3JEFG1Y2Cxsg7ebgCAQZ29DR6zsVFhTK+WFh1vWNfmODE3DGvHdcfoYD98PfZRa5ymjsfbNkFwq/IgZWpdjB/G97D6ayuFm5O9Tq3Y39P7YNPE8nWiVr/cDZ2auaORXpib+0wHi16DfSoqx1RVdFgHT53v1XMY6Y/eA3RrX74YFaT5f/v7f7vVRWyySSKlY5NQLfLLpF5ImNUfrZrUF308rIMnpvRrjdcef8jsY9rYqOBoZ4sFQwLQp21Ta53qg+ObuehcyMONTdY4KJ1Ux2ftP8QWjZw1I7/6tffEb2/2RvRLQTr7OzuINzuEtBKvRevW0nQt2XvPdjL5eF1n7H1SEMpnmz45Lwxvh7XBr5N6aR6zFfnd1t7Up11TvNDdF9Eju2Lrm72xPSLUYP/XHn8Izg62BtuD/BpgYIBhc5Ta6GDTIwWXS/w+PtTExeTj1lQVN0JUO5mxxFKVYWCxMntbGzSqb3yGWpVKhbeebIN+7TyN7iNl1UjrLYzo4+4EJ3vDN2O1p/Vqiky9QZujexU2bUkJ8mtg8nGx9W2MCWzuDgCY3PdhNPOoh7aerprHfpjQE3Ez+qL3w40xd7BuLYyp+Xm8Oe+OScZXuxWgUqng6mSPSX1bo3NzD81jNiLvcNq1Lva2Noga1hkDO3nDxkYlWuvh5eaEd/RWXV84pCM2vx6C95/rbPR8Fwwx3jcKAP7VybAWVtvTnauvk35V3AgRWRsDi0wqM+3+vzp54/zigVY5j3/rjbDQX3n0Ub1ageHdfPH1mEdxZFZ/xL71GFo3Fa9JEvNkB0+0aOhc8ZOtJHuJKnhL7hzUtSVTw9pi33/7GPT98fGoh+/H98DYXv6abSqVeJPb/Gc6YvfbT8DIoq90n2CkjsXUZROrYTG3RlHbkEd0h/g/c/97S45lbDSTml8jZywc0tHicyOqThVdrNEaGFhk4t+4ctW9Uh++FT0PTzfdIKX/y2ljo0Kfdk3RuL4jWnu6YrgFHU/rO9ohon/rip9sBYV18MTLwX7wdDNdg9GpmbvZx5zU52HN/1UqFcI6lteY6f/8tHm5OekElukD2uKt/m3wckhLtGzsYjKvVGfzgBJ99lJXo8lEv2+RNhuRPiwimzT0J4AEymt2Grg4YMbAdppt6rlfjOUVsdF2HzwfaLS5sPy8VCgWWRRSzOyndWvu/t3VeBjycXfSmVLh6Own0b99xWt4LXFxyaBqeZ3qMudpy/qt1UYytggxsNR2HhLrGQ3Vu3Ps264p3uz7MD7T669hzEs9/dC3nXR1cqdm7pgxsB2aN3CGl0RwqIgJof5GH5sxsB3mS1TPA0BbL1dsfj0Ye9/pI/q4dlNCA70PydHBLfHFqCBsnWzYB+LzUUEY19vf4C79jT4PY4pWgDN1t65/U9PG0/yaLTHDuzWXJTxWlEqlMvpG2VqrOU6fWKdbS8O++nXrmWg61bbyxS6Y3E/8Zyt1c3qvtEzz/5d6tjC637je/ji36EEtq6nfB5VKhV4PNwYAuDnZoaGLA74cHVTlnYztbWtflWHrSv7d1QbsdEtVJnH2k0Yfc7C1MbgDValUmBbWFk/d76si9btZz8EWa8ZId9j77c3emhqOn9/oJbG35WYOss6dT5BfQ/gaabbq4uuB3g83xgvdDT9IbG1UCOvohcYi/ZcGdPTC7Kc7wNZGZdDkps1U64J+/5qmruaFPid78T/xyf1aI6J/G9HOpEokCLq1fd+N644GzvblNS8miDUJ9X64MR5t2QCjehp2im1qoqn2uaDmaONZH6899qDDfD17W3T3b4jOzR/Uzom9plpRifFpzVUoHyrfuL4DRjzqK3mNHeweXFsBuiOetNnYlNfAfDm6G3ZOfbz8tVQqeJmoDVQ7t2ggHqpgbXBlV6tXImOzKtclxppmqwMDi8JI1YiY0ri+YdW4WBX3gwelj1kVadrL3QlrxnSz/oGNqEifBdHj2Kjw/fgeiBpW8dE8pk6lZSPjHwz6b5Qq1YMO0f99qp3R+X20O3ZqNyupO1q39TJeO6EkT7RtovO7GNq6CY7OfhJPBZjuuBr9UhBcHGyxROua2dnaYOPEENEJA10c7fD39D6Im9FXs00dlFwc7bDjrccR+a/2msdUKhU2vNoTP//HvBB+916Z8QdV5TV3B9/tjyX/Nt6ZV0zrpvUR1tFLtAnGRqWCrY0KT3bwRFOt2s0FQwLQzssVHzwfaPS42qEIgGggN0a7Cc1Sn7zQBfMGK6/5pbqHviuRJb8D1sbAIiOxX/7KdUrV/TT83MgdlyWe7dIMro52BqOFKkvqTsUac1Q81qYJnmjbBH6N5Ovoq8/Rzni5fBs644cJ4nPdNKnvqNOxV6VSYXn4I9geEYqJjz+EH1/tiWEiaz8N1hpp4uxgi2lPtsHkfq1lfdOpCCd7WzwdWF6Wlvevp8kwfl93/4Y4MW8ARmjVikk9rUUjZ/hojeaSCnUqlQo2NirNCLAeJiaHVC+Kqp4e4NDMfprHmorMHaPum6I9Cs234YNz+3VSL0QN66TTLKs/Es1YYPdt6IztEY9pOgMP72a6UzAA7J8h3lyq7z9PtDIIO/r+mva40ceeCfTBmF7Gm3nlYq2bn5rM1I1VVeP81TLybVAPp/UWkqrMn4P+35L+lOV+jZxxKbfQotdq4OKAo3OehJ2pnopGLH42ADN/OiX6WOfmHni4aX1cyDGyvLoV3hdWjeyquCnaPx7RBRPWHsG0MPElEEJaNdb5ftqTbbDzdDbmD+mIO8WlePKjvwGU/3jsbG3QzutB6H3UvyG2JGboPN9Rr0noTSN9Kyyx4oUuePPHxEofx1KP+Hrg7+l90NSMpgxtYv1YzLF1cm+cyy5AqJlLaux6+wncLSmFm5NhGHdzKv89HN7NF52aeaBV0/I3/aauTlj7Snd8uTdFdB6eBUM64tGWDdC/gye6LdoJoPzDXK1zcw+dYdwAsC0iFClXb2Pop/sBmL9MwXvPdsLlG3cQ90+u0X0c7aSbEJcND9Q5x5E9WmDdwTQ0cnHQWezvISNzVVWWh7M9bhbeq5JjV/BXqVaR82fAGhaFadbA+Dwd+v7vtWCd7439Hg19xAd+jZyxfcpjOPTugzs6c28W7G1tzLqb1Tfi0RaY/XQHbJ3cW/SYOyIeEx3h0fvhxgbbKkKs05+6GP3aNUVgc3esq+bZe9t7u2Hff/vi2S7G72Zd73/AtG5aH2/2a41fJvVG8wbOOp1Lm4v8ngzv5osBHat+9MfgQB9MH9BWtEZH31ArL/jZopGzyXmDzGHub3JHH3eT10mfg52NaFjReW2VCh183HQ++B9r0wTfjesh2nfKxdEOI7q3sKhGzM3JHo/4emDli13Q1tMVH4Ubb/LRZmdrY5UmwmFdm8NOq4Z00dAA7H2nDxJM9KezpmNzwqrs2BV5H6xtzUhy1jIxsMhIexK1Hyf0xOBAH8x/Rno0i9jz9f04oafm/8tHdMGuaU+gnoOtThu2qQ6gFeXsYIt69raIHNgOtjYqjOvtj44+4sOFbWxUBqHp7bA2+HjEIzpNGVIe8fUQ3W4vMmvYnrf7YMGQjvh0ZFf8Mqm3ZvSEkmx6PQTDujYT7cz83bjueLZLM7wzwLB/gK2NCtEjg6wW+Ex5o8/DBnP4iLEz0bSn3efK2KiaqlCd77ddW3gAKP8QtxZTnXq1Pd3ZB3+89RgeblqxELLyxS6S+/z+puHNiD6VSqUJYx19LPvwNjUxX2UZe98wRurcPZztESMyStC/sXKapK1BzlYxBhYZjQlpiaX/7oQ9059AcKtGWPFCF4snlFNPNDVvcAedX6RgvfketEcDqUdHvK03e6c1BPi449T8AXjtcfGF6qRM6tsajeo7YuHQjkY7Az6l1dTVyMUB39+vJflytG5HXrE5OFo0csbo4JaVvkuvSm29XLFs+COid9yhrZvgo/BH4G6kc7aNjQrLhpt3Rw1U7xBF/blktO9WxeYtUc8VYmpum4qoiqBuzNdjuyN6ZNdKdUBVm9yvNR5q7IJXeldP3w5zZtoNsGDuIsDw902qqXl4N18cntnfotfQJlYTqWZqdt92ejVNX43uht8mlYezHyf0xMt6yy60auKCxNlPooNIqCkxc26dyqrMZKSWqEgtk7UwsMjIztYG4Y+2gF8lOjGNCm6JE/PCMKaXv9lvxPOf6Yg905/AKxYuxGgWlWV9Bh5qLN6O7exgpzMz6KuPPYSFQzrCr5EzZg56MEqjx0MNNW30T3bwxLE51VPtrGRN3Zyw+fUQ7HjrMYue91RH8WUXNr8eYnZoeMTXA+tffVC7pz0cu5ve0gjd788WbKyD9QfPd8bbYW2w+fUQs17bXNX5futezx4DO3lbJSBPfbIN/nr7CXg4V92K6uYEWHXnb1NhwOjx9b7X7uuipt/515IP4g1av3uA+LX2cXfCsuGBeP0J4zdVL+kNebe3ezAFRHCrRgah0UalMvpBXmLGFNoBzSrfbKTuJyXGx0rLfkitx1bVGFhqAXW7ufoDPlCiqtPGRgW/Ri5VkpQtPaLUAnCa46rKw9me6X2MzpMCAB7ODtj7Tp9K3ZXVBkF+DdDG0xWtJZoDtH8FPhsVhL+mPa4z70ZE/9YI8msAO7FFeUSMDvbTGZWl/QHo7a77AbdwaAAm92stuuDg72/2hoezAyb1bY3mDaxbpc5+k5Z5/7nOsLNRYdb9G4X/ey0Yw7o2w3fjKt//SzvQDr4fXipTg9SlhW4oFruJa+LmhGFdm5scxaQ/SaD+UfSPa+qtVDuwtDQyYnHja9YN5fpGagWwYV2boZlHPfz+Zm+885Rltez6k19WNwaWWmRK/9ZY/XI3fDeue7W/tvqPP7S1Zf0nfDzqad6oTLGkGt+3oXO1VY8qnfbPwZwF7h5qUl+nhiyiv/hoJmNsbVQ6Q9a1p4Cf+HgrnQnWPOrZY+qTbURHi7hU4eguOau0a6JuLRvizMKnMD60fMK8h5vWx7Lhj2iW9Zj/zIP1j6Tu5PWX+lAf81+dvPDJiEeQNH+Azsg3S+lfWrFLbWotnOCHGmHEo76aiTPV9Dua3i4u0X0drfcn/XXFSrRmLxZ7ZR93J9SzwgSOpn6vtc9/2fBHsH9GXwQ0c8eonn4I9PXAOJGQ+L8q7D9UUcoa80mVYm9rg37VtEaIvl1vP4H9F64ZTPVvjjIzqkxr4zTf1eXgu/2w7/w1PB1o3lw65n6ei73vq1QqODvY4fc3e8NGpUJ7b1d8+0p3tPNyRT0HW7z/XGc8tXyvRa9jbfoLepI0U52nXw5piaGPNMOGI2kWrzAd0MwdJ+aFwdXRDiqVqtJBVT9YiP2KGcsr3fwa4Ltx3TVl/eWNXhhyf2i4/u+qj95cN33bP7gZeKG7Lz7d9Y/me+0+LGNCWmL+b8m653j/4BNC/bH/Qi6Staa6eOeptjiefhN/JGUDgOmpIEx4vltzfPznOYPPB1cne/zyRi/k5N/F6n2pOo/9u2tzHL98ExsOp+NeNfXDkcLAQlbRzKOeRQshais1EVgm9XkYv524gleMTCIl57oWNYWnm5NZI3rUKtMpVV05o90ZUz1JGqA7YaD+HeGGV3si/IsD98/B+va+0wenMvIM7p6p8tyd7fHqYxXraC81FBwoH1Sw9WQmDl+8Uf569eyRd6d8rhUXB1v87/lA1LO31dQOznm6A6K2ncb/ng/E85/F6xxLf5kLtU16faW0m9b1A4t7PXvEzeiLm4X3cCojD88YGb6/bUoovt6fikMXrwPQ/Vt4Pqg5NiZc1szJpF5epOWMrZp9/vNE+SKrpzLy8OmuC3jnqXaYsPaIaGgx9jcz5BEfNK7viBNzB1h042djo8KioZ1QJgA/HEwz+3lViYGFZGfqrurtAW2rZDQTGdeqqQvOZhfobDO2JpE+qTtkb/d6WPrvTnAV+ZB65P4Q4Kri29DZZP8nMt1cIqcxvfwxppc/Ei7dwJGL13Hl5h18G38JQHmtivYSFEB5P5jRwX6iNUM9/B+MoDw8sz8eXbxTcoZxsblHfDzqwcejnsHIoJdDWmJt/CUMDvRBe283vPuv9rCztcG/uzbXaRJa/GwnTAtrCy8zOsQGNHNH9P0Fabf8JwSnr+Rrwr2asRrLMSEtARgus6DN0gVB5cLAQrL771NtkXrtFkb2MFyMjqrfwiEBcHW0x4juD2rMVr7YFf9Zd9ToDL0z/9UeyZn5eNyMWWHDHxVfhdjB1gZNXB1xp7jUogkUyXqs3cFZX2XzUJBfAwT5NUDK1VuawNLbSL85dVgJ7+aLDUfS8fXYR5Fy9TZe1FqmoYmrI07NH2ByyQzAssnSmro64dicME1tj4ezg2YW43+uPqgZUalgVljR5+Zkjx4PNUKXFh5ITLuJxvUdsOX1XvhybwrOZYvUvJhx7g1cHBDRvzWW7zxv8JiSMiwDC8muqZsTtpi5eBxVvUb1HbFUr8Nde2837Hr7CZ1t2qu2TtBawbiiVCoV4mb0RZkg1Jg7vtpmdIgfMm7eQZ920h205fRQk/rYOfUx/JGUjZckbnSWPtcZ84d0hJO9LfqIVNaas3SB9vpN5jA2tUOLhs5o4GwPF0c7o3PQONjZoLikTHQWcG3fjO2OfeevoV/7pnCyt8WMge3QrEE9PNXRC098sFuzn7lRK6J/G9HAIt5VWB4MLFSjVXSdGFImBhV5OdrZYp7WqB9re7FHC8z9NUkzB09lPNzU1exZfCs6D862KaHIu3PPYEh+Rdnb2uDgu/1hozJe87Hl9RB8uOMsZgxsL/q4mns9ewzSWpTWxdEOE0Um7LSkdkilUlaNij4GFqqR5jzdAV/HpVplBlGqGLF+KESmjOrph87N3Ss1dLk6VcU6QFKrWAc0c8fXY603NYUlQ6bFwor+MG05MbBQjfRKb/9qm6K8NqvM3VRgc3dMCPWX7LBIpGZjozKY3I2s79DMfvgo9jxcHGzxcFPzV8X+9pXueO27I1j67wdNwhMfb4ULObcsHrJeFVSCUruFWyg/Px/u7u7Iy8uDm1vNSO9Echv66X4cS78JALi4ZJC8J0NEsistE6q9qd3cz282GBPVYZz0lYi0KblfIAMLERERKR4DCxERESkeAwsREREpHgMLUR0W0qp8mnIHzn9CRArHYc1EddibfVvD272ezqJsRERKxMBCVIc52dvipZ5cw4mIlI/1wERERKR4DCxERESkeAwsREREpHgMLERERKR4DCxERESkeAwsREREpHgVCiyrVq2Cv78/nJycEBQUhL179xrdd8yYMVCpVAZfHTt21Nlv+fLlaNu2LerVqwdfX1+89dZbuHv3bkVOj4iIiGoZiwPLhg0bEBERgZkzZyIxMRGhoaEYOHAg0tLSRPf/+OOPkZmZqflKT09Hw4YN8fzzz2v2WbduHWbMmIG5c+fi9OnTWL16NTZs2IDIyMiKl4yIiIhqDZUgCIIlT+jRowe6du2K6Ohozbb27dtj6NChiIqKknz+zz//jGHDhiE1NRV+fuUTVk2aNAmnT5/Gn3/+qdlv2rRpOHTokMnaG235+flwd3dHXl4e3NzcLCkSERERycTcz2+LaliKi4uRkJCAsLAwne1hYWGIi4sz6xirV69G//79NWEFAHr37o2EhAQcOnQIAJCSkoKYmBgMGjTIktMjIiKiWsqiqfmvXbuG0tJSeHp66mz39PREVlaW5PMzMzOxbds2/PDDDzrbR4wYgatXr6J3794QBAElJSV4/fXXMWPGDKPHKioqQlFRkeb7/Px8S4pCRERENUiFOt2qVCqd7wVBMNgm5ptvvoGHhweGDh2qs3337t1YvHgxVq1ahaNHj2LLli34/fffsXDhQqPHioqKgru7u+bL19e3IkUhIiKiGsCiGpbGjRvD1tbWoDYlJyfHoNZFnyAIWLNmDUaNGgUHBwedx2bPno1Ro0Zh/PjxAIBOnTrh9u3bePXVVzFz5kzY2BjmqsjISEydOlXzfX5+PkMLERFRLWVRYHFwcEBQUBBiY2Px7LPParbHxsZiyJAhJp+7Z88eXLhwAePGjTN4rLCw0CCU2NraQhAEGOsT7OjoCEdHR8336v3YNERERFRzqD+3JccACRZav369YG9vL6xevVpITk4WIiIiBBcXF+HixYuCIAjCjBkzhFGjRhk876WXXhJ69Oghesy5c+cKrq6uwo8//iikpKQIO3bsEFq1aiUMHz7c7PNKT08XAPCLX/ziF7/4xa8a+JWenm7yc96iGhYACA8PR25uLhYsWIDMzEwEBAQgJiZGM+onMzPTYE6WvLw8bN68GR9//LHoMWfNmgWVSoVZs2YhIyMDTZo0weDBg7F48WKzz8vHxwfp6elwdXU1qz+NudRNTenp6bVyuHRtLh/LVjPV5rIBtbt8LFvNJHfZBEFAQUEBfHx8TO5n8TwsdU1tn9+lNpePZauZanPZgNpdPpatZqopZeNaQkRERKR4DCxERESkeAwsEhwdHTF37lydEUm1SW0uH8tWM9XmsgG1u3wsW81UU8rGPixERESkeKxhISIiIsVjYCEiIiLFY2AhIiIixWNgISIiIsVjYJGwatUq+Pv7w8nJCUFBQdi7d6/cp2TSvHnzoFKpdL68vLw0jwuCgHnz5sHHxwf16tXDE088gaSkJJ1jFBUV4c0330Tjxo3h4uKCZ555BpcvX67uogAA/v77bwwePBg+Pj5QqVT4+eefdR63Vnlu3LiBUaNGaVb/HjVqFG7evClr2caMGWNwLXv27FkjyhYVFYVHH30Urq6uaNq0KYYOHYqzZ8/q7FNTr505Zaup1y46OhqdO3eGm5sb3NzcEBwcjG3btmker6nXzJyy1dRrJiYqKgoqlQoRERGabTX52mkXgoxQr5v05ZdfCsnJycKUKVMEFxcX4dKlS3KfmlFz584VOnbsKGRmZmq+cnJyNI8vWbJEcHV1FTZv3iycPHlSCA8PF7y9vYX8/HzNPhMnThSaNWsmxMbGCkePHhX69OkjBAYGCiUlJdVenpiYGGHmzJnC5s2bBQDCTz/9pPO4tcrz1FNPCQEBAUJcXJwQFxcnBAQECE8//bSsZXv55ZeFp556Suda5ubm6uyj1LINGDBA+Prrr4VTp04Jx44dEwYNGiS0aNFCuHXrlmafmnrtzClbTb12v/76q7B161bh7NmzwtmzZ4V3331XsLe3F06dOiUIQs29ZuaUraZeM32HDh0SWrZsKXTu3FmYMmWKZntNvnZqDCwmdO/eXZg4caLOtnbt2gkzZsyQ6YykzZ07VwgMDBR9rKysTPDy8hKWLFmi2Xb37l3B3d1d+OyzzwRBEISbN28K9vb2wvr16zX7ZGRkCDY2NsL27dur9Nyl6H+oW6s8ycnJAgDhwIEDmn3i4+MFAMKZM2equFTljAWWIUOGGH1OTSmbIAhCTk6OAEDYs2ePIAi169rpl00Qate1a9CggfDVV1/Vqmumpi6bINSOa1ZQUCC0bt1aiI2NFR5//HFNYKkt145NQkYUFxcjISEBYWFhOtvDwsIQFxcn01mZ5/z58/Dx8YG/vz9GjBiBlJQUAEBqaiqysrJ0yuTo6IjHH39cU6aEhATcu3dPZx8fHx8EBAQortzWKk98fDzc3d3Ro0cPzT49e/aEu7u77GXevXs3mjZtijZt2mDChAnIycnRPFaTypaXlwcAaNiwIYDade30y6ZW069daWkp1q9fj9u3byM4OLhWXTP9sqnV9Gv2xhtvYNCgQejfv7/O9tpy7SxerbmuuHbtGkpLS+Hp6amz3dPTE1lZWTKdlbQePXpg7dq1aNOmDbKzs7Fo0SKEhIQgKSlJc95iZbp06RIAICsrCw4ODmjQoIHBPkort7XKk5WVhaZNmxocv2nTprKWeeDAgXj++efh5+eH1NRUzJ49G3379kVCQgIcHR1rTNkEQcDUqVPRu3dvBAQEaM5Lfa7aatq1EysbULOv3cmTJxEcHIy7d++ifv36+Omnn9ChQwfNB1JNvmbGygbU7GsGAOvXr8fRo0dx+PBhg8dqy98bA4sElUql870gCAbblGTgwIGa/3fq1AnBwcFo1aoVvv32W00HsoqUScnltkZ5xPaXu8zh4eGa/wcEBKBbt27w8/PD1q1bMWzYMKPPU1rZJk2ahBMnTmDfvn0Gj9X0a2esbDX52rVt2xbHjh3DzZs3sXnzZrz88svYs2eP0XOqSdfMWNk6dOhQo69Zeno6pkyZgh07dsDJycnofjX52gEcJWRU48aNYWtra5Aac3JyDFKqkrm4uKBTp044f/68ZrSQqTJ5eXmhuLgYN27cMLqPUlirPF5eXsjOzjY4/tWrVxVVZm9vb/j5+eH8+fMAakbZ3nzzTfz666/YtWsXmjdvrtleG66dsbKJqUnXzsHBAQ8//DC6deuGqKgoBAYG4uOPP64V18xY2cTUpGuWkJCAnJwcBAUFwc7ODnZ2dtizZw8++eQT2NnZaV67Jl87gIHFKAcHBwQFBSE2NlZne2xsLEJCQmQ6K8sVFRXh9OnT8Pb2hr+/P7y8vHTKVFxcjD179mjKFBQUBHt7e519MjMzcerUKcWV21rlCQ4ORl5eHg4dOqTZ5+DBg8jLy1NUmXNzc5Geng5vb28Ayi6bIAiYNGkStmzZgr/++gv+/v46j9fkaydVNjE16drpEwQBRUVFNfqaGaMum5iadM369euHkydP4tixY5qvbt26YeTIkTh27Bgeeuih2nHtqrxbbw2mHta8evVqITk5WYiIiBBcXFyEixcvyn1qRk2bNk3YvXu3kJKSIhw4cEB4+umnBVdXV805L1myRHB3dxe2bNkinDx5UnjhhRdEh7Y1b95c2Llzp3D06FGhb9++sg1rLigoEBITE4XExEQBgLBs2TIhMTFRM7TcWuV56qmnhM6dOwvx8fFCfHy80KlTpyofqmeqbAUFBcK0adOEuLg4ITU1Vdi1a5cQHBwsNGvWrEaU7fXXXxfc3d2F3bt36wwTLSws1OxTU6+dVNlq8rWLjIwU/v77byE1NVU4ceKE8O677wo2NjbCjh07BEGouddMqmw1+ZoZoz1KSBBq9rVTY2CR8Omnnwp+fn6Cg4OD0LVrV52hi0qkHltvb28v+Pj4CMOGDROSkpI0j5eVlQlz584VvLy8BEdHR+Gxxx4TTp48qXOMO3fuCJMmTRIaNmwo1KtXT3j66aeFtLS06i6KIAiCsGvXLgGAwdfLL78sCIL1ypObmyuMHDlScHV1FVxdXYWRI0cKN27ckK1shYWFQlhYmNCkSRPB3t5eaNGihfDyyy8bnLdSyyZWLgDC119/rdmnpl47qbLV5Gv3yiuvaN7vmjRpIvTr108TVgSh5l4zqbLV5GtmjH5gqcnXTk0lCIJQ9fU4RERERBXHPixERESkeAwsREREpHgMLERERKR4DCxERESkeAwsREREpHgMLERERKR4DCxERESkeAwsREREpHgMLERERKR4DCxERESkeAwsREREpHgMLERERKR4/w9t5IuE0EovTQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(len(Eval)),Eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ffaa9d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVALUATING ON TRAIN DATA : \n",
      "score_train = 0.7226094603538513\n",
      "\n",
      "EVALUATING ON TEST DATA : \n",
      "score_test = 0.8081712126731873\n",
      "\n",
      "EVALUATING ON VAL DATA : \n",
      "score_val = 0.7929782271385193\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fname = \"models/stateATT_6L_fixed.pth\" \n",
    "SCORES = eval_model(fname,train_dataloader,test_dataloader,val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "51ce3b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVALUATING ON TRAIN DATA : \n",
      "score_train = 0.7360283136367798\n",
      "\n",
      "EVALUATING ON TEST DATA : \n",
      "score_test = 0.8089258074760437\n",
      "\n",
      "EVALUATING ON VAL DATA : \n",
      "score_val = 0.7931158542633057\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fname = \"models/stateATT_6L_fixed_best.pth\" \n",
    "SCORES = eval_model(fname,train_dataloader,test_dataloader,val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a955b8ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3030e689",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
